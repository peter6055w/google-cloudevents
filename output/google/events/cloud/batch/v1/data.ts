// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/batch/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration";
import { Timestamp } from "../../../../protobuf/timestamp";

export const protobufPackage = "google.events.cloud.batch.v1";

/** Volume describes a volume and parameters for it to be mounted to a VM. */
export interface Volume {
  /**
   * A Network File System (NFS) volume. For example, a
   * Filestore file share.
   */
  nfs?:
    | NFS
    | undefined;
  /** A Google Cloud Storage (GCS) volume. */
  gcs?:
    | GCS
    | undefined;
  /**
   * Device name of an attached disk volume, which should align with a
   * device_name specified by
   * job.allocation_policy.instances[0].policy.disks[i].device_name or
   * defined by the given instance template in
   * job.allocation_policy.instances[0].instance_template.
   */
  deviceName?:
    | string
    | undefined;
  /** The mount path for the volume, e.g. /mnt/disks/share. */
  mountPath: string;
  /**
   * For Google Cloud Storage (GCS), mount options are the options supported by
   * the gcsfuse tool (https://github.com/GoogleCloudPlatform/gcsfuse).
   * For existing persistent disks, mount options provided by the
   * mount command (https://man7.org/linux/man-pages/man8/mount.8.html) except
   * writing are supported. This is due to restrictions of multi-writer mode
   * (https://cloud.google.com/compute/docs/disks/sharing-disks-between-vms).
   * For other attached disks and Network File System (NFS), mount options are
   * these supported by the mount command
   * (https://man7.org/linux/man-pages/man8/mount.8.html).
   */
  mountOptions: string[];
}

/** Represents an NFS volume. */
export interface NFS {
  /** The IP address of the NFS. */
  server: string;
  /** Remote source path exported from the NFS, e.g., "/share". */
  remotePath: string;
}

/** Represents a Google Cloud Storage volume. */
export interface GCS {
  /**
   * Remote path, either a bucket name or a subdirectory of a bucket, e.g.:
   * bucket_name, bucket_name/subdirectory/
   */
  remotePath: string;
}

/** Compute resource requirements */
export interface ComputeResource {
  /** The milliCPU count. */
  cpuMilli: Long;
  /** Memory in MiB. */
  memoryMib: Long;
  /** Extra boot disk size in MiB for each task. */
  bootDiskMib: Long;
}

/** Status event */
export interface StatusEvent {
  /** Type of the event. */
  type: string;
  /** Description of the event. */
  description: string;
  /** The time this event occurred. */
  eventTime?:
    | Date
    | undefined;
  /** Task Execution */
  taskExecution?:
    | TaskExecution
    | undefined;
  /** Task State */
  taskState: TaskStatus_State;
}

/**
 * This Task Execution field includes detail information for
 * task execution procedures, based on StatusEvent types.
 */
export interface TaskExecution {
  /**
   * When task is completed as the status of FAILED or SUCCEEDED,
   * exit code is for one task execution result, default is 0 as success.
   */
  exitCode: number;
}

/** Status of a task */
export interface TaskStatus {
}

/** Task states. */
export enum TaskStatus_State {
  /** STATE_UNSPECIFIED - Unknown state. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The Task is created and waiting for resources. */
  PENDING = 1,
  /** ASSIGNED - The Task is assigned to at least one VM. */
  ASSIGNED = 2,
  /** RUNNING - The Task is running. */
  RUNNING = 3,
  /** FAILED - The Task has failed. */
  FAILED = 4,
  /** SUCCEEDED - The Task has succeeded. */
  SUCCEEDED = 5,
  /** UNEXECUTED - The Task has not been executed when the Job finishes. */
  UNEXECUTED = 6,
  UNRECOGNIZED = -1,
}

export function taskStatus_StateFromJSON(object: any): TaskStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return TaskStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return TaskStatus_State.PENDING;
    case 2:
    case "ASSIGNED":
      return TaskStatus_State.ASSIGNED;
    case 3:
    case "RUNNING":
      return TaskStatus_State.RUNNING;
    case 4:
    case "FAILED":
      return TaskStatus_State.FAILED;
    case 5:
    case "SUCCEEDED":
      return TaskStatus_State.SUCCEEDED;
    case 6:
    case "UNEXECUTED":
      return TaskStatus_State.UNEXECUTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TaskStatus_State.UNRECOGNIZED;
  }
}

export function taskStatus_StateToJSON(object: TaskStatus_State): string {
  switch (object) {
    case TaskStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case TaskStatus_State.PENDING:
      return "PENDING";
    case TaskStatus_State.ASSIGNED:
      return "ASSIGNED";
    case TaskStatus_State.RUNNING:
      return "RUNNING";
    case TaskStatus_State.FAILED:
      return "FAILED";
    case TaskStatus_State.SUCCEEDED:
      return "SUCCEEDED";
    case TaskStatus_State.UNEXECUTED:
      return "UNEXECUTED";
    case TaskStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Runnable describes instructions for executing a specific script or container
 * as part of a Task.
 */
export interface Runnable {
  /** Container runnable. */
  container?:
    | Runnable_Container
    | undefined;
  /** Script runnable. */
  script?:
    | Runnable_Script
    | undefined;
  /** Barrier runnable. */
  barrier?:
    | Runnable_Barrier
    | undefined;
  /**
   * Normally, a non-zero exit status causes the Task to fail. This flag allows
   * execution of other Runnables to continue instead.
   */
  ignoreExitStatus: boolean;
  /**
   * This flag allows a Runnable to continue running in the background while the
   * Task executes subsequent Runnables. This is useful to provide services to
   * other Runnables (or to provide debugging support tools like SSH servers).
   */
  background: boolean;
  /**
   * By default, after a Runnable fails, no further Runnable are executed. This
   * flag indicates that this Runnable must be run even if the Task has already
   * failed. This is useful for Runnables that copy output files off of the VM
   * or for debugging.
   *
   * The always_run flag does not override the Task's overall max_run_duration.
   * If the max_run_duration has expired then no further Runnables will execute,
   * not even always_run Runnables.
   */
  alwaysRun: boolean;
  /**
   * Environment variables for this Runnable (overrides variables set for the
   * whole Task or TaskGroup).
   */
  environment?:
    | Environment
    | undefined;
  /** Timeout for this Runnable. */
  timeout?:
    | Duration
    | undefined;
  /** Labels for this Runnable. */
  labels: { [key: string]: string };
}

/** Container runnable. */
export interface Runnable_Container {
  /** The URI to pull the container image from. */
  imageUri: string;
  /**
   * Overrides the `CMD` specified in the container. If there is an ENTRYPOINT
   * (either in the container image or with the entrypoint field below) then
   * commands are appended as arguments to the ENTRYPOINT.
   */
  commands: string[];
  /** Overrides the `ENTRYPOINT` specified in the container. */
  entrypoint: string;
  /**
   * Volumes to mount (bind mount) from the host machine files or directories
   * into the container, formatted to match docker run's --volume option,
   * e.g. /foo:/bar, or /foo:/bar:ro
   */
  volumes: string[];
  /**
   * Arbitrary additional options to include in the "docker run" command when
   * running this container, e.g. "--network host".
   */
  options: string;
  /**
   * If set to true, external network access to and from container will be
   * blocked, containers that are with block_external_network as true can
   * still communicate with each other, network cannot be specified in the
   * `container.options` field.
   */
  blockExternalNetwork: boolean;
  /**
   * Optional username for logging in to a docker registry. If username
   * matches `projects/* /secrets/* /versions/*` then Batch will read the
   * username from the Secret Manager.
   */
  username: string;
  /**
   * Optional password for logging in to a docker registry. If password
   * matches `projects/* /secrets/* /versions/*` then Batch will read the
   * password from the Secret Manager;
   */
  password: string;
}

/** Script runnable. */
export interface Runnable_Script {
  /**
   * Script file path on the host VM.
   *
   * To specify an interpreter, please add a `#!<interpreter>`(also known as
   * [shebang line](https://en.wikipedia.org/wiki/Shebang_(Unix))) as the
   * first line of the file.(For example, to execute the script using bash,
   * `#!/bin/bash` should be the first line of the file. To execute the
   * script using`Python3`, `#!/usr/bin/env python3` should be the first
   * line of the file.) Otherwise, the file will by default be excuted by
   * `/bin/sh`.
   */
  path?:
    | string
    | undefined;
  /**
   * Shell script text.
   *
   * To specify an interpreter, please add a `#!<interpreter>\n` at the
   * beginning of the text.(For example, to execute the script using bash,
   * `#!/bin/bash\n` should be added. To execute the script using`Python3`,
   * `#!/usr/bin/env python3\n` should be added.) Otherwise, the script will
   * by default be excuted by `/bin/sh`.
   */
  text?: string | undefined;
}

/** Barrier runnable blocks until all tasks in a taskgroup reach it. */
export interface Runnable_Barrier {
  /**
   * Barriers are identified by their index in runnable list.
   * Names are not required, but if present should be an identifier.
   */
  name: string;
}

export interface Runnable_LabelsEntry {
  key: string;
  value: string;
}

/** Spec of a task */
export interface TaskSpec {
  /**
   * The sequence of scripts or containers to run for this Task. Each Task using
   * this TaskSpec executes its list of runnables in order. The Task succeeds if
   * all of its runnables either exit with a zero status or any that exit with a
   * non-zero status have the ignore_exit_status flag.
   *
   * Background runnables are killed automatically (if they have not already
   * exited) a short time after all foreground runnables have completed. Even
   * though this is likely to result in a non-zero exit status for the
   * background runnable, these automatic kills are not treated as Task
   * failures.
   */
  runnables: Runnable[];
  /** ComputeResource requirements. */
  computeResource?:
    | ComputeResource
    | undefined;
  /**
   * Maximum duration the task should run.
   * The task will be killed and marked as FAILED if over this limit.
   */
  maxRunDuration?:
    | Duration
    | undefined;
  /**
   * Maximum number of retries on failures.
   * The default, 0, which means never retry.
   * The valid value range is [0, 10].
   */
  maxRetryCount: number;
  /**
   * Lifecycle management schema when any task in a task group is failed.
   * Currently we only support one lifecycle policy.
   * When the lifecycle policy condition is met,
   * the action in the policy will execute.
   * If task execution result does not meet with the defined lifecycle
   * policy, we consider it as the default policy.
   * Default policy means if the exit code is 0, exit task.
   * If task ends with non-zero exit code, retry the task with max_retry_count.
   */
  lifecyclePolicies: LifecyclePolicy[];
  /** Deprecated: please use environment(non-plural) instead. */
  environments: { [key: string]: string };
  /** Volumes to mount before running Tasks using this TaskSpec. */
  volumes: Volume[];
  /** Environment variables to set before running the Task. */
  environment?: Environment | undefined;
}

export interface TaskSpec_EnvironmentsEntry {
  key: string;
  value: string;
}

/**
 * LifecyclePolicy describes how to deal with task failures
 * based on different conditions.
 */
export interface LifecyclePolicy {
  /**
   * Action to execute when ActionCondition is true.
   * When RETRY_TASK is specified, we will retry failed tasks
   * if we notice any exit code match and fail tasks if no match is found.
   * Likewise, when FAIL_TASK is specified, we will fail tasks
   * if we notice any exit code match and retry tasks if no match is found.
   */
  action: LifecyclePolicy_Action;
  /** Conditions that decide why a task failure is dealt with a specific action. */
  actionCondition?: LifecyclePolicy_ActionCondition | undefined;
}

/** Action on task failures based on different conditions. */
export enum LifecyclePolicy_Action {
  /** ACTION_UNSPECIFIED - Action unspecified. */
  ACTION_UNSPECIFIED = 0,
  /** RETRY_TASK - Action that tasks in the group will be scheduled to re-execute. */
  RETRY_TASK = 1,
  /** FAIL_TASK - Action that tasks in the group will be stopped immediately. */
  FAIL_TASK = 2,
  UNRECOGNIZED = -1,
}

export function lifecyclePolicy_ActionFromJSON(object: any): LifecyclePolicy_Action {
  switch (object) {
    case 0:
    case "ACTION_UNSPECIFIED":
      return LifecyclePolicy_Action.ACTION_UNSPECIFIED;
    case 1:
    case "RETRY_TASK":
      return LifecyclePolicy_Action.RETRY_TASK;
    case 2:
    case "FAIL_TASK":
      return LifecyclePolicy_Action.FAIL_TASK;
    case -1:
    case "UNRECOGNIZED":
    default:
      return LifecyclePolicy_Action.UNRECOGNIZED;
  }
}

export function lifecyclePolicy_ActionToJSON(object: LifecyclePolicy_Action): string {
  switch (object) {
    case LifecyclePolicy_Action.ACTION_UNSPECIFIED:
      return "ACTION_UNSPECIFIED";
    case LifecyclePolicy_Action.RETRY_TASK:
      return "RETRY_TASK";
    case LifecyclePolicy_Action.FAIL_TASK:
      return "FAIL_TASK";
    case LifecyclePolicy_Action.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Conditions for actions to deal with task failures. */
export interface LifecyclePolicy_ActionCondition {
  /**
   * Exit codes of a task execution.
   * If there are more than 1 exit codes,
   * when task executes with any of the exit code in the list,
   * the condition is met and the action will be executed.
   */
  exitCodes: number[];
}

/**
 * An Environment describes a collection of environment variables to set when
 * executing Tasks.
 */
export interface Environment {
  /** A map of environment variable names to values. */
  variables: { [key: string]: string };
  /**
   * A map of environment variable names to Secret Manager secret names.
   * The VM will access the named secrets to set the value of each environment
   * variable.
   */
  secretVariables: { [key: string]: string };
  /**
   * An encrypted JSON dictionary where the key/value pairs correspond to
   * environment variable names and their values.
   */
  encryptedVariables?: Environment_KMSEnvMap | undefined;
}

export interface Environment_KMSEnvMap {
  /** The name of the KMS key that will be used to decrypt the cipher text. */
  keyName: string;
  /** The value of the cipherText response from the `encrypt` method. */
  cipherText: string;
}

export interface Environment_VariablesEntry {
  key: string;
  value: string;
}

export interface Environment_SecretVariablesEntry {
  key: string;
  value: string;
}

/** The Cloud Batch Job description. */
export interface Job {
  /**
   * Output only. Job name.
   * For example: "projects/123456/locations/us-central1/jobs/job01".
   */
  name: string;
  /** Output only. A system generated unique ID (in UUID4 format) for the Job. */
  uid: string;
  /**
   * Priority of the Job.
   * The valid value range is [0, 100). Default value is 0.
   * Higher value indicates higher priority.
   * A job with higher priority value is more likely to run earlier if all other
   * requirements are satisfied.
   */
  priority: Long;
  /** Required. TaskGroups in the Job. Only one TaskGroup is supported now. */
  taskGroups: TaskGroup[];
  /** Compute resource allocation for all TaskGroups in the Job. */
  allocationPolicy?:
    | AllocationPolicy
    | undefined;
  /**
   * Labels for the Job. Labels could be user provided or system generated.
   * For example,
   * "labels": {
   *    "department": "finance",
   *    "environment": "test"
   *  }
   * You can assign up to 64 labels.  [Google Compute Engine label
   * restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
   * apply.
   * Label names that start with "goog-" or "google-" are reserved.
   */
  labels: { [key: string]: string };
  /** Output only. Job status. It is read only for users. */
  status?:
    | JobStatus
    | undefined;
  /** Output only. When the Job was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The last time the Job was updated. */
  updateTime?:
    | Date
    | undefined;
  /** Log preservation policy for the Job. */
  logsPolicy?:
    | LogsPolicy
    | undefined;
  /** Notification configurations. */
  notifications: JobNotification[];
}

export interface Job_LabelsEntry {
  key: string;
  value: string;
}

/**
 * LogsPolicy describes how outputs from a Job's Tasks (stdout/stderr) will be
 * preserved.
 */
export interface LogsPolicy {
  /** Where logs should be saved. */
  destination: LogsPolicy_Destination;
  /**
   * The path to which logs are saved when the destination = PATH. This can be a
   * local file path on the VM, or under the mount point of a Persistent Disk or
   * Filestore, or a Cloud Storage path.
   */
  logsPath: string;
}

/** The destination (if any) for logs. */
export enum LogsPolicy_Destination {
  /** DESTINATION_UNSPECIFIED - Logs are not preserved. */
  DESTINATION_UNSPECIFIED = 0,
  /** CLOUD_LOGGING - Logs are streamed to Cloud Logging. */
  CLOUD_LOGGING = 1,
  /** PATH - Logs are saved to a file path. */
  PATH = 2,
  UNRECOGNIZED = -1,
}

export function logsPolicy_DestinationFromJSON(object: any): LogsPolicy_Destination {
  switch (object) {
    case 0:
    case "DESTINATION_UNSPECIFIED":
      return LogsPolicy_Destination.DESTINATION_UNSPECIFIED;
    case 1:
    case "CLOUD_LOGGING":
      return LogsPolicy_Destination.CLOUD_LOGGING;
    case 2:
    case "PATH":
      return LogsPolicy_Destination.PATH;
    case -1:
    case "UNRECOGNIZED":
    default:
      return LogsPolicy_Destination.UNRECOGNIZED;
  }
}

export function logsPolicy_DestinationToJSON(object: LogsPolicy_Destination): string {
  switch (object) {
    case LogsPolicy_Destination.DESTINATION_UNSPECIFIED:
      return "DESTINATION_UNSPECIFIED";
    case LogsPolicy_Destination.CLOUD_LOGGING:
      return "CLOUD_LOGGING";
    case LogsPolicy_Destination.PATH:
      return "PATH";
    case LogsPolicy_Destination.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Job status. */
export interface JobStatus {
  /** Job state */
  state: JobStatus_State;
  /** Job status events */
  statusEvents: StatusEvent[];
  /**
   * Aggregated task status for each TaskGroup in the Job.
   * The map key is TaskGroup ID.
   */
  taskGroups: { [key: string]: JobStatus_TaskGroupStatus };
  /** The duration of time that the Job spent in status RUNNING. */
  runDuration?: Duration | undefined;
}

/** Valid Job states. */
export enum JobStatus_State {
  /** STATE_UNSPECIFIED - Job state unspecified. */
  STATE_UNSPECIFIED = 0,
  /** QUEUED - Job is admitted (validated and persisted) and waiting for resources. */
  QUEUED = 1,
  /**
   * SCHEDULED - Job is scheduled to run as soon as resource allocation is ready.
   * The resource allocation may happen at a later time but with a high
   * chance to succeed.
   */
  SCHEDULED = 2,
  /**
   * RUNNING - Resource allocation has been successful. At least one Task in the Job is
   * RUNNING.
   */
  RUNNING = 3,
  /** SUCCEEDED - All Tasks in the Job have finished successfully. */
  SUCCEEDED = 4,
  /** FAILED - At least one Task in the Job has failed. */
  FAILED = 5,
  /**
   * DELETION_IN_PROGRESS - The Job will be deleted, but has not been deleted yet. Typically this is
   * because resources used by the Job are still being cleaned up.
   */
  DELETION_IN_PROGRESS = 6,
  UNRECOGNIZED = -1,
}

export function jobStatus_StateFromJSON(object: any): JobStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return JobStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "QUEUED":
      return JobStatus_State.QUEUED;
    case 2:
    case "SCHEDULED":
      return JobStatus_State.SCHEDULED;
    case 3:
    case "RUNNING":
      return JobStatus_State.RUNNING;
    case 4:
    case "SUCCEEDED":
      return JobStatus_State.SUCCEEDED;
    case 5:
    case "FAILED":
      return JobStatus_State.FAILED;
    case 6:
    case "DELETION_IN_PROGRESS":
      return JobStatus_State.DELETION_IN_PROGRESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobStatus_State.UNRECOGNIZED;
  }
}

export function jobStatus_StateToJSON(object: JobStatus_State): string {
  switch (object) {
    case JobStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case JobStatus_State.QUEUED:
      return "QUEUED";
    case JobStatus_State.SCHEDULED:
      return "SCHEDULED";
    case JobStatus_State.RUNNING:
      return "RUNNING";
    case JobStatus_State.SUCCEEDED:
      return "SUCCEEDED";
    case JobStatus_State.FAILED:
      return "FAILED";
    case JobStatus_State.DELETION_IN_PROGRESS:
      return "DELETION_IN_PROGRESS";
    case JobStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** VM instance status. */
export interface JobStatus_InstanceStatus {
  /** The Compute Engine machine type. */
  machineType: string;
  /** The VM instance provisioning model. */
  provisioningModel: AllocationPolicy_ProvisioningModel;
  /** The max number of tasks can be assigned to this instance type. */
  taskPack: Long;
  /** The VM boot disk. */
  bootDisk?: AllocationPolicy_Disk | undefined;
}

/** Aggregated task status for a TaskGroup. */
export interface JobStatus_TaskGroupStatus {
  /**
   * Count of task in each state in the TaskGroup.
   * The map key is task state name.
   */
  counts: { [key: string]: Long };
  /** Status of instances allocated for the TaskGroup. */
  instances: JobStatus_InstanceStatus[];
}

export interface JobStatus_TaskGroupStatus_CountsEntry {
  key: string;
  value: Long;
}

export interface JobStatus_TaskGroupsEntry {
  key: string;
  value?: JobStatus_TaskGroupStatus | undefined;
}

/** Notification configurations. */
export interface JobNotification {
  /**
   * The Pub/Sub topic where notifications like the job state changes
   * will be published. This topic exist in the same project as the job
   * and billings will be charged to this project.
   * If not specified, no Pub/Sub messages will be sent.
   * Topic format: `projects/{project}/topics/{topic}`.
   */
  pubsubTopic: string;
  /**
   * The attribute requirements of messages to be sent to this Pub/Sub topic.
   * Without this field, no message will be sent.
   */
  message?: JobNotification_Message | undefined;
}

/** The message type. */
export enum JobNotification_Type {
  /** TYPE_UNSPECIFIED - Unspecified. */
  TYPE_UNSPECIFIED = 0,
  /** JOB_STATE_CHANGED - Notify users that the job state has changed. */
  JOB_STATE_CHANGED = 1,
  /** TASK_STATE_CHANGED - Notify users that the task state has changed. */
  TASK_STATE_CHANGED = 2,
  UNRECOGNIZED = -1,
}

export function jobNotification_TypeFromJSON(object: any): JobNotification_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return JobNotification_Type.TYPE_UNSPECIFIED;
    case 1:
    case "JOB_STATE_CHANGED":
      return JobNotification_Type.JOB_STATE_CHANGED;
    case 2:
    case "TASK_STATE_CHANGED":
      return JobNotification_Type.TASK_STATE_CHANGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return JobNotification_Type.UNRECOGNIZED;
  }
}

export function jobNotification_TypeToJSON(object: JobNotification_Type): string {
  switch (object) {
    case JobNotification_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case JobNotification_Type.JOB_STATE_CHANGED:
      return "JOB_STATE_CHANGED";
    case JobNotification_Type.TASK_STATE_CHANGED:
      return "TASK_STATE_CHANGED";
    case JobNotification_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Message details.
 * Describe the attribute that a message should have.
 * Without specified message attributes, no message will be sent by default.
 */
export interface JobNotification_Message {
  /** The message type. */
  type: JobNotification_Type;
  /** The new job state. */
  newJobState: JobStatus_State;
  /** The new task state. */
  newTaskState: TaskStatus_State;
}

/**
 * A Job's resource allocation policy describes when, where, and how compute
 * resources should be allocated for the Job.
 */
export interface AllocationPolicy {
  /** Location where compute resources should be allocated for the Job. */
  location?:
    | AllocationPolicy_LocationPolicy
    | undefined;
  /**
   * Describe instances that can be created by this AllocationPolicy.
   * Only instances[0] is supported now.
   */
  instances: AllocationPolicy_InstancePolicyOrTemplate[];
  /** Service account that VMs will run as. */
  serviceAccount?:
    | ServiceAccount
    | undefined;
  /**
   * Labels applied to all VM instances and other resources
   * created by AllocationPolicy.
   * Labels could be user provided or system generated.
   * You can assign up to 64 labels. [Google Compute Engine label
   * restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions)
   * apply.
   * Label names that start with "goog-" or "google-" are reserved.
   */
  labels: { [key: string]: string };
  /** The network policy. */
  network?:
    | AllocationPolicy_NetworkPolicy
    | undefined;
  /** The placement policy. */
  placement?: AllocationPolicy_PlacementPolicy | undefined;
}

/** Compute Engine VM instance provisioning model. */
export enum AllocationPolicy_ProvisioningModel {
  /** PROVISIONING_MODEL_UNSPECIFIED - Unspecified. */
  PROVISIONING_MODEL_UNSPECIFIED = 0,
  /** STANDARD - Standard VM. */
  STANDARD = 1,
  /** SPOT - SPOT VM. */
  SPOT = 2,
  /**
   * PREEMPTIBLE - Preemptible VM (PVM).
   *
   * Above SPOT VM is the preferable model for preemptible VM instances: the
   * old preemptible VM model (indicated by this field) is the older model,
   * and has been migrated to use the SPOT model as the underlying technology.
   * This old model will still be supported.
   */
  PREEMPTIBLE = 3,
  UNRECOGNIZED = -1,
}

export function allocationPolicy_ProvisioningModelFromJSON(object: any): AllocationPolicy_ProvisioningModel {
  switch (object) {
    case 0:
    case "PROVISIONING_MODEL_UNSPECIFIED":
      return AllocationPolicy_ProvisioningModel.PROVISIONING_MODEL_UNSPECIFIED;
    case 1:
    case "STANDARD":
      return AllocationPolicy_ProvisioningModel.STANDARD;
    case 2:
    case "SPOT":
      return AllocationPolicy_ProvisioningModel.SPOT;
    case 3:
    case "PREEMPTIBLE":
      return AllocationPolicy_ProvisioningModel.PREEMPTIBLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AllocationPolicy_ProvisioningModel.UNRECOGNIZED;
  }
}

export function allocationPolicy_ProvisioningModelToJSON(object: AllocationPolicy_ProvisioningModel): string {
  switch (object) {
    case AllocationPolicy_ProvisioningModel.PROVISIONING_MODEL_UNSPECIFIED:
      return "PROVISIONING_MODEL_UNSPECIFIED";
    case AllocationPolicy_ProvisioningModel.STANDARD:
      return "STANDARD";
    case AllocationPolicy_ProvisioningModel.SPOT:
      return "SPOT";
    case AllocationPolicy_ProvisioningModel.PREEMPTIBLE:
      return "PREEMPTIBLE";
    case AllocationPolicy_ProvisioningModel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface AllocationPolicy_LocationPolicy {
  /**
   * A list of allowed location names represented by internal URLs.
   *
   * Each location can be a region or a zone.
   * Only one region or multiple zones in one region is supported now.
   * For example,
   * ["regions/us-central1"] allow VMs in any zones in region us-central1.
   * ["zones/us-central1-a", "zones/us-central1-c"] only allow VMs
   * in zones us-central1-a and us-central1-c.
   *
   * All locations end up in different regions would cause errors.
   * For example,
   * ["regions/us-central1", "zones/us-central1-a", "zones/us-central1-b",
   * "zones/us-west1-a"] contains 2 regions "us-central1" and
   * "us-west1". An error is expected in this case.
   */
  allowedLocations: string[];
}

/**
 * A new persistent disk or a local ssd.
 * A VM can only have one local SSD setting but multiple local SSD partitions.
 * See https://cloud.google.com/compute/docs/disks#pdspecs and
 * https://cloud.google.com/compute/docs/disks#localssds.
 */
export interface AllocationPolicy_Disk {
  /**
   * Name of a public or custom image used as the data source.
   * For example, the following are all valid URLs:
   *
   * * Specify the image by its family name:
   * projects/{project}/global/images/family/{image_family}
   * * Specify the image version:
   * projects/{project}/global/images/{image_version}
   *
   * You can also use Batch customized image in short names.
   * The following image values are supported for a boot disk:
   *
   * * "batch-debian": use Batch Debian images.
   * * "batch-centos": use Batch CentOS images.
   * * "batch-cos": use Batch Container-Optimized images.
   * * "batch-hpc-centos": use Batch HPC CentOS images.
   */
  image?:
    | string
    | undefined;
  /**
   * Name of a snapshot used as the data source.
   * Snapshot is not supported as boot disk now.
   */
  snapshot?:
    | string
    | undefined;
  /**
   * Disk type as shown in `gcloud compute disk-types list`.
   * For example, local SSD uses type "local-ssd".
   * Persistent disks and boot disks use "pd-balanced", "pd-extreme", "pd-ssd"
   * or "pd-standard".
   */
  type: string;
  /**
   * Disk size in GB.
   *
   * For persistent disk, this field is ignored if `data_source` is `image` or
   * `snapshot`.
   * For local SSD, size_gb should be a multiple of 375GB,
   * otherwise, the final size will be the next greater multiple of 375 GB.
   * For boot disk, Batch will calculate the boot disk size based on source
   * image and task requirements if you do not speicify the size.
   * If both this field and the boot_disk_mib field in task spec's
   * compute_resource are defined, Batch will only honor this field.
   */
  sizeGb: Long;
  /**
   * Local SSDs are available through both "SCSI" and "NVMe" interfaces.
   * If not indicated, "NVMe" will be the default one for local ssds.
   * We only support "SCSI" for persistent disks now.
   */
  diskInterface: string;
}

/**
 * A new or an existing persistent disk (PD) or a local ssd attached to a VM
 * instance.
 */
export interface AllocationPolicy_AttachedDisk {
  newDisk?:
    | AllocationPolicy_Disk
    | undefined;
  /** Name of an existing PD. */
  existingDisk?:
    | string
    | undefined;
  /**
   * Device name that the guest operating system will see.
   * It is used by Runnable.volumes field to mount disks. So please specify
   * the device_name if you want Batch to help mount the disk, and it should
   * match the device_name field in volumes.
   */
  deviceName: string;
}

/** Accelerator describes Compute Engine accelerators to be attached to the VM. */
export interface AllocationPolicy_Accelerator {
  /**
   * The accelerator type. For example, "nvidia-tesla-t4".
   * See `gcloud compute accelerator-types list`.
   */
  type: string;
  /** The number of accelerators of this type. */
  count: Long;
  /** Deprecated: please use instances[0].install_gpu_drivers instead. */
  installGpuDrivers: boolean;
}

/**
 * InstancePolicy describes an instance type and resources attached to each VM
 * created by this InstancePolicy.
 */
export interface AllocationPolicy_InstancePolicy {
  /** The Compute Engine machine type. */
  machineType: string;
  /**
   * The minimum CPU platform.
   * See
   * https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform.
   */
  minCpuPlatform: string;
  /** The provisioning model. */
  provisioningModel: AllocationPolicy_ProvisioningModel;
  /** The accelerators attached to each VM instance. */
  accelerators: AllocationPolicy_Accelerator[];
  /**
   * Boot disk to be created and attached to each VM by this InstancePolicy.
   * Boot disk will be deleted when the VM is deleted.
   * Batch API now only supports booting from image.
   */
  bootDisk?:
    | AllocationPolicy_Disk
    | undefined;
  /**
   * Non-boot disks to be attached for each VM created by this InstancePolicy.
   * New disks will be deleted when the VM is deleted.
   */
  disks: AllocationPolicy_AttachedDisk[];
}

/** Either an InstancePolicy or an instance template. */
export interface AllocationPolicy_InstancePolicyOrTemplate {
  /** InstancePolicy. */
  policy?:
    | AllocationPolicy_InstancePolicy
    | undefined;
  /**
   * Name of an instance template used to create VMs.
   * Named the field as 'instance_template' instead of 'template' to avoid
   * c++ keyword conflict.
   */
  instanceTemplate?:
    | string
    | undefined;
  /**
   * Set this field true if users want Batch to help fetch drivers from a
   * third party location and install them for GPUs specified in
   * policy.accelerators or instance_template on their behalf. Default is
   * false.
   */
  installGpuDrivers: boolean;
}

/** A network interface. */
export interface AllocationPolicy_NetworkInterface {
  /**
   * The URL of an existing network resource.
   * You can specify the network as a full or partial URL.
   *
   * For example, the following are all valid URLs:
   *
   * * https://www.googleapis.com/compute/v1/projects/{project}/global/networks/{network}
   * * projects/{project}/global/networks/{network}
   * * global/networks/{network}
   */
  network: string;
  /**
   * The URL of an existing subnetwork resource in the network.
   * You can specify the subnetwork as a full or partial URL.
   *
   * For example, the following are all valid URLs:
   *
   * * https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/subnetworks/{subnetwork}
   * * projects/{project}/regions/{region}/subnetworks/{subnetwork}
   * * regions/{region}/subnetworks/{subnetwork}
   */
  subnetwork: string;
  /**
   * Default is false (with an external IP address). Required if
   * no external public IP address is attached to the VM. If no external
   * public IP address, additional configuration is required to allow the VM
   * to access Google Services. See
   * https://cloud.google.com/vpc/docs/configure-private-google-access and
   * https://cloud.google.com/nat/docs/gce-example#create-nat for more
   * information.
   */
  noExternalIpAddress: boolean;
}

/** NetworkPolicy describes VM instance network configurations. */
export interface AllocationPolicy_NetworkPolicy {
  /** Network configurations. */
  networkInterfaces: AllocationPolicy_NetworkInterface[];
}

/**
 * PlacementPolicy describes a group placement policy for the VMs controlled
 * by this AllocationPolicy.
 */
export interface AllocationPolicy_PlacementPolicy {
  /**
   * UNSPECIFIED vs. COLLOCATED (default UNSPECIFIED). Use COLLOCATED when you
   * want VMs to be located close to each other for low network latency
   * between the VMs. No placement policy will be generated when collocation
   * is UNSPECIFIED.
   */
  collocation: string;
  /**
   * When specified, causes the job to fail if more than max_distance logical
   * switches are required between VMs. Batch uses the most compact possible
   * placement of VMs even when max_distance is not specified. An explicit
   * max_distance makes that level of compactness a strict requirement.
   * Not yet implemented
   */
  maxDistance: Long;
}

export interface AllocationPolicy_LabelsEntry {
  key: string;
  value: string;
}

/** A TaskGroup defines one or more Tasks that all share the same TaskSpec. */
export interface TaskGroup {
  /**
   * Output only. TaskGroup name.
   * The system generates this field based on parent Job name.
   * For example:
   * "projects/123456/locations/us-west1/jobs/job01/taskGroups/group01".
   */
  name: string;
  /** Required. Tasks in the group share the same task spec. */
  taskSpec?:
    | TaskSpec
    | undefined;
  /**
   * Number of Tasks in the TaskGroup.
   * Default is 1.
   */
  taskCount: Long;
  /**
   * Max number of tasks that can run in parallel.
   * Default to min(task_count, 1000).
   * Field parallelism must be 1 if the scheduling_policy is IN_ORDER.
   */
  parallelism: Long;
  /**
   * Scheduling policy for Tasks in the TaskGroup.
   * The default value is AS_SOON_AS_POSSIBLE.
   */
  schedulingPolicy: TaskGroup_SchedulingPolicy;
  /**
   * An array of environment variable mappings, which are passed to Tasks with
   * matching indices. If task_environments is used then task_count should
   * not be specified in the request (and will be ignored). Task count will be
   * the length of task_environments.
   *
   * Tasks get a BATCH_TASK_INDEX and BATCH_TASK_COUNT environment variable, in
   * addition to any environment variables set in task_environments, specifying
   * the number of Tasks in the Task's parent TaskGroup, and the specific Task's
   * index in the TaskGroup (0 through BATCH_TASK_COUNT - 1).
   */
  taskEnvironments: Environment[];
  /**
   * Max number of tasks that can be run on a VM at the same time.
   * If not specified, the system will decide a value based on available
   * compute resources on a VM and task requirements.
   */
  taskCountPerNode: Long;
  /**
   * When true, Batch will populate a file with a list of all VMs assigned to
   * the TaskGroup and set the BATCH_HOSTS_FILE environment variable to the path
   * of that file. Defaults to false.
   */
  requireHostsFile: boolean;
  /**
   * When true, Batch will configure SSH to allow passwordless login between
   * VMs running the Batch tasks in the same TaskGroup.
   */
  permissiveSsh: boolean;
}

/** How Tasks in the TaskGroup should be scheduled relative to each other. */
export enum TaskGroup_SchedulingPolicy {
  /** SCHEDULING_POLICY_UNSPECIFIED - Unspecified. */
  SCHEDULING_POLICY_UNSPECIFIED = 0,
  /**
   * AS_SOON_AS_POSSIBLE - Run Tasks as soon as resources are available.
   *
   * Tasks might be executed in parallel depending on parallelism and
   * task_count values.
   */
  AS_SOON_AS_POSSIBLE = 1,
  /** IN_ORDER - Run Tasks sequentially with increased task index. */
  IN_ORDER = 2,
  UNRECOGNIZED = -1,
}

export function taskGroup_SchedulingPolicyFromJSON(object: any): TaskGroup_SchedulingPolicy {
  switch (object) {
    case 0:
    case "SCHEDULING_POLICY_UNSPECIFIED":
      return TaskGroup_SchedulingPolicy.SCHEDULING_POLICY_UNSPECIFIED;
    case 1:
    case "AS_SOON_AS_POSSIBLE":
      return TaskGroup_SchedulingPolicy.AS_SOON_AS_POSSIBLE;
    case 2:
    case "IN_ORDER":
      return TaskGroup_SchedulingPolicy.IN_ORDER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TaskGroup_SchedulingPolicy.UNRECOGNIZED;
  }
}

export function taskGroup_SchedulingPolicyToJSON(object: TaskGroup_SchedulingPolicy): string {
  switch (object) {
    case TaskGroup_SchedulingPolicy.SCHEDULING_POLICY_UNSPECIFIED:
      return "SCHEDULING_POLICY_UNSPECIFIED";
    case TaskGroup_SchedulingPolicy.AS_SOON_AS_POSSIBLE:
      return "AS_SOON_AS_POSSIBLE";
    case TaskGroup_SchedulingPolicy.IN_ORDER:
      return "IN_ORDER";
    case TaskGroup_SchedulingPolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Carries information about a Google Cloud service account. */
export interface ServiceAccount {
  /**
   * Email address of the service account. If not specified, the default
   * Compute Engine service account for the project will be used. If instance
   * template is being used, the service account has to be specified in the
   * instance template and it has to match the email field here.
   */
  email: string;
  /**
   * List of scopes to be enabled for this service account on the VM, in
   * addition to the cloud-platform API scope that will be added by default.
   */
  scopes: string[];
}

/** The data within all Job events. */
export interface JobEventData {
  /** Optional. The Job event payload. Unset for deletion events. */
  payload?: Job | undefined;
}

function createBaseVolume(): Volume {
  return { nfs: undefined, gcs: undefined, deviceName: undefined, mountPath: "", mountOptions: [] };
}

export const Volume: MessageFns<Volume> = {
  encode(message: Volume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.nfs !== undefined) {
      NFS.encode(message.nfs, writer.uint32(10).fork()).join();
    }
    if (message.gcs !== undefined) {
      GCS.encode(message.gcs, writer.uint32(26).fork()).join();
    }
    if (message.deviceName !== undefined) {
      writer.uint32(50).string(message.deviceName);
    }
    if (message.mountPath !== "") {
      writer.uint32(34).string(message.mountPath);
    }
    for (const v of message.mountOptions) {
      writer.uint32(42).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Volume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.nfs = NFS.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.gcs = GCS.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.deviceName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.mountPath = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.mountOptions.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Volume {
    return {
      nfs: isSet(object.nfs) ? NFS.fromJSON(object.nfs) : undefined,
      gcs: isSet(object.gcs) ? GCS.fromJSON(object.gcs) : undefined,
      deviceName: isSet(object.deviceName) ? globalThis.String(object.deviceName) : undefined,
      mountPath: isSet(object.mountPath) ? globalThis.String(object.mountPath) : "",
      mountOptions: globalThis.Array.isArray(object?.mountOptions)
        ? object.mountOptions.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Volume): unknown {
    const obj: any = {};
    if (message.nfs !== undefined) {
      obj.nfs = NFS.toJSON(message.nfs);
    }
    if (message.gcs !== undefined) {
      obj.gcs = GCS.toJSON(message.gcs);
    }
    if (message.deviceName !== undefined) {
      obj.deviceName = message.deviceName;
    }
    if (message.mountPath !== "") {
      obj.mountPath = message.mountPath;
    }
    if (message.mountOptions?.length) {
      obj.mountOptions = message.mountOptions;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Volume>, I>>(base?: I): Volume {
    return Volume.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Volume>, I>>(object: I): Volume {
    const message = createBaseVolume();
    message.nfs = (object.nfs !== undefined && object.nfs !== null) ? NFS.fromPartial(object.nfs) : undefined;
    message.gcs = (object.gcs !== undefined && object.gcs !== null) ? GCS.fromPartial(object.gcs) : undefined;
    message.deviceName = object.deviceName ?? undefined;
    message.mountPath = object.mountPath ?? "";
    message.mountOptions = object.mountOptions?.map((e) => e) || [];
    return message;
  },
};

function createBaseNFS(): NFS {
  return { server: "", remotePath: "" };
}

export const NFS: MessageFns<NFS> = {
  encode(message: NFS, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.server !== "") {
      writer.uint32(10).string(message.server);
    }
    if (message.remotePath !== "") {
      writer.uint32(18).string(message.remotePath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NFS {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNFS();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.server = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.remotePath = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NFS {
    return {
      server: isSet(object.server) ? globalThis.String(object.server) : "",
      remotePath: isSet(object.remotePath) ? globalThis.String(object.remotePath) : "",
    };
  },

  toJSON(message: NFS): unknown {
    const obj: any = {};
    if (message.server !== "") {
      obj.server = message.server;
    }
    if (message.remotePath !== "") {
      obj.remotePath = message.remotePath;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NFS>, I>>(base?: I): NFS {
    return NFS.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NFS>, I>>(object: I): NFS {
    const message = createBaseNFS();
    message.server = object.server ?? "";
    message.remotePath = object.remotePath ?? "";
    return message;
  },
};

function createBaseGCS(): GCS {
  return { remotePath: "" };
}

export const GCS: MessageFns<GCS> = {
  encode(message: GCS, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.remotePath !== "") {
      writer.uint32(10).string(message.remotePath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GCS {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGCS();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.remotePath = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GCS {
    return { remotePath: isSet(object.remotePath) ? globalThis.String(object.remotePath) : "" };
  },

  toJSON(message: GCS): unknown {
    const obj: any = {};
    if (message.remotePath !== "") {
      obj.remotePath = message.remotePath;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GCS>, I>>(base?: I): GCS {
    return GCS.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GCS>, I>>(object: I): GCS {
    const message = createBaseGCS();
    message.remotePath = object.remotePath ?? "";
    return message;
  },
};

function createBaseComputeResource(): ComputeResource {
  return { cpuMilli: Long.ZERO, memoryMib: Long.ZERO, bootDiskMib: Long.ZERO };
}

export const ComputeResource: MessageFns<ComputeResource> = {
  encode(message: ComputeResource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.cpuMilli.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.cpuMilli.toString());
    }
    if (!message.memoryMib.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.memoryMib.toString());
    }
    if (!message.bootDiskMib.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.bootDiskMib.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeResource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeResource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.cpuMilli = Long.fromString(reader.int64().toString());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.memoryMib = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.bootDiskMib = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeResource {
    return {
      cpuMilli: isSet(object.cpuMilli) ? Long.fromValue(object.cpuMilli) : Long.ZERO,
      memoryMib: isSet(object.memoryMib) ? Long.fromValue(object.memoryMib) : Long.ZERO,
      bootDiskMib: isSet(object.bootDiskMib) ? Long.fromValue(object.bootDiskMib) : Long.ZERO,
    };
  },

  toJSON(message: ComputeResource): unknown {
    const obj: any = {};
    if (!message.cpuMilli.equals(Long.ZERO)) {
      obj.cpuMilli = (message.cpuMilli || Long.ZERO).toString();
    }
    if (!message.memoryMib.equals(Long.ZERO)) {
      obj.memoryMib = (message.memoryMib || Long.ZERO).toString();
    }
    if (!message.bootDiskMib.equals(Long.ZERO)) {
      obj.bootDiskMib = (message.bootDiskMib || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeResource>, I>>(base?: I): ComputeResource {
    return ComputeResource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeResource>, I>>(object: I): ComputeResource {
    const message = createBaseComputeResource();
    message.cpuMilli = (object.cpuMilli !== undefined && object.cpuMilli !== null)
      ? Long.fromValue(object.cpuMilli)
      : Long.ZERO;
    message.memoryMib = (object.memoryMib !== undefined && object.memoryMib !== null)
      ? Long.fromValue(object.memoryMib)
      : Long.ZERO;
    message.bootDiskMib = (object.bootDiskMib !== undefined && object.bootDiskMib !== null)
      ? Long.fromValue(object.bootDiskMib)
      : Long.ZERO;
    return message;
  },
};

function createBaseStatusEvent(): StatusEvent {
  return { type: "", description: "", eventTime: undefined, taskExecution: undefined, taskState: 0 };
}

export const StatusEvent: MessageFns<StatusEvent> = {
  encode(message: StatusEvent, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(26).string(message.type);
    }
    if (message.description !== "") {
      writer.uint32(10).string(message.description);
    }
    if (message.eventTime !== undefined) {
      Timestamp.encode(toTimestamp(message.eventTime), writer.uint32(18).fork()).join();
    }
    if (message.taskExecution !== undefined) {
      TaskExecution.encode(message.taskExecution, writer.uint32(34).fork()).join();
    }
    if (message.taskState !== 0) {
      writer.uint32(40).int32(message.taskState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StatusEvent {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStatusEvent();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.eventTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.taskExecution = TaskExecution.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.taskState = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StatusEvent {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      eventTime: isSet(object.eventTime) ? fromJsonTimestamp(object.eventTime) : undefined,
      taskExecution: isSet(object.taskExecution) ? TaskExecution.fromJSON(object.taskExecution) : undefined,
      taskState: isSet(object.taskState) ? taskStatus_StateFromJSON(object.taskState) : 0,
    };
  },

  toJSON(message: StatusEvent): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.eventTime !== undefined) {
      obj.eventTime = message.eventTime.toISOString();
    }
    if (message.taskExecution !== undefined) {
      obj.taskExecution = TaskExecution.toJSON(message.taskExecution);
    }
    if (message.taskState !== 0) {
      obj.taskState = taskStatus_StateToJSON(message.taskState);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<StatusEvent>, I>>(base?: I): StatusEvent {
    return StatusEvent.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<StatusEvent>, I>>(object: I): StatusEvent {
    const message = createBaseStatusEvent();
    message.type = object.type ?? "";
    message.description = object.description ?? "";
    message.eventTime = object.eventTime ?? undefined;
    message.taskExecution = (object.taskExecution !== undefined && object.taskExecution !== null)
      ? TaskExecution.fromPartial(object.taskExecution)
      : undefined;
    message.taskState = object.taskState ?? 0;
    return message;
  },
};

function createBaseTaskExecution(): TaskExecution {
  return { exitCode: 0 };
}

export const TaskExecution: MessageFns<TaskExecution> = {
  encode(message: TaskExecution, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.exitCode !== 0) {
      writer.uint32(8).int32(message.exitCode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskExecution {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskExecution();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.exitCode = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TaskExecution {
    return { exitCode: isSet(object.exitCode) ? globalThis.Number(object.exitCode) : 0 };
  },

  toJSON(message: TaskExecution): unknown {
    const obj: any = {};
    if (message.exitCode !== 0) {
      obj.exitCode = Math.round(message.exitCode);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskExecution>, I>>(base?: I): TaskExecution {
    return TaskExecution.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskExecution>, I>>(object: I): TaskExecution {
    const message = createBaseTaskExecution();
    message.exitCode = object.exitCode ?? 0;
    return message;
  },
};

function createBaseTaskStatus(): TaskStatus {
  return {};
}

export const TaskStatus: MessageFns<TaskStatus> = {
  encode(_: TaskStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): TaskStatus {
    return {};
  },

  toJSON(_: TaskStatus): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskStatus>, I>>(base?: I): TaskStatus {
    return TaskStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskStatus>, I>>(_: I): TaskStatus {
    const message = createBaseTaskStatus();
    return message;
  },
};

function createBaseRunnable(): Runnable {
  return {
    container: undefined,
    script: undefined,
    barrier: undefined,
    ignoreExitStatus: false,
    background: false,
    alwaysRun: false,
    environment: undefined,
    timeout: undefined,
    labels: {},
  };
}

export const Runnable: MessageFns<Runnable> = {
  encode(message: Runnable, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.container !== undefined) {
      Runnable_Container.encode(message.container, writer.uint32(10).fork()).join();
    }
    if (message.script !== undefined) {
      Runnable_Script.encode(message.script, writer.uint32(18).fork()).join();
    }
    if (message.barrier !== undefined) {
      Runnable_Barrier.encode(message.barrier, writer.uint32(50).fork()).join();
    }
    if (message.ignoreExitStatus !== false) {
      writer.uint32(24).bool(message.ignoreExitStatus);
    }
    if (message.background !== false) {
      writer.uint32(32).bool(message.background);
    }
    if (message.alwaysRun !== false) {
      writer.uint32(40).bool(message.alwaysRun);
    }
    if (message.environment !== undefined) {
      Environment.encode(message.environment, writer.uint32(58).fork()).join();
    }
    if (message.timeout !== undefined) {
      Duration.encode(message.timeout, writer.uint32(66).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Runnable_LabelsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Runnable {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunnable();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.container = Runnable_Container.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.script = Runnable_Script.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.barrier = Runnable_Barrier.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.ignoreExitStatus = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.background = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.alwaysRun = reader.bool();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.environment = Environment.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.timeout = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          const entry9 = Runnable_LabelsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Runnable {
    return {
      container: isSet(object.container) ? Runnable_Container.fromJSON(object.container) : undefined,
      script: isSet(object.script) ? Runnable_Script.fromJSON(object.script) : undefined,
      barrier: isSet(object.barrier) ? Runnable_Barrier.fromJSON(object.barrier) : undefined,
      ignoreExitStatus: isSet(object.ignoreExitStatus) ? globalThis.Boolean(object.ignoreExitStatus) : false,
      background: isSet(object.background) ? globalThis.Boolean(object.background) : false,
      alwaysRun: isSet(object.alwaysRun) ? globalThis.Boolean(object.alwaysRun) : false,
      environment: isSet(object.environment) ? Environment.fromJSON(object.environment) : undefined,
      timeout: isSet(object.timeout) ? Duration.fromJSON(object.timeout) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Runnable): unknown {
    const obj: any = {};
    if (message.container !== undefined) {
      obj.container = Runnable_Container.toJSON(message.container);
    }
    if (message.script !== undefined) {
      obj.script = Runnable_Script.toJSON(message.script);
    }
    if (message.barrier !== undefined) {
      obj.barrier = Runnable_Barrier.toJSON(message.barrier);
    }
    if (message.ignoreExitStatus !== false) {
      obj.ignoreExitStatus = message.ignoreExitStatus;
    }
    if (message.background !== false) {
      obj.background = message.background;
    }
    if (message.alwaysRun !== false) {
      obj.alwaysRun = message.alwaysRun;
    }
    if (message.environment !== undefined) {
      obj.environment = Environment.toJSON(message.environment);
    }
    if (message.timeout !== undefined) {
      obj.timeout = Duration.toJSON(message.timeout);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Runnable>, I>>(base?: I): Runnable {
    return Runnable.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Runnable>, I>>(object: I): Runnable {
    const message = createBaseRunnable();
    message.container = (object.container !== undefined && object.container !== null)
      ? Runnable_Container.fromPartial(object.container)
      : undefined;
    message.script = (object.script !== undefined && object.script !== null)
      ? Runnable_Script.fromPartial(object.script)
      : undefined;
    message.barrier = (object.barrier !== undefined && object.barrier !== null)
      ? Runnable_Barrier.fromPartial(object.barrier)
      : undefined;
    message.ignoreExitStatus = object.ignoreExitStatus ?? false;
    message.background = object.background ?? false;
    message.alwaysRun = object.alwaysRun ?? false;
    message.environment = (object.environment !== undefined && object.environment !== null)
      ? Environment.fromPartial(object.environment)
      : undefined;
    message.timeout = (object.timeout !== undefined && object.timeout !== null)
      ? Duration.fromPartial(object.timeout)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseRunnable_Container(): Runnable_Container {
  return {
    imageUri: "",
    commands: [],
    entrypoint: "",
    volumes: [],
    options: "",
    blockExternalNetwork: false,
    username: "",
    password: "",
  };
}

export const Runnable_Container: MessageFns<Runnable_Container> = {
  encode(message: Runnable_Container, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.imageUri !== "") {
      writer.uint32(10).string(message.imageUri);
    }
    for (const v of message.commands) {
      writer.uint32(18).string(v!);
    }
    if (message.entrypoint !== "") {
      writer.uint32(26).string(message.entrypoint);
    }
    for (const v of message.volumes) {
      writer.uint32(58).string(v!);
    }
    if (message.options !== "") {
      writer.uint32(66).string(message.options);
    }
    if (message.blockExternalNetwork !== false) {
      writer.uint32(72).bool(message.blockExternalNetwork);
    }
    if (message.username !== "") {
      writer.uint32(82).string(message.username);
    }
    if (message.password !== "") {
      writer.uint32(90).string(message.password);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Runnable_Container {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunnable_Container();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.imageUri = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.commands.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.entrypoint = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.volumes.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.options = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.blockExternalNetwork = reader.bool();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.username = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.password = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Runnable_Container {
    return {
      imageUri: isSet(object.imageUri) ? globalThis.String(object.imageUri) : "",
      commands: globalThis.Array.isArray(object?.commands) ? object.commands.map((e: any) => globalThis.String(e)) : [],
      entrypoint: isSet(object.entrypoint) ? globalThis.String(object.entrypoint) : "",
      volumes: globalThis.Array.isArray(object?.volumes) ? object.volumes.map((e: any) => globalThis.String(e)) : [],
      options: isSet(object.options) ? globalThis.String(object.options) : "",
      blockExternalNetwork: isSet(object.blockExternalNetwork)
        ? globalThis.Boolean(object.blockExternalNetwork)
        : false,
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      password: isSet(object.password) ? globalThis.String(object.password) : "",
    };
  },

  toJSON(message: Runnable_Container): unknown {
    const obj: any = {};
    if (message.imageUri !== "") {
      obj.imageUri = message.imageUri;
    }
    if (message.commands?.length) {
      obj.commands = message.commands;
    }
    if (message.entrypoint !== "") {
      obj.entrypoint = message.entrypoint;
    }
    if (message.volumes?.length) {
      obj.volumes = message.volumes;
    }
    if (message.options !== "") {
      obj.options = message.options;
    }
    if (message.blockExternalNetwork !== false) {
      obj.blockExternalNetwork = message.blockExternalNetwork;
    }
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.password !== "") {
      obj.password = message.password;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Runnable_Container>, I>>(base?: I): Runnable_Container {
    return Runnable_Container.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Runnable_Container>, I>>(object: I): Runnable_Container {
    const message = createBaseRunnable_Container();
    message.imageUri = object.imageUri ?? "";
    message.commands = object.commands?.map((e) => e) || [];
    message.entrypoint = object.entrypoint ?? "";
    message.volumes = object.volumes?.map((e) => e) || [];
    message.options = object.options ?? "";
    message.blockExternalNetwork = object.blockExternalNetwork ?? false;
    message.username = object.username ?? "";
    message.password = object.password ?? "";
    return message;
  },
};

function createBaseRunnable_Script(): Runnable_Script {
  return { path: undefined, text: undefined };
}

export const Runnable_Script: MessageFns<Runnable_Script> = {
  encode(message: Runnable_Script, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== undefined) {
      writer.uint32(10).string(message.path);
    }
    if (message.text !== undefined) {
      writer.uint32(18).string(message.text);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Runnable_Script {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunnable_Script();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.text = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Runnable_Script {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : undefined,
      text: isSet(object.text) ? globalThis.String(object.text) : undefined,
    };
  },

  toJSON(message: Runnable_Script): unknown {
    const obj: any = {};
    if (message.path !== undefined) {
      obj.path = message.path;
    }
    if (message.text !== undefined) {
      obj.text = message.text;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Runnable_Script>, I>>(base?: I): Runnable_Script {
    return Runnable_Script.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Runnable_Script>, I>>(object: I): Runnable_Script {
    const message = createBaseRunnable_Script();
    message.path = object.path ?? undefined;
    message.text = object.text ?? undefined;
    return message;
  },
};

function createBaseRunnable_Barrier(): Runnable_Barrier {
  return { name: "" };
}

export const Runnable_Barrier: MessageFns<Runnable_Barrier> = {
  encode(message: Runnable_Barrier, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Runnable_Barrier {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunnable_Barrier();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Runnable_Barrier {
    return { name: isSet(object.name) ? globalThis.String(object.name) : "" };
  },

  toJSON(message: Runnable_Barrier): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Runnable_Barrier>, I>>(base?: I): Runnable_Barrier {
    return Runnable_Barrier.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Runnable_Barrier>, I>>(object: I): Runnable_Barrier {
    const message = createBaseRunnable_Barrier();
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseRunnable_LabelsEntry(): Runnable_LabelsEntry {
  return { key: "", value: "" };
}

export const Runnable_LabelsEntry: MessageFns<Runnable_LabelsEntry> = {
  encode(message: Runnable_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Runnable_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRunnable_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Runnable_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Runnable_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Runnable_LabelsEntry>, I>>(base?: I): Runnable_LabelsEntry {
    return Runnable_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Runnable_LabelsEntry>, I>>(object: I): Runnable_LabelsEntry {
    const message = createBaseRunnable_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTaskSpec(): TaskSpec {
  return {
    runnables: [],
    computeResource: undefined,
    maxRunDuration: undefined,
    maxRetryCount: 0,
    lifecyclePolicies: [],
    environments: {},
    volumes: [],
    environment: undefined,
  };
}

export const TaskSpec: MessageFns<TaskSpec> = {
  encode(message: TaskSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.runnables) {
      Runnable.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.computeResource !== undefined) {
      ComputeResource.encode(message.computeResource, writer.uint32(26).fork()).join();
    }
    if (message.maxRunDuration !== undefined) {
      Duration.encode(message.maxRunDuration, writer.uint32(34).fork()).join();
    }
    if (message.maxRetryCount !== 0) {
      writer.uint32(40).int32(message.maxRetryCount);
    }
    for (const v of message.lifecyclePolicies) {
      LifecyclePolicy.encode(v!, writer.uint32(74).fork()).join();
    }
    Object.entries(message.environments).forEach(([key, value]) => {
      TaskSpec_EnvironmentsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    for (const v of message.volumes) {
      Volume.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.environment !== undefined) {
      Environment.encode(message.environment, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.runnables.push(Runnable.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.computeResource = ComputeResource.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.maxRunDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.maxRetryCount = reader.int32();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.lifecyclePolicies.push(LifecyclePolicy.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = TaskSpec_EnvironmentsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.environments[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.volumes.push(Volume.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.environment = Environment.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TaskSpec {
    return {
      runnables: globalThis.Array.isArray(object?.runnables)
        ? object.runnables.map((e: any) => Runnable.fromJSON(e))
        : [],
      computeResource: isSet(object.computeResource) ? ComputeResource.fromJSON(object.computeResource) : undefined,
      maxRunDuration: isSet(object.maxRunDuration) ? Duration.fromJSON(object.maxRunDuration) : undefined,
      maxRetryCount: isSet(object.maxRetryCount) ? globalThis.Number(object.maxRetryCount) : 0,
      lifecyclePolicies: globalThis.Array.isArray(object?.lifecyclePolicies)
        ? object.lifecyclePolicies.map((e: any) => LifecyclePolicy.fromJSON(e))
        : [],
      environments: isObject(object.environments)
        ? Object.entries(object.environments).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      volumes: globalThis.Array.isArray(object?.volumes) ? object.volumes.map((e: any) => Volume.fromJSON(e)) : [],
      environment: isSet(object.environment) ? Environment.fromJSON(object.environment) : undefined,
    };
  },

  toJSON(message: TaskSpec): unknown {
    const obj: any = {};
    if (message.runnables?.length) {
      obj.runnables = message.runnables.map((e) => Runnable.toJSON(e));
    }
    if (message.computeResource !== undefined) {
      obj.computeResource = ComputeResource.toJSON(message.computeResource);
    }
    if (message.maxRunDuration !== undefined) {
      obj.maxRunDuration = Duration.toJSON(message.maxRunDuration);
    }
    if (message.maxRetryCount !== 0) {
      obj.maxRetryCount = Math.round(message.maxRetryCount);
    }
    if (message.lifecyclePolicies?.length) {
      obj.lifecyclePolicies = message.lifecyclePolicies.map((e) => LifecyclePolicy.toJSON(e));
    }
    if (message.environments) {
      const entries = Object.entries(message.environments);
      if (entries.length > 0) {
        obj.environments = {};
        entries.forEach(([k, v]) => {
          obj.environments[k] = v;
        });
      }
    }
    if (message.volumes?.length) {
      obj.volumes = message.volumes.map((e) => Volume.toJSON(e));
    }
    if (message.environment !== undefined) {
      obj.environment = Environment.toJSON(message.environment);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskSpec>, I>>(base?: I): TaskSpec {
    return TaskSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskSpec>, I>>(object: I): TaskSpec {
    const message = createBaseTaskSpec();
    message.runnables = object.runnables?.map((e) => Runnable.fromPartial(e)) || [];
    message.computeResource = (object.computeResource !== undefined && object.computeResource !== null)
      ? ComputeResource.fromPartial(object.computeResource)
      : undefined;
    message.maxRunDuration = (object.maxRunDuration !== undefined && object.maxRunDuration !== null)
      ? Duration.fromPartial(object.maxRunDuration)
      : undefined;
    message.maxRetryCount = object.maxRetryCount ?? 0;
    message.lifecyclePolicies = object.lifecyclePolicies?.map((e) => LifecyclePolicy.fromPartial(e)) || [];
    message.environments = Object.entries(object.environments ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.volumes = object.volumes?.map((e) => Volume.fromPartial(e)) || [];
    message.environment = (object.environment !== undefined && object.environment !== null)
      ? Environment.fromPartial(object.environment)
      : undefined;
    return message;
  },
};

function createBaseTaskSpec_EnvironmentsEntry(): TaskSpec_EnvironmentsEntry {
  return { key: "", value: "" };
}

export const TaskSpec_EnvironmentsEntry: MessageFns<TaskSpec_EnvironmentsEntry> = {
  encode(message: TaskSpec_EnvironmentsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskSpec_EnvironmentsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskSpec_EnvironmentsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TaskSpec_EnvironmentsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: TaskSpec_EnvironmentsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskSpec_EnvironmentsEntry>, I>>(base?: I): TaskSpec_EnvironmentsEntry {
    return TaskSpec_EnvironmentsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskSpec_EnvironmentsEntry>, I>>(object: I): TaskSpec_EnvironmentsEntry {
    const message = createBaseTaskSpec_EnvironmentsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseLifecyclePolicy(): LifecyclePolicy {
  return { action: 0, actionCondition: undefined };
}

export const LifecyclePolicy: MessageFns<LifecyclePolicy> = {
  encode(message: LifecyclePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.action !== 0) {
      writer.uint32(8).int32(message.action);
    }
    if (message.actionCondition !== undefined) {
      LifecyclePolicy_ActionCondition.encode(message.actionCondition, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LifecyclePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLifecyclePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.action = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.actionCondition = LifecyclePolicy_ActionCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LifecyclePolicy {
    return {
      action: isSet(object.action) ? lifecyclePolicy_ActionFromJSON(object.action) : 0,
      actionCondition: isSet(object.actionCondition)
        ? LifecyclePolicy_ActionCondition.fromJSON(object.actionCondition)
        : undefined,
    };
  },

  toJSON(message: LifecyclePolicy): unknown {
    const obj: any = {};
    if (message.action !== 0) {
      obj.action = lifecyclePolicy_ActionToJSON(message.action);
    }
    if (message.actionCondition !== undefined) {
      obj.actionCondition = LifecyclePolicy_ActionCondition.toJSON(message.actionCondition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LifecyclePolicy>, I>>(base?: I): LifecyclePolicy {
    return LifecyclePolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LifecyclePolicy>, I>>(object: I): LifecyclePolicy {
    const message = createBaseLifecyclePolicy();
    message.action = object.action ?? 0;
    message.actionCondition = (object.actionCondition !== undefined && object.actionCondition !== null)
      ? LifecyclePolicy_ActionCondition.fromPartial(object.actionCondition)
      : undefined;
    return message;
  },
};

function createBaseLifecyclePolicy_ActionCondition(): LifecyclePolicy_ActionCondition {
  return { exitCodes: [] };
}

export const LifecyclePolicy_ActionCondition: MessageFns<LifecyclePolicy_ActionCondition> = {
  encode(message: LifecyclePolicy_ActionCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.exitCodes) {
      writer.int32(v);
    }
    writer.join();
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LifecyclePolicy_ActionCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLifecyclePolicy_ActionCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag === 8) {
            message.exitCodes.push(reader.int32());

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.exitCodes.push(reader.int32());
            }

            continue;
          }

          break;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LifecyclePolicy_ActionCondition {
    return {
      exitCodes: globalThis.Array.isArray(object?.exitCodes)
        ? object.exitCodes.map((e: any) => globalThis.Number(e))
        : [],
    };
  },

  toJSON(message: LifecyclePolicy_ActionCondition): unknown {
    const obj: any = {};
    if (message.exitCodes?.length) {
      obj.exitCodes = message.exitCodes.map((e) => Math.round(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LifecyclePolicy_ActionCondition>, I>>(base?: I): LifecyclePolicy_ActionCondition {
    return LifecyclePolicy_ActionCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LifecyclePolicy_ActionCondition>, I>>(
    object: I,
  ): LifecyclePolicy_ActionCondition {
    const message = createBaseLifecyclePolicy_ActionCondition();
    message.exitCodes = object.exitCodes?.map((e) => e) || [];
    return message;
  },
};

function createBaseEnvironment(): Environment {
  return { variables: {}, secretVariables: {}, encryptedVariables: undefined };
}

export const Environment: MessageFns<Environment> = {
  encode(message: Environment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.variables).forEach(([key, value]) => {
      Environment_VariablesEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    Object.entries(message.secretVariables).forEach(([key, value]) => {
      Environment_SecretVariablesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.encryptedVariables !== undefined) {
      Environment_KMSEnvMap.encode(message.encryptedVariables, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = Environment_VariablesEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.variables[entry1.key] = entry1.value;
          }
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          const entry2 = Environment_SecretVariablesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.secretVariables[entry2.key] = entry2.value;
          }
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.encryptedVariables = Environment_KMSEnvMap.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment {
    return {
      variables: isObject(object.variables)
        ? Object.entries(object.variables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      secretVariables: isObject(object.secretVariables)
        ? Object.entries(object.secretVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      encryptedVariables: isSet(object.encryptedVariables)
        ? Environment_KMSEnvMap.fromJSON(object.encryptedVariables)
        : undefined,
    };
  },

  toJSON(message: Environment): unknown {
    const obj: any = {};
    if (message.variables) {
      const entries = Object.entries(message.variables);
      if (entries.length > 0) {
        obj.variables = {};
        entries.forEach(([k, v]) => {
          obj.variables[k] = v;
        });
      }
    }
    if (message.secretVariables) {
      const entries = Object.entries(message.secretVariables);
      if (entries.length > 0) {
        obj.secretVariables = {};
        entries.forEach(([k, v]) => {
          obj.secretVariables[k] = v;
        });
      }
    }
    if (message.encryptedVariables !== undefined) {
      obj.encryptedVariables = Environment_KMSEnvMap.toJSON(message.encryptedVariables);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment>, I>>(base?: I): Environment {
    return Environment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment>, I>>(object: I): Environment {
    const message = createBaseEnvironment();
    message.variables = Object.entries(object.variables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.secretVariables = Object.entries(object.secretVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.encryptedVariables = (object.encryptedVariables !== undefined && object.encryptedVariables !== null)
      ? Environment_KMSEnvMap.fromPartial(object.encryptedVariables)
      : undefined;
    return message;
  },
};

function createBaseEnvironment_KMSEnvMap(): Environment_KMSEnvMap {
  return { keyName: "", cipherText: "" };
}

export const Environment_KMSEnvMap: MessageFns<Environment_KMSEnvMap> = {
  encode(message: Environment_KMSEnvMap, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keyName !== "") {
      writer.uint32(10).string(message.keyName);
    }
    if (message.cipherText !== "") {
      writer.uint32(18).string(message.cipherText);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_KMSEnvMap {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_KMSEnvMap();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.keyName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cipherText = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_KMSEnvMap {
    return {
      keyName: isSet(object.keyName) ? globalThis.String(object.keyName) : "",
      cipherText: isSet(object.cipherText) ? globalThis.String(object.cipherText) : "",
    };
  },

  toJSON(message: Environment_KMSEnvMap): unknown {
    const obj: any = {};
    if (message.keyName !== "") {
      obj.keyName = message.keyName;
    }
    if (message.cipherText !== "") {
      obj.cipherText = message.cipherText;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_KMSEnvMap>, I>>(base?: I): Environment_KMSEnvMap {
    return Environment_KMSEnvMap.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_KMSEnvMap>, I>>(object: I): Environment_KMSEnvMap {
    const message = createBaseEnvironment_KMSEnvMap();
    message.keyName = object.keyName ?? "";
    message.cipherText = object.cipherText ?? "";
    return message;
  },
};

function createBaseEnvironment_VariablesEntry(): Environment_VariablesEntry {
  return { key: "", value: "" };
}

export const Environment_VariablesEntry: MessageFns<Environment_VariablesEntry> = {
  encode(message: Environment_VariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_VariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_VariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_VariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Environment_VariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_VariablesEntry>, I>>(base?: I): Environment_VariablesEntry {
    return Environment_VariablesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_VariablesEntry>, I>>(object: I): Environment_VariablesEntry {
    const message = createBaseEnvironment_VariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseEnvironment_SecretVariablesEntry(): Environment_SecretVariablesEntry {
  return { key: "", value: "" };
}

export const Environment_SecretVariablesEntry: MessageFns<Environment_SecretVariablesEntry> = {
  encode(message: Environment_SecretVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_SecretVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_SecretVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_SecretVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Environment_SecretVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_SecretVariablesEntry>, I>>(
    base?: I,
  ): Environment_SecretVariablesEntry {
    return Environment_SecretVariablesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_SecretVariablesEntry>, I>>(
    object: I,
  ): Environment_SecretVariablesEntry {
    const message = createBaseEnvironment_SecretVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseJob(): Job {
  return {
    name: "",
    uid: "",
    priority: Long.ZERO,
    taskGroups: [],
    allocationPolicy: undefined,
    labels: {},
    status: undefined,
    createTime: undefined,
    updateTime: undefined,
    logsPolicy: undefined,
    notifications: [],
  };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (!message.priority.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.priority.toString());
    }
    for (const v of message.taskGroups) {
      TaskGroup.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.allocationPolicy !== undefined) {
      AllocationPolicy.encode(message.allocationPolicy, writer.uint32(58).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Job_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.status !== undefined) {
      JobStatus.encode(message.status, writer.uint32(74).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(90).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(98).fork()).join();
    }
    if (message.logsPolicy !== undefined) {
      LogsPolicy.encode(message.logsPolicy, writer.uint32(106).fork()).join();
    }
    for (const v of message.notifications) {
      JobNotification.encode(v!, writer.uint32(114).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.priority = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.taskGroups.push(TaskGroup.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.allocationPolicy = AllocationPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = Job_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.status = JobStatus.decode(reader, reader.uint32());
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.logsPolicy = LogsPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.notifications.push(JobNotification.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      priority: isSet(object.priority) ? Long.fromValue(object.priority) : Long.ZERO,
      taskGroups: globalThis.Array.isArray(object?.taskGroups)
        ? object.taskGroups.map((e: any) => TaskGroup.fromJSON(e))
        : [],
      allocationPolicy: isSet(object.allocationPolicy) ? AllocationPolicy.fromJSON(object.allocationPolicy) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      status: isSet(object.status) ? JobStatus.fromJSON(object.status) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      logsPolicy: isSet(object.logsPolicy) ? LogsPolicy.fromJSON(object.logsPolicy) : undefined,
      notifications: globalThis.Array.isArray(object?.notifications)
        ? object.notifications.map((e: any) => JobNotification.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (!message.priority.equals(Long.ZERO)) {
      obj.priority = (message.priority || Long.ZERO).toString();
    }
    if (message.taskGroups?.length) {
      obj.taskGroups = message.taskGroups.map((e) => TaskGroup.toJSON(e));
    }
    if (message.allocationPolicy !== undefined) {
      obj.allocationPolicy = AllocationPolicy.toJSON(message.allocationPolicy);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.status !== undefined) {
      obj.status = JobStatus.toJSON(message.status);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.logsPolicy !== undefined) {
      obj.logsPolicy = LogsPolicy.toJSON(message.logsPolicy);
    }
    if (message.notifications?.length) {
      obj.notifications = message.notifications.map((e) => JobNotification.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Job>, I>>(base?: I): Job {
    return Job.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Job>, I>>(object: I): Job {
    const message = createBaseJob();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.priority = (object.priority !== undefined && object.priority !== null)
      ? Long.fromValue(object.priority)
      : Long.ZERO;
    message.taskGroups = object.taskGroups?.map((e) => TaskGroup.fromPartial(e)) || [];
    message.allocationPolicy = (object.allocationPolicy !== undefined && object.allocationPolicy !== null)
      ? AllocationPolicy.fromPartial(object.allocationPolicy)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.status = (object.status !== undefined && object.status !== null)
      ? JobStatus.fromPartial(object.status)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.logsPolicy = (object.logsPolicy !== undefined && object.logsPolicy !== null)
      ? LogsPolicy.fromPartial(object.logsPolicy)
      : undefined;
    message.notifications = object.notifications?.map((e) => JobNotification.fromPartial(e)) || [];
    return message;
  },
};

function createBaseJob_LabelsEntry(): Job_LabelsEntry {
  return { key: "", value: "" };
}

export const Job_LabelsEntry: MessageFns<Job_LabelsEntry> = {
  encode(message: Job_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Job_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Job_LabelsEntry>, I>>(base?: I): Job_LabelsEntry {
    return Job_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Job_LabelsEntry>, I>>(object: I): Job_LabelsEntry {
    const message = createBaseJob_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseLogsPolicy(): LogsPolicy {
  return { destination: 0, logsPath: "" };
}

export const LogsPolicy: MessageFns<LogsPolicy> = {
  encode(message: LogsPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destination !== 0) {
      writer.uint32(8).int32(message.destination);
    }
    if (message.logsPath !== "") {
      writer.uint32(18).string(message.logsPath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LogsPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLogsPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.destination = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.logsPath = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LogsPolicy {
    return {
      destination: isSet(object.destination) ? logsPolicy_DestinationFromJSON(object.destination) : 0,
      logsPath: isSet(object.logsPath) ? globalThis.String(object.logsPath) : "",
    };
  },

  toJSON(message: LogsPolicy): unknown {
    const obj: any = {};
    if (message.destination !== 0) {
      obj.destination = logsPolicy_DestinationToJSON(message.destination);
    }
    if (message.logsPath !== "") {
      obj.logsPath = message.logsPath;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LogsPolicy>, I>>(base?: I): LogsPolicy {
    return LogsPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LogsPolicy>, I>>(object: I): LogsPolicy {
    const message = createBaseLogsPolicy();
    message.destination = object.destination ?? 0;
    message.logsPath = object.logsPath ?? "";
    return message;
  },
};

function createBaseJobStatus(): JobStatus {
  return { state: 0, statusEvents: [], taskGroups: {}, runDuration: undefined };
}

export const JobStatus: MessageFns<JobStatus> = {
  encode(message: JobStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    for (const v of message.statusEvents) {
      StatusEvent.encode(v!, writer.uint32(18).fork()).join();
    }
    Object.entries(message.taskGroups).forEach(([key, value]) => {
      JobStatus_TaskGroupsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.runDuration !== undefined) {
      Duration.encode(message.runDuration, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.statusEvents.push(StatusEvent.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = JobStatus_TaskGroupsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.taskGroups[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.runDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus {
    return {
      state: isSet(object.state) ? jobStatus_StateFromJSON(object.state) : 0,
      statusEvents: globalThis.Array.isArray(object?.statusEvents)
        ? object.statusEvents.map((e: any) => StatusEvent.fromJSON(e))
        : [],
      taskGroups: isObject(object.taskGroups)
        ? Object.entries(object.taskGroups).reduce<{ [key: string]: JobStatus_TaskGroupStatus }>(
          (acc, [key, value]) => {
            acc[key] = JobStatus_TaskGroupStatus.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
      runDuration: isSet(object.runDuration) ? Duration.fromJSON(object.runDuration) : undefined,
    };
  },

  toJSON(message: JobStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = jobStatus_StateToJSON(message.state);
    }
    if (message.statusEvents?.length) {
      obj.statusEvents = message.statusEvents.map((e) => StatusEvent.toJSON(e));
    }
    if (message.taskGroups) {
      const entries = Object.entries(message.taskGroups);
      if (entries.length > 0) {
        obj.taskGroups = {};
        entries.forEach(([k, v]) => {
          obj.taskGroups[k] = JobStatus_TaskGroupStatus.toJSON(v);
        });
      }
    }
    if (message.runDuration !== undefined) {
      obj.runDuration = Duration.toJSON(message.runDuration);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobStatus>, I>>(base?: I): JobStatus {
    return JobStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobStatus>, I>>(object: I): JobStatus {
    const message = createBaseJobStatus();
    message.state = object.state ?? 0;
    message.statusEvents = object.statusEvents?.map((e) => StatusEvent.fromPartial(e)) || [];
    message.taskGroups = Object.entries(object.taskGroups ?? {}).reduce<{ [key: string]: JobStatus_TaskGroupStatus }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = JobStatus_TaskGroupStatus.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.runDuration = (object.runDuration !== undefined && object.runDuration !== null)
      ? Duration.fromPartial(object.runDuration)
      : undefined;
    return message;
  },
};

function createBaseJobStatus_InstanceStatus(): JobStatus_InstanceStatus {
  return { machineType: "", provisioningModel: 0, taskPack: Long.ZERO, bootDisk: undefined };
}

export const JobStatus_InstanceStatus: MessageFns<JobStatus_InstanceStatus> = {
  encode(message: JobStatus_InstanceStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.machineType !== "") {
      writer.uint32(10).string(message.machineType);
    }
    if (message.provisioningModel !== 0) {
      writer.uint32(16).int32(message.provisioningModel);
    }
    if (!message.taskPack.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.taskPack.toString());
    }
    if (message.bootDisk !== undefined) {
      AllocationPolicy_Disk.encode(message.bootDisk, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus_InstanceStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus_InstanceStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.machineType = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.provisioningModel = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.taskPack = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.bootDisk = AllocationPolicy_Disk.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus_InstanceStatus {
    return {
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      provisioningModel: isSet(object.provisioningModel)
        ? allocationPolicy_ProvisioningModelFromJSON(object.provisioningModel)
        : 0,
      taskPack: isSet(object.taskPack) ? Long.fromValue(object.taskPack) : Long.ZERO,
      bootDisk: isSet(object.bootDisk) ? AllocationPolicy_Disk.fromJSON(object.bootDisk) : undefined,
    };
  },

  toJSON(message: JobStatus_InstanceStatus): unknown {
    const obj: any = {};
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (message.provisioningModel !== 0) {
      obj.provisioningModel = allocationPolicy_ProvisioningModelToJSON(message.provisioningModel);
    }
    if (!message.taskPack.equals(Long.ZERO)) {
      obj.taskPack = (message.taskPack || Long.ZERO).toString();
    }
    if (message.bootDisk !== undefined) {
      obj.bootDisk = AllocationPolicy_Disk.toJSON(message.bootDisk);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobStatus_InstanceStatus>, I>>(base?: I): JobStatus_InstanceStatus {
    return JobStatus_InstanceStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobStatus_InstanceStatus>, I>>(object: I): JobStatus_InstanceStatus {
    const message = createBaseJobStatus_InstanceStatus();
    message.machineType = object.machineType ?? "";
    message.provisioningModel = object.provisioningModel ?? 0;
    message.taskPack = (object.taskPack !== undefined && object.taskPack !== null)
      ? Long.fromValue(object.taskPack)
      : Long.ZERO;
    message.bootDisk = (object.bootDisk !== undefined && object.bootDisk !== null)
      ? AllocationPolicy_Disk.fromPartial(object.bootDisk)
      : undefined;
    return message;
  },
};

function createBaseJobStatus_TaskGroupStatus(): JobStatus_TaskGroupStatus {
  return { counts: {}, instances: [] };
}

export const JobStatus_TaskGroupStatus: MessageFns<JobStatus_TaskGroupStatus> = {
  encode(message: JobStatus_TaskGroupStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.counts).forEach(([key, value]) => {
      JobStatus_TaskGroupStatus_CountsEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    for (const v of message.instances) {
      JobStatus_InstanceStatus.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus_TaskGroupStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus_TaskGroupStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = JobStatus_TaskGroupStatus_CountsEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.counts[entry1.key] = entry1.value;
          }
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.instances.push(JobStatus_InstanceStatus.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus_TaskGroupStatus {
    return {
      counts: isObject(object.counts)
        ? Object.entries(object.counts).reduce<{ [key: string]: Long }>((acc, [key, value]) => {
          acc[key] = Long.fromValue(value as Long | string);
          return acc;
        }, {})
        : {},
      instances: globalThis.Array.isArray(object?.instances)
        ? object.instances.map((e: any) => JobStatus_InstanceStatus.fromJSON(e))
        : [],
    };
  },

  toJSON(message: JobStatus_TaskGroupStatus): unknown {
    const obj: any = {};
    if (message.counts) {
      const entries = Object.entries(message.counts);
      if (entries.length > 0) {
        obj.counts = {};
        entries.forEach(([k, v]) => {
          obj.counts[k] = v.toString();
        });
      }
    }
    if (message.instances?.length) {
      obj.instances = message.instances.map((e) => JobStatus_InstanceStatus.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobStatus_TaskGroupStatus>, I>>(base?: I): JobStatus_TaskGroupStatus {
    return JobStatus_TaskGroupStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobStatus_TaskGroupStatus>, I>>(object: I): JobStatus_TaskGroupStatus {
    const message = createBaseJobStatus_TaskGroupStatus();
    message.counts = Object.entries(object.counts ?? {}).reduce<{ [key: string]: Long }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = Long.fromValue(value);
      }
      return acc;
    }, {});
    message.instances = object.instances?.map((e) => JobStatus_InstanceStatus.fromPartial(e)) || [];
    return message;
  },
};

function createBaseJobStatus_TaskGroupStatus_CountsEntry(): JobStatus_TaskGroupStatus_CountsEntry {
  return { key: "", value: Long.ZERO };
}

export const JobStatus_TaskGroupStatus_CountsEntry: MessageFns<JobStatus_TaskGroupStatus_CountsEntry> = {
  encode(message: JobStatus_TaskGroupStatus_CountsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (!message.value.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.value.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus_TaskGroupStatus_CountsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus_TaskGroupStatus_CountsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.value = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus_TaskGroupStatus_CountsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Long.fromValue(object.value) : Long.ZERO,
    };
  },

  toJSON(message: JobStatus_TaskGroupStatus_CountsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (!message.value.equals(Long.ZERO)) {
      obj.value = (message.value || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobStatus_TaskGroupStatus_CountsEntry>, I>>(
    base?: I,
  ): JobStatus_TaskGroupStatus_CountsEntry {
    return JobStatus_TaskGroupStatus_CountsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobStatus_TaskGroupStatus_CountsEntry>, I>>(
    object: I,
  ): JobStatus_TaskGroupStatus_CountsEntry {
    const message = createBaseJobStatus_TaskGroupStatus_CountsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null) ? Long.fromValue(object.value) : Long.ZERO;
    return message;
  },
};

function createBaseJobStatus_TaskGroupsEntry(): JobStatus_TaskGroupsEntry {
  return { key: "", value: undefined };
}

export const JobStatus_TaskGroupsEntry: MessageFns<JobStatus_TaskGroupsEntry> = {
  encode(message: JobStatus_TaskGroupsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      JobStatus_TaskGroupStatus.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobStatus_TaskGroupsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobStatus_TaskGroupsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = JobStatus_TaskGroupStatus.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobStatus_TaskGroupsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? JobStatus_TaskGroupStatus.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: JobStatus_TaskGroupsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = JobStatus_TaskGroupStatus.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobStatus_TaskGroupsEntry>, I>>(base?: I): JobStatus_TaskGroupsEntry {
    return JobStatus_TaskGroupsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobStatus_TaskGroupsEntry>, I>>(object: I): JobStatus_TaskGroupsEntry {
    const message = createBaseJobStatus_TaskGroupsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? JobStatus_TaskGroupStatus.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseJobNotification(): JobNotification {
  return { pubsubTopic: "", message: undefined };
}

export const JobNotification: MessageFns<JobNotification> = {
  encode(message: JobNotification, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pubsubTopic !== "") {
      writer.uint32(10).string(message.pubsubTopic);
    }
    if (message.message !== undefined) {
      JobNotification_Message.encode(message.message, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobNotification {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobNotification();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.pubsubTopic = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = JobNotification_Message.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobNotification {
    return {
      pubsubTopic: isSet(object.pubsubTopic) ? globalThis.String(object.pubsubTopic) : "",
      message: isSet(object.message) ? JobNotification_Message.fromJSON(object.message) : undefined,
    };
  },

  toJSON(message: JobNotification): unknown {
    const obj: any = {};
    if (message.pubsubTopic !== "") {
      obj.pubsubTopic = message.pubsubTopic;
    }
    if (message.message !== undefined) {
      obj.message = JobNotification_Message.toJSON(message.message);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobNotification>, I>>(base?: I): JobNotification {
    return JobNotification.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobNotification>, I>>(object: I): JobNotification {
    const message = createBaseJobNotification();
    message.pubsubTopic = object.pubsubTopic ?? "";
    message.message = (object.message !== undefined && object.message !== null)
      ? JobNotification_Message.fromPartial(object.message)
      : undefined;
    return message;
  },
};

function createBaseJobNotification_Message(): JobNotification_Message {
  return { type: 0, newJobState: 0, newTaskState: 0 };
}

export const JobNotification_Message: MessageFns<JobNotification_Message> = {
  encode(message: JobNotification_Message, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.newJobState !== 0) {
      writer.uint32(16).int32(message.newJobState);
    }
    if (message.newTaskState !== 0) {
      writer.uint32(24).int32(message.newTaskState);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobNotification_Message {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobNotification_Message();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.newJobState = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.newTaskState = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobNotification_Message {
    return {
      type: isSet(object.type) ? jobNotification_TypeFromJSON(object.type) : 0,
      newJobState: isSet(object.newJobState) ? jobStatus_StateFromJSON(object.newJobState) : 0,
      newTaskState: isSet(object.newTaskState) ? taskStatus_StateFromJSON(object.newTaskState) : 0,
    };
  },

  toJSON(message: JobNotification_Message): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = jobNotification_TypeToJSON(message.type);
    }
    if (message.newJobState !== 0) {
      obj.newJobState = jobStatus_StateToJSON(message.newJobState);
    }
    if (message.newTaskState !== 0) {
      obj.newTaskState = taskStatus_StateToJSON(message.newTaskState);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobNotification_Message>, I>>(base?: I): JobNotification_Message {
    return JobNotification_Message.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobNotification_Message>, I>>(object: I): JobNotification_Message {
    const message = createBaseJobNotification_Message();
    message.type = object.type ?? 0;
    message.newJobState = object.newJobState ?? 0;
    message.newTaskState = object.newTaskState ?? 0;
    return message;
  },
};

function createBaseAllocationPolicy(): AllocationPolicy {
  return {
    location: undefined,
    instances: [],
    serviceAccount: undefined,
    labels: {},
    network: undefined,
    placement: undefined,
  };
}

export const AllocationPolicy: MessageFns<AllocationPolicy> = {
  encode(message: AllocationPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== undefined) {
      AllocationPolicy_LocationPolicy.encode(message.location, writer.uint32(10).fork()).join();
    }
    for (const v of message.instances) {
      AllocationPolicy_InstancePolicyOrTemplate.encode(v!, writer.uint32(66).fork()).join();
    }
    if (message.serviceAccount !== undefined) {
      ServiceAccount.encode(message.serviceAccount, writer.uint32(74).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      AllocationPolicy_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.network !== undefined) {
      AllocationPolicy_NetworkPolicy.encode(message.network, writer.uint32(58).fork()).join();
    }
    if (message.placement !== undefined) {
      AllocationPolicy_PlacementPolicy.encode(message.placement, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.location = AllocationPolicy_LocationPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.instances.push(AllocationPolicy_InstancePolicyOrTemplate.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.serviceAccount = ServiceAccount.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = AllocationPolicy_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.network = AllocationPolicy_NetworkPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.placement = AllocationPolicy_PlacementPolicy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy {
    return {
      location: isSet(object.location) ? AllocationPolicy_LocationPolicy.fromJSON(object.location) : undefined,
      instances: globalThis.Array.isArray(object?.instances)
        ? object.instances.map((e: any) => AllocationPolicy_InstancePolicyOrTemplate.fromJSON(e))
        : [],
      serviceAccount: isSet(object.serviceAccount) ? ServiceAccount.fromJSON(object.serviceAccount) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      network: isSet(object.network) ? AllocationPolicy_NetworkPolicy.fromJSON(object.network) : undefined,
      placement: isSet(object.placement) ? AllocationPolicy_PlacementPolicy.fromJSON(object.placement) : undefined,
    };
  },

  toJSON(message: AllocationPolicy): unknown {
    const obj: any = {};
    if (message.location !== undefined) {
      obj.location = AllocationPolicy_LocationPolicy.toJSON(message.location);
    }
    if (message.instances?.length) {
      obj.instances = message.instances.map((e) => AllocationPolicy_InstancePolicyOrTemplate.toJSON(e));
    }
    if (message.serviceAccount !== undefined) {
      obj.serviceAccount = ServiceAccount.toJSON(message.serviceAccount);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.network !== undefined) {
      obj.network = AllocationPolicy_NetworkPolicy.toJSON(message.network);
    }
    if (message.placement !== undefined) {
      obj.placement = AllocationPolicy_PlacementPolicy.toJSON(message.placement);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy>, I>>(base?: I): AllocationPolicy {
    return AllocationPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy>, I>>(object: I): AllocationPolicy {
    const message = createBaseAllocationPolicy();
    message.location = (object.location !== undefined && object.location !== null)
      ? AllocationPolicy_LocationPolicy.fromPartial(object.location)
      : undefined;
    message.instances = object.instances?.map((e) => AllocationPolicy_InstancePolicyOrTemplate.fromPartial(e)) || [];
    message.serviceAccount = (object.serviceAccount !== undefined && object.serviceAccount !== null)
      ? ServiceAccount.fromPartial(object.serviceAccount)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.network = (object.network !== undefined && object.network !== null)
      ? AllocationPolicy_NetworkPolicy.fromPartial(object.network)
      : undefined;
    message.placement = (object.placement !== undefined && object.placement !== null)
      ? AllocationPolicy_PlacementPolicy.fromPartial(object.placement)
      : undefined;
    return message;
  },
};

function createBaseAllocationPolicy_LocationPolicy(): AllocationPolicy_LocationPolicy {
  return { allowedLocations: [] };
}

export const AllocationPolicy_LocationPolicy: MessageFns<AllocationPolicy_LocationPolicy> = {
  encode(message: AllocationPolicy_LocationPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.allowedLocations) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_LocationPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_LocationPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.allowedLocations.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_LocationPolicy {
    return {
      allowedLocations: globalThis.Array.isArray(object?.allowedLocations)
        ? object.allowedLocations.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: AllocationPolicy_LocationPolicy): unknown {
    const obj: any = {};
    if (message.allowedLocations?.length) {
      obj.allowedLocations = message.allowedLocations;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_LocationPolicy>, I>>(base?: I): AllocationPolicy_LocationPolicy {
    return AllocationPolicy_LocationPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_LocationPolicy>, I>>(
    object: I,
  ): AllocationPolicy_LocationPolicy {
    const message = createBaseAllocationPolicy_LocationPolicy();
    message.allowedLocations = object.allowedLocations?.map((e) => e) || [];
    return message;
  },
};

function createBaseAllocationPolicy_Disk(): AllocationPolicy_Disk {
  return { image: undefined, snapshot: undefined, type: "", sizeGb: Long.ZERO, diskInterface: "" };
}

export const AllocationPolicy_Disk: MessageFns<AllocationPolicy_Disk> = {
  encode(message: AllocationPolicy_Disk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.image !== undefined) {
      writer.uint32(34).string(message.image);
    }
    if (message.snapshot !== undefined) {
      writer.uint32(42).string(message.snapshot);
    }
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (!message.sizeGb.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.sizeGb.toString());
    }
    if (message.diskInterface !== "") {
      writer.uint32(50).string(message.diskInterface);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_Disk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_Disk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.image = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.snapshot = reader.string();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.sizeGb = Long.fromString(reader.int64().toString());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.diskInterface = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_Disk {
    return {
      image: isSet(object.image) ? globalThis.String(object.image) : undefined,
      snapshot: isSet(object.snapshot) ? globalThis.String(object.snapshot) : undefined,
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      sizeGb: isSet(object.sizeGb) ? Long.fromValue(object.sizeGb) : Long.ZERO,
      diskInterface: isSet(object.diskInterface) ? globalThis.String(object.diskInterface) : "",
    };
  },

  toJSON(message: AllocationPolicy_Disk): unknown {
    const obj: any = {};
    if (message.image !== undefined) {
      obj.image = message.image;
    }
    if (message.snapshot !== undefined) {
      obj.snapshot = message.snapshot;
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (!message.sizeGb.equals(Long.ZERO)) {
      obj.sizeGb = (message.sizeGb || Long.ZERO).toString();
    }
    if (message.diskInterface !== "") {
      obj.diskInterface = message.diskInterface;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_Disk>, I>>(base?: I): AllocationPolicy_Disk {
    return AllocationPolicy_Disk.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_Disk>, I>>(object: I): AllocationPolicy_Disk {
    const message = createBaseAllocationPolicy_Disk();
    message.image = object.image ?? undefined;
    message.snapshot = object.snapshot ?? undefined;
    message.type = object.type ?? "";
    message.sizeGb = (object.sizeGb !== undefined && object.sizeGb !== null)
      ? Long.fromValue(object.sizeGb)
      : Long.ZERO;
    message.diskInterface = object.diskInterface ?? "";
    return message;
  },
};

function createBaseAllocationPolicy_AttachedDisk(): AllocationPolicy_AttachedDisk {
  return { newDisk: undefined, existingDisk: undefined, deviceName: "" };
}

export const AllocationPolicy_AttachedDisk: MessageFns<AllocationPolicy_AttachedDisk> = {
  encode(message: AllocationPolicy_AttachedDisk, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.newDisk !== undefined) {
      AllocationPolicy_Disk.encode(message.newDisk, writer.uint32(10).fork()).join();
    }
    if (message.existingDisk !== undefined) {
      writer.uint32(18).string(message.existingDisk);
    }
    if (message.deviceName !== "") {
      writer.uint32(26).string(message.deviceName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_AttachedDisk {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_AttachedDisk();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.newDisk = AllocationPolicy_Disk.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.existingDisk = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.deviceName = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_AttachedDisk {
    return {
      newDisk: isSet(object.newDisk) ? AllocationPolicy_Disk.fromJSON(object.newDisk) : undefined,
      existingDisk: isSet(object.existingDisk) ? globalThis.String(object.existingDisk) : undefined,
      deviceName: isSet(object.deviceName) ? globalThis.String(object.deviceName) : "",
    };
  },

  toJSON(message: AllocationPolicy_AttachedDisk): unknown {
    const obj: any = {};
    if (message.newDisk !== undefined) {
      obj.newDisk = AllocationPolicy_Disk.toJSON(message.newDisk);
    }
    if (message.existingDisk !== undefined) {
      obj.existingDisk = message.existingDisk;
    }
    if (message.deviceName !== "") {
      obj.deviceName = message.deviceName;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_AttachedDisk>, I>>(base?: I): AllocationPolicy_AttachedDisk {
    return AllocationPolicy_AttachedDisk.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_AttachedDisk>, I>>(
    object: I,
  ): AllocationPolicy_AttachedDisk {
    const message = createBaseAllocationPolicy_AttachedDisk();
    message.newDisk = (object.newDisk !== undefined && object.newDisk !== null)
      ? AllocationPolicy_Disk.fromPartial(object.newDisk)
      : undefined;
    message.existingDisk = object.existingDisk ?? undefined;
    message.deviceName = object.deviceName ?? "";
    return message;
  },
};

function createBaseAllocationPolicy_Accelerator(): AllocationPolicy_Accelerator {
  return { type: "", count: Long.ZERO, installGpuDrivers: false };
}

export const AllocationPolicy_Accelerator: MessageFns<AllocationPolicy_Accelerator> = {
  encode(message: AllocationPolicy_Accelerator, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== "") {
      writer.uint32(10).string(message.type);
    }
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.count.toString());
    }
    if (message.installGpuDrivers !== false) {
      writer.uint32(24).bool(message.installGpuDrivers);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_Accelerator {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_Accelerator();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.installGpuDrivers = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_Accelerator {
    return {
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
      installGpuDrivers: isSet(object.installGpuDrivers) ? globalThis.Boolean(object.installGpuDrivers) : false,
    };
  },

  toJSON(message: AllocationPolicy_Accelerator): unknown {
    const obj: any = {};
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    if (message.installGpuDrivers !== false) {
      obj.installGpuDrivers = message.installGpuDrivers;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_Accelerator>, I>>(base?: I): AllocationPolicy_Accelerator {
    return AllocationPolicy_Accelerator.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_Accelerator>, I>>(object: I): AllocationPolicy_Accelerator {
    const message = createBaseAllocationPolicy_Accelerator();
    message.type = object.type ?? "";
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    message.installGpuDrivers = object.installGpuDrivers ?? false;
    return message;
  },
};

function createBaseAllocationPolicy_InstancePolicy(): AllocationPolicy_InstancePolicy {
  return {
    machineType: "",
    minCpuPlatform: "",
    provisioningModel: 0,
    accelerators: [],
    bootDisk: undefined,
    disks: [],
  };
}

export const AllocationPolicy_InstancePolicy: MessageFns<AllocationPolicy_InstancePolicy> = {
  encode(message: AllocationPolicy_InstancePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.machineType !== "") {
      writer.uint32(18).string(message.machineType);
    }
    if (message.minCpuPlatform !== "") {
      writer.uint32(26).string(message.minCpuPlatform);
    }
    if (message.provisioningModel !== 0) {
      writer.uint32(32).int32(message.provisioningModel);
    }
    for (const v of message.accelerators) {
      AllocationPolicy_Accelerator.encode(v!, writer.uint32(42).fork()).join();
    }
    if (message.bootDisk !== undefined) {
      AllocationPolicy_Disk.encode(message.bootDisk, writer.uint32(66).fork()).join();
    }
    for (const v of message.disks) {
      AllocationPolicy_AttachedDisk.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_InstancePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_InstancePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.machineType = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.minCpuPlatform = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.provisioningModel = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.accelerators.push(AllocationPolicy_Accelerator.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.bootDisk = AllocationPolicy_Disk.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.disks.push(AllocationPolicy_AttachedDisk.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_InstancePolicy {
    return {
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      minCpuPlatform: isSet(object.minCpuPlatform) ? globalThis.String(object.minCpuPlatform) : "",
      provisioningModel: isSet(object.provisioningModel)
        ? allocationPolicy_ProvisioningModelFromJSON(object.provisioningModel)
        : 0,
      accelerators: globalThis.Array.isArray(object?.accelerators)
        ? object.accelerators.map((e: any) => AllocationPolicy_Accelerator.fromJSON(e))
        : [],
      bootDisk: isSet(object.bootDisk) ? AllocationPolicy_Disk.fromJSON(object.bootDisk) : undefined,
      disks: globalThis.Array.isArray(object?.disks)
        ? object.disks.map((e: any) => AllocationPolicy_AttachedDisk.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AllocationPolicy_InstancePolicy): unknown {
    const obj: any = {};
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (message.minCpuPlatform !== "") {
      obj.minCpuPlatform = message.minCpuPlatform;
    }
    if (message.provisioningModel !== 0) {
      obj.provisioningModel = allocationPolicy_ProvisioningModelToJSON(message.provisioningModel);
    }
    if (message.accelerators?.length) {
      obj.accelerators = message.accelerators.map((e) => AllocationPolicy_Accelerator.toJSON(e));
    }
    if (message.bootDisk !== undefined) {
      obj.bootDisk = AllocationPolicy_Disk.toJSON(message.bootDisk);
    }
    if (message.disks?.length) {
      obj.disks = message.disks.map((e) => AllocationPolicy_AttachedDisk.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_InstancePolicy>, I>>(base?: I): AllocationPolicy_InstancePolicy {
    return AllocationPolicy_InstancePolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_InstancePolicy>, I>>(
    object: I,
  ): AllocationPolicy_InstancePolicy {
    const message = createBaseAllocationPolicy_InstancePolicy();
    message.machineType = object.machineType ?? "";
    message.minCpuPlatform = object.minCpuPlatform ?? "";
    message.provisioningModel = object.provisioningModel ?? 0;
    message.accelerators = object.accelerators?.map((e) => AllocationPolicy_Accelerator.fromPartial(e)) || [];
    message.bootDisk = (object.bootDisk !== undefined && object.bootDisk !== null)
      ? AllocationPolicy_Disk.fromPartial(object.bootDisk)
      : undefined;
    message.disks = object.disks?.map((e) => AllocationPolicy_AttachedDisk.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAllocationPolicy_InstancePolicyOrTemplate(): AllocationPolicy_InstancePolicyOrTemplate {
  return { policy: undefined, instanceTemplate: undefined, installGpuDrivers: false };
}

export const AllocationPolicy_InstancePolicyOrTemplate: MessageFns<AllocationPolicy_InstancePolicyOrTemplate> = {
  encode(message: AllocationPolicy_InstancePolicyOrTemplate, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.policy !== undefined) {
      AllocationPolicy_InstancePolicy.encode(message.policy, writer.uint32(10).fork()).join();
    }
    if (message.instanceTemplate !== undefined) {
      writer.uint32(18).string(message.instanceTemplate);
    }
    if (message.installGpuDrivers !== false) {
      writer.uint32(24).bool(message.installGpuDrivers);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_InstancePolicyOrTemplate {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_InstancePolicyOrTemplate();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.policy = AllocationPolicy_InstancePolicy.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.instanceTemplate = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.installGpuDrivers = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_InstancePolicyOrTemplate {
    return {
      policy: isSet(object.policy) ? AllocationPolicy_InstancePolicy.fromJSON(object.policy) : undefined,
      instanceTemplate: isSet(object.instanceTemplate) ? globalThis.String(object.instanceTemplate) : undefined,
      installGpuDrivers: isSet(object.installGpuDrivers) ? globalThis.Boolean(object.installGpuDrivers) : false,
    };
  },

  toJSON(message: AllocationPolicy_InstancePolicyOrTemplate): unknown {
    const obj: any = {};
    if (message.policy !== undefined) {
      obj.policy = AllocationPolicy_InstancePolicy.toJSON(message.policy);
    }
    if (message.instanceTemplate !== undefined) {
      obj.instanceTemplate = message.instanceTemplate;
    }
    if (message.installGpuDrivers !== false) {
      obj.installGpuDrivers = message.installGpuDrivers;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_InstancePolicyOrTemplate>, I>>(
    base?: I,
  ): AllocationPolicy_InstancePolicyOrTemplate {
    return AllocationPolicy_InstancePolicyOrTemplate.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_InstancePolicyOrTemplate>, I>>(
    object: I,
  ): AllocationPolicy_InstancePolicyOrTemplate {
    const message = createBaseAllocationPolicy_InstancePolicyOrTemplate();
    message.policy = (object.policy !== undefined && object.policy !== null)
      ? AllocationPolicy_InstancePolicy.fromPartial(object.policy)
      : undefined;
    message.instanceTemplate = object.instanceTemplate ?? undefined;
    message.installGpuDrivers = object.installGpuDrivers ?? false;
    return message;
  },
};

function createBaseAllocationPolicy_NetworkInterface(): AllocationPolicy_NetworkInterface {
  return { network: "", subnetwork: "", noExternalIpAddress: false };
}

export const AllocationPolicy_NetworkInterface: MessageFns<AllocationPolicy_NetworkInterface> = {
  encode(message: AllocationPolicy_NetworkInterface, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.network !== "") {
      writer.uint32(10).string(message.network);
    }
    if (message.subnetwork !== "") {
      writer.uint32(18).string(message.subnetwork);
    }
    if (message.noExternalIpAddress !== false) {
      writer.uint32(24).bool(message.noExternalIpAddress);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_NetworkInterface {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_NetworkInterface();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.network = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.subnetwork = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.noExternalIpAddress = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_NetworkInterface {
    return {
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      subnetwork: isSet(object.subnetwork) ? globalThis.String(object.subnetwork) : "",
      noExternalIpAddress: isSet(object.noExternalIpAddress) ? globalThis.Boolean(object.noExternalIpAddress) : false,
    };
  },

  toJSON(message: AllocationPolicy_NetworkInterface): unknown {
    const obj: any = {};
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.subnetwork !== "") {
      obj.subnetwork = message.subnetwork;
    }
    if (message.noExternalIpAddress !== false) {
      obj.noExternalIpAddress = message.noExternalIpAddress;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_NetworkInterface>, I>>(
    base?: I,
  ): AllocationPolicy_NetworkInterface {
    return AllocationPolicy_NetworkInterface.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_NetworkInterface>, I>>(
    object: I,
  ): AllocationPolicy_NetworkInterface {
    const message = createBaseAllocationPolicy_NetworkInterface();
    message.network = object.network ?? "";
    message.subnetwork = object.subnetwork ?? "";
    message.noExternalIpAddress = object.noExternalIpAddress ?? false;
    return message;
  },
};

function createBaseAllocationPolicy_NetworkPolicy(): AllocationPolicy_NetworkPolicy {
  return { networkInterfaces: [] };
}

export const AllocationPolicy_NetworkPolicy: MessageFns<AllocationPolicy_NetworkPolicy> = {
  encode(message: AllocationPolicy_NetworkPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.networkInterfaces) {
      AllocationPolicy_NetworkInterface.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_NetworkPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_NetworkPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.networkInterfaces.push(AllocationPolicy_NetworkInterface.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_NetworkPolicy {
    return {
      networkInterfaces: globalThis.Array.isArray(object?.networkInterfaces)
        ? object.networkInterfaces.map((e: any) => AllocationPolicy_NetworkInterface.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AllocationPolicy_NetworkPolicy): unknown {
    const obj: any = {};
    if (message.networkInterfaces?.length) {
      obj.networkInterfaces = message.networkInterfaces.map((e) => AllocationPolicy_NetworkInterface.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_NetworkPolicy>, I>>(base?: I): AllocationPolicy_NetworkPolicy {
    return AllocationPolicy_NetworkPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_NetworkPolicy>, I>>(
    object: I,
  ): AllocationPolicy_NetworkPolicy {
    const message = createBaseAllocationPolicy_NetworkPolicy();
    message.networkInterfaces =
      object.networkInterfaces?.map((e) => AllocationPolicy_NetworkInterface.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAllocationPolicy_PlacementPolicy(): AllocationPolicy_PlacementPolicy {
  return { collocation: "", maxDistance: Long.ZERO };
}

export const AllocationPolicy_PlacementPolicy: MessageFns<AllocationPolicy_PlacementPolicy> = {
  encode(message: AllocationPolicy_PlacementPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.collocation !== "") {
      writer.uint32(10).string(message.collocation);
    }
    if (!message.maxDistance.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.maxDistance.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_PlacementPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_PlacementPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.collocation = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.maxDistance = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_PlacementPolicy {
    return {
      collocation: isSet(object.collocation) ? globalThis.String(object.collocation) : "",
      maxDistance: isSet(object.maxDistance) ? Long.fromValue(object.maxDistance) : Long.ZERO,
    };
  },

  toJSON(message: AllocationPolicy_PlacementPolicy): unknown {
    const obj: any = {};
    if (message.collocation !== "") {
      obj.collocation = message.collocation;
    }
    if (!message.maxDistance.equals(Long.ZERO)) {
      obj.maxDistance = (message.maxDistance || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_PlacementPolicy>, I>>(
    base?: I,
  ): AllocationPolicy_PlacementPolicy {
    return AllocationPolicy_PlacementPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_PlacementPolicy>, I>>(
    object: I,
  ): AllocationPolicy_PlacementPolicy {
    const message = createBaseAllocationPolicy_PlacementPolicy();
    message.collocation = object.collocation ?? "";
    message.maxDistance = (object.maxDistance !== undefined && object.maxDistance !== null)
      ? Long.fromValue(object.maxDistance)
      : Long.ZERO;
    return message;
  },
};

function createBaseAllocationPolicy_LabelsEntry(): AllocationPolicy_LabelsEntry {
  return { key: "", value: "" };
}

export const AllocationPolicy_LabelsEntry: MessageFns<AllocationPolicy_LabelsEntry> = {
  encode(message: AllocationPolicy_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AllocationPolicy_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAllocationPolicy_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AllocationPolicy_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AllocationPolicy_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AllocationPolicy_LabelsEntry>, I>>(base?: I): AllocationPolicy_LabelsEntry {
    return AllocationPolicy_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AllocationPolicy_LabelsEntry>, I>>(object: I): AllocationPolicy_LabelsEntry {
    const message = createBaseAllocationPolicy_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTaskGroup(): TaskGroup {
  return {
    name: "",
    taskSpec: undefined,
    taskCount: Long.ZERO,
    parallelism: Long.ZERO,
    schedulingPolicy: 0,
    taskEnvironments: [],
    taskCountPerNode: Long.ZERO,
    requireHostsFile: false,
    permissiveSsh: false,
  };
}

export const TaskGroup: MessageFns<TaskGroup> = {
  encode(message: TaskGroup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.taskSpec !== undefined) {
      TaskSpec.encode(message.taskSpec, writer.uint32(26).fork()).join();
    }
    if (!message.taskCount.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.taskCount.toString());
    }
    if (!message.parallelism.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.parallelism.toString());
    }
    if (message.schedulingPolicy !== 0) {
      writer.uint32(48).int32(message.schedulingPolicy);
    }
    for (const v of message.taskEnvironments) {
      Environment.encode(v!, writer.uint32(74).fork()).join();
    }
    if (!message.taskCountPerNode.equals(Long.ZERO)) {
      writer.uint32(80).int64(message.taskCountPerNode.toString());
    }
    if (message.requireHostsFile !== false) {
      writer.uint32(88).bool(message.requireHostsFile);
    }
    if (message.permissiveSsh !== false) {
      writer.uint32(96).bool(message.permissiveSsh);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskGroup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskGroup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.taskSpec = TaskSpec.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.taskCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.parallelism = Long.fromString(reader.int64().toString());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.schedulingPolicy = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.taskEnvironments.push(Environment.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.taskCountPerNode = Long.fromString(reader.int64().toString());
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.requireHostsFile = reader.bool();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.permissiveSsh = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TaskGroup {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      taskSpec: isSet(object.taskSpec) ? TaskSpec.fromJSON(object.taskSpec) : undefined,
      taskCount: isSet(object.taskCount) ? Long.fromValue(object.taskCount) : Long.ZERO,
      parallelism: isSet(object.parallelism) ? Long.fromValue(object.parallelism) : Long.ZERO,
      schedulingPolicy: isSet(object.schedulingPolicy)
        ? taskGroup_SchedulingPolicyFromJSON(object.schedulingPolicy)
        : 0,
      taskEnvironments: globalThis.Array.isArray(object?.taskEnvironments)
        ? object.taskEnvironments.map((e: any) => Environment.fromJSON(e))
        : [],
      taskCountPerNode: isSet(object.taskCountPerNode) ? Long.fromValue(object.taskCountPerNode) : Long.ZERO,
      requireHostsFile: isSet(object.requireHostsFile) ? globalThis.Boolean(object.requireHostsFile) : false,
      permissiveSsh: isSet(object.permissiveSsh) ? globalThis.Boolean(object.permissiveSsh) : false,
    };
  },

  toJSON(message: TaskGroup): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.taskSpec !== undefined) {
      obj.taskSpec = TaskSpec.toJSON(message.taskSpec);
    }
    if (!message.taskCount.equals(Long.ZERO)) {
      obj.taskCount = (message.taskCount || Long.ZERO).toString();
    }
    if (!message.parallelism.equals(Long.ZERO)) {
      obj.parallelism = (message.parallelism || Long.ZERO).toString();
    }
    if (message.schedulingPolicy !== 0) {
      obj.schedulingPolicy = taskGroup_SchedulingPolicyToJSON(message.schedulingPolicy);
    }
    if (message.taskEnvironments?.length) {
      obj.taskEnvironments = message.taskEnvironments.map((e) => Environment.toJSON(e));
    }
    if (!message.taskCountPerNode.equals(Long.ZERO)) {
      obj.taskCountPerNode = (message.taskCountPerNode || Long.ZERO).toString();
    }
    if (message.requireHostsFile !== false) {
      obj.requireHostsFile = message.requireHostsFile;
    }
    if (message.permissiveSsh !== false) {
      obj.permissiveSsh = message.permissiveSsh;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskGroup>, I>>(base?: I): TaskGroup {
    return TaskGroup.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskGroup>, I>>(object: I): TaskGroup {
    const message = createBaseTaskGroup();
    message.name = object.name ?? "";
    message.taskSpec = (object.taskSpec !== undefined && object.taskSpec !== null)
      ? TaskSpec.fromPartial(object.taskSpec)
      : undefined;
    message.taskCount = (object.taskCount !== undefined && object.taskCount !== null)
      ? Long.fromValue(object.taskCount)
      : Long.ZERO;
    message.parallelism = (object.parallelism !== undefined && object.parallelism !== null)
      ? Long.fromValue(object.parallelism)
      : Long.ZERO;
    message.schedulingPolicy = object.schedulingPolicy ?? 0;
    message.taskEnvironments = object.taskEnvironments?.map((e) => Environment.fromPartial(e)) || [];
    message.taskCountPerNode = (object.taskCountPerNode !== undefined && object.taskCountPerNode !== null)
      ? Long.fromValue(object.taskCountPerNode)
      : Long.ZERO;
    message.requireHostsFile = object.requireHostsFile ?? false;
    message.permissiveSsh = object.permissiveSsh ?? false;
    return message;
  },
};

function createBaseServiceAccount(): ServiceAccount {
  return { email: "", scopes: [] };
}

export const ServiceAccount: MessageFns<ServiceAccount> = {
  encode(message: ServiceAccount, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.email !== "") {
      writer.uint32(10).string(message.email);
    }
    for (const v of message.scopes) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceAccount {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceAccount();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.email = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.scopes.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceAccount {
    return {
      email: isSet(object.email) ? globalThis.String(object.email) : "",
      scopes: globalThis.Array.isArray(object?.scopes) ? object.scopes.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ServiceAccount): unknown {
    const obj: any = {};
    if (message.email !== "") {
      obj.email = message.email;
    }
    if (message.scopes?.length) {
      obj.scopes = message.scopes;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ServiceAccount>, I>>(base?: I): ServiceAccount {
    return ServiceAccount.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ServiceAccount>, I>>(object: I): ServiceAccount {
    const message = createBaseServiceAccount();
    message.email = object.email ?? "";
    message.scopes = object.scopes?.map((e) => e) || [];
    return message;
  },
};

function createBaseJobEventData(): JobEventData {
  return { payload: undefined };
}

export const JobEventData: MessageFns<JobEventData> = {
  encode(message: JobEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Job.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): JobEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJobEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Job.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): JobEventData {
    return { payload: isSet(object.payload) ? Job.fromJSON(object.payload) : undefined };
  },

  toJSON(message: JobEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Job.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<JobEventData>, I>>(base?: I): JobEventData {
    return JobEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<JobEventData>, I>>(object: I): JobEventData {
    const message = createBaseJobEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Job.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
