// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/dataplex/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration";
import { Timestamp } from "../../../../protobuf/timestamp";

export const protobufPackage = "google.events.cloud.dataplex.v1";

/** State of a resource. */
export enum State {
  /** STATE_UNSPECIFIED - State is not specified. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Resource is active, i.e., ready to use. */
  ACTIVE = 1,
  /** CREATING - Resource is under creation. */
  CREATING = 2,
  /** DELETING - Resource is under deletion. */
  DELETING = 3,
  /** ACTION_REQUIRED - Resource is active but has unresolved actions. */
  ACTION_REQUIRED = 4,
  UNRECOGNIZED = -1,
}

export function stateFromJSON(object: any): State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return State.ACTIVE;
    case 2:
    case "CREATING":
      return State.CREATING;
    case 3:
    case "DELETING":
      return State.DELETING;
    case 4:
    case "ACTION_REQUIRED":
      return State.ACTION_REQUIRED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return State.UNRECOGNIZED;
  }
}

export function stateToJSON(object: State): string {
  switch (object) {
    case State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case State.ACTIVE:
      return "ACTIVE";
    case State.CREATING:
      return "CREATING";
    case State.DELETING:
      return "DELETING";
    case State.ACTION_REQUIRED:
      return "ACTION_REQUIRED";
    case State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The type of DataScan. */
export enum DataScanType {
  /** DATA_SCAN_TYPE_UNSPECIFIED - The DataScan type is unspecified. */
  DATA_SCAN_TYPE_UNSPECIFIED = 0,
  /** DATA_QUALITY - Data Quality scan. */
  DATA_QUALITY = 1,
  /** DATA_PROFILE - Data Profile scan. */
  DATA_PROFILE = 2,
  UNRECOGNIZED = -1,
}

export function dataScanTypeFromJSON(object: any): DataScanType {
  switch (object) {
    case 0:
    case "DATA_SCAN_TYPE_UNSPECIFIED":
      return DataScanType.DATA_SCAN_TYPE_UNSPECIFIED;
    case 1:
    case "DATA_QUALITY":
      return DataScanType.DATA_QUALITY;
    case 2:
    case "DATA_PROFILE":
      return DataScanType.DATA_PROFILE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataScanType.UNRECOGNIZED;
  }
}

export function dataScanTypeToJSON(object: DataScanType): string {
  switch (object) {
    case DataScanType.DATA_SCAN_TYPE_UNSPECIFIED:
      return "DATA_SCAN_TYPE_UNSPECIFIED";
    case DataScanType.DATA_QUALITY:
      return "DATA_QUALITY";
    case DataScanType.DATA_PROFILE:
      return "DATA_PROFILE";
    case DataScanType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A lake is a centralized repository for managing enterprise data across the
 * organization distributed across many cloud projects, and stored in a variety
 * of storage services such as Google Cloud Storage and BigQuery. The resources
 * attached to a lake are referred to as managed resources. Data within these
 * managed resources can be structured or unstructured. A lake provides data
 * admins with tools to organize, secure and manage their data at scale, and
 * provides data scientists and data engineers an integrated experience to
 * easily search, discover, analyze and transform data and associated metadata.
 */
export interface Lake {
  /**
   * Output only. The relative resource name of the lake, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the lake. This ID will
   * be different if the lake is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the lake was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the lake was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. User-defined labels for the lake. */
  labels: { [key: string]: string };
  /** Optional. Description of the lake. */
  description: string;
  /** Output only. Current state of the lake. */
  state: State;
  /**
   * Output only. Service account associated with this lake. This service
   * account must be authorized to access or operate on resources managed by the
   * lake.
   */
  serviceAccount: string;
  /**
   * Optional. Settings to manage lake and Dataproc Metastore service instance
   * association.
   */
  metastore?:
    | Lake_Metastore
    | undefined;
  /** Output only. Aggregated status of the underlying assets of the lake. */
  assetStatus?:
    | AssetStatus
    | undefined;
  /** Output only. Metastore status of the lake. */
  metastoreStatus?: Lake_MetastoreStatus | undefined;
}

/** Settings to manage association of Dataproc Metastore with a lake. */
export interface Lake_Metastore {
  /**
   * Optional. A relative reference to the Dataproc Metastore
   * (https://cloud.google.com/dataproc-metastore/docs) service associated
   * with the lake:
   * `projects/{project_id}/locations/{location_id}/services/{service_id}`
   */
  service: string;
}

/** Status of Lake and Dataproc Metastore service instance association. */
export interface Lake_MetastoreStatus {
  /** Current state of association. */
  state: Lake_MetastoreStatus_State;
  /** Additional information about the current status. */
  message: string;
  /** Last update time of the metastore status of the lake. */
  updateTime?:
    | Date
    | undefined;
  /** The URI of the endpoint used to access the Metastore service. */
  endpoint: string;
}

/** Current state of association. */
export enum Lake_MetastoreStatus_State {
  /** STATE_UNSPECIFIED - Unspecified. */
  STATE_UNSPECIFIED = 0,
  /** NONE - A Metastore service instance is not associated with the lake. */
  NONE = 1,
  /** READY - A Metastore service instance is attached to the lake. */
  READY = 2,
  /** UPDATING - Attach/detach is in progress. */
  UPDATING = 3,
  /** ERROR - Attach/detach could not be done due to errors. */
  ERROR = 4,
  UNRECOGNIZED = -1,
}

export function lake_MetastoreStatus_StateFromJSON(object: any): Lake_MetastoreStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Lake_MetastoreStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "NONE":
      return Lake_MetastoreStatus_State.NONE;
    case 2:
    case "READY":
      return Lake_MetastoreStatus_State.READY;
    case 3:
    case "UPDATING":
      return Lake_MetastoreStatus_State.UPDATING;
    case 4:
    case "ERROR":
      return Lake_MetastoreStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Lake_MetastoreStatus_State.UNRECOGNIZED;
  }
}

export function lake_MetastoreStatus_StateToJSON(object: Lake_MetastoreStatus_State): string {
  switch (object) {
    case Lake_MetastoreStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Lake_MetastoreStatus_State.NONE:
      return "NONE";
    case Lake_MetastoreStatus_State.READY:
      return "READY";
    case Lake_MetastoreStatus_State.UPDATING:
      return "UPDATING";
    case Lake_MetastoreStatus_State.ERROR:
      return "ERROR";
    case Lake_MetastoreStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Lake_LabelsEntry {
  key: string;
  value: string;
}

/** Aggregated status of the underlying assets of a lake or zone. */
export interface AssetStatus {
  /** Last update time of the status. */
  updateTime?:
    | Date
    | undefined;
  /** Number of active assets. */
  activeAssets: number;
  /**
   * Number of assets that are in process of updating the security policy on
   * attached resources.
   */
  securityPolicyApplyingAssets: number;
}

/**
 * A zone represents a logical group of related assets within a lake. A zone can
 * be used to map to organizational structure or represent stages of data
 * readiness from raw to curated. It provides managing behavior that is shared
 * or inherited by all contained assets.
 */
export interface Zone {
  /**
   * Output only. The relative resource name of the zone, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the zone. This ID will
   * be different if the zone is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the zone was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the zone was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. User defined labels for the zone. */
  labels: { [key: string]: string };
  /** Optional. Description of the zone. */
  description: string;
  /** Output only. Current state of the zone. */
  state: State;
  /** Required. Immutable. The type of the zone. */
  type: Zone_Type;
  /**
   * Optional. Specification of the discovery feature applied to data in this
   * zone.
   */
  discoverySpec?:
    | Zone_DiscoverySpec
    | undefined;
  /**
   * Required. Specification of the resources that are referenced by the assets
   * within this zone.
   */
  resourceSpec?:
    | Zone_ResourceSpec
    | undefined;
  /** Output only. Aggregated status of the underlying assets of the zone. */
  assetStatus?: AssetStatus | undefined;
}

/** Type of zone. */
export enum Zone_Type {
  /** TYPE_UNSPECIFIED - Zone type not specified. */
  TYPE_UNSPECIFIED = 0,
  /**
   * RAW - A zone that contains data that needs further processing before it is
   * considered generally ready for consumption and analytics workloads.
   */
  RAW = 1,
  /**
   * CURATED - A zone that contains data that is considered to be ready for broader
   * consumption and analytics workloads. Curated structured data stored in
   * Cloud Storage must conform to certain file formats (parquet, avro and
   * orc) and organized in a hive-compatible directory layout.
   */
  CURATED = 2,
  UNRECOGNIZED = -1,
}

export function zone_TypeFromJSON(object: any): Zone_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Zone_Type.TYPE_UNSPECIFIED;
    case 1:
    case "RAW":
      return Zone_Type.RAW;
    case 2:
    case "CURATED":
      return Zone_Type.CURATED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Zone_Type.UNRECOGNIZED;
  }
}

export function zone_TypeToJSON(object: Zone_Type): string {
  switch (object) {
    case Zone_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Zone_Type.RAW:
      return "RAW";
    case Zone_Type.CURATED:
      return "CURATED";
    case Zone_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings for resources attached as assets within a zone. */
export interface Zone_ResourceSpec {
  /**
   * Required. Immutable. The location type of the resources that are allowed
   * to be attached to the assets within this zone.
   */
  locationType: Zone_ResourceSpec_LocationType;
}

/** Location type of the resources attached to a zone. */
export enum Zone_ResourceSpec_LocationType {
  /** LOCATION_TYPE_UNSPECIFIED - Unspecified location type. */
  LOCATION_TYPE_UNSPECIFIED = 0,
  /** SINGLE_REGION - Resources that are associated with a single region. */
  SINGLE_REGION = 1,
  /** MULTI_REGION - Resources that are associated with a multi-region location. */
  MULTI_REGION = 2,
  UNRECOGNIZED = -1,
}

export function zone_ResourceSpec_LocationTypeFromJSON(object: any): Zone_ResourceSpec_LocationType {
  switch (object) {
    case 0:
    case "LOCATION_TYPE_UNSPECIFIED":
      return Zone_ResourceSpec_LocationType.LOCATION_TYPE_UNSPECIFIED;
    case 1:
    case "SINGLE_REGION":
      return Zone_ResourceSpec_LocationType.SINGLE_REGION;
    case 2:
    case "MULTI_REGION":
      return Zone_ResourceSpec_LocationType.MULTI_REGION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Zone_ResourceSpec_LocationType.UNRECOGNIZED;
  }
}

export function zone_ResourceSpec_LocationTypeToJSON(object: Zone_ResourceSpec_LocationType): string {
  switch (object) {
    case Zone_ResourceSpec_LocationType.LOCATION_TYPE_UNSPECIFIED:
      return "LOCATION_TYPE_UNSPECIFIED";
    case Zone_ResourceSpec_LocationType.SINGLE_REGION:
      return "SINGLE_REGION";
    case Zone_ResourceSpec_LocationType.MULTI_REGION:
      return "MULTI_REGION";
    case Zone_ResourceSpec_LocationType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings to manage the metadata discovery and publishing in a zone. */
export interface Zone_DiscoverySpec {
  /** Required. Whether discovery is enabled. */
  enabled: boolean;
  /**
   * Optional. The list of patterns to apply for selecting data to include
   * during discovery if only a subset of the data should considered. For
   * Cloud Storage bucket assets, these are interpreted as glob patterns used
   * to match object names. For BigQuery dataset assets, these are interpreted
   * as patterns to match table names.
   */
  includePatterns: string[];
  /**
   * Optional. The list of patterns to apply for selecting data to exclude
   * during discovery.  For Cloud Storage bucket assets, these are interpreted
   * as glob patterns used to match object names. For BigQuery dataset assets,
   * these are interpreted as patterns to match table names.
   */
  excludePatterns: string[];
  /** Optional. Configuration for CSV data. */
  csvOptions?:
    | Zone_DiscoverySpec_CsvOptions
    | undefined;
  /** Optional. Configuration for Json data. */
  jsonOptions?:
    | Zone_DiscoverySpec_JsonOptions
    | undefined;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running discovery periodically. Successive discovery runs must be
   * scheduled at least 60 minutes apart. The default value is to run
   * discovery every 60 minutes. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
   * from IANA time zone database. For example, `CRON_TZ=America/New_York 1
   * * * * *`, or `TZ=America/New_York 1 * * * *`.
   */
  schedule?: string | undefined;
}

/** Describe CSV and similar semi-structured data formats. */
export interface Zone_DiscoverySpec_CsvOptions {
  /**
   * Optional. The number of rows to interpret as header rows that should be
   * skipped when reading data rows.
   */
  headerRows: number;
  /**
   * Optional. The delimiter being used to separate values. This defaults to
   * ','.
   */
  delimiter: string;
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for CSV data.
   * If true, all columns will be registered as strings.
   */
  disableTypeInference: boolean;
}

/** Describe JSON data format. */
export interface Zone_DiscoverySpec_JsonOptions {
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for Json data.
   * If true, all columns will be registered as their primitive types
   * (strings, number or boolean).
   */
  disableTypeInference: boolean;
}

export interface Zone_LabelsEntry {
  key: string;
  value: string;
}

/**
 * An asset represents a cloud resource that is being managed within a lake as a
 * member of a zone.
 */
export interface Asset {
  /**
   * Output only. The relative resource name of the asset, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}`.
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the asset. This ID
   * will be different if the asset is deleted and re-created with the same
   * name.
   */
  uid: string;
  /** Output only. The time when the asset was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the asset was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. User defined labels for the asset. */
  labels: { [key: string]: string };
  /** Optional. Description of the asset. */
  description: string;
  /** Output only. Current state of the asset. */
  state: State;
  /** Required. Specification of the resource that is referenced by this asset. */
  resourceSpec?:
    | Asset_ResourceSpec
    | undefined;
  /** Output only. Status of the resource referenced by this asset. */
  resourceStatus?:
    | Asset_ResourceStatus
    | undefined;
  /**
   * Output only. Status of the security policy applied to resource referenced
   * by this asset.
   */
  securityStatus?:
    | Asset_SecurityStatus
    | undefined;
  /**
   * Optional. Specification of the discovery feature applied to data referenced
   * by this asset. When this spec is left unset, the asset will use the spec
   * set on the parent zone.
   */
  discoverySpec?:
    | Asset_DiscoverySpec
    | undefined;
  /**
   * Output only. Status of the discovery feature applied to data referenced by
   * this asset.
   */
  discoveryStatus?: Asset_DiscoveryStatus | undefined;
}

/**
 * Security policy status of the asset. Data security policy, i.e., readers,
 * writers & owners, should be specified in the lake/zone/asset IAM policy.
 */
export interface Asset_SecurityStatus {
  /**
   * The current state of the security policy applied to the attached
   * resource.
   */
  state: Asset_SecurityStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime?: Date | undefined;
}

/** The state of the security policy. */
export enum Asset_SecurityStatus_State {
  /** STATE_UNSPECIFIED - State unspecified. */
  STATE_UNSPECIFIED = 0,
  /** READY - Security policy has been successfully applied to the attached resource. */
  READY = 1,
  /**
   * APPLYING - Security policy is in the process of being applied to the attached
   * resource.
   */
  APPLYING = 2,
  /**
   * ERROR - Security policy could not be applied to the attached resource due to
   * errors.
   */
  ERROR = 3,
  UNRECOGNIZED = -1,
}

export function asset_SecurityStatus_StateFromJSON(object: any): Asset_SecurityStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_SecurityStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "READY":
      return Asset_SecurityStatus_State.READY;
    case 2:
    case "APPLYING":
      return Asset_SecurityStatus_State.APPLYING;
    case 3:
    case "ERROR":
      return Asset_SecurityStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_SecurityStatus_State.UNRECOGNIZED;
  }
}

export function asset_SecurityStatus_StateToJSON(object: Asset_SecurityStatus_State): string {
  switch (object) {
    case Asset_SecurityStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_SecurityStatus_State.READY:
      return "READY";
    case Asset_SecurityStatus_State.APPLYING:
      return "APPLYING";
    case Asset_SecurityStatus_State.ERROR:
      return "ERROR";
    case Asset_SecurityStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Settings to manage the metadata discovery and publishing for an asset. */
export interface Asset_DiscoverySpec {
  /** Optional. Whether discovery is enabled. */
  enabled: boolean;
  /**
   * Optional. The list of patterns to apply for selecting data to include
   * during discovery if only a subset of the data should considered.  For
   * Cloud Storage bucket assets, these are interpreted as glob patterns used
   * to match object names. For BigQuery dataset assets, these are interpreted
   * as patterns to match table names.
   */
  includePatterns: string[];
  /**
   * Optional. The list of patterns to apply for selecting data to exclude
   * during discovery.  For Cloud Storage bucket assets, these are interpreted
   * as glob patterns used to match object names. For BigQuery dataset assets,
   * these are interpreted as patterns to match table names.
   */
  excludePatterns: string[];
  /** Optional. Configuration for CSV data. */
  csvOptions?:
    | Asset_DiscoverySpec_CsvOptions
    | undefined;
  /** Optional. Configuration for Json data. */
  jsonOptions?:
    | Asset_DiscoverySpec_JsonOptions
    | undefined;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running discovery periodically. Successive discovery runs must be
   * scheduled at least 60 minutes apart. The default value is to run
   * discovery every 60 minutes. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid string
   * from IANA time zone database. For example, `CRON_TZ=America/New_York 1
   * * * * *`, or `TZ=America/New_York 1 * * * *`.
   */
  schedule?: string | undefined;
}

/** Describe CSV and similar semi-structured data formats. */
export interface Asset_DiscoverySpec_CsvOptions {
  /**
   * Optional. The number of rows to interpret as header rows that should be
   * skipped when reading data rows.
   */
  headerRows: number;
  /**
   * Optional. The delimiter being used to separate values. This defaults to
   * ','.
   */
  delimiter: string;
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for CSV data.
   * If true, all columns will be registered as strings.
   */
  disableTypeInference: boolean;
}

/** Describe JSON data format. */
export interface Asset_DiscoverySpec_JsonOptions {
  /** Optional. The character encoding of the data. The default is UTF-8. */
  encoding: string;
  /**
   * Optional. Whether to disable the inference of data type for Json data.
   * If true, all columns will be registered as their primitive types
   * (strings, number or boolean).
   */
  disableTypeInference: boolean;
}

/** Identifies the cloud resource that is referenced by this asset. */
export interface Asset_ResourceSpec {
  /**
   * Immutable. Relative name of the cloud resource that contains the data
   * that is being managed within a lake. For example:
   *   `projects/{project_number}/buckets/{bucket_id}`
   *   `projects/{project_number}/datasets/{dataset_id}`
   */
  name: string;
  /** Required. Immutable. Type of resource. */
  type: Asset_ResourceSpec_Type;
  /**
   * Optional. Determines how read permissions are handled for each asset and
   * their associated tables. Only available to storage buckets assets.
   */
  readAccessMode: Asset_ResourceSpec_AccessMode;
}

/** Type of resource. */
export enum Asset_ResourceSpec_Type {
  /** TYPE_UNSPECIFIED - Type not specified. */
  TYPE_UNSPECIFIED = 0,
  /** STORAGE_BUCKET - Cloud Storage bucket. */
  STORAGE_BUCKET = 1,
  /** BIGQUERY_DATASET - BigQuery dataset. */
  BIGQUERY_DATASET = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceSpec_TypeFromJSON(object: any): Asset_ResourceSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Asset_ResourceSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "STORAGE_BUCKET":
      return Asset_ResourceSpec_Type.STORAGE_BUCKET;
    case 2:
    case "BIGQUERY_DATASET":
      return Asset_ResourceSpec_Type.BIGQUERY_DATASET;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceSpec_Type.UNRECOGNIZED;
  }
}

export function asset_ResourceSpec_TypeToJSON(object: Asset_ResourceSpec_Type): string {
  switch (object) {
    case Asset_ResourceSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Asset_ResourceSpec_Type.STORAGE_BUCKET:
      return "STORAGE_BUCKET";
    case Asset_ResourceSpec_Type.BIGQUERY_DATASET:
      return "BIGQUERY_DATASET";
    case Asset_ResourceSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Access Mode determines how data stored within the resource is read. This
 * is only applicable to storage bucket assets.
 */
export enum Asset_ResourceSpec_AccessMode {
  /** ACCESS_MODE_UNSPECIFIED - Access mode unspecified. */
  ACCESS_MODE_UNSPECIFIED = 0,
  /** DIRECT - Default. Data is accessed directly using storage APIs. */
  DIRECT = 1,
  /** MANAGED - Data is accessed through a managed interface using BigQuery APIs. */
  MANAGED = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceSpec_AccessModeFromJSON(object: any): Asset_ResourceSpec_AccessMode {
  switch (object) {
    case 0:
    case "ACCESS_MODE_UNSPECIFIED":
      return Asset_ResourceSpec_AccessMode.ACCESS_MODE_UNSPECIFIED;
    case 1:
    case "DIRECT":
      return Asset_ResourceSpec_AccessMode.DIRECT;
    case 2:
    case "MANAGED":
      return Asset_ResourceSpec_AccessMode.MANAGED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceSpec_AccessMode.UNRECOGNIZED;
  }
}

export function asset_ResourceSpec_AccessModeToJSON(object: Asset_ResourceSpec_AccessMode): string {
  switch (object) {
    case Asset_ResourceSpec_AccessMode.ACCESS_MODE_UNSPECIFIED:
      return "ACCESS_MODE_UNSPECIFIED";
    case Asset_ResourceSpec_AccessMode.DIRECT:
      return "DIRECT";
    case Asset_ResourceSpec_AccessMode.MANAGED:
      return "MANAGED";
    case Asset_ResourceSpec_AccessMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Status of the resource referenced by an asset. */
export interface Asset_ResourceStatus {
  /** The current state of the managed resource. */
  state: Asset_ResourceStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime?:
    | Date
    | undefined;
  /** Output only. Service account associated with the BigQuery Connection. */
  managedAccessIdentity: string;
}

/** The state of a resource. */
export enum Asset_ResourceStatus_State {
  /** STATE_UNSPECIFIED - State unspecified. */
  STATE_UNSPECIFIED = 0,
  /** READY - Resource does not have any errors. */
  READY = 1,
  /** ERROR - Resource has errors. */
  ERROR = 2,
  UNRECOGNIZED = -1,
}

export function asset_ResourceStatus_StateFromJSON(object: any): Asset_ResourceStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_ResourceStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "READY":
      return Asset_ResourceStatus_State.READY;
    case 2:
    case "ERROR":
      return Asset_ResourceStatus_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_ResourceStatus_State.UNRECOGNIZED;
  }
}

export function asset_ResourceStatus_StateToJSON(object: Asset_ResourceStatus_State): string {
  switch (object) {
    case Asset_ResourceStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_ResourceStatus_State.READY:
      return "READY";
    case Asset_ResourceStatus_State.ERROR:
      return "ERROR";
    case Asset_ResourceStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Status of discovery for an asset. */
export interface Asset_DiscoveryStatus {
  /** The current status of the discovery feature. */
  state: Asset_DiscoveryStatus_State;
  /** Additional information about the current state. */
  message: string;
  /** Last update time of the status. */
  updateTime?:
    | Date
    | undefined;
  /** The start time of the last discovery run. */
  lastRunTime?:
    | Date
    | undefined;
  /** Data Stats of the asset reported by discovery. */
  stats?:
    | Asset_DiscoveryStatus_Stats
    | undefined;
  /** The duration of the last discovery run. */
  lastRunDuration?: Duration | undefined;
}

/** Current state of discovery. */
export enum Asset_DiscoveryStatus_State {
  /** STATE_UNSPECIFIED - State is unspecified. */
  STATE_UNSPECIFIED = 0,
  /** SCHEDULED - Discovery for the asset is scheduled. */
  SCHEDULED = 1,
  /** IN_PROGRESS - Discovery for the asset is running. */
  IN_PROGRESS = 2,
  /**
   * PAUSED - Discovery for the asset is currently paused (e.g. due to a lack
   * of available resources). It will be automatically resumed.
   */
  PAUSED = 3,
  /** DISABLED - Discovery for the asset is disabled. */
  DISABLED = 5,
  UNRECOGNIZED = -1,
}

export function asset_DiscoveryStatus_StateFromJSON(object: any): Asset_DiscoveryStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Asset_DiscoveryStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "SCHEDULED":
      return Asset_DiscoveryStatus_State.SCHEDULED;
    case 2:
    case "IN_PROGRESS":
      return Asset_DiscoveryStatus_State.IN_PROGRESS;
    case 3:
    case "PAUSED":
      return Asset_DiscoveryStatus_State.PAUSED;
    case 5:
    case "DISABLED":
      return Asset_DiscoveryStatus_State.DISABLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Asset_DiscoveryStatus_State.UNRECOGNIZED;
  }
}

export function asset_DiscoveryStatus_StateToJSON(object: Asset_DiscoveryStatus_State): string {
  switch (object) {
    case Asset_DiscoveryStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Asset_DiscoveryStatus_State.SCHEDULED:
      return "SCHEDULED";
    case Asset_DiscoveryStatus_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Asset_DiscoveryStatus_State.PAUSED:
      return "PAUSED";
    case Asset_DiscoveryStatus_State.DISABLED:
      return "DISABLED";
    case Asset_DiscoveryStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The aggregated data statistics for the asset reported by discovery. */
export interface Asset_DiscoveryStatus_Stats {
  /** The count of data items within the referenced resource. */
  dataItems: Long;
  /** The number of stored data bytes within the referenced resource. */
  dataSize: Long;
  /** The count of table entities within the referenced resource. */
  tables: Long;
  /** The count of fileset entities within the referenced resource. */
  filesets: Long;
}

export interface Asset_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Environment represents a user-visible compute infrastructure for analytics
 * within a lake.
 */
export interface Environment {
  /**
   * Output only. The relative resource name of the environment, of the form:
   * projects/{project_id}/locations/{location_id}/lakes/{lake_id}/environment/{environment_id}
   */
  name: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /**
   * Output only. System generated globally unique ID for the environment. This
   * ID will be different if the environment is deleted and re-created with the
   * same name.
   */
  uid: string;
  /** Output only. Environment creation time. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the environment was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. User defined labels for the environment. */
  labels: { [key: string]: string };
  /** Optional. Description of the environment. */
  description: string;
  /** Output only. Current state of the environment. */
  state: State;
  /** Required. Infrastructure specification for the Environment. */
  infrastructureSpec?:
    | Environment_InfrastructureSpec
    | undefined;
  /** Optional. Configuration for sessions created for this environment. */
  sessionSpec?:
    | Environment_SessionSpec
    | undefined;
  /** Output only. Status of sessions created for this environment. */
  sessionStatus?:
    | Environment_SessionStatus
    | undefined;
  /**
   * Output only. URI Endpoints to access sessions associated with the
   * Environment.
   */
  endpoints?: Environment_Endpoints | undefined;
}

/** Configuration for the underlying infrastructure used to run workloads. */
export interface Environment_InfrastructureSpec {
  /** Optional. Compute resources needed for analyze interactive workloads. */
  compute?:
    | Environment_InfrastructureSpec_ComputeResources
    | undefined;
  /**
   * Required. Software Runtime Configuration for analyze interactive
   * workloads.
   */
  osImage?: Environment_InfrastructureSpec_OsImageRuntime | undefined;
}

/** Compute resources associated with the analyze interactive workloads. */
export interface Environment_InfrastructureSpec_ComputeResources {
  /** Optional. Size in GB of the disk. Default is 100 GB. */
  diskSizeGb: number;
  /**
   * Optional. Total number of nodes in the sessions created for this
   * environment.
   */
  nodeCount: number;
  /**
   * Optional. Max configurable nodes.
   * If max_node_count > node_count, then auto-scaling is enabled.
   */
  maxNodeCount: number;
}

/** Software Runtime Configuration to run Analyze. */
export interface Environment_InfrastructureSpec_OsImageRuntime {
  /** Required. Dataplex Image version. */
  imageVersion: string;
  /**
   * Optional. List of Java jars to be included in the runtime environment.
   * Valid input includes Cloud Storage URIs to Jar binaries.
   * For example, gs://bucket-name/my/path/to/file.jar
   */
  javaLibraries: string[];
  /**
   * Optional. A list of python packages to be installed.
   * Valid formats include Cloud Storage URI to a PIP installable library.
   * For example, gs://bucket-name/my/path/to/lib.tar.gz
   */
  pythonPackages: string[];
  /**
   * Optional. Spark properties to provide configuration for use in sessions
   * created for this environment. The properties to set on daemon config
   * files. Property keys are specified in `prefix:property` format. The
   * prefix must be "spark".
   */
  properties: { [key: string]: string };
}

export interface Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
  key: string;
  value: string;
}

/** Configuration for sessions created for this environment. */
export interface Environment_SessionSpec {
  /**
   * Optional. The idle time configuration of the session. The session will be
   * auto-terminated at the end of this period.
   */
  maxIdleDuration?:
    | Duration
    | undefined;
  /**
   * Optional. If True, this causes sessions to be pre-created and available
   * for faster startup to enable interactive exploration use-cases. This
   * defaults to False to avoid additional billed charges. These can only be
   * set to True for the environment with name set to "default", and with
   * default configuration.
   */
  enableFastStartup: boolean;
}

/** Status of sessions created for this environment. */
export interface Environment_SessionStatus {
  /**
   * Output only. Queries over sessions to mark whether the environment is
   * currently active or not
   */
  active: boolean;
}

/** URI Endpoints to access sessions associated with the Environment. */
export interface Environment_Endpoints {
  /** Output only. URI to serve notebook APIs */
  notebooks: string;
  /** Output only. URI to serve SQL APIs */
  sql: string;
}

export interface Environment_LabelsEntry {
  key: string;
  value: string;
}

/** DataScan scheduling and trigger settings. */
export interface Trigger {
  /** The scan runs once via `RunDataScan` API. */
  onDemand?:
    | Trigger_OnDemand
    | undefined;
  /** The scan is scheduled to run periodically. */
  schedule?: Trigger_Schedule | undefined;
}

/** The scan runs once via `RunDataScan` API. */
export interface Trigger_OnDemand {
}

/** The scan is scheduled to run periodically. */
export interface Trigger_Schedule {
  /**
   * Required. [Cron](https://en.wikipedia.org/wiki/Cron) schedule for running
   * scans periodically.
   *
   * To explicitly set a timezone in the cron tab, apply a prefix in the
   * cron tab: **"CRON_TZ=${IANA_TIME_ZONE}"** or **"TZ=${IANA_TIME_ZONE}"**.
   * The **${IANA_TIME_ZONE}** may only be a valid string from IANA time zone
   * database
   * ([wikipedia](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones#List)).
   * For example, `CRON_TZ=America/New_York 1 * * * *`, or
   * `TZ=America/New_York 1 * * * *`.
   *
   * This field is required for Schedule scans.
   */
  cron: string;
}

/** The data source for DataScan. */
export interface DataSource {
  /**
   * Immutable. The Dataplex entity that represents the data source (e.g.
   * BigQuery table) for DataScan, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}`.
   */
  entity?: string | undefined;
}

/** The data scanned during processing (e.g. in incremental DataScan) */
export interface ScannedData {
  /** The range denoted by values of an incremental field */
  incrementalField?: ScannedData_IncrementalField | undefined;
}

/** A data range denoted by a pair of start/end values of a field. */
export interface ScannedData_IncrementalField {
  /**
   * The field that contains values which monotonically increases over time
   * (e.g. a timestamp column).
   */
  field: string;
  /** Value that marks the start of the range. */
  start: string;
  /** Value that marks the end of the range. */
  end: string;
}

/** DataProfileScan related setting. */
export interface DataProfileSpec {
}

/**
 * DataProfileResult defines the output of DataProfileScan. Each field of the
 * table will have field type specific profile result.
 */
export interface DataProfileResult {
  /** The count of rows scanned. */
  rowCount: Long;
  /** The profile information per field. */
  profile?:
    | DataProfileResult_Profile
    | undefined;
  /** The data scanned for this result. */
  scannedData?: ScannedData | undefined;
}

/** Contains name, type, mode and field type specific profile information. */
export interface DataProfileResult_Profile {
  /** List of fields with structural and profile information for each field. */
  fields: DataProfileResult_Profile_Field[];
}

/** A field within a table. */
export interface DataProfileResult_Profile_Field {
  /** The name of the field. */
  name: string;
  /**
   * The field data type. Possible values include:
   *
   * * STRING
   * * BYTE
   * * INT64
   * * INT32
   * * INT16
   * * DOUBLE
   * * FLOAT
   * * DECIMAL
   * * BOOLEAN
   * * BINARY
   * * TIMESTAMP
   * * DATE
   * * TIME
   * * NULL
   * * RECORD
   */
  type: string;
  /**
   * The mode of the field. Possible values include:
   *
   * * REQUIRED, if it is a required field.
   * * NULLABLE, if it is an optional field.
   * * REPEATED, if it is a repeated field.
   */
  mode: string;
  /** Profile information for the corresponding field. */
  profile?: DataProfileResult_Profile_Field_ProfileInfo | undefined;
}

/** The profile information for each field type. */
export interface DataProfileResult_Profile_Field_ProfileInfo {
  /** Ratio of rows with null value against total scanned rows. */
  nullRatio: number;
  /**
   * Ratio of rows with distinct values against total scanned rows.
   * Not available for complex non-groupable field type RECORD and fields
   * with REPEATABLE mode.
   */
  distinctRatio: number;
  /**
   * The list of top N non-null values and number of times they occur in
   * the scanned data. N is 10 or equal to the number of distinct values
   * in the field, whichever is smaller. Not available for complex
   * non-groupable field type RECORD and fields with REPEATABLE mode.
   */
  topNValues: DataProfileResult_Profile_Field_ProfileInfo_TopNValue[];
  /** String type field information. */
  stringProfile?:
    | DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo
    | undefined;
  /** Integer type field information. */
  integerProfile?:
    | DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo
    | undefined;
  /** Double type field information. */
  doubleProfile?: DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo | undefined;
}

/** The profile information for a string type field. */
export interface DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
  /** Minimum length of non-null values in the scanned data. */
  minLength: Long;
  /** Maximum length of non-null values in the scanned data. */
  maxLength: Long;
  /** Average length of non-null values in the scanned data. */
  averageLength: number;
}

/** The profile information for an integer type field. */
export interface DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
  /**
   * Average of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  average: number;
  /**
   * Standard deviation of non-null values in the scanned data. NaN, if
   * the field has a NaN.
   */
  standardDeviation: number;
  /**
   * Minimum of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  min: Long;
  /**
   * A quartile divides the number of data points into four parts, or
   * quarters, of more-or-less equal size. Three main quartiles used
   * are: The first quartile (Q1) splits off the lowest 25% of data from
   * the highest 75%. It is also known as the lower or 25th empirical
   * quartile, as 25% of the data is below this point. The second
   * quartile (Q2) is the median of a data set. So, 50% of the data lies
   * below this point. The third quartile (Q3) splits off the highest
   * 25% of data from the lowest 75%. It is known as the upper or 75th
   * empirical quartile, as 75% of the data lies below this point.
   * Here, the quartiles is provided as an ordered list of quartile
   * values for the scanned data, occurring in order Q1, median, Q3.
   */
  quartiles: Long[];
  /**
   * Maximum of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  max: Long;
}

/** The profile information for a double type field. */
export interface DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
  /**
   * Average of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  average: number;
  /**
   * Standard deviation of non-null values in the scanned data. NaN, if
   * the field has a NaN.
   */
  standardDeviation: number;
  /**
   * Minimum of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  min: number;
  /**
   * A quartile divides the number of data points into four parts, or
   * quarters, of more-or-less equal size. Three main quartiles used
   * are: The first quartile (Q1) splits off the lowest 25% of data from
   * the highest 75%. It is also known as the lower or 25th empirical
   * quartile, as 25% of the data is below this point. The second
   * quartile (Q2) is the median of a data set. So, 50% of the data lies
   * below this point. The third quartile (Q3) splits off the highest
   * 25% of data from the lowest 75%. It is known as the upper or 75th
   * empirical quartile, as 75% of the data lies below this point.
   * Here, the quartiles is provided as an ordered list of quartile
   * values for the scanned data, occurring in order Q1, median, Q3.
   */
  quartiles: number[];
  /**
   * Maximum of non-null values in the scanned data. NaN, if the field
   * has a NaN.
   */
  max: number;
}

/** Top N non-null values in the scanned data. */
export interface DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
  /** String value of a top N non-null value. */
  value: string;
  /** Count of the corresponding value in the scanned data. */
  count: Long;
}

/** DataQualityScan related setting. */
export interface DataQualitySpec {
  /**
   * The list of rules to evaluate against a data source. At least one rule is
   * required.
   */
  rules: DataQualityRule[];
}

/** The output of a DataQualityScan. */
export interface DataQualityResult {
  /** Overall data quality result -- `true` if all rules passed. */
  passed: boolean;
  /** A list of results at the dimension level. */
  dimensions: DataQualityDimensionResult[];
  /** A list of all the rules in a job, and their results. */
  rules: DataQualityRuleResult[];
  /** The count of rows processed. */
  rowCount: Long;
  /** The data scanned for this result. */
  scannedData?: ScannedData | undefined;
}

/** DataQualityRuleResult provides a more detailed, per-rule view of the results. */
export interface DataQualityRuleResult {
  /** The rule specified in the DataQualitySpec, as is. */
  rule?:
    | DataQualityRule
    | undefined;
  /** Whether the rule passed or failed. */
  passed: boolean;
  /**
   * The number of rows a rule was evaluated against. This field is only valid
   * for ColumnMap type rules.
   *
   * Evaluated count can be configured to either
   *
   * * include all rows (default) - with `null` rows automatically failing rule
   * evaluation, or
   * * exclude `null` rows from the `evaluated_count`, by setting
   * `ignore_nulls = true`.
   */
  evaluatedCount: Long;
  /**
   * The number of rows which passed a rule evaluation.
   * This field is only valid for ColumnMap type rules.
   */
  passedCount: Long;
  /** The number of rows with null values in the specified column. */
  nullCount: Long;
  /**
   * The ratio of **passed_count / evaluated_count**.
   * This field is only valid for ColumnMap type rules.
   */
  passRatio: number;
  /**
   * The query to find rows that did not pass this rule.
   * Only applies to ColumnMap and RowCondition rules.
   */
  failingRowsQuery: string;
}

/**
 * DataQualityDimensionResult provides a more detailed, per-dimension view of
 * the results.
 */
export interface DataQualityDimensionResult {
  /** Whether the dimension passed or failed. */
  passed: boolean;
}

/** A rule captures data quality intent about a data source. */
export interface DataQualityRule {
  /**
   * ColumnMap rule which evaluates whether each column value lies between a
   * specified range.
   */
  rangeExpectation?:
    | DataQualityRule_RangeExpectation
    | undefined;
  /** ColumnMap rule which evaluates whether each column value is null. */
  nonNullExpectation?:
    | DataQualityRule_NonNullExpectation
    | undefined;
  /**
   * ColumnMap rule which evaluates whether each column value is contained by
   * a specified set.
   */
  setExpectation?:
    | DataQualityRule_SetExpectation
    | undefined;
  /**
   * ColumnMap rule which evaluates whether each column value matches a
   * specified regex.
   */
  regexExpectation?:
    | DataQualityRule_RegexExpectation
    | undefined;
  /** ColumnAggregate rule which evaluates whether the column has duplicates. */
  uniquenessExpectation?:
    | DataQualityRule_UniquenessExpectation
    | undefined;
  /**
   * ColumnAggregate rule which evaluates whether the column aggregate
   * statistic lies between a specified range.
   */
  statisticRangeExpectation?:
    | DataQualityRule_StatisticRangeExpectation
    | undefined;
  /**
   * Table rule which evaluates whether each row passes the specified
   * condition.
   */
  rowConditionExpectation?:
    | DataQualityRule_RowConditionExpectation
    | undefined;
  /** Table rule which evaluates whether the provided expression is true. */
  tableConditionExpectation?:
    | DataQualityRule_TableConditionExpectation
    | undefined;
  /** Optional. The unnested column which this rule is evaluated against. */
  column: string;
  /**
   * Optional. Rows with `null` values will automatically fail a rule, unless
   * `ignore_null` is `true`. In that case, such `null` rows are trivially
   * considered passing.
   *
   * Only applicable to ColumnMap rules.
   */
  ignoreNull: boolean;
  /**
   * Required. The dimension a rule belongs to. Results are also aggregated at
   * the dimension level. Supported dimensions are **["COMPLETENESS",
   * "ACCURACY", "CONSISTENCY", "VALIDITY", "UNIQUENESS", "INTEGRITY"]**
   */
  dimension: string;
  /**
   * Optional. The minimum ratio of **passing_rows / total_rows** required to
   * pass this rule, with a range of [0.0, 1.0].
   *
   * 0 indicates default value (i.e. 1.0).
   */
  threshold: number;
}

/** Evaluates whether each column value lies between a specified range. */
export interface DataQualityRule_RangeExpectation {
  /**
   * Optional. The minimum column value allowed for a row to pass this
   * validation. At least one of `min_value` and `max_value` need to be
   * provided.
   */
  minValue: string;
  /**
   * Optional. The maximum column value allowed for a row to pass this
   * validation. At least one of `min_value` and `max_value` need to be
   * provided.
   */
  maxValue: string;
  /**
   * Optional. Whether each value needs to be strictly greater than ('>') the
   * minimum, or if equality is allowed.
   *
   * Only relevant if a `min_value` has been defined. Default = false.
   */
  strictMinEnabled: boolean;
  /**
   * Optional. Whether each value needs to be strictly lesser than ('<') the
   * maximum, or if equality is allowed.
   *
   * Only relevant if a `max_value` has been defined. Default = false.
   */
  strictMaxEnabled: boolean;
}

/** Evaluates whether each column value is null. */
export interface DataQualityRule_NonNullExpectation {
}

/** Evaluates whether each column value is contained by a specified set. */
export interface DataQualityRule_SetExpectation {
  /** Expected values for the column value. */
  values: string[];
}

/** Evaluates whether each column value matches a specified regex. */
export interface DataQualityRule_RegexExpectation {
  /** A regular expression the column value is expected to match. */
  regex: string;
}

/** Evaluates whether the column has duplicates. */
export interface DataQualityRule_UniquenessExpectation {
}

/**
 * Evaluates whether the column aggregate statistic lies between a specified
 * range.
 */
export interface DataQualityRule_StatisticRangeExpectation {
  statistic: DataQualityRule_StatisticRangeExpectation_ColumnStatistic;
  /**
   * The minimum column statistic value allowed for a row to pass this
   * validation.
   *
   * At least one of `min_value` and `max_value` need to be provided.
   */
  minValue: string;
  /**
   * The maximum column statistic value allowed for a row to pass this
   * validation.
   *
   * At least one of `min_value` and `max_value` need to be provided.
   */
  maxValue: string;
  /**
   * Whether column statistic needs to be strictly greater than ('>')
   * the minimum, or if equality is allowed.
   *
   * Only relevant if a `min_value` has been defined. Default = false.
   */
  strictMinEnabled: boolean;
  /**
   * Whether column statistic needs to be strictly lesser than ('<') the
   * maximum, or if equality is allowed.
   *
   * Only relevant if a `max_value` has been defined. Default = false.
   */
  strictMaxEnabled: boolean;
}

export enum DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
  /** STATISTIC_UNDEFINED - Unspecified statistic type */
  STATISTIC_UNDEFINED = 0,
  /** MEAN - Evaluate the column mean */
  MEAN = 1,
  /** MIN - Evaluate the column min */
  MIN = 2,
  /** MAX - Evaluate the column max */
  MAX = 3,
  UNRECOGNIZED = -1,
}

export function dataQualityRule_StatisticRangeExpectation_ColumnStatisticFromJSON(
  object: any,
): DataQualityRule_StatisticRangeExpectation_ColumnStatistic {
  switch (object) {
    case 0:
    case "STATISTIC_UNDEFINED":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.STATISTIC_UNDEFINED;
    case 1:
    case "MEAN":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MEAN;
    case 2:
    case "MIN":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MIN;
    case 3:
    case "MAX":
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MAX;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DataQualityRule_StatisticRangeExpectation_ColumnStatistic.UNRECOGNIZED;
  }
}

export function dataQualityRule_StatisticRangeExpectation_ColumnStatisticToJSON(
  object: DataQualityRule_StatisticRangeExpectation_ColumnStatistic,
): string {
  switch (object) {
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.STATISTIC_UNDEFINED:
      return "STATISTIC_UNDEFINED";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MEAN:
      return "MEAN";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MIN:
      return "MIN";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.MAX:
      return "MAX";
    case DataQualityRule_StatisticRangeExpectation_ColumnStatistic.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Evaluates whether each row passes the specified condition.
 *
 * The SQL expression needs to use BigQuery standard SQL syntax and should
 * produce a boolean value per row as the result.
 *
 * Example: col1 >= 0 AND col2 < 10
 */
export interface DataQualityRule_RowConditionExpectation {
  /** The SQL expression. */
  sqlExpression: string;
}

/**
 * Evaluates whether the provided expression is true.
 *
 * The SQL expression needs to use BigQuery standard SQL syntax and should
 * produce a scalar boolean result.
 *
 * Example: MIN(col1) >= 0
 */
export interface DataQualityRule_TableConditionExpectation {
  /** The SQL expression. */
  sqlExpression: string;
}

/**
 * ResourceAccessSpec holds the access control configuration to be enforced
 * on the resources, for example, Cloud Storage bucket, BigQuery dataset,
 * BigQuery table.
 */
export interface ResourceAccessSpec {
  /**
   * Optional. The format of strings follows the pattern followed by IAM in the
   * bindings. user:{email}, serviceAccount:{email} group:{email}.
   * The set of principals to be granted reader role on the resource.
   */
  readers: string[];
  /** Optional. The set of principals to be granted writer role on the resource. */
  writers: string[];
  /** Optional. The set of principals to be granted owner role on the resource. */
  owners: string[];
}

/**
 * DataAccessSpec holds the access control configuration to be enforced on data
 * stored within resources (eg: rows, columns in BigQuery Tables). When
 * associated with data, the data is only accessible to
 * principals explicitly granted access through the DataAccessSpec. Principals
 * with access to the containing resource are not implicitly granted access.
 */
export interface DataAccessSpec {
  /**
   * Optional. The format of strings follows the pattern followed by IAM in the
   * bindings. user:{email}, serviceAccount:{email} group:{email}.
   * The set of principals to be granted reader role on data
   * stored within resources.
   */
  readers: string[];
}

/**
 * DataTaxonomy represents a set of hierarchical DataAttributes resources,
 * grouped with a common theme Eg: 'SensitiveDataTaxonomy' can have attributes
 * to manage PII data. It is defined at project level.
 */
export interface DataTaxonomy {
  /**
   * Output only. The relative resource name of the DataTaxonomy, of the form:
   * projects/{project_number}/locations/{location_id}/dataTaxonomies/{data_taxonomy_id}.
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the dataTaxonomy. This
   * ID will be different if the DataTaxonomy is deleted and re-created with the
   * same name.
   */
  uid: string;
  /** Output only. The time when the DataTaxonomy was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the DataTaxonomy was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Description of the DataTaxonomy. */
  description: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /** Optional. User-defined labels for the DataTaxonomy. */
  labels: { [key: string]: string };
  /** Output only. The number of attributes in the DataTaxonomy. */
  attributeCount: number;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
}

export interface DataTaxonomy_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Denotes one dataAttribute in a dataTaxonomy, for example, PII.
 * DataAttribute resources can be defined in a hierarchy.
 * A single dataAttribute resource can contain specs of multiple types
 *
 * ```
 * PII
 *   - ResourceAccessSpec :
 *                 - readers :foo@bar.com
 *   - DataAccessSpec :
 *                 - readers :bar@foo.com
 * ```
 */
export interface DataAttribute {
  /**
   * Output only. The relative resource name of the dataAttribute, of the form:
   * projects/{project_number}/locations/{location_id}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}.
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the DataAttribute.
   * This ID will be different if the DataAttribute is deleted and re-created
   * with the same name.
   */
  uid: string;
  /** Output only. The time when the DataAttribute was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the DataAttribute was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Description of the DataAttribute. */
  description: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /** Optional. User-defined labels for the DataAttribute. */
  labels: { [key: string]: string };
  /**
   * Optional. The ID of the parent DataAttribute resource, should belong to the
   * same data taxonomy. Circular dependency in parent chain is not valid.
   * Maximum depth of the hierarchy allowed is 4.
   * [a -> b -> c -> d -> e, depth = 4]
   */
  parentId: string;
  /** Output only. The number of child attributes present for this attribute. */
  attributeCount: number;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Optional. Specified when applied to a resource (eg: Cloud Storage bucket,
   * BigQuery dataset, BigQuery table).
   */
  resourceAccessSpec?:
    | ResourceAccessSpec
    | undefined;
  /**
   * Optional. Specified when applied to data stored on the resource (eg: rows,
   * columns in BigQuery Tables).
   */
  dataAccessSpec?: DataAccessSpec | undefined;
}

export interface DataAttribute_LabelsEntry {
  key: string;
  value: string;
}

/**
 * DataAttributeBinding represents binding of attributes to resources. Eg: Bind
 * 'CustomerInfo' entity with 'PII' attribute.
 */
export interface DataAttributeBinding {
  /**
   * Output only. The relative resource name of the Data Attribute Binding, of
   * the form:
   * projects/{project_number}/locations/{location}/dataAttributeBindings/{data_attribute_binding_id}
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the
   * DataAttributeBinding. This ID will be different if the DataAttributeBinding
   * is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the DataAttributeBinding was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the DataAttributeBinding was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Description of the DataAttributeBinding. */
  description: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /** Optional. User-defined labels for the DataAttributeBinding. */
  labels: { [key: string]: string };
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   * Etags must be used when calling the DeleteDataAttributeBinding and the
   * UpdateDataAttributeBinding method.
   */
  etag: string;
  /**
   * Optional. Immutable. The resource name of the resource that is associated
   * to attributes. Presently, only entity resource is supported in the form:
   * projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/entities/{entity_id}
   * Must belong in the same project and region as the attribute binding, and
   * there can only exist one active binding for a resource.
   */
  resource?:
    | string
    | undefined;
  /**
   * Optional. List of attributes to be associated with the resource, provided
   * in the form:
   * projects/{project}/locations/{location}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
   */
  attributes: string[];
  /**
   * Optional. The list of paths for items within the associated resource (eg.
   * columns within a table) along with attribute bindings.
   */
  paths: DataAttributeBinding_Path[];
}

/**
 * Represents a subresource of a given resource, and associated bindings with
 * it.
 */
export interface DataAttributeBinding_Path {
  /**
   * Required. The name identifier of the path.
   * Nested columns should be of the form: 'country.state.city'.
   */
  name: string;
  /**
   * Optional. List of attributes to be associated with the path of the
   * resource, provided in the form:
   * projects/{project}/locations/{location}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
   */
  attributes: string[];
}

export interface DataAttributeBinding_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Represents a user-visible job which provides the insights for the related
 * data source.
 *
 * For example:
 *
 * * Data Quality: generates queries based on the rules and runs against the
 *   data to get data quality check results.
 * * Data Profile: analyzes the data in table(s) and generates insights about
 *   the structure, content and relationships (such as null percent,
 *   cardinality, min/max/mean, etc).
 */
export interface DataScan {
  /**
   * Output only. The relative resource name of the scan, of the form:
   * `projects/{project}/locations/{location_id}/dataScans/{datascan_id}`,
   * where `project` refers to a *project_id* or *project_number* and
   * `location_id` refers to a GCP region.
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the scan. This ID will
   * be different if the scan is deleted and re-created with the same name.
   */
  uid: string;
  /**
   * Optional. Description of the scan.
   *
   * * Must be between 1-1024 characters.
   */
  description: string;
  /**
   * Optional. User friendly display name.
   *
   * * Must be between 1-256 characters.
   */
  displayName: string;
  /** Optional. User-defined labels for the scan. */
  labels: { [key: string]: string };
  /** Output only. Current state of the DataScan. */
  state: State;
  /** Output only. The time when the scan was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the scan was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Required. The data source for DataScan. */
  data?:
    | DataSource
    | undefined;
  /**
   * Optional. DataScan execution settings.
   *
   * If not specified, the fields in it will use their default values.
   */
  executionSpec?:
    | DataScan_ExecutionSpec
    | undefined;
  /** Output only. Status of the data scan execution. */
  executionStatus?:
    | DataScan_ExecutionStatus
    | undefined;
  /** Output only. The type of DataScan. */
  type: DataScanType;
  /** DataQualityScan related setting. */
  dataQualitySpec?:
    | DataQualitySpec
    | undefined;
  /** DataProfileScan related setting. */
  dataProfileSpec?:
    | DataProfileSpec
    | undefined;
  /** Output only. The result of the data quality scan. */
  dataQualityResult?:
    | DataQualityResult
    | undefined;
  /** Output only. The result of the data profile scan. */
  dataProfileResult?: DataProfileResult | undefined;
}

/** DataScan execution settings. */
export interface DataScan_ExecutionSpec {
  /**
   * Optional. Spec related to how often and when a scan should be triggered.
   *
   * If not specified, the default is `OnDemand`, which means the scan will
   * not run until the user calls `RunDataScan` API.
   */
  trigger?:
    | Trigger
    | undefined;
  /**
   * Immutable. The unnested field (of type *Date* or *Timestamp*) that
   * contains values which monotonically increase over time.
   *
   * If not specified, a data scan will run for all data in the table.
   */
  field?: string | undefined;
}

/** Status of the data scan execution. */
export interface DataScan_ExecutionStatus {
  /** The time when the latest DataScanJob started. */
  latestJobStartTime?:
    | Date
    | undefined;
  /** The time when the latest DataScanJob ended. */
  latestJobEndTime?: Date | undefined;
}

export interface DataScan_LabelsEntry {
  key: string;
  value: string;
}

/** A task represents a user-visible job. */
export interface Task {
  /**
   * Output only. The relative resource name of the task, of the form:
   * projects/{project_number}/locations/{location_id}/lakes/{lake_id}/
   * tasks/{task_id}.
   */
  name: string;
  /**
   * Output only. System generated globally unique ID for the task. This ID will
   * be different if the task is deleted and re-created with the same name.
   */
  uid: string;
  /** Output only. The time when the task was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the task was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Description of the task. */
  description: string;
  /** Optional. User friendly display name. */
  displayName: string;
  /** Output only. Current state of the task. */
  state: State;
  /** Optional. User-defined labels for the task. */
  labels: { [key: string]: string };
  /** Required. Spec related to how often and when a task should be triggered. */
  triggerSpec?:
    | Task_TriggerSpec
    | undefined;
  /** Required. Spec related to how a task is executed. */
  executionSpec?:
    | Task_ExecutionSpec
    | undefined;
  /** Output only. Status of the latest task executions. */
  executionStatus?:
    | Task_ExecutionStatus
    | undefined;
  /** Config related to running custom Spark tasks. */
  spark?:
    | Task_SparkTaskConfig
    | undefined;
  /** Config related to running scheduled Notebooks. */
  notebook?: Task_NotebookTaskConfig | undefined;
}

/** Configuration for the underlying infrastructure used to run workloads. */
export interface Task_InfrastructureSpec {
  /** Compute resources needed for a Task when using Dataproc Serverless. */
  batch?:
    | Task_InfrastructureSpec_BatchComputeResources
    | undefined;
  /** Container Image Runtime Configuration. */
  containerImage?:
    | Task_InfrastructureSpec_ContainerImageRuntime
    | undefined;
  /** Vpc network. */
  vpcNetwork?: Task_InfrastructureSpec_VpcNetwork | undefined;
}

/** Batch compute resources associated with the task. */
export interface Task_InfrastructureSpec_BatchComputeResources {
  /**
   * Optional. Total number of job executors.
   * Executor Count should be between 2 and 100. [Default=2]
   */
  executorsCount: number;
  /**
   * Optional. Max configurable executors.
   * If max_executors_count > executors_count, then auto-scaling is enabled.
   * Max Executor Count should be between 2 and 1000. [Default=1000]
   */
  maxExecutorsCount: number;
}

/** Container Image Runtime Configuration used with Batch execution. */
export interface Task_InfrastructureSpec_ContainerImageRuntime {
  /** Optional. Container image to use. */
  image: string;
  /**
   * Optional. A list of Java JARS to add to the classpath.
   * Valid input includes Cloud Storage URIs to Jar binaries.
   * For example, gs://bucket-name/my/path/to/file.jar
   */
  javaJars: string[];
  /**
   * Optional. A list of python packages to be installed.
   * Valid formats include Cloud Storage URI to a PIP installable library.
   * For example, gs://bucket-name/my/path/to/lib.tar.gz
   */
  pythonPackages: string[];
  /**
   * Optional. Override to common configuration of open source components
   * installed on the Dataproc cluster. The properties to set on daemon
   * config files. Property keys are specified in `prefix:property` format,
   * for example `core:hadoop.tmp.dir`. For more information, see [Cluster
   * properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
   */
  properties: { [key: string]: string };
}

export interface Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
  key: string;
  value: string;
}

/** Cloud VPC Network used to run the infrastructure. */
export interface Task_InfrastructureSpec_VpcNetwork {
  /**
   * Optional. The Cloud VPC network in which the job is run. By default,
   * the Cloud VPC network named Default within the project is used.
   */
  network?:
    | string
    | undefined;
  /** Optional. The Cloud VPC sub-network in which the job is run. */
  subNetwork?:
    | string
    | undefined;
  /** Optional. List of network tags to apply to the job. */
  networkTags: string[];
}

/** Task scheduling and trigger settings. */
export interface Task_TriggerSpec {
  /** Required. Immutable. Trigger type of the user-specified Task. */
  type: Task_TriggerSpec_Type;
  /**
   * Optional. The first run of the task will be after this time.
   * If not specified, the task will run shortly after being submitted if
   * ON_DEMAND and based on the schedule if RECURRING.
   */
  startTime?:
    | Date
    | undefined;
  /**
   * Optional. Prevent the task from executing.
   * This does not cancel already running tasks. It is intended to temporarily
   * disable RECURRING tasks.
   */
  disabled: boolean;
  /**
   * Optional. Number of retry attempts before aborting.
   * Set to zero to never attempt to retry a failed task.
   */
  maxRetries: number;
  /**
   * Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for
   * running tasks periodically. To explicitly set a timezone to the cron
   * tab, apply a prefix in the cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or
   * "TZ=${IANA_TIME_ZONE}". The ${IANA_TIME_ZONE} may only be a valid
   * string from IANA time zone database. For example,
   * `CRON_TZ=America/New_York 1 * * * *`, or `TZ=America/New_York 1 * * *
   * *`. This field is required for RECURRING tasks.
   */
  schedule?: string | undefined;
}

/** Determines how often and when the job will run. */
export enum Task_TriggerSpec_Type {
  /** TYPE_UNSPECIFIED - Unspecified trigger type. */
  TYPE_UNSPECIFIED = 0,
  /** ON_DEMAND - The task runs one-time shortly after Task Creation. */
  ON_DEMAND = 1,
  /** RECURRING - The task is scheduled to run periodically. */
  RECURRING = 2,
  UNRECOGNIZED = -1,
}

export function task_TriggerSpec_TypeFromJSON(object: any): Task_TriggerSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return Task_TriggerSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "ON_DEMAND":
      return Task_TriggerSpec_Type.ON_DEMAND;
    case 2:
    case "RECURRING":
      return Task_TriggerSpec_Type.RECURRING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Task_TriggerSpec_Type.UNRECOGNIZED;
  }
}

export function task_TriggerSpec_TypeToJSON(object: Task_TriggerSpec_Type): string {
  switch (object) {
    case Task_TriggerSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case Task_TriggerSpec_Type.ON_DEMAND:
      return "ON_DEMAND";
    case Task_TriggerSpec_Type.RECURRING:
      return "RECURRING";
    case Task_TriggerSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Execution related settings, like retry and service_account. */
export interface Task_ExecutionSpec {
  /**
   * Optional. The arguments to pass to the task.
   * The args can use placeholders of the format ${placeholder} as
   * part of key/value string. These will be interpolated before passing the
   * args to the driver. Currently supported placeholders:
   * - ${task_id}
   * - ${job_time}
   * To pass positional args, set the key as TASK_ARGS. The value should be a
   * comma-separated string of all the positional arguments. To use a
   * delimiter other than comma, refer to
   * https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of
   * other keys being present in the args, then TASK_ARGS will be passed as
   * the last argument.
   */
  args: { [key: string]: string };
  /**
   * Required. Service account to use to execute a task.
   * If not provided, the default Compute service account for the project is
   * used.
   */
  serviceAccount: string;
  /**
   * Optional. The project in which jobs are run. By default, the project
   * containing the Lake is used. If a project is provided, the
   * [ExecutionSpec.service_account][google.cloud.dataplex.v1.Task.ExecutionSpec.service_account]
   * must belong to this project.
   */
  project: string;
  /** Optional. The maximum duration after which the job execution is expired. */
  maxJobExecutionLifetime?:
    | Duration
    | undefined;
  /**
   * Optional. The Cloud KMS key to use for encryption, of the form:
   * `projects/{project_number}/locations/{location_id}/keyRings/{key-ring-name}/cryptoKeys/{key-name}`.
   */
  kmsKey: string;
}

export interface Task_ExecutionSpec_ArgsEntry {
  key: string;
  value: string;
}

/** User-specified config for running a Spark task. */
export interface Task_SparkTaskConfig {
  /**
   * The Cloud Storage URI of the jar file that contains the main class.
   * The execution args are passed in as a sequence of named process
   * arguments (`--key=value`).
   */
  mainJarFileUri?:
    | string
    | undefined;
  /**
   * The name of the driver's main class. The jar file that contains the
   * class must be in the default CLASSPATH or specified in
   * `jar_file_uris`.
   * The execution args are passed in as a sequence of named process
   * arguments (`--key=value`).
   */
  mainClass?:
    | string
    | undefined;
  /**
   * The Gcloud Storage URI of the main Python file to use as the driver.
   * Must be a .py file. The execution args are passed in as a sequence of
   * named process arguments (`--key=value`).
   */
  pythonScriptFile?:
    | string
    | undefined;
  /**
   * A reference to a query file. This can be the Cloud Storage URI of the
   * query file or it can the path to a SqlScript Content. The execution
   * args are used to declare a set of script variables
   * (`set key="value";`).
   */
  sqlScriptFile?:
    | string
    | undefined;
  /**
   * The query text.
   * The execution args are used to declare a set of script variables
   * (`set key="value";`).
   */
  sqlScript?:
    | string
    | undefined;
  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   */
  fileUris: string[];
  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   */
  archiveUris: string[];
  /** Optional. Infrastructure specification for the execution. */
  infrastructureSpec?: Task_InfrastructureSpec | undefined;
}

/** Config for running scheduled notebooks. */
export interface Task_NotebookTaskConfig {
  /**
   * Required. Path to input notebook. This can be the Cloud Storage URI of
   * the notebook file or the path to a Notebook Content. The execution args
   * are accessible as environment variables
   * (`TASK_key=value`).
   */
  notebook: string;
  /** Optional. Infrastructure specification for the execution. */
  infrastructureSpec?:
    | Task_InfrastructureSpec
    | undefined;
  /**
   * Optional. Cloud Storage URIs of files to be placed in the working
   * directory of each executor.
   */
  fileUris: string[];
  /**
   * Optional. Cloud Storage URIs of archives to be extracted into the working
   * directory of each executor. Supported file types: .jar, .tar, .tar.gz,
   * .tgz, and .zip.
   */
  archiveUris: string[];
}

/** Status of the task execution (e.g. Jobs). */
export interface Task_ExecutionStatus {
  /** Output only. Last update time of the status. */
  updateTime?:
    | Date
    | undefined;
  /** Output only. latest job execution */
  latestJob?: Job | undefined;
}

export interface Task_LabelsEntry {
  key: string;
  value: string;
}

/** A job represents an instance of a task. */
export interface Job {
  /**
   * Output only. The relative resource name of the job, of the form:
   * `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
   */
  name: string;
  /** Output only. System generated globally unique ID for the job. */
  uid: string;
  /** Output only. The time when the job was started. */
  startTime?:
    | Date
    | undefined;
  /** Output only. The time when the job ended. */
  endTime?:
    | Date
    | undefined;
  /** Output only. Execution state for the job. */
  state: Job_State;
  /**
   * Output only. The number of times the job has been retried (excluding the
   * initial attempt).
   */
  retryCount: number;
  /** Output only. The underlying service running a job. */
  service: Job_Service;
  /**
   * Output only. The full resource name for the job run under a particular
   * service.
   */
  serviceJob: string;
  /** Output only. Additional information about the current state. */
  message: string;
}

export enum Job_Service {
  /** SERVICE_UNSPECIFIED - Service used to run the job is unspecified. */
  SERVICE_UNSPECIFIED = 0,
  /** DATAPROC - Dataproc service is used to run this job. */
  DATAPROC = 1,
  UNRECOGNIZED = -1,
}

export function job_ServiceFromJSON(object: any): Job_Service {
  switch (object) {
    case 0:
    case "SERVICE_UNSPECIFIED":
      return Job_Service.SERVICE_UNSPECIFIED;
    case 1:
    case "DATAPROC":
      return Job_Service.DATAPROC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_Service.UNRECOGNIZED;
  }
}

export function job_ServiceToJSON(object: Job_Service): string {
  switch (object) {
    case Job_Service.SERVICE_UNSPECIFIED:
      return "SERVICE_UNSPECIFIED";
    case Job_Service.DATAPROC:
      return "DATAPROC";
    case Job_Service.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export enum Job_State {
  /** STATE_UNSPECIFIED - The job state is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The job is running. */
  RUNNING = 1,
  /** CANCELLING - The job is cancelling. */
  CANCELLING = 2,
  /** CANCELLED - The job cancellation was successful. */
  CANCELLED = 3,
  /** SUCCEEDED - The job completed successfully. */
  SUCCEEDED = 4,
  /** FAILED - The job is no longer running due to an error. */
  FAILED = 5,
  /** ABORTED - The job was cancelled outside of Dataplex. */
  ABORTED = 6,
  UNRECOGNIZED = -1,
}

export function job_StateFromJSON(object: any): Job_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Job_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return Job_State.RUNNING;
    case 2:
    case "CANCELLING":
      return Job_State.CANCELLING;
    case 3:
    case "CANCELLED":
      return Job_State.CANCELLED;
    case 4:
    case "SUCCEEDED":
      return Job_State.SUCCEEDED;
    case 5:
    case "FAILED":
      return Job_State.FAILED;
    case 6:
    case "ABORTED":
      return Job_State.ABORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_State.UNRECOGNIZED;
  }
}

export function job_StateToJSON(object: Job_State): string {
  switch (object) {
    case Job_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Job_State.RUNNING:
      return "RUNNING";
    case Job_State.CANCELLING:
      return "CANCELLING";
    case Job_State.CANCELLED:
      return "CANCELLED";
    case Job_State.SUCCEEDED:
      return "SUCCEEDED";
    case Job_State.FAILED:
      return "FAILED";
    case Job_State.ABORTED:
      return "ABORTED";
    case Job_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The data within all Task events. */
export interface TaskEventData {
  /** Optional. The Task event payload. Unset for deletion events. */
  payload?: Task | undefined;
}

/** The data within all Zone events. */
export interface ZoneEventData {
  /** Optional. The Zone event payload. Unset for deletion events. */
  payload?: Zone | undefined;
}

/** The data within all Asset events. */
export interface AssetEventData {
  /** Optional. The Asset event payload. Unset for deletion events. */
  payload?: Asset | undefined;
}

/** The data within all Environment events. */
export interface EnvironmentEventData {
  /** Optional. The Environment event payload. Unset for deletion events. */
  payload?: Environment | undefined;
}

/** The data within all DataTaxonomy events. */
export interface DataTaxonomyEventData {
  /** Optional. The DataTaxonomy event payload. Unset for deletion events. */
  payload?: DataTaxonomy | undefined;
}

/** The data within all DataAttributeBinding events. */
export interface DataAttributeBindingEventData {
  /**
   * Optional. The DataAttributeBinding event payload. Unset for deletion
   * events.
   */
  payload?: DataAttributeBinding | undefined;
}

/** The data within all DataScan events. */
export interface DataScanEventData {
  /** Optional. The DataScan event payload. Unset for deletion events. */
  payload?: DataScan | undefined;
}

/** The data within all Lake events. */
export interface LakeEventData {
  /** Optional. The Lake event payload. Unset for deletion events. */
  payload?: Lake | undefined;
}

/** The data within all DataAttribute events. */
export interface DataAttributeEventData {
  /** Optional. The DataAttribute event payload. Unset for deletion events. */
  payload?: DataAttribute | undefined;
}

function createBaseLake(): Lake {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    serviceAccount: "",
    metastore: undefined,
    assetStatus: undefined,
    metastoreStatus: undefined,
  };
}

export const Lake: MessageFns<Lake> = {
  encode(message: Lake, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Lake_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(74).string(message.serviceAccount);
    }
    if (message.metastore !== undefined) {
      Lake_Metastore.encode(message.metastore, writer.uint32(818).fork()).join();
    }
    if (message.assetStatus !== undefined) {
      AssetStatus.encode(message.assetStatus, writer.uint32(826).fork()).join();
    }
    if (message.metastoreStatus !== undefined) {
      Lake_MetastoreStatus.encode(message.metastoreStatus, writer.uint32(834).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Lake_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 102: {
          if (tag !== 818) {
            break;
          }

          message.metastore = Lake_Metastore.decode(reader, reader.uint32());
          continue;
        }
        case 103: {
          if (tag !== 826) {
            break;
          }

          message.assetStatus = AssetStatus.decode(reader, reader.uint32());
          continue;
        }
        case 104: {
          if (tag !== 834) {
            break;
          }

          message.metastoreStatus = Lake_MetastoreStatus.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      metastore: isSet(object.metastore) ? Lake_Metastore.fromJSON(object.metastore) : undefined,
      assetStatus: isSet(object.assetStatus) ? AssetStatus.fromJSON(object.assetStatus) : undefined,
      metastoreStatus: isSet(object.metastoreStatus)
        ? Lake_MetastoreStatus.fromJSON(object.metastoreStatus)
        : undefined,
    };
  },

  toJSON(message: Lake): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.metastore !== undefined) {
      obj.metastore = Lake_Metastore.toJSON(message.metastore);
    }
    if (message.assetStatus !== undefined) {
      obj.assetStatus = AssetStatus.toJSON(message.assetStatus);
    }
    if (message.metastoreStatus !== undefined) {
      obj.metastoreStatus = Lake_MetastoreStatus.toJSON(message.metastoreStatus);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Lake>, I>>(base?: I): Lake {
    return Lake.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Lake>, I>>(object: I): Lake {
    const message = createBaseLake();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.serviceAccount = object.serviceAccount ?? "";
    message.metastore = (object.metastore !== undefined && object.metastore !== null)
      ? Lake_Metastore.fromPartial(object.metastore)
      : undefined;
    message.assetStatus = (object.assetStatus !== undefined && object.assetStatus !== null)
      ? AssetStatus.fromPartial(object.assetStatus)
      : undefined;
    message.metastoreStatus = (object.metastoreStatus !== undefined && object.metastoreStatus !== null)
      ? Lake_MetastoreStatus.fromPartial(object.metastoreStatus)
      : undefined;
    return message;
  },
};

function createBaseLake_Metastore(): Lake_Metastore {
  return { service: "" };
}

export const Lake_Metastore: MessageFns<Lake_Metastore> = {
  encode(message: Lake_Metastore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_Metastore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_Metastore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_Metastore {
    return { service: isSet(object.service) ? globalThis.String(object.service) : "" };
  },

  toJSON(message: Lake_Metastore): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Lake_Metastore>, I>>(base?: I): Lake_Metastore {
    return Lake_Metastore.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Lake_Metastore>, I>>(object: I): Lake_Metastore {
    const message = createBaseLake_Metastore();
    message.service = object.service ?? "";
    return message;
  },
};

function createBaseLake_MetastoreStatus(): Lake_MetastoreStatus {
  return { state: 0, message: "", updateTime: undefined, endpoint: "" };
}

export const Lake_MetastoreStatus: MessageFns<Lake_MetastoreStatus> = {
  encode(message: Lake_MetastoreStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.endpoint !== "") {
      writer.uint32(34).string(message.endpoint);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_MetastoreStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_MetastoreStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.endpoint = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_MetastoreStatus {
    return {
      state: isSet(object.state) ? lake_MetastoreStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      endpoint: isSet(object.endpoint) ? globalThis.String(object.endpoint) : "",
    };
  },

  toJSON(message: Lake_MetastoreStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = lake_MetastoreStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.endpoint !== "") {
      obj.endpoint = message.endpoint;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Lake_MetastoreStatus>, I>>(base?: I): Lake_MetastoreStatus {
    return Lake_MetastoreStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Lake_MetastoreStatus>, I>>(object: I): Lake_MetastoreStatus {
    const message = createBaseLake_MetastoreStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.endpoint = object.endpoint ?? "";
    return message;
  },
};

function createBaseLake_LabelsEntry(): Lake_LabelsEntry {
  return { key: "", value: "" };
}

export const Lake_LabelsEntry: MessageFns<Lake_LabelsEntry> = {
  encode(message: Lake_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Lake_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLake_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Lake_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Lake_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Lake_LabelsEntry>, I>>(base?: I): Lake_LabelsEntry {
    return Lake_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Lake_LabelsEntry>, I>>(object: I): Lake_LabelsEntry {
    const message = createBaseLake_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAssetStatus(): AssetStatus {
  return { updateTime: undefined, activeAssets: 0, securityPolicyApplyingAssets: 0 };
}

export const AssetStatus: MessageFns<AssetStatus> = {
  encode(message: AssetStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(10).fork()).join();
    }
    if (message.activeAssets !== 0) {
      writer.uint32(16).int32(message.activeAssets);
    }
    if (message.securityPolicyApplyingAssets !== 0) {
      writer.uint32(24).int32(message.securityPolicyApplyingAssets);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AssetStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAssetStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.activeAssets = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.securityPolicyApplyingAssets = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AssetStatus {
    return {
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      activeAssets: isSet(object.activeAssets) ? globalThis.Number(object.activeAssets) : 0,
      securityPolicyApplyingAssets: isSet(object.securityPolicyApplyingAssets)
        ? globalThis.Number(object.securityPolicyApplyingAssets)
        : 0,
    };
  },

  toJSON(message: AssetStatus): unknown {
    const obj: any = {};
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.activeAssets !== 0) {
      obj.activeAssets = Math.round(message.activeAssets);
    }
    if (message.securityPolicyApplyingAssets !== 0) {
      obj.securityPolicyApplyingAssets = Math.round(message.securityPolicyApplyingAssets);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AssetStatus>, I>>(base?: I): AssetStatus {
    return AssetStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AssetStatus>, I>>(object: I): AssetStatus {
    const message = createBaseAssetStatus();
    message.updateTime = object.updateTime ?? undefined;
    message.activeAssets = object.activeAssets ?? 0;
    message.securityPolicyApplyingAssets = object.securityPolicyApplyingAssets ?? 0;
    return message;
  },
};

function createBaseZone(): Zone {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    type: 0,
    discoverySpec: undefined,
    resourceSpec: undefined,
    assetStatus: undefined,
  };
}

export const Zone: MessageFns<Zone> = {
  encode(message: Zone, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Zone_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.type !== 0) {
      writer.uint32(72).int32(message.type);
    }
    if (message.discoverySpec !== undefined) {
      Zone_DiscoverySpec.encode(message.discoverySpec, writer.uint32(826).fork()).join();
    }
    if (message.resourceSpec !== undefined) {
      Zone_ResourceSpec.encode(message.resourceSpec, writer.uint32(834).fork()).join();
    }
    if (message.assetStatus !== undefined) {
      AssetStatus.encode(message.assetStatus, writer.uint32(842).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Zone_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 103: {
          if (tag !== 826) {
            break;
          }

          message.discoverySpec = Zone_DiscoverySpec.decode(reader, reader.uint32());
          continue;
        }
        case 104: {
          if (tag !== 834) {
            break;
          }

          message.resourceSpec = Zone_ResourceSpec.decode(reader, reader.uint32());
          continue;
        }
        case 105: {
          if (tag !== 842) {
            break;
          }

          message.assetStatus = AssetStatus.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      type: isSet(object.type) ? zone_TypeFromJSON(object.type) : 0,
      discoverySpec: isSet(object.discoverySpec) ? Zone_DiscoverySpec.fromJSON(object.discoverySpec) : undefined,
      resourceSpec: isSet(object.resourceSpec) ? Zone_ResourceSpec.fromJSON(object.resourceSpec) : undefined,
      assetStatus: isSet(object.assetStatus) ? AssetStatus.fromJSON(object.assetStatus) : undefined,
    };
  },

  toJSON(message: Zone): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.type !== 0) {
      obj.type = zone_TypeToJSON(message.type);
    }
    if (message.discoverySpec !== undefined) {
      obj.discoverySpec = Zone_DiscoverySpec.toJSON(message.discoverySpec);
    }
    if (message.resourceSpec !== undefined) {
      obj.resourceSpec = Zone_ResourceSpec.toJSON(message.resourceSpec);
    }
    if (message.assetStatus !== undefined) {
      obj.assetStatus = AssetStatus.toJSON(message.assetStatus);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone>, I>>(base?: I): Zone {
    return Zone.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone>, I>>(object: I): Zone {
    const message = createBaseZone();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.type = object.type ?? 0;
    message.discoverySpec = (object.discoverySpec !== undefined && object.discoverySpec !== null)
      ? Zone_DiscoverySpec.fromPartial(object.discoverySpec)
      : undefined;
    message.resourceSpec = (object.resourceSpec !== undefined && object.resourceSpec !== null)
      ? Zone_ResourceSpec.fromPartial(object.resourceSpec)
      : undefined;
    message.assetStatus = (object.assetStatus !== undefined && object.assetStatus !== null)
      ? AssetStatus.fromPartial(object.assetStatus)
      : undefined;
    return message;
  },
};

function createBaseZone_ResourceSpec(): Zone_ResourceSpec {
  return { locationType: 0 };
}

export const Zone_ResourceSpec: MessageFns<Zone_ResourceSpec> = {
  encode(message: Zone_ResourceSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.locationType !== 0) {
      writer.uint32(8).int32(message.locationType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_ResourceSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_ResourceSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.locationType = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_ResourceSpec {
    return {
      locationType: isSet(object.locationType) ? zone_ResourceSpec_LocationTypeFromJSON(object.locationType) : 0,
    };
  },

  toJSON(message: Zone_ResourceSpec): unknown {
    const obj: any = {};
    if (message.locationType !== 0) {
      obj.locationType = zone_ResourceSpec_LocationTypeToJSON(message.locationType);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone_ResourceSpec>, I>>(base?: I): Zone_ResourceSpec {
    return Zone_ResourceSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone_ResourceSpec>, I>>(object: I): Zone_ResourceSpec {
    const message = createBaseZone_ResourceSpec();
    message.locationType = object.locationType ?? 0;
    return message;
  },
};

function createBaseZone_DiscoverySpec(): Zone_DiscoverySpec {
  return {
    enabled: false,
    includePatterns: [],
    excludePatterns: [],
    csvOptions: undefined,
    jsonOptions: undefined,
    schedule: undefined,
  };
}

export const Zone_DiscoverySpec: MessageFns<Zone_DiscoverySpec> = {
  encode(message: Zone_DiscoverySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    for (const v of message.includePatterns) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.excludePatterns) {
      writer.uint32(26).string(v!);
    }
    if (message.csvOptions !== undefined) {
      Zone_DiscoverySpec_CsvOptions.encode(message.csvOptions, writer.uint32(34).fork()).join();
    }
    if (message.jsonOptions !== undefined) {
      Zone_DiscoverySpec_JsonOptions.encode(message.jsonOptions, writer.uint32(42).fork()).join();
    }
    if (message.schedule !== undefined) {
      writer.uint32(82).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.includePatterns.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.excludePatterns.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.csvOptions = Zone_DiscoverySpec_CsvOptions.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.jsonOptions = Zone_DiscoverySpec_JsonOptions.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.schedule = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      includePatterns: globalThis.Array.isArray(object?.includePatterns)
        ? object.includePatterns.map((e: any) => globalThis.String(e))
        : [],
      excludePatterns: globalThis.Array.isArray(object?.excludePatterns)
        ? object.excludePatterns.map((e: any) => globalThis.String(e))
        : [],
      csvOptions: isSet(object.csvOptions) ? Zone_DiscoverySpec_CsvOptions.fromJSON(object.csvOptions) : undefined,
      jsonOptions: isSet(object.jsonOptions) ? Zone_DiscoverySpec_JsonOptions.fromJSON(object.jsonOptions) : undefined,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Zone_DiscoverySpec): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.includePatterns?.length) {
      obj.includePatterns = message.includePatterns;
    }
    if (message.excludePatterns?.length) {
      obj.excludePatterns = message.excludePatterns;
    }
    if (message.csvOptions !== undefined) {
      obj.csvOptions = Zone_DiscoverySpec_CsvOptions.toJSON(message.csvOptions);
    }
    if (message.jsonOptions !== undefined) {
      obj.jsonOptions = Zone_DiscoverySpec_JsonOptions.toJSON(message.jsonOptions);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone_DiscoverySpec>, I>>(base?: I): Zone_DiscoverySpec {
    return Zone_DiscoverySpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone_DiscoverySpec>, I>>(object: I): Zone_DiscoverySpec {
    const message = createBaseZone_DiscoverySpec();
    message.enabled = object.enabled ?? false;
    message.includePatterns = object.includePatterns?.map((e) => e) || [];
    message.excludePatterns = object.excludePatterns?.map((e) => e) || [];
    message.csvOptions = (object.csvOptions !== undefined && object.csvOptions !== null)
      ? Zone_DiscoverySpec_CsvOptions.fromPartial(object.csvOptions)
      : undefined;
    message.jsonOptions = (object.jsonOptions !== undefined && object.jsonOptions !== null)
      ? Zone_DiscoverySpec_JsonOptions.fromPartial(object.jsonOptions)
      : undefined;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseZone_DiscoverySpec_CsvOptions(): Zone_DiscoverySpec_CsvOptions {
  return { headerRows: 0, delimiter: "", encoding: "", disableTypeInference: false };
}

export const Zone_DiscoverySpec_CsvOptions: MessageFns<Zone_DiscoverySpec_CsvOptions> = {
  encode(message: Zone_DiscoverySpec_CsvOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.headerRows !== 0) {
      writer.uint32(8).int32(message.headerRows);
    }
    if (message.delimiter !== "") {
      writer.uint32(18).string(message.delimiter);
    }
    if (message.encoding !== "") {
      writer.uint32(26).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(32).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec_CsvOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec_CsvOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.headerRows = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.encoding = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec_CsvOptions {
    return {
      headerRows: isSet(object.headerRows) ? globalThis.Number(object.headerRows) : 0,
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Zone_DiscoverySpec_CsvOptions): unknown {
    const obj: any = {};
    if (message.headerRows !== 0) {
      obj.headerRows = Math.round(message.headerRows);
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone_DiscoverySpec_CsvOptions>, I>>(base?: I): Zone_DiscoverySpec_CsvOptions {
    return Zone_DiscoverySpec_CsvOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone_DiscoverySpec_CsvOptions>, I>>(
    object: I,
  ): Zone_DiscoverySpec_CsvOptions {
    const message = createBaseZone_DiscoverySpec_CsvOptions();
    message.headerRows = object.headerRows ?? 0;
    message.delimiter = object.delimiter ?? "";
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseZone_DiscoverySpec_JsonOptions(): Zone_DiscoverySpec_JsonOptions {
  return { encoding: "", disableTypeInference: false };
}

export const Zone_DiscoverySpec_JsonOptions: MessageFns<Zone_DiscoverySpec_JsonOptions> = {
  encode(message: Zone_DiscoverySpec_JsonOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(16).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_DiscoverySpec_JsonOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_DiscoverySpec_JsonOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_DiscoverySpec_JsonOptions {
    return {
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Zone_DiscoverySpec_JsonOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone_DiscoverySpec_JsonOptions>, I>>(base?: I): Zone_DiscoverySpec_JsonOptions {
    return Zone_DiscoverySpec_JsonOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone_DiscoverySpec_JsonOptions>, I>>(
    object: I,
  ): Zone_DiscoverySpec_JsonOptions {
    const message = createBaseZone_DiscoverySpec_JsonOptions();
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseZone_LabelsEntry(): Zone_LabelsEntry {
  return { key: "", value: "" };
}

export const Zone_LabelsEntry: MessageFns<Zone_LabelsEntry> = {
  encode(message: Zone_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Zone_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZone_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Zone_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Zone_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Zone_LabelsEntry>, I>>(base?: I): Zone_LabelsEntry {
    return Zone_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Zone_LabelsEntry>, I>>(object: I): Zone_LabelsEntry {
    const message = createBaseZone_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAsset(): Asset {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    resourceSpec: undefined,
    resourceStatus: undefined,
    securityStatus: undefined,
    discoverySpec: undefined,
    discoveryStatus: undefined,
  };
}

export const Asset: MessageFns<Asset> = {
  encode(message: Asset, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Asset_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.resourceSpec !== undefined) {
      Asset_ResourceSpec.encode(message.resourceSpec, writer.uint32(802).fork()).join();
    }
    if (message.resourceStatus !== undefined) {
      Asset_ResourceStatus.encode(message.resourceStatus, writer.uint32(810).fork()).join();
    }
    if (message.securityStatus !== undefined) {
      Asset_SecurityStatus.encode(message.securityStatus, writer.uint32(826).fork()).join();
    }
    if (message.discoverySpec !== undefined) {
      Asset_DiscoverySpec.encode(message.discoverySpec, writer.uint32(850).fork()).join();
    }
    if (message.discoveryStatus !== undefined) {
      Asset_DiscoveryStatus.encode(message.discoveryStatus, writer.uint32(858).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Asset_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.resourceSpec = Asset_ResourceSpec.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.resourceStatus = Asset_ResourceStatus.decode(reader, reader.uint32());
          continue;
        }
        case 103: {
          if (tag !== 826) {
            break;
          }

          message.securityStatus = Asset_SecurityStatus.decode(reader, reader.uint32());
          continue;
        }
        case 106: {
          if (tag !== 850) {
            break;
          }

          message.discoverySpec = Asset_DiscoverySpec.decode(reader, reader.uint32());
          continue;
        }
        case 107: {
          if (tag !== 858) {
            break;
          }

          message.discoveryStatus = Asset_DiscoveryStatus.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      resourceSpec: isSet(object.resourceSpec) ? Asset_ResourceSpec.fromJSON(object.resourceSpec) : undefined,
      resourceStatus: isSet(object.resourceStatus) ? Asset_ResourceStatus.fromJSON(object.resourceStatus) : undefined,
      securityStatus: isSet(object.securityStatus) ? Asset_SecurityStatus.fromJSON(object.securityStatus) : undefined,
      discoverySpec: isSet(object.discoverySpec) ? Asset_DiscoverySpec.fromJSON(object.discoverySpec) : undefined,
      discoveryStatus: isSet(object.discoveryStatus)
        ? Asset_DiscoveryStatus.fromJSON(object.discoveryStatus)
        : undefined,
    };
  },

  toJSON(message: Asset): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.resourceSpec !== undefined) {
      obj.resourceSpec = Asset_ResourceSpec.toJSON(message.resourceSpec);
    }
    if (message.resourceStatus !== undefined) {
      obj.resourceStatus = Asset_ResourceStatus.toJSON(message.resourceStatus);
    }
    if (message.securityStatus !== undefined) {
      obj.securityStatus = Asset_SecurityStatus.toJSON(message.securityStatus);
    }
    if (message.discoverySpec !== undefined) {
      obj.discoverySpec = Asset_DiscoverySpec.toJSON(message.discoverySpec);
    }
    if (message.discoveryStatus !== undefined) {
      obj.discoveryStatus = Asset_DiscoveryStatus.toJSON(message.discoveryStatus);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset>, I>>(base?: I): Asset {
    return Asset.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset>, I>>(object: I): Asset {
    const message = createBaseAsset();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.resourceSpec = (object.resourceSpec !== undefined && object.resourceSpec !== null)
      ? Asset_ResourceSpec.fromPartial(object.resourceSpec)
      : undefined;
    message.resourceStatus = (object.resourceStatus !== undefined && object.resourceStatus !== null)
      ? Asset_ResourceStatus.fromPartial(object.resourceStatus)
      : undefined;
    message.securityStatus = (object.securityStatus !== undefined && object.securityStatus !== null)
      ? Asset_SecurityStatus.fromPartial(object.securityStatus)
      : undefined;
    message.discoverySpec = (object.discoverySpec !== undefined && object.discoverySpec !== null)
      ? Asset_DiscoverySpec.fromPartial(object.discoverySpec)
      : undefined;
    message.discoveryStatus = (object.discoveryStatus !== undefined && object.discoveryStatus !== null)
      ? Asset_DiscoveryStatus.fromPartial(object.discoveryStatus)
      : undefined;
    return message;
  },
};

function createBaseAsset_SecurityStatus(): Asset_SecurityStatus {
  return { state: 0, message: "", updateTime: undefined };
}

export const Asset_SecurityStatus: MessageFns<Asset_SecurityStatus> = {
  encode(message: Asset_SecurityStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_SecurityStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_SecurityStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_SecurityStatus {
    return {
      state: isSet(object.state) ? asset_SecurityStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: Asset_SecurityStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_SecurityStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_SecurityStatus>, I>>(base?: I): Asset_SecurityStatus {
    return Asset_SecurityStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_SecurityStatus>, I>>(object: I): Asset_SecurityStatus {
    const message = createBaseAsset_SecurityStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseAsset_DiscoverySpec(): Asset_DiscoverySpec {
  return {
    enabled: false,
    includePatterns: [],
    excludePatterns: [],
    csvOptions: undefined,
    jsonOptions: undefined,
    schedule: undefined,
  };
}

export const Asset_DiscoverySpec: MessageFns<Asset_DiscoverySpec> = {
  encode(message: Asset_DiscoverySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.enabled !== false) {
      writer.uint32(8).bool(message.enabled);
    }
    for (const v of message.includePatterns) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.excludePatterns) {
      writer.uint32(26).string(v!);
    }
    if (message.csvOptions !== undefined) {
      Asset_DiscoverySpec_CsvOptions.encode(message.csvOptions, writer.uint32(34).fork()).join();
    }
    if (message.jsonOptions !== undefined) {
      Asset_DiscoverySpec_JsonOptions.encode(message.jsonOptions, writer.uint32(42).fork()).join();
    }
    if (message.schedule !== undefined) {
      writer.uint32(82).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.enabled = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.includePatterns.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.excludePatterns.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.csvOptions = Asset_DiscoverySpec_CsvOptions.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.jsonOptions = Asset_DiscoverySpec_JsonOptions.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.schedule = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec {
    return {
      enabled: isSet(object.enabled) ? globalThis.Boolean(object.enabled) : false,
      includePatterns: globalThis.Array.isArray(object?.includePatterns)
        ? object.includePatterns.map((e: any) => globalThis.String(e))
        : [],
      excludePatterns: globalThis.Array.isArray(object?.excludePatterns)
        ? object.excludePatterns.map((e: any) => globalThis.String(e))
        : [],
      csvOptions: isSet(object.csvOptions) ? Asset_DiscoverySpec_CsvOptions.fromJSON(object.csvOptions) : undefined,
      jsonOptions: isSet(object.jsonOptions) ? Asset_DiscoverySpec_JsonOptions.fromJSON(object.jsonOptions) : undefined,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Asset_DiscoverySpec): unknown {
    const obj: any = {};
    if (message.enabled !== false) {
      obj.enabled = message.enabled;
    }
    if (message.includePatterns?.length) {
      obj.includePatterns = message.includePatterns;
    }
    if (message.excludePatterns?.length) {
      obj.excludePatterns = message.excludePatterns;
    }
    if (message.csvOptions !== undefined) {
      obj.csvOptions = Asset_DiscoverySpec_CsvOptions.toJSON(message.csvOptions);
    }
    if (message.jsonOptions !== undefined) {
      obj.jsonOptions = Asset_DiscoverySpec_JsonOptions.toJSON(message.jsonOptions);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_DiscoverySpec>, I>>(base?: I): Asset_DiscoverySpec {
    return Asset_DiscoverySpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_DiscoverySpec>, I>>(object: I): Asset_DiscoverySpec {
    const message = createBaseAsset_DiscoverySpec();
    message.enabled = object.enabled ?? false;
    message.includePatterns = object.includePatterns?.map((e) => e) || [];
    message.excludePatterns = object.excludePatterns?.map((e) => e) || [];
    message.csvOptions = (object.csvOptions !== undefined && object.csvOptions !== null)
      ? Asset_DiscoverySpec_CsvOptions.fromPartial(object.csvOptions)
      : undefined;
    message.jsonOptions = (object.jsonOptions !== undefined && object.jsonOptions !== null)
      ? Asset_DiscoverySpec_JsonOptions.fromPartial(object.jsonOptions)
      : undefined;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseAsset_DiscoverySpec_CsvOptions(): Asset_DiscoverySpec_CsvOptions {
  return { headerRows: 0, delimiter: "", encoding: "", disableTypeInference: false };
}

export const Asset_DiscoverySpec_CsvOptions: MessageFns<Asset_DiscoverySpec_CsvOptions> = {
  encode(message: Asset_DiscoverySpec_CsvOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.headerRows !== 0) {
      writer.uint32(8).int32(message.headerRows);
    }
    if (message.delimiter !== "") {
      writer.uint32(18).string(message.delimiter);
    }
    if (message.encoding !== "") {
      writer.uint32(26).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(32).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec_CsvOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec_CsvOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.headerRows = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.delimiter = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.encoding = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec_CsvOptions {
    return {
      headerRows: isSet(object.headerRows) ? globalThis.Number(object.headerRows) : 0,
      delimiter: isSet(object.delimiter) ? globalThis.String(object.delimiter) : "",
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Asset_DiscoverySpec_CsvOptions): unknown {
    const obj: any = {};
    if (message.headerRows !== 0) {
      obj.headerRows = Math.round(message.headerRows);
    }
    if (message.delimiter !== "") {
      obj.delimiter = message.delimiter;
    }
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_DiscoverySpec_CsvOptions>, I>>(base?: I): Asset_DiscoverySpec_CsvOptions {
    return Asset_DiscoverySpec_CsvOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_DiscoverySpec_CsvOptions>, I>>(
    object: I,
  ): Asset_DiscoverySpec_CsvOptions {
    const message = createBaseAsset_DiscoverySpec_CsvOptions();
    message.headerRows = object.headerRows ?? 0;
    message.delimiter = object.delimiter ?? "";
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseAsset_DiscoverySpec_JsonOptions(): Asset_DiscoverySpec_JsonOptions {
  return { encoding: "", disableTypeInference: false };
}

export const Asset_DiscoverySpec_JsonOptions: MessageFns<Asset_DiscoverySpec_JsonOptions> = {
  encode(message: Asset_DiscoverySpec_JsonOptions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.encoding !== "") {
      writer.uint32(10).string(message.encoding);
    }
    if (message.disableTypeInference !== false) {
      writer.uint32(16).bool(message.disableTypeInference);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoverySpec_JsonOptions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoverySpec_JsonOptions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.encoding = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.disableTypeInference = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoverySpec_JsonOptions {
    return {
      encoding: isSet(object.encoding) ? globalThis.String(object.encoding) : "",
      disableTypeInference: isSet(object.disableTypeInference)
        ? globalThis.Boolean(object.disableTypeInference)
        : false,
    };
  },

  toJSON(message: Asset_DiscoverySpec_JsonOptions): unknown {
    const obj: any = {};
    if (message.encoding !== "") {
      obj.encoding = message.encoding;
    }
    if (message.disableTypeInference !== false) {
      obj.disableTypeInference = message.disableTypeInference;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_DiscoverySpec_JsonOptions>, I>>(base?: I): Asset_DiscoverySpec_JsonOptions {
    return Asset_DiscoverySpec_JsonOptions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_DiscoverySpec_JsonOptions>, I>>(
    object: I,
  ): Asset_DiscoverySpec_JsonOptions {
    const message = createBaseAsset_DiscoverySpec_JsonOptions();
    message.encoding = object.encoding ?? "";
    message.disableTypeInference = object.disableTypeInference ?? false;
    return message;
  },
};

function createBaseAsset_ResourceSpec(): Asset_ResourceSpec {
  return { name: "", type: 0, readAccessMode: 0 };
}

export const Asset_ResourceSpec: MessageFns<Asset_ResourceSpec> = {
  encode(message: Asset_ResourceSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== 0) {
      writer.uint32(16).int32(message.type);
    }
    if (message.readAccessMode !== 0) {
      writer.uint32(40).int32(message.readAccessMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_ResourceSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_ResourceSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.readAccessMode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_ResourceSpec {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? asset_ResourceSpec_TypeFromJSON(object.type) : 0,
      readAccessMode: isSet(object.readAccessMode) ? asset_ResourceSpec_AccessModeFromJSON(object.readAccessMode) : 0,
    };
  },

  toJSON(message: Asset_ResourceSpec): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== 0) {
      obj.type = asset_ResourceSpec_TypeToJSON(message.type);
    }
    if (message.readAccessMode !== 0) {
      obj.readAccessMode = asset_ResourceSpec_AccessModeToJSON(message.readAccessMode);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_ResourceSpec>, I>>(base?: I): Asset_ResourceSpec {
    return Asset_ResourceSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_ResourceSpec>, I>>(object: I): Asset_ResourceSpec {
    const message = createBaseAsset_ResourceSpec();
    message.name = object.name ?? "";
    message.type = object.type ?? 0;
    message.readAccessMode = object.readAccessMode ?? 0;
    return message;
  },
};

function createBaseAsset_ResourceStatus(): Asset_ResourceStatus {
  return { state: 0, message: "", updateTime: undefined, managedAccessIdentity: "" };
}

export const Asset_ResourceStatus: MessageFns<Asset_ResourceStatus> = {
  encode(message: Asset_ResourceStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.managedAccessIdentity !== "") {
      writer.uint32(34).string(message.managedAccessIdentity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_ResourceStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_ResourceStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.managedAccessIdentity = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_ResourceStatus {
    return {
      state: isSet(object.state) ? asset_ResourceStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      managedAccessIdentity: isSet(object.managedAccessIdentity) ? globalThis.String(object.managedAccessIdentity) : "",
    };
  },

  toJSON(message: Asset_ResourceStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_ResourceStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.managedAccessIdentity !== "") {
      obj.managedAccessIdentity = message.managedAccessIdentity;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_ResourceStatus>, I>>(base?: I): Asset_ResourceStatus {
    return Asset_ResourceStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_ResourceStatus>, I>>(object: I): Asset_ResourceStatus {
    const message = createBaseAsset_ResourceStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.managedAccessIdentity = object.managedAccessIdentity ?? "";
    return message;
  },
};

function createBaseAsset_DiscoveryStatus(): Asset_DiscoveryStatus {
  return {
    state: 0,
    message: "",
    updateTime: undefined,
    lastRunTime: undefined,
    stats: undefined,
    lastRunDuration: undefined,
  };
}

export const Asset_DiscoveryStatus: MessageFns<Asset_DiscoveryStatus> = {
  encode(message: Asset_DiscoveryStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.state !== 0) {
      writer.uint32(8).int32(message.state);
    }
    if (message.message !== "") {
      writer.uint32(18).string(message.message);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.lastRunTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastRunTime), writer.uint32(34).fork()).join();
    }
    if (message.stats !== undefined) {
      Asset_DiscoveryStatus_Stats.encode(message.stats, writer.uint32(50).fork()).join();
    }
    if (message.lastRunDuration !== undefined) {
      Duration.encode(message.lastRunDuration, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoveryStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoveryStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.lastRunTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.stats = Asset_DiscoveryStatus_Stats.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.lastRunDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoveryStatus {
    return {
      state: isSet(object.state) ? asset_DiscoveryStatus_StateFromJSON(object.state) : 0,
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      lastRunTime: isSet(object.lastRunTime) ? fromJsonTimestamp(object.lastRunTime) : undefined,
      stats: isSet(object.stats) ? Asset_DiscoveryStatus_Stats.fromJSON(object.stats) : undefined,
      lastRunDuration: isSet(object.lastRunDuration) ? Duration.fromJSON(object.lastRunDuration) : undefined,
    };
  },

  toJSON(message: Asset_DiscoveryStatus): unknown {
    const obj: any = {};
    if (message.state !== 0) {
      obj.state = asset_DiscoveryStatus_StateToJSON(message.state);
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.lastRunTime !== undefined) {
      obj.lastRunTime = message.lastRunTime.toISOString();
    }
    if (message.stats !== undefined) {
      obj.stats = Asset_DiscoveryStatus_Stats.toJSON(message.stats);
    }
    if (message.lastRunDuration !== undefined) {
      obj.lastRunDuration = Duration.toJSON(message.lastRunDuration);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_DiscoveryStatus>, I>>(base?: I): Asset_DiscoveryStatus {
    return Asset_DiscoveryStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_DiscoveryStatus>, I>>(object: I): Asset_DiscoveryStatus {
    const message = createBaseAsset_DiscoveryStatus();
    message.state = object.state ?? 0;
    message.message = object.message ?? "";
    message.updateTime = object.updateTime ?? undefined;
    message.lastRunTime = object.lastRunTime ?? undefined;
    message.stats = (object.stats !== undefined && object.stats !== null)
      ? Asset_DiscoveryStatus_Stats.fromPartial(object.stats)
      : undefined;
    message.lastRunDuration = (object.lastRunDuration !== undefined && object.lastRunDuration !== null)
      ? Duration.fromPartial(object.lastRunDuration)
      : undefined;
    return message;
  },
};

function createBaseAsset_DiscoveryStatus_Stats(): Asset_DiscoveryStatus_Stats {
  return { dataItems: Long.ZERO, dataSize: Long.ZERO, tables: Long.ZERO, filesets: Long.ZERO };
}

export const Asset_DiscoveryStatus_Stats: MessageFns<Asset_DiscoveryStatus_Stats> = {
  encode(message: Asset_DiscoveryStatus_Stats, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.dataItems.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.dataItems.toString());
    }
    if (!message.dataSize.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.dataSize.toString());
    }
    if (!message.tables.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.tables.toString());
    }
    if (!message.filesets.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.filesets.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_DiscoveryStatus_Stats {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_DiscoveryStatus_Stats();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.dataItems = Long.fromString(reader.int64().toString());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.dataSize = Long.fromString(reader.int64().toString());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.tables = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.filesets = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_DiscoveryStatus_Stats {
    return {
      dataItems: isSet(object.dataItems) ? Long.fromValue(object.dataItems) : Long.ZERO,
      dataSize: isSet(object.dataSize) ? Long.fromValue(object.dataSize) : Long.ZERO,
      tables: isSet(object.tables) ? Long.fromValue(object.tables) : Long.ZERO,
      filesets: isSet(object.filesets) ? Long.fromValue(object.filesets) : Long.ZERO,
    };
  },

  toJSON(message: Asset_DiscoveryStatus_Stats): unknown {
    const obj: any = {};
    if (!message.dataItems.equals(Long.ZERO)) {
      obj.dataItems = (message.dataItems || Long.ZERO).toString();
    }
    if (!message.dataSize.equals(Long.ZERO)) {
      obj.dataSize = (message.dataSize || Long.ZERO).toString();
    }
    if (!message.tables.equals(Long.ZERO)) {
      obj.tables = (message.tables || Long.ZERO).toString();
    }
    if (!message.filesets.equals(Long.ZERO)) {
      obj.filesets = (message.filesets || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_DiscoveryStatus_Stats>, I>>(base?: I): Asset_DiscoveryStatus_Stats {
    return Asset_DiscoveryStatus_Stats.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_DiscoveryStatus_Stats>, I>>(object: I): Asset_DiscoveryStatus_Stats {
    const message = createBaseAsset_DiscoveryStatus_Stats();
    message.dataItems = (object.dataItems !== undefined && object.dataItems !== null)
      ? Long.fromValue(object.dataItems)
      : Long.ZERO;
    message.dataSize = (object.dataSize !== undefined && object.dataSize !== null)
      ? Long.fromValue(object.dataSize)
      : Long.ZERO;
    message.tables = (object.tables !== undefined && object.tables !== null)
      ? Long.fromValue(object.tables)
      : Long.ZERO;
    message.filesets = (object.filesets !== undefined && object.filesets !== null)
      ? Long.fromValue(object.filesets)
      : Long.ZERO;
    return message;
  },
};

function createBaseAsset_LabelsEntry(): Asset_LabelsEntry {
  return { key: "", value: "" };
}

export const Asset_LabelsEntry: MessageFns<Asset_LabelsEntry> = {
  encode(message: Asset_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Asset_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAsset_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Asset_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Asset_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Asset_LabelsEntry>, I>>(base?: I): Asset_LabelsEntry {
    return Asset_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Asset_LabelsEntry>, I>>(object: I): Asset_LabelsEntry {
    const message = createBaseAsset_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseEnvironment(): Environment {
  return {
    name: "",
    displayName: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
    state: 0,
    infrastructureSpec: undefined,
    sessionSpec: undefined,
    sessionStatus: undefined,
    endpoints: undefined,
  };
}

export const Environment: MessageFns<Environment> = {
  encode(message: Environment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Environment_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(58).string(message.description);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.infrastructureSpec !== undefined) {
      Environment_InfrastructureSpec.encode(message.infrastructureSpec, writer.uint32(802).fork()).join();
    }
    if (message.sessionSpec !== undefined) {
      Environment_SessionSpec.encode(message.sessionSpec, writer.uint32(810).fork()).join();
    }
    if (message.sessionStatus !== undefined) {
      Environment_SessionStatus.encode(message.sessionStatus, writer.uint32(818).fork()).join();
    }
    if (message.endpoints !== undefined) {
      Environment_Endpoints.encode(message.endpoints, writer.uint32(1602).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Environment_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.infrastructureSpec = Environment_InfrastructureSpec.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.sessionSpec = Environment_SessionSpec.decode(reader, reader.uint32());
          continue;
        }
        case 102: {
          if (tag !== 818) {
            break;
          }

          message.sessionStatus = Environment_SessionStatus.decode(reader, reader.uint32());
          continue;
        }
        case 200: {
          if (tag !== 1602) {
            break;
          }

          message.endpoints = Environment_Endpoints.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      infrastructureSpec: isSet(object.infrastructureSpec)
        ? Environment_InfrastructureSpec.fromJSON(object.infrastructureSpec)
        : undefined,
      sessionSpec: isSet(object.sessionSpec) ? Environment_SessionSpec.fromJSON(object.sessionSpec) : undefined,
      sessionStatus: isSet(object.sessionStatus) ? Environment_SessionStatus.fromJSON(object.sessionStatus) : undefined,
      endpoints: isSet(object.endpoints) ? Environment_Endpoints.fromJSON(object.endpoints) : undefined,
    };
  },

  toJSON(message: Environment): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.infrastructureSpec !== undefined) {
      obj.infrastructureSpec = Environment_InfrastructureSpec.toJSON(message.infrastructureSpec);
    }
    if (message.sessionSpec !== undefined) {
      obj.sessionSpec = Environment_SessionSpec.toJSON(message.sessionSpec);
    }
    if (message.sessionStatus !== undefined) {
      obj.sessionStatus = Environment_SessionStatus.toJSON(message.sessionStatus);
    }
    if (message.endpoints !== undefined) {
      obj.endpoints = Environment_Endpoints.toJSON(message.endpoints);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment>, I>>(base?: I): Environment {
    return Environment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment>, I>>(object: I): Environment {
    const message = createBaseEnvironment();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    message.state = object.state ?? 0;
    message.infrastructureSpec = (object.infrastructureSpec !== undefined && object.infrastructureSpec !== null)
      ? Environment_InfrastructureSpec.fromPartial(object.infrastructureSpec)
      : undefined;
    message.sessionSpec = (object.sessionSpec !== undefined && object.sessionSpec !== null)
      ? Environment_SessionSpec.fromPartial(object.sessionSpec)
      : undefined;
    message.sessionStatus = (object.sessionStatus !== undefined && object.sessionStatus !== null)
      ? Environment_SessionStatus.fromPartial(object.sessionStatus)
      : undefined;
    message.endpoints = (object.endpoints !== undefined && object.endpoints !== null)
      ? Environment_Endpoints.fromPartial(object.endpoints)
      : undefined;
    return message;
  },
};

function createBaseEnvironment_InfrastructureSpec(): Environment_InfrastructureSpec {
  return { compute: undefined, osImage: undefined };
}

export const Environment_InfrastructureSpec: MessageFns<Environment_InfrastructureSpec> = {
  encode(message: Environment_InfrastructureSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.compute !== undefined) {
      Environment_InfrastructureSpec_ComputeResources.encode(message.compute, writer.uint32(402).fork()).join();
    }
    if (message.osImage !== undefined) {
      Environment_InfrastructureSpec_OsImageRuntime.encode(message.osImage, writer.uint32(802).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_InfrastructureSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_InfrastructureSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 50: {
          if (tag !== 402) {
            break;
          }

          message.compute = Environment_InfrastructureSpec_ComputeResources.decode(reader, reader.uint32());
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.osImage = Environment_InfrastructureSpec_OsImageRuntime.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_InfrastructureSpec {
    return {
      compute: isSet(object.compute)
        ? Environment_InfrastructureSpec_ComputeResources.fromJSON(object.compute)
        : undefined,
      osImage: isSet(object.osImage)
        ? Environment_InfrastructureSpec_OsImageRuntime.fromJSON(object.osImage)
        : undefined,
    };
  },

  toJSON(message: Environment_InfrastructureSpec): unknown {
    const obj: any = {};
    if (message.compute !== undefined) {
      obj.compute = Environment_InfrastructureSpec_ComputeResources.toJSON(message.compute);
    }
    if (message.osImage !== undefined) {
      obj.osImage = Environment_InfrastructureSpec_OsImageRuntime.toJSON(message.osImage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_InfrastructureSpec>, I>>(base?: I): Environment_InfrastructureSpec {
    return Environment_InfrastructureSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_InfrastructureSpec>, I>>(
    object: I,
  ): Environment_InfrastructureSpec {
    const message = createBaseEnvironment_InfrastructureSpec();
    message.compute = (object.compute !== undefined && object.compute !== null)
      ? Environment_InfrastructureSpec_ComputeResources.fromPartial(object.compute)
      : undefined;
    message.osImage = (object.osImage !== undefined && object.osImage !== null)
      ? Environment_InfrastructureSpec_OsImageRuntime.fromPartial(object.osImage)
      : undefined;
    return message;
  },
};

function createBaseEnvironment_InfrastructureSpec_ComputeResources(): Environment_InfrastructureSpec_ComputeResources {
  return { diskSizeGb: 0, nodeCount: 0, maxNodeCount: 0 };
}

export const Environment_InfrastructureSpec_ComputeResources: MessageFns<
  Environment_InfrastructureSpec_ComputeResources
> = {
  encode(
    message: Environment_InfrastructureSpec_ComputeResources,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.diskSizeGb !== 0) {
      writer.uint32(8).int32(message.diskSizeGb);
    }
    if (message.nodeCount !== 0) {
      writer.uint32(16).int32(message.nodeCount);
    }
    if (message.maxNodeCount !== 0) {
      writer.uint32(24).int32(message.maxNodeCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_InfrastructureSpec_ComputeResources {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_InfrastructureSpec_ComputeResources();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.diskSizeGb = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.nodeCount = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.maxNodeCount = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_InfrastructureSpec_ComputeResources {
    return {
      diskSizeGb: isSet(object.diskSizeGb) ? globalThis.Number(object.diskSizeGb) : 0,
      nodeCount: isSet(object.nodeCount) ? globalThis.Number(object.nodeCount) : 0,
      maxNodeCount: isSet(object.maxNodeCount) ? globalThis.Number(object.maxNodeCount) : 0,
    };
  },

  toJSON(message: Environment_InfrastructureSpec_ComputeResources): unknown {
    const obj: any = {};
    if (message.diskSizeGb !== 0) {
      obj.diskSizeGb = Math.round(message.diskSizeGb);
    }
    if (message.nodeCount !== 0) {
      obj.nodeCount = Math.round(message.nodeCount);
    }
    if (message.maxNodeCount !== 0) {
      obj.maxNodeCount = Math.round(message.maxNodeCount);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_InfrastructureSpec_ComputeResources>, I>>(
    base?: I,
  ): Environment_InfrastructureSpec_ComputeResources {
    return Environment_InfrastructureSpec_ComputeResources.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_InfrastructureSpec_ComputeResources>, I>>(
    object: I,
  ): Environment_InfrastructureSpec_ComputeResources {
    const message = createBaseEnvironment_InfrastructureSpec_ComputeResources();
    message.diskSizeGb = object.diskSizeGb ?? 0;
    message.nodeCount = object.nodeCount ?? 0;
    message.maxNodeCount = object.maxNodeCount ?? 0;
    return message;
  },
};

function createBaseEnvironment_InfrastructureSpec_OsImageRuntime(): Environment_InfrastructureSpec_OsImageRuntime {
  return { imageVersion: "", javaLibraries: [], pythonPackages: [], properties: {} };
}

export const Environment_InfrastructureSpec_OsImageRuntime: MessageFns<Environment_InfrastructureSpec_OsImageRuntime> =
  {
    encode(
      message: Environment_InfrastructureSpec_OsImageRuntime,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.imageVersion !== "") {
        writer.uint32(10).string(message.imageVersion);
      }
      for (const v of message.javaLibraries) {
        writer.uint32(18).string(v!);
      }
      for (const v of message.pythonPackages) {
        writer.uint32(26).string(v!);
      }
      Object.entries(message.properties).forEach(([key, value]) => {
        Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry.encode(
          { key: key as any, value },
          writer.uint32(34).fork(),
        ).join();
      });
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Environment_InfrastructureSpec_OsImageRuntime {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      const end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseEnvironment_InfrastructureSpec_OsImageRuntime();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.imageVersion = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.javaLibraries.push(reader.string());
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.pythonPackages.push(reader.string());
            continue;
          }
          case 4: {
            if (tag !== 34) {
              break;
            }

            const entry4 = Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry.decode(
              reader,
              reader.uint32(),
            );
            if (entry4.value !== undefined) {
              message.properties[entry4.key] = entry4.value;
            }
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Environment_InfrastructureSpec_OsImageRuntime {
      return {
        imageVersion: isSet(object.imageVersion) ? globalThis.String(object.imageVersion) : "",
        javaLibraries: globalThis.Array.isArray(object?.javaLibraries)
          ? object.javaLibraries.map((e: any) => globalThis.String(e))
          : [],
        pythonPackages: globalThis.Array.isArray(object?.pythonPackages)
          ? object.pythonPackages.map((e: any) => globalThis.String(e))
          : [],
        properties: isObject(object.properties)
          ? Object.entries(object.properties).reduce<{ [key: string]: string }>((acc, [key, value]) => {
            acc[key] = String(value);
            return acc;
          }, {})
          : {},
      };
    },

    toJSON(message: Environment_InfrastructureSpec_OsImageRuntime): unknown {
      const obj: any = {};
      if (message.imageVersion !== "") {
        obj.imageVersion = message.imageVersion;
      }
      if (message.javaLibraries?.length) {
        obj.javaLibraries = message.javaLibraries;
      }
      if (message.pythonPackages?.length) {
        obj.pythonPackages = message.pythonPackages;
      }
      if (message.properties) {
        const entries = Object.entries(message.properties);
        if (entries.length > 0) {
          obj.properties = {};
          entries.forEach(([k, v]) => {
            obj.properties[k] = v;
          });
        }
      }
      return obj;
    },

    create<I extends Exact<DeepPartial<Environment_InfrastructureSpec_OsImageRuntime>, I>>(
      base?: I,
    ): Environment_InfrastructureSpec_OsImageRuntime {
      return Environment_InfrastructureSpec_OsImageRuntime.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<Environment_InfrastructureSpec_OsImageRuntime>, I>>(
      object: I,
    ): Environment_InfrastructureSpec_OsImageRuntime {
      const message = createBaseEnvironment_InfrastructureSpec_OsImageRuntime();
      message.imageVersion = object.imageVersion ?? "";
      message.javaLibraries = object.javaLibraries?.map((e) => e) || [];
      message.pythonPackages = object.pythonPackages?.map((e) => e) || [];
      message.properties = Object.entries(object.properties ?? {}).reduce<{ [key: string]: string }>(
        (acc, [key, value]) => {
          if (value !== undefined) {
            acc[key] = globalThis.String(value);
          }
          return acc;
        },
        {},
      );
      return message;
    },
  };

function createBaseEnvironment_InfrastructureSpec_OsImageRuntime_PropertiesEntry(): Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
  return { key: "", value: "" };
}

export const Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry: MessageFns<
  Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry
> = {
  encode(
    message: Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_InfrastructureSpec_OsImageRuntime_PropertiesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry>, I>>(
    base?: I,
  ): Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
    return Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry>, I>>(
    object: I,
  ): Environment_InfrastructureSpec_OsImageRuntime_PropertiesEntry {
    const message = createBaseEnvironment_InfrastructureSpec_OsImageRuntime_PropertiesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseEnvironment_SessionSpec(): Environment_SessionSpec {
  return { maxIdleDuration: undefined, enableFastStartup: false };
}

export const Environment_SessionSpec: MessageFns<Environment_SessionSpec> = {
  encode(message: Environment_SessionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.maxIdleDuration !== undefined) {
      Duration.encode(message.maxIdleDuration, writer.uint32(10).fork()).join();
    }
    if (message.enableFastStartup !== false) {
      writer.uint32(16).bool(message.enableFastStartup);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_SessionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_SessionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.maxIdleDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.enableFastStartup = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_SessionSpec {
    return {
      maxIdleDuration: isSet(object.maxIdleDuration) ? Duration.fromJSON(object.maxIdleDuration) : undefined,
      enableFastStartup: isSet(object.enableFastStartup) ? globalThis.Boolean(object.enableFastStartup) : false,
    };
  },

  toJSON(message: Environment_SessionSpec): unknown {
    const obj: any = {};
    if (message.maxIdleDuration !== undefined) {
      obj.maxIdleDuration = Duration.toJSON(message.maxIdleDuration);
    }
    if (message.enableFastStartup !== false) {
      obj.enableFastStartup = message.enableFastStartup;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_SessionSpec>, I>>(base?: I): Environment_SessionSpec {
    return Environment_SessionSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_SessionSpec>, I>>(object: I): Environment_SessionSpec {
    const message = createBaseEnvironment_SessionSpec();
    message.maxIdleDuration = (object.maxIdleDuration !== undefined && object.maxIdleDuration !== null)
      ? Duration.fromPartial(object.maxIdleDuration)
      : undefined;
    message.enableFastStartup = object.enableFastStartup ?? false;
    return message;
  },
};

function createBaseEnvironment_SessionStatus(): Environment_SessionStatus {
  return { active: false };
}

export const Environment_SessionStatus: MessageFns<Environment_SessionStatus> = {
  encode(message: Environment_SessionStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.active !== false) {
      writer.uint32(8).bool(message.active);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_SessionStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_SessionStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.active = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_SessionStatus {
    return { active: isSet(object.active) ? globalThis.Boolean(object.active) : false };
  },

  toJSON(message: Environment_SessionStatus): unknown {
    const obj: any = {};
    if (message.active !== false) {
      obj.active = message.active;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_SessionStatus>, I>>(base?: I): Environment_SessionStatus {
    return Environment_SessionStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_SessionStatus>, I>>(object: I): Environment_SessionStatus {
    const message = createBaseEnvironment_SessionStatus();
    message.active = object.active ?? false;
    return message;
  },
};

function createBaseEnvironment_Endpoints(): Environment_Endpoints {
  return { notebooks: "", sql: "" };
}

export const Environment_Endpoints: MessageFns<Environment_Endpoints> = {
  encode(message: Environment_Endpoints, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.notebooks !== "") {
      writer.uint32(10).string(message.notebooks);
    }
    if (message.sql !== "") {
      writer.uint32(18).string(message.sql);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_Endpoints {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_Endpoints();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.notebooks = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.sql = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_Endpoints {
    return {
      notebooks: isSet(object.notebooks) ? globalThis.String(object.notebooks) : "",
      sql: isSet(object.sql) ? globalThis.String(object.sql) : "",
    };
  },

  toJSON(message: Environment_Endpoints): unknown {
    const obj: any = {};
    if (message.notebooks !== "") {
      obj.notebooks = message.notebooks;
    }
    if (message.sql !== "") {
      obj.sql = message.sql;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_Endpoints>, I>>(base?: I): Environment_Endpoints {
    return Environment_Endpoints.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_Endpoints>, I>>(object: I): Environment_Endpoints {
    const message = createBaseEnvironment_Endpoints();
    message.notebooks = object.notebooks ?? "";
    message.sql = object.sql ?? "";
    return message;
  },
};

function createBaseEnvironment_LabelsEntry(): Environment_LabelsEntry {
  return { key: "", value: "" };
}

export const Environment_LabelsEntry: MessageFns<Environment_LabelsEntry> = {
  encode(message: Environment_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Environment_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironment_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Environment_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Environment_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Environment_LabelsEntry>, I>>(base?: I): Environment_LabelsEntry {
    return Environment_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Environment_LabelsEntry>, I>>(object: I): Environment_LabelsEntry {
    const message = createBaseEnvironment_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTrigger(): Trigger {
  return { onDemand: undefined, schedule: undefined };
}

export const Trigger: MessageFns<Trigger> = {
  encode(message: Trigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.onDemand !== undefined) {
      Trigger_OnDemand.encode(message.onDemand, writer.uint32(802).fork()).join();
    }
    if (message.schedule !== undefined) {
      Trigger_Schedule.encode(message.schedule, writer.uint32(810).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.onDemand = Trigger_OnDemand.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.schedule = Trigger_Schedule.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Trigger {
    return {
      onDemand: isSet(object.onDemand) ? Trigger_OnDemand.fromJSON(object.onDemand) : undefined,
      schedule: isSet(object.schedule) ? Trigger_Schedule.fromJSON(object.schedule) : undefined,
    };
  },

  toJSON(message: Trigger): unknown {
    const obj: any = {};
    if (message.onDemand !== undefined) {
      obj.onDemand = Trigger_OnDemand.toJSON(message.onDemand);
    }
    if (message.schedule !== undefined) {
      obj.schedule = Trigger_Schedule.toJSON(message.schedule);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Trigger>, I>>(base?: I): Trigger {
    return Trigger.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Trigger>, I>>(object: I): Trigger {
    const message = createBaseTrigger();
    message.onDemand = (object.onDemand !== undefined && object.onDemand !== null)
      ? Trigger_OnDemand.fromPartial(object.onDemand)
      : undefined;
    message.schedule = (object.schedule !== undefined && object.schedule !== null)
      ? Trigger_Schedule.fromPartial(object.schedule)
      : undefined;
    return message;
  },
};

function createBaseTrigger_OnDemand(): Trigger_OnDemand {
  return {};
}

export const Trigger_OnDemand: MessageFns<Trigger_OnDemand> = {
  encode(_: Trigger_OnDemand, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger_OnDemand {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger_OnDemand();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): Trigger_OnDemand {
    return {};
  },

  toJSON(_: Trigger_OnDemand): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<Trigger_OnDemand>, I>>(base?: I): Trigger_OnDemand {
    return Trigger_OnDemand.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Trigger_OnDemand>, I>>(_: I): Trigger_OnDemand {
    const message = createBaseTrigger_OnDemand();
    return message;
  },
};

function createBaseTrigger_Schedule(): Trigger_Schedule {
  return { cron: "" };
}

export const Trigger_Schedule: MessageFns<Trigger_Schedule> = {
  encode(message: Trigger_Schedule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cron !== "") {
      writer.uint32(10).string(message.cron);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Trigger_Schedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTrigger_Schedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cron = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Trigger_Schedule {
    return { cron: isSet(object.cron) ? globalThis.String(object.cron) : "" };
  },

  toJSON(message: Trigger_Schedule): unknown {
    const obj: any = {};
    if (message.cron !== "") {
      obj.cron = message.cron;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Trigger_Schedule>, I>>(base?: I): Trigger_Schedule {
    return Trigger_Schedule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Trigger_Schedule>, I>>(object: I): Trigger_Schedule {
    const message = createBaseTrigger_Schedule();
    message.cron = object.cron ?? "";
    return message;
  },
};

function createBaseDataSource(): DataSource {
  return { entity: undefined };
}

export const DataSource: MessageFns<DataSource> = {
  encode(message: DataSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.entity !== undefined) {
      writer.uint32(802).string(message.entity);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.entity = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataSource {
    return { entity: isSet(object.entity) ? globalThis.String(object.entity) : undefined };
  },

  toJSON(message: DataSource): unknown {
    const obj: any = {};
    if (message.entity !== undefined) {
      obj.entity = message.entity;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataSource>, I>>(base?: I): DataSource {
    return DataSource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataSource>, I>>(object: I): DataSource {
    const message = createBaseDataSource();
    message.entity = object.entity ?? undefined;
    return message;
  },
};

function createBaseScannedData(): ScannedData {
  return { incrementalField: undefined };
}

export const ScannedData: MessageFns<ScannedData> = {
  encode(message: ScannedData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.incrementalField !== undefined) {
      ScannedData_IncrementalField.encode(message.incrementalField, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScannedData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScannedData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.incrementalField = ScannedData_IncrementalField.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScannedData {
    return {
      incrementalField: isSet(object.incrementalField)
        ? ScannedData_IncrementalField.fromJSON(object.incrementalField)
        : undefined,
    };
  },

  toJSON(message: ScannedData): unknown {
    const obj: any = {};
    if (message.incrementalField !== undefined) {
      obj.incrementalField = ScannedData_IncrementalField.toJSON(message.incrementalField);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ScannedData>, I>>(base?: I): ScannedData {
    return ScannedData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ScannedData>, I>>(object: I): ScannedData {
    const message = createBaseScannedData();
    message.incrementalField = (object.incrementalField !== undefined && object.incrementalField !== null)
      ? ScannedData_IncrementalField.fromPartial(object.incrementalField)
      : undefined;
    return message;
  },
};

function createBaseScannedData_IncrementalField(): ScannedData_IncrementalField {
  return { field: "", start: "", end: "" };
}

export const ScannedData_IncrementalField: MessageFns<ScannedData_IncrementalField> = {
  encode(message: ScannedData_IncrementalField, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.field !== "") {
      writer.uint32(10).string(message.field);
    }
    if (message.start !== "") {
      writer.uint32(18).string(message.start);
    }
    if (message.end !== "") {
      writer.uint32(26).string(message.end);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScannedData_IncrementalField {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScannedData_IncrementalField();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.field = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.start = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.end = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScannedData_IncrementalField {
    return {
      field: isSet(object.field) ? globalThis.String(object.field) : "",
      start: isSet(object.start) ? globalThis.String(object.start) : "",
      end: isSet(object.end) ? globalThis.String(object.end) : "",
    };
  },

  toJSON(message: ScannedData_IncrementalField): unknown {
    const obj: any = {};
    if (message.field !== "") {
      obj.field = message.field;
    }
    if (message.start !== "") {
      obj.start = message.start;
    }
    if (message.end !== "") {
      obj.end = message.end;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ScannedData_IncrementalField>, I>>(base?: I): ScannedData_IncrementalField {
    return ScannedData_IncrementalField.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ScannedData_IncrementalField>, I>>(object: I): ScannedData_IncrementalField {
    const message = createBaseScannedData_IncrementalField();
    message.field = object.field ?? "";
    message.start = object.start ?? "";
    message.end = object.end ?? "";
    return message;
  },
};

function createBaseDataProfileSpec(): DataProfileSpec {
  return {};
}

export const DataProfileSpec: MessageFns<DataProfileSpec> = {
  encode(_: DataProfileSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataProfileSpec {
    return {};
  },

  toJSON(_: DataProfileSpec): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileSpec>, I>>(base?: I): DataProfileSpec {
    return DataProfileSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileSpec>, I>>(_: I): DataProfileSpec {
    const message = createBaseDataProfileSpec();
    return message;
  },
};

function createBaseDataProfileResult(): DataProfileResult {
  return { rowCount: Long.ZERO, profile: undefined, scannedData: undefined };
}

export const DataProfileResult: MessageFns<DataProfileResult> = {
  encode(message: DataProfileResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.rowCount.toString());
    }
    if (message.profile !== undefined) {
      DataProfileResult_Profile.encode(message.profile, writer.uint32(34).fork()).join();
    }
    if (message.scannedData !== undefined) {
      ScannedData.encode(message.scannedData, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.profile = DataProfileResult_Profile.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.scannedData = ScannedData.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult {
    return {
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      profile: isSet(object.profile) ? DataProfileResult_Profile.fromJSON(object.profile) : undefined,
      scannedData: isSet(object.scannedData) ? ScannedData.fromJSON(object.scannedData) : undefined,
    };
  },

  toJSON(message: DataProfileResult): unknown {
    const obj: any = {};
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (message.profile !== undefined) {
      obj.profile = DataProfileResult_Profile.toJSON(message.profile);
    }
    if (message.scannedData !== undefined) {
      obj.scannedData = ScannedData.toJSON(message.scannedData);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult>, I>>(base?: I): DataProfileResult {
    return DataProfileResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult>, I>>(object: I): DataProfileResult {
    const message = createBaseDataProfileResult();
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.profile = (object.profile !== undefined && object.profile !== null)
      ? DataProfileResult_Profile.fromPartial(object.profile)
      : undefined;
    message.scannedData = (object.scannedData !== undefined && object.scannedData !== null)
      ? ScannedData.fromPartial(object.scannedData)
      : undefined;
    return message;
  },
};

function createBaseDataProfileResult_Profile(): DataProfileResult_Profile {
  return { fields: [] };
}

export const DataProfileResult_Profile: MessageFns<DataProfileResult_Profile> = {
  encode(message: DataProfileResult_Profile, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.fields) {
      DataProfileResult_Profile_Field.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileResult_Profile {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.fields.push(DataProfileResult_Profile_Field.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile {
    return {
      fields: globalThis.Array.isArray(object?.fields)
        ? object.fields.map((e: any) => DataProfileResult_Profile_Field.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DataProfileResult_Profile): unknown {
    const obj: any = {};
    if (message.fields?.length) {
      obj.fields = message.fields.map((e) => DataProfileResult_Profile_Field.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile>, I>>(base?: I): DataProfileResult_Profile {
    return DataProfileResult_Profile.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile>, I>>(object: I): DataProfileResult_Profile {
    const message = createBaseDataProfileResult_Profile();
    message.fields = object.fields?.map((e) => DataProfileResult_Profile_Field.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field(): DataProfileResult_Profile_Field {
  return { name: "", type: "", mode: "", profile: undefined };
}

export const DataProfileResult_Profile_Field: MessageFns<DataProfileResult_Profile_Field> = {
  encode(message: DataProfileResult_Profile_Field, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.mode !== "") {
      writer.uint32(26).string(message.mode);
    }
    if (message.profile !== undefined) {
      DataProfileResult_Profile_Field_ProfileInfo.encode(message.profile, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileResult_Profile_Field {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.mode = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.profile = DataProfileResult_Profile_Field_ProfileInfo.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      mode: isSet(object.mode) ? globalThis.String(object.mode) : "",
      profile: isSet(object.profile) ? DataProfileResult_Profile_Field_ProfileInfo.fromJSON(object.profile) : undefined,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.mode !== "") {
      obj.mode = message.mode;
    }
    if (message.profile !== undefined) {
      obj.profile = DataProfileResult_Profile_Field_ProfileInfo.toJSON(message.profile);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field>, I>>(base?: I): DataProfileResult_Profile_Field {
    return DataProfileResult_Profile_Field.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field {
    const message = createBaseDataProfileResult_Profile_Field();
    message.name = object.name ?? "";
    message.type = object.type ?? "";
    message.mode = object.mode ?? "";
    message.profile = (object.profile !== undefined && object.profile !== null)
      ? DataProfileResult_Profile_Field_ProfileInfo.fromPartial(object.profile)
      : undefined;
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field_ProfileInfo(): DataProfileResult_Profile_Field_ProfileInfo {
  return {
    nullRatio: 0,
    distinctRatio: 0,
    topNValues: [],
    stringProfile: undefined,
    integerProfile: undefined,
    doubleProfile: undefined,
  };
}

export const DataProfileResult_Profile_Field_ProfileInfo: MessageFns<DataProfileResult_Profile_Field_ProfileInfo> = {
  encode(
    message: DataProfileResult_Profile_Field_ProfileInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.nullRatio !== 0) {
      writer.uint32(17).double(message.nullRatio);
    }
    if (message.distinctRatio !== 0) {
      writer.uint32(25).double(message.distinctRatio);
    }
    for (const v of message.topNValues) {
      DataProfileResult_Profile_Field_ProfileInfo_TopNValue.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.stringProfile !== undefined) {
      DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.encode(
        message.stringProfile,
        writer.uint32(810).fork(),
      ).join();
    }
    if (message.integerProfile !== undefined) {
      DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.encode(
        message.integerProfile,
        writer.uint32(818).fork(),
      ).join();
    }
    if (message.doubleProfile !== undefined) {
      DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.encode(
        message.doubleProfile,
        writer.uint32(826).fork(),
      ).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileResult_Profile_Field_ProfileInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 17) {
            break;
          }

          message.nullRatio = reader.double();
          continue;
        }
        case 3: {
          if (tag !== 25) {
            break;
          }

          message.distinctRatio = reader.double();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.topNValues.push(
            DataProfileResult_Profile_Field_ProfileInfo_TopNValue.decode(reader, reader.uint32()),
          );
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.stringProfile = DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 102: {
          if (tag !== 818) {
            break;
          }

          message.integerProfile = DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 103: {
          if (tag !== 826) {
            break;
          }

          message.doubleProfile = DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field_ProfileInfo {
    return {
      nullRatio: isSet(object.nullRatio) ? globalThis.Number(object.nullRatio) : 0,
      distinctRatio: isSet(object.distinctRatio) ? globalThis.Number(object.distinctRatio) : 0,
      topNValues: globalThis.Array.isArray(object?.topNValues)
        ? object.topNValues.map((e: any) => DataProfileResult_Profile_Field_ProfileInfo_TopNValue.fromJSON(e))
        : [],
      stringProfile: isSet(object.stringProfile)
        ? DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.fromJSON(object.stringProfile)
        : undefined,
      integerProfile: isSet(object.integerProfile)
        ? DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.fromJSON(object.integerProfile)
        : undefined,
      doubleProfile: isSet(object.doubleProfile)
        ? DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.fromJSON(object.doubleProfile)
        : undefined,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field_ProfileInfo): unknown {
    const obj: any = {};
    if (message.nullRatio !== 0) {
      obj.nullRatio = message.nullRatio;
    }
    if (message.distinctRatio !== 0) {
      obj.distinctRatio = message.distinctRatio;
    }
    if (message.topNValues?.length) {
      obj.topNValues = message.topNValues.map((e) => DataProfileResult_Profile_Field_ProfileInfo_TopNValue.toJSON(e));
    }
    if (message.stringProfile !== undefined) {
      obj.stringProfile = DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.toJSON(message.stringProfile);
    }
    if (message.integerProfile !== undefined) {
      obj.integerProfile = DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.toJSON(message.integerProfile);
    }
    if (message.doubleProfile !== undefined) {
      obj.doubleProfile = DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.toJSON(message.doubleProfile);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo>, I>>(
    base?: I,
  ): DataProfileResult_Profile_Field_ProfileInfo {
    return DataProfileResult_Profile_Field_ProfileInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field_ProfileInfo {
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo();
    message.nullRatio = object.nullRatio ?? 0;
    message.distinctRatio = object.distinctRatio ?? 0;
    message.topNValues =
      object.topNValues?.map((e) => DataProfileResult_Profile_Field_ProfileInfo_TopNValue.fromPartial(e)) || [];
    message.stringProfile = (object.stringProfile !== undefined && object.stringProfile !== null)
      ? DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.fromPartial(object.stringProfile)
      : undefined;
    message.integerProfile = (object.integerProfile !== undefined && object.integerProfile !== null)
      ? DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.fromPartial(object.integerProfile)
      : undefined;
    message.doubleProfile = (object.doubleProfile !== undefined && object.doubleProfile !== null)
      ? DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.fromPartial(object.doubleProfile)
      : undefined;
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo(): DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
  return { minLength: Long.ZERO, maxLength: Long.ZERO, averageLength: 0 };
}

export const DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo: MessageFns<
  DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo
> = {
  encode(
    message: DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (!message.minLength.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.minLength.toString());
    }
    if (!message.maxLength.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.maxLength.toString());
    }
    if (message.averageLength !== 0) {
      writer.uint32(25).double(message.averageLength);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.minLength = Long.fromString(reader.int64().toString());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.maxLength = Long.fromString(reader.int64().toString());
          continue;
        }
        case 3: {
          if (tag !== 25) {
            break;
          }

          message.averageLength = reader.double();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
    return {
      minLength: isSet(object.minLength) ? Long.fromValue(object.minLength) : Long.ZERO,
      maxLength: isSet(object.maxLength) ? Long.fromValue(object.maxLength) : Long.ZERO,
      averageLength: isSet(object.averageLength) ? globalThis.Number(object.averageLength) : 0,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo): unknown {
    const obj: any = {};
    if (!message.minLength.equals(Long.ZERO)) {
      obj.minLength = (message.minLength || Long.ZERO).toString();
    }
    if (!message.maxLength.equals(Long.ZERO)) {
      obj.maxLength = (message.maxLength || Long.ZERO).toString();
    }
    if (message.averageLength !== 0) {
      obj.averageLength = message.averageLength;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo>, I>>(
    base?: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
    return DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo {
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_StringFieldInfo();
    message.minLength = (object.minLength !== undefined && object.minLength !== null)
      ? Long.fromValue(object.minLength)
      : Long.ZERO;
    message.maxLength = (object.maxLength !== undefined && object.maxLength !== null)
      ? Long.fromValue(object.maxLength)
      : Long.ZERO;
    message.averageLength = object.averageLength ?? 0;
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo(): DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
  return { average: 0, standardDeviation: 0, min: Long.ZERO, quartiles: [], max: Long.ZERO };
}

export const DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo: MessageFns<
  DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo
> = {
  encode(
    message: DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.average !== 0) {
      writer.uint32(9).double(message.average);
    }
    if (message.standardDeviation !== 0) {
      writer.uint32(25).double(message.standardDeviation);
    }
    if (!message.min.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.min.toString());
    }
    writer.uint32(50).fork();
    for (const v of message.quartiles) {
      writer.int64(v.toString());
    }
    writer.join();
    if (!message.max.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.max.toString());
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 9) {
            break;
          }

          message.average = reader.double();
          continue;
        }
        case 3: {
          if (tag !== 25) {
            break;
          }

          message.standardDeviation = reader.double();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.min = Long.fromString(reader.int64().toString());
          continue;
        }
        case 6: {
          if (tag === 48) {
            message.quartiles.push(Long.fromString(reader.int64().toString()));

            continue;
          }

          if (tag === 50) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.quartiles.push(Long.fromString(reader.int64().toString()));
            }

            continue;
          }

          break;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.max = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
    return {
      average: isSet(object.average) ? globalThis.Number(object.average) : 0,
      standardDeviation: isSet(object.standardDeviation) ? globalThis.Number(object.standardDeviation) : 0,
      min: isSet(object.min) ? Long.fromValue(object.min) : Long.ZERO,
      quartiles: globalThis.Array.isArray(object?.quartiles) ? object.quartiles.map((e: any) => Long.fromValue(e)) : [],
      max: isSet(object.max) ? Long.fromValue(object.max) : Long.ZERO,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo): unknown {
    const obj: any = {};
    if (message.average !== 0) {
      obj.average = message.average;
    }
    if (message.standardDeviation !== 0) {
      obj.standardDeviation = message.standardDeviation;
    }
    if (!message.min.equals(Long.ZERO)) {
      obj.min = (message.min || Long.ZERO).toString();
    }
    if (message.quartiles?.length) {
      obj.quartiles = message.quartiles.map((e) => (e || Long.ZERO).toString());
    }
    if (!message.max.equals(Long.ZERO)) {
      obj.max = (message.max || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo>, I>>(
    base?: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
    return DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo {
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_IntegerFieldInfo();
    message.average = object.average ?? 0;
    message.standardDeviation = object.standardDeviation ?? 0;
    message.min = (object.min !== undefined && object.min !== null) ? Long.fromValue(object.min) : Long.ZERO;
    message.quartiles = object.quartiles?.map((e) => Long.fromValue(e)) || [];
    message.max = (object.max !== undefined && object.max !== null) ? Long.fromValue(object.max) : Long.ZERO;
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo(): DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
  return { average: 0, standardDeviation: 0, min: 0, quartiles: [], max: 0 };
}

export const DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo: MessageFns<
  DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo
> = {
  encode(
    message: DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.average !== 0) {
      writer.uint32(9).double(message.average);
    }
    if (message.standardDeviation !== 0) {
      writer.uint32(25).double(message.standardDeviation);
    }
    if (message.min !== 0) {
      writer.uint32(33).double(message.min);
    }
    writer.uint32(50).fork();
    for (const v of message.quartiles) {
      writer.double(v);
    }
    writer.join();
    if (message.max !== 0) {
      writer.uint32(41).double(message.max);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 9) {
            break;
          }

          message.average = reader.double();
          continue;
        }
        case 3: {
          if (tag !== 25) {
            break;
          }

          message.standardDeviation = reader.double();
          continue;
        }
        case 4: {
          if (tag !== 33) {
            break;
          }

          message.min = reader.double();
          continue;
        }
        case 6: {
          if (tag === 49) {
            message.quartiles.push(reader.double());

            continue;
          }

          if (tag === 50) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.quartiles.push(reader.double());
            }

            continue;
          }

          break;
        }
        case 5: {
          if (tag !== 41) {
            break;
          }

          message.max = reader.double();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
    return {
      average: isSet(object.average) ? globalThis.Number(object.average) : 0,
      standardDeviation: isSet(object.standardDeviation) ? globalThis.Number(object.standardDeviation) : 0,
      min: isSet(object.min) ? globalThis.Number(object.min) : 0,
      quartiles: globalThis.Array.isArray(object?.quartiles)
        ? object.quartiles.map((e: any) => globalThis.Number(e))
        : [],
      max: isSet(object.max) ? globalThis.Number(object.max) : 0,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo): unknown {
    const obj: any = {};
    if (message.average !== 0) {
      obj.average = message.average;
    }
    if (message.standardDeviation !== 0) {
      obj.standardDeviation = message.standardDeviation;
    }
    if (message.min !== 0) {
      obj.min = message.min;
    }
    if (message.quartiles?.length) {
      obj.quartiles = message.quartiles;
    }
    if (message.max !== 0) {
      obj.max = message.max;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo>, I>>(
    base?: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
    return DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo {
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_DoubleFieldInfo();
    message.average = object.average ?? 0;
    message.standardDeviation = object.standardDeviation ?? 0;
    message.min = object.min ?? 0;
    message.quartiles = object.quartiles?.map((e) => e) || [];
    message.max = object.max ?? 0;
    return message;
  },
};

function createBaseDataProfileResult_Profile_Field_ProfileInfo_TopNValue(): DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
  return { value: "", count: Long.ZERO };
}

export const DataProfileResult_Profile_Field_ProfileInfo_TopNValue: MessageFns<
  DataProfileResult_Profile_Field_ProfileInfo_TopNValue
> = {
  encode(
    message: DataProfileResult_Profile_Field_ProfileInfo_TopNValue,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.value !== "") {
      writer.uint32(10).string(message.value);
    }
    if (!message.count.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.count.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_TopNValue();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.value = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.count = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
    return {
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      count: isSet(object.count) ? Long.fromValue(object.count) : Long.ZERO,
    };
  },

  toJSON(message: DataProfileResult_Profile_Field_ProfileInfo_TopNValue): unknown {
    const obj: any = {};
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (!message.count.equals(Long.ZERO)) {
      obj.count = (message.count || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_TopNValue>, I>>(
    base?: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
    return DataProfileResult_Profile_Field_ProfileInfo_TopNValue.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataProfileResult_Profile_Field_ProfileInfo_TopNValue>, I>>(
    object: I,
  ): DataProfileResult_Profile_Field_ProfileInfo_TopNValue {
    const message = createBaseDataProfileResult_Profile_Field_ProfileInfo_TopNValue();
    message.value = object.value ?? "";
    message.count = (object.count !== undefined && object.count !== null) ? Long.fromValue(object.count) : Long.ZERO;
    return message;
  },
};

function createBaseDataQualitySpec(): DataQualitySpec {
  return { rules: [] };
}

export const DataQualitySpec: MessageFns<DataQualitySpec> = {
  encode(message: DataQualitySpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.rules) {
      DataQualityRule.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualitySpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualitySpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.rules.push(DataQualityRule.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualitySpec {
    return {
      rules: globalThis.Array.isArray(object?.rules) ? object.rules.map((e: any) => DataQualityRule.fromJSON(e)) : [],
    };
  },

  toJSON(message: DataQualitySpec): unknown {
    const obj: any = {};
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => DataQualityRule.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualitySpec>, I>>(base?: I): DataQualitySpec {
    return DataQualitySpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualitySpec>, I>>(object: I): DataQualitySpec {
    const message = createBaseDataQualitySpec();
    message.rules = object.rules?.map((e) => DataQualityRule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDataQualityResult(): DataQualityResult {
  return { passed: false, dimensions: [], rules: [], rowCount: Long.ZERO, scannedData: undefined };
}

export const DataQualityResult: MessageFns<DataQualityResult> = {
  encode(message: DataQualityResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.passed !== false) {
      writer.uint32(40).bool(message.passed);
    }
    for (const v of message.dimensions) {
      DataQualityDimensionResult.encode(v!, writer.uint32(18).fork()).join();
    }
    for (const v of message.rules) {
      DataQualityRuleResult.encode(v!, writer.uint32(26).fork()).join();
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.rowCount.toString());
    }
    if (message.scannedData !== undefined) {
      ScannedData.encode(message.scannedData, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.passed = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.dimensions.push(DataQualityDimensionResult.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.rules.push(DataQualityRuleResult.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.rowCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.scannedData = ScannedData.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityResult {
    return {
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      dimensions: globalThis.Array.isArray(object?.dimensions)
        ? object.dimensions.map((e: any) => DataQualityDimensionResult.fromJSON(e))
        : [],
      rules: globalThis.Array.isArray(object?.rules)
        ? object.rules.map((e: any) => DataQualityRuleResult.fromJSON(e))
        : [],
      rowCount: isSet(object.rowCount) ? Long.fromValue(object.rowCount) : Long.ZERO,
      scannedData: isSet(object.scannedData) ? ScannedData.fromJSON(object.scannedData) : undefined,
    };
  },

  toJSON(message: DataQualityResult): unknown {
    const obj: any = {};
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (message.dimensions?.length) {
      obj.dimensions = message.dimensions.map((e) => DataQualityDimensionResult.toJSON(e));
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => DataQualityRuleResult.toJSON(e));
    }
    if (!message.rowCount.equals(Long.ZERO)) {
      obj.rowCount = (message.rowCount || Long.ZERO).toString();
    }
    if (message.scannedData !== undefined) {
      obj.scannedData = ScannedData.toJSON(message.scannedData);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityResult>, I>>(base?: I): DataQualityResult {
    return DataQualityResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityResult>, I>>(object: I): DataQualityResult {
    const message = createBaseDataQualityResult();
    message.passed = object.passed ?? false;
    message.dimensions = object.dimensions?.map((e) => DataQualityDimensionResult.fromPartial(e)) || [];
    message.rules = object.rules?.map((e) => DataQualityRuleResult.fromPartial(e)) || [];
    message.rowCount = (object.rowCount !== undefined && object.rowCount !== null)
      ? Long.fromValue(object.rowCount)
      : Long.ZERO;
    message.scannedData = (object.scannedData !== undefined && object.scannedData !== null)
      ? ScannedData.fromPartial(object.scannedData)
      : undefined;
    return message;
  },
};

function createBaseDataQualityRuleResult(): DataQualityRuleResult {
  return {
    rule: undefined,
    passed: false,
    evaluatedCount: Long.ZERO,
    passedCount: Long.ZERO,
    nullCount: Long.ZERO,
    passRatio: 0,
    failingRowsQuery: "",
  };
}

export const DataQualityRuleResult: MessageFns<DataQualityRuleResult> = {
  encode(message: DataQualityRuleResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rule !== undefined) {
      DataQualityRule.encode(message.rule, writer.uint32(10).fork()).join();
    }
    if (message.passed !== false) {
      writer.uint32(56).bool(message.passed);
    }
    if (!message.evaluatedCount.equals(Long.ZERO)) {
      writer.uint32(72).int64(message.evaluatedCount.toString());
    }
    if (!message.passedCount.equals(Long.ZERO)) {
      writer.uint32(64).int64(message.passedCount.toString());
    }
    if (!message.nullCount.equals(Long.ZERO)) {
      writer.uint32(40).int64(message.nullCount.toString());
    }
    if (message.passRatio !== 0) {
      writer.uint32(49).double(message.passRatio);
    }
    if (message.failingRowsQuery !== "") {
      writer.uint32(82).string(message.failingRowsQuery);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRuleResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRuleResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.rule = DataQualityRule.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.passed = reader.bool();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.evaluatedCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.passedCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.nullCount = Long.fromString(reader.int64().toString());
          continue;
        }
        case 6: {
          if (tag !== 49) {
            break;
          }

          message.passRatio = reader.double();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.failingRowsQuery = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRuleResult {
    return {
      rule: isSet(object.rule) ? DataQualityRule.fromJSON(object.rule) : undefined,
      passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false,
      evaluatedCount: isSet(object.evaluatedCount) ? Long.fromValue(object.evaluatedCount) : Long.ZERO,
      passedCount: isSet(object.passedCount) ? Long.fromValue(object.passedCount) : Long.ZERO,
      nullCount: isSet(object.nullCount) ? Long.fromValue(object.nullCount) : Long.ZERO,
      passRatio: isSet(object.passRatio) ? globalThis.Number(object.passRatio) : 0,
      failingRowsQuery: isSet(object.failingRowsQuery) ? globalThis.String(object.failingRowsQuery) : "",
    };
  },

  toJSON(message: DataQualityRuleResult): unknown {
    const obj: any = {};
    if (message.rule !== undefined) {
      obj.rule = DataQualityRule.toJSON(message.rule);
    }
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    if (!message.evaluatedCount.equals(Long.ZERO)) {
      obj.evaluatedCount = (message.evaluatedCount || Long.ZERO).toString();
    }
    if (!message.passedCount.equals(Long.ZERO)) {
      obj.passedCount = (message.passedCount || Long.ZERO).toString();
    }
    if (!message.nullCount.equals(Long.ZERO)) {
      obj.nullCount = (message.nullCount || Long.ZERO).toString();
    }
    if (message.passRatio !== 0) {
      obj.passRatio = message.passRatio;
    }
    if (message.failingRowsQuery !== "") {
      obj.failingRowsQuery = message.failingRowsQuery;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRuleResult>, I>>(base?: I): DataQualityRuleResult {
    return DataQualityRuleResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRuleResult>, I>>(object: I): DataQualityRuleResult {
    const message = createBaseDataQualityRuleResult();
    message.rule = (object.rule !== undefined && object.rule !== null)
      ? DataQualityRule.fromPartial(object.rule)
      : undefined;
    message.passed = object.passed ?? false;
    message.evaluatedCount = (object.evaluatedCount !== undefined && object.evaluatedCount !== null)
      ? Long.fromValue(object.evaluatedCount)
      : Long.ZERO;
    message.passedCount = (object.passedCount !== undefined && object.passedCount !== null)
      ? Long.fromValue(object.passedCount)
      : Long.ZERO;
    message.nullCount = (object.nullCount !== undefined && object.nullCount !== null)
      ? Long.fromValue(object.nullCount)
      : Long.ZERO;
    message.passRatio = object.passRatio ?? 0;
    message.failingRowsQuery = object.failingRowsQuery ?? "";
    return message;
  },
};

function createBaseDataQualityDimensionResult(): DataQualityDimensionResult {
  return { passed: false };
}

export const DataQualityDimensionResult: MessageFns<DataQualityDimensionResult> = {
  encode(message: DataQualityDimensionResult, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.passed !== false) {
      writer.uint32(24).bool(message.passed);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityDimensionResult {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityDimensionResult();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.passed = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityDimensionResult {
    return { passed: isSet(object.passed) ? globalThis.Boolean(object.passed) : false };
  },

  toJSON(message: DataQualityDimensionResult): unknown {
    const obj: any = {};
    if (message.passed !== false) {
      obj.passed = message.passed;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityDimensionResult>, I>>(base?: I): DataQualityDimensionResult {
    return DataQualityDimensionResult.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityDimensionResult>, I>>(object: I): DataQualityDimensionResult {
    const message = createBaseDataQualityDimensionResult();
    message.passed = object.passed ?? false;
    return message;
  },
};

function createBaseDataQualityRule(): DataQualityRule {
  return {
    rangeExpectation: undefined,
    nonNullExpectation: undefined,
    setExpectation: undefined,
    regexExpectation: undefined,
    uniquenessExpectation: undefined,
    statisticRangeExpectation: undefined,
    rowConditionExpectation: undefined,
    tableConditionExpectation: undefined,
    column: "",
    ignoreNull: false,
    dimension: "",
    threshold: 0,
  };
}

export const DataQualityRule: MessageFns<DataQualityRule> = {
  encode(message: DataQualityRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.rangeExpectation !== undefined) {
      DataQualityRule_RangeExpectation.encode(message.rangeExpectation, writer.uint32(10).fork()).join();
    }
    if (message.nonNullExpectation !== undefined) {
      DataQualityRule_NonNullExpectation.encode(message.nonNullExpectation, writer.uint32(18).fork()).join();
    }
    if (message.setExpectation !== undefined) {
      DataQualityRule_SetExpectation.encode(message.setExpectation, writer.uint32(26).fork()).join();
    }
    if (message.regexExpectation !== undefined) {
      DataQualityRule_RegexExpectation.encode(message.regexExpectation, writer.uint32(34).fork()).join();
    }
    if (message.uniquenessExpectation !== undefined) {
      DataQualityRule_UniquenessExpectation.encode(message.uniquenessExpectation, writer.uint32(802).fork()).join();
    }
    if (message.statisticRangeExpectation !== undefined) {
      DataQualityRule_StatisticRangeExpectation.encode(message.statisticRangeExpectation, writer.uint32(810).fork())
        .join();
    }
    if (message.rowConditionExpectation !== undefined) {
      DataQualityRule_RowConditionExpectation.encode(message.rowConditionExpectation, writer.uint32(1602).fork())
        .join();
    }
    if (message.tableConditionExpectation !== undefined) {
      DataQualityRule_TableConditionExpectation.encode(message.tableConditionExpectation, writer.uint32(1610).fork())
        .join();
    }
    if (message.column !== "") {
      writer.uint32(4002).string(message.column);
    }
    if (message.ignoreNull !== false) {
      writer.uint32(4008).bool(message.ignoreNull);
    }
    if (message.dimension !== "") {
      writer.uint32(4018).string(message.dimension);
    }
    if (message.threshold !== 0) {
      writer.uint32(4025).double(message.threshold);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.rangeExpectation = DataQualityRule_RangeExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.nonNullExpectation = DataQualityRule_NonNullExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.setExpectation = DataQualityRule_SetExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.regexExpectation = DataQualityRule_RegexExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.uniquenessExpectation = DataQualityRule_UniquenessExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.statisticRangeExpectation = DataQualityRule_StatisticRangeExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 200: {
          if (tag !== 1602) {
            break;
          }

          message.rowConditionExpectation = DataQualityRule_RowConditionExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 201: {
          if (tag !== 1610) {
            break;
          }

          message.tableConditionExpectation = DataQualityRule_TableConditionExpectation.decode(reader, reader.uint32());
          continue;
        }
        case 500: {
          if (tag !== 4002) {
            break;
          }

          message.column = reader.string();
          continue;
        }
        case 501: {
          if (tag !== 4008) {
            break;
          }

          message.ignoreNull = reader.bool();
          continue;
        }
        case 502: {
          if (tag !== 4018) {
            break;
          }

          message.dimension = reader.string();
          continue;
        }
        case 503: {
          if (tag !== 4025) {
            break;
          }

          message.threshold = reader.double();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule {
    return {
      rangeExpectation: isSet(object.rangeExpectation)
        ? DataQualityRule_RangeExpectation.fromJSON(object.rangeExpectation)
        : undefined,
      nonNullExpectation: isSet(object.nonNullExpectation)
        ? DataQualityRule_NonNullExpectation.fromJSON(object.nonNullExpectation)
        : undefined,
      setExpectation: isSet(object.setExpectation)
        ? DataQualityRule_SetExpectation.fromJSON(object.setExpectation)
        : undefined,
      regexExpectation: isSet(object.regexExpectation)
        ? DataQualityRule_RegexExpectation.fromJSON(object.regexExpectation)
        : undefined,
      uniquenessExpectation: isSet(object.uniquenessExpectation)
        ? DataQualityRule_UniquenessExpectation.fromJSON(object.uniquenessExpectation)
        : undefined,
      statisticRangeExpectation: isSet(object.statisticRangeExpectation)
        ? DataQualityRule_StatisticRangeExpectation.fromJSON(object.statisticRangeExpectation)
        : undefined,
      rowConditionExpectation: isSet(object.rowConditionExpectation)
        ? DataQualityRule_RowConditionExpectation.fromJSON(object.rowConditionExpectation)
        : undefined,
      tableConditionExpectation: isSet(object.tableConditionExpectation)
        ? DataQualityRule_TableConditionExpectation.fromJSON(object.tableConditionExpectation)
        : undefined,
      column: isSet(object.column) ? globalThis.String(object.column) : "",
      ignoreNull: isSet(object.ignoreNull) ? globalThis.Boolean(object.ignoreNull) : false,
      dimension: isSet(object.dimension) ? globalThis.String(object.dimension) : "",
      threshold: isSet(object.threshold) ? globalThis.Number(object.threshold) : 0,
    };
  },

  toJSON(message: DataQualityRule): unknown {
    const obj: any = {};
    if (message.rangeExpectation !== undefined) {
      obj.rangeExpectation = DataQualityRule_RangeExpectation.toJSON(message.rangeExpectation);
    }
    if (message.nonNullExpectation !== undefined) {
      obj.nonNullExpectation = DataQualityRule_NonNullExpectation.toJSON(message.nonNullExpectation);
    }
    if (message.setExpectation !== undefined) {
      obj.setExpectation = DataQualityRule_SetExpectation.toJSON(message.setExpectation);
    }
    if (message.regexExpectation !== undefined) {
      obj.regexExpectation = DataQualityRule_RegexExpectation.toJSON(message.regexExpectation);
    }
    if (message.uniquenessExpectation !== undefined) {
      obj.uniquenessExpectation = DataQualityRule_UniquenessExpectation.toJSON(message.uniquenessExpectation);
    }
    if (message.statisticRangeExpectation !== undefined) {
      obj.statisticRangeExpectation = DataQualityRule_StatisticRangeExpectation.toJSON(
        message.statisticRangeExpectation,
      );
    }
    if (message.rowConditionExpectation !== undefined) {
      obj.rowConditionExpectation = DataQualityRule_RowConditionExpectation.toJSON(message.rowConditionExpectation);
    }
    if (message.tableConditionExpectation !== undefined) {
      obj.tableConditionExpectation = DataQualityRule_TableConditionExpectation.toJSON(
        message.tableConditionExpectation,
      );
    }
    if (message.column !== "") {
      obj.column = message.column;
    }
    if (message.ignoreNull !== false) {
      obj.ignoreNull = message.ignoreNull;
    }
    if (message.dimension !== "") {
      obj.dimension = message.dimension;
    }
    if (message.threshold !== 0) {
      obj.threshold = message.threshold;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule>, I>>(base?: I): DataQualityRule {
    return DataQualityRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule>, I>>(object: I): DataQualityRule {
    const message = createBaseDataQualityRule();
    message.rangeExpectation = (object.rangeExpectation !== undefined && object.rangeExpectation !== null)
      ? DataQualityRule_RangeExpectation.fromPartial(object.rangeExpectation)
      : undefined;
    message.nonNullExpectation = (object.nonNullExpectation !== undefined && object.nonNullExpectation !== null)
      ? DataQualityRule_NonNullExpectation.fromPartial(object.nonNullExpectation)
      : undefined;
    message.setExpectation = (object.setExpectation !== undefined && object.setExpectation !== null)
      ? DataQualityRule_SetExpectation.fromPartial(object.setExpectation)
      : undefined;
    message.regexExpectation = (object.regexExpectation !== undefined && object.regexExpectation !== null)
      ? DataQualityRule_RegexExpectation.fromPartial(object.regexExpectation)
      : undefined;
    message.uniquenessExpectation =
      (object.uniquenessExpectation !== undefined && object.uniquenessExpectation !== null)
        ? DataQualityRule_UniquenessExpectation.fromPartial(object.uniquenessExpectation)
        : undefined;
    message.statisticRangeExpectation =
      (object.statisticRangeExpectation !== undefined && object.statisticRangeExpectation !== null)
        ? DataQualityRule_StatisticRangeExpectation.fromPartial(object.statisticRangeExpectation)
        : undefined;
    message.rowConditionExpectation =
      (object.rowConditionExpectation !== undefined && object.rowConditionExpectation !== null)
        ? DataQualityRule_RowConditionExpectation.fromPartial(object.rowConditionExpectation)
        : undefined;
    message.tableConditionExpectation =
      (object.tableConditionExpectation !== undefined && object.tableConditionExpectation !== null)
        ? DataQualityRule_TableConditionExpectation.fromPartial(object.tableConditionExpectation)
        : undefined;
    message.column = object.column ?? "";
    message.ignoreNull = object.ignoreNull ?? false;
    message.dimension = object.dimension ?? "";
    message.threshold = object.threshold ?? 0;
    return message;
  },
};

function createBaseDataQualityRule_RangeExpectation(): DataQualityRule_RangeExpectation {
  return { minValue: "", maxValue: "", strictMinEnabled: false, strictMaxEnabled: false };
}

export const DataQualityRule_RangeExpectation: MessageFns<DataQualityRule_RangeExpectation> = {
  encode(message: DataQualityRule_RangeExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.minValue !== "") {
      writer.uint32(10).string(message.minValue);
    }
    if (message.maxValue !== "") {
      writer.uint32(18).string(message.maxValue);
    }
    if (message.strictMinEnabled !== false) {
      writer.uint32(24).bool(message.strictMinEnabled);
    }
    if (message.strictMaxEnabled !== false) {
      writer.uint32(32).bool(message.strictMaxEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RangeExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RangeExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.minValue = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.maxValue = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.strictMinEnabled = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.strictMaxEnabled = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RangeExpectation {
    return {
      minValue: isSet(object.minValue) ? globalThis.String(object.minValue) : "",
      maxValue: isSet(object.maxValue) ? globalThis.String(object.maxValue) : "",
      strictMinEnabled: isSet(object.strictMinEnabled) ? globalThis.Boolean(object.strictMinEnabled) : false,
      strictMaxEnabled: isSet(object.strictMaxEnabled) ? globalThis.Boolean(object.strictMaxEnabled) : false,
    };
  },

  toJSON(message: DataQualityRule_RangeExpectation): unknown {
    const obj: any = {};
    if (message.minValue !== "") {
      obj.minValue = message.minValue;
    }
    if (message.maxValue !== "") {
      obj.maxValue = message.maxValue;
    }
    if (message.strictMinEnabled !== false) {
      obj.strictMinEnabled = message.strictMinEnabled;
    }
    if (message.strictMaxEnabled !== false) {
      obj.strictMaxEnabled = message.strictMaxEnabled;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_RangeExpectation>, I>>(
    base?: I,
  ): DataQualityRule_RangeExpectation {
    return DataQualityRule_RangeExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_RangeExpectation>, I>>(
    object: I,
  ): DataQualityRule_RangeExpectation {
    const message = createBaseDataQualityRule_RangeExpectation();
    message.minValue = object.minValue ?? "";
    message.maxValue = object.maxValue ?? "";
    message.strictMinEnabled = object.strictMinEnabled ?? false;
    message.strictMaxEnabled = object.strictMaxEnabled ?? false;
    return message;
  },
};

function createBaseDataQualityRule_NonNullExpectation(): DataQualityRule_NonNullExpectation {
  return {};
}

export const DataQualityRule_NonNullExpectation: MessageFns<DataQualityRule_NonNullExpectation> = {
  encode(_: DataQualityRule_NonNullExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_NonNullExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_NonNullExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataQualityRule_NonNullExpectation {
    return {};
  },

  toJSON(_: DataQualityRule_NonNullExpectation): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_NonNullExpectation>, I>>(
    base?: I,
  ): DataQualityRule_NonNullExpectation {
    return DataQualityRule_NonNullExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_NonNullExpectation>, I>>(
    _: I,
  ): DataQualityRule_NonNullExpectation {
    const message = createBaseDataQualityRule_NonNullExpectation();
    return message;
  },
};

function createBaseDataQualityRule_SetExpectation(): DataQualityRule_SetExpectation {
  return { values: [] };
}

export const DataQualityRule_SetExpectation: MessageFns<DataQualityRule_SetExpectation> = {
  encode(message: DataQualityRule_SetExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.values) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_SetExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_SetExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.values.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_SetExpectation {
    return {
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: DataQualityRule_SetExpectation): unknown {
    const obj: any = {};
    if (message.values?.length) {
      obj.values = message.values;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_SetExpectation>, I>>(base?: I): DataQualityRule_SetExpectation {
    return DataQualityRule_SetExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_SetExpectation>, I>>(
    object: I,
  ): DataQualityRule_SetExpectation {
    const message = createBaseDataQualityRule_SetExpectation();
    message.values = object.values?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataQualityRule_RegexExpectation(): DataQualityRule_RegexExpectation {
  return { regex: "" };
}

export const DataQualityRule_RegexExpectation: MessageFns<DataQualityRule_RegexExpectation> = {
  encode(message: DataQualityRule_RegexExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.regex !== "") {
      writer.uint32(10).string(message.regex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RegexExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RegexExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.regex = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RegexExpectation {
    return { regex: isSet(object.regex) ? globalThis.String(object.regex) : "" };
  },

  toJSON(message: DataQualityRule_RegexExpectation): unknown {
    const obj: any = {};
    if (message.regex !== "") {
      obj.regex = message.regex;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_RegexExpectation>, I>>(
    base?: I,
  ): DataQualityRule_RegexExpectation {
    return DataQualityRule_RegexExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_RegexExpectation>, I>>(
    object: I,
  ): DataQualityRule_RegexExpectation {
    const message = createBaseDataQualityRule_RegexExpectation();
    message.regex = object.regex ?? "";
    return message;
  },
};

function createBaseDataQualityRule_UniquenessExpectation(): DataQualityRule_UniquenessExpectation {
  return {};
}

export const DataQualityRule_UniquenessExpectation: MessageFns<DataQualityRule_UniquenessExpectation> = {
  encode(_: DataQualityRule_UniquenessExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_UniquenessExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_UniquenessExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DataQualityRule_UniquenessExpectation {
    return {};
  },

  toJSON(_: DataQualityRule_UniquenessExpectation): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_UniquenessExpectation>, I>>(
    base?: I,
  ): DataQualityRule_UniquenessExpectation {
    return DataQualityRule_UniquenessExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_UniquenessExpectation>, I>>(
    _: I,
  ): DataQualityRule_UniquenessExpectation {
    const message = createBaseDataQualityRule_UniquenessExpectation();
    return message;
  },
};

function createBaseDataQualityRule_StatisticRangeExpectation(): DataQualityRule_StatisticRangeExpectation {
  return { statistic: 0, minValue: "", maxValue: "", strictMinEnabled: false, strictMaxEnabled: false };
}

export const DataQualityRule_StatisticRangeExpectation: MessageFns<DataQualityRule_StatisticRangeExpectation> = {
  encode(message: DataQualityRule_StatisticRangeExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.statistic !== 0) {
      writer.uint32(8).int32(message.statistic);
    }
    if (message.minValue !== "") {
      writer.uint32(18).string(message.minValue);
    }
    if (message.maxValue !== "") {
      writer.uint32(26).string(message.maxValue);
    }
    if (message.strictMinEnabled !== false) {
      writer.uint32(32).bool(message.strictMinEnabled);
    }
    if (message.strictMaxEnabled !== false) {
      writer.uint32(40).bool(message.strictMaxEnabled);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_StatisticRangeExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_StatisticRangeExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.statistic = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.minValue = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.maxValue = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.strictMinEnabled = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.strictMaxEnabled = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_StatisticRangeExpectation {
    return {
      statistic: isSet(object.statistic)
        ? dataQualityRule_StatisticRangeExpectation_ColumnStatisticFromJSON(object.statistic)
        : 0,
      minValue: isSet(object.minValue) ? globalThis.String(object.minValue) : "",
      maxValue: isSet(object.maxValue) ? globalThis.String(object.maxValue) : "",
      strictMinEnabled: isSet(object.strictMinEnabled) ? globalThis.Boolean(object.strictMinEnabled) : false,
      strictMaxEnabled: isSet(object.strictMaxEnabled) ? globalThis.Boolean(object.strictMaxEnabled) : false,
    };
  },

  toJSON(message: DataQualityRule_StatisticRangeExpectation): unknown {
    const obj: any = {};
    if (message.statistic !== 0) {
      obj.statistic = dataQualityRule_StatisticRangeExpectation_ColumnStatisticToJSON(message.statistic);
    }
    if (message.minValue !== "") {
      obj.minValue = message.minValue;
    }
    if (message.maxValue !== "") {
      obj.maxValue = message.maxValue;
    }
    if (message.strictMinEnabled !== false) {
      obj.strictMinEnabled = message.strictMinEnabled;
    }
    if (message.strictMaxEnabled !== false) {
      obj.strictMaxEnabled = message.strictMaxEnabled;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_StatisticRangeExpectation>, I>>(
    base?: I,
  ): DataQualityRule_StatisticRangeExpectation {
    return DataQualityRule_StatisticRangeExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_StatisticRangeExpectation>, I>>(
    object: I,
  ): DataQualityRule_StatisticRangeExpectation {
    const message = createBaseDataQualityRule_StatisticRangeExpectation();
    message.statistic = object.statistic ?? 0;
    message.minValue = object.minValue ?? "";
    message.maxValue = object.maxValue ?? "";
    message.strictMinEnabled = object.strictMinEnabled ?? false;
    message.strictMaxEnabled = object.strictMaxEnabled ?? false;
    return message;
  },
};

function createBaseDataQualityRule_RowConditionExpectation(): DataQualityRule_RowConditionExpectation {
  return { sqlExpression: "" };
}

export const DataQualityRule_RowConditionExpectation: MessageFns<DataQualityRule_RowConditionExpectation> = {
  encode(message: DataQualityRule_RowConditionExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlExpression !== "") {
      writer.uint32(10).string(message.sqlExpression);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_RowConditionExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_RowConditionExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.sqlExpression = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_RowConditionExpectation {
    return { sqlExpression: isSet(object.sqlExpression) ? globalThis.String(object.sqlExpression) : "" };
  },

  toJSON(message: DataQualityRule_RowConditionExpectation): unknown {
    const obj: any = {};
    if (message.sqlExpression !== "") {
      obj.sqlExpression = message.sqlExpression;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_RowConditionExpectation>, I>>(
    base?: I,
  ): DataQualityRule_RowConditionExpectation {
    return DataQualityRule_RowConditionExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_RowConditionExpectation>, I>>(
    object: I,
  ): DataQualityRule_RowConditionExpectation {
    const message = createBaseDataQualityRule_RowConditionExpectation();
    message.sqlExpression = object.sqlExpression ?? "";
    return message;
  },
};

function createBaseDataQualityRule_TableConditionExpectation(): DataQualityRule_TableConditionExpectation {
  return { sqlExpression: "" };
}

export const DataQualityRule_TableConditionExpectation: MessageFns<DataQualityRule_TableConditionExpectation> = {
  encode(message: DataQualityRule_TableConditionExpectation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.sqlExpression !== "") {
      writer.uint32(10).string(message.sqlExpression);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataQualityRule_TableConditionExpectation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataQualityRule_TableConditionExpectation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.sqlExpression = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataQualityRule_TableConditionExpectation {
    return { sqlExpression: isSet(object.sqlExpression) ? globalThis.String(object.sqlExpression) : "" };
  },

  toJSON(message: DataQualityRule_TableConditionExpectation): unknown {
    const obj: any = {};
    if (message.sqlExpression !== "") {
      obj.sqlExpression = message.sqlExpression;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataQualityRule_TableConditionExpectation>, I>>(
    base?: I,
  ): DataQualityRule_TableConditionExpectation {
    return DataQualityRule_TableConditionExpectation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataQualityRule_TableConditionExpectation>, I>>(
    object: I,
  ): DataQualityRule_TableConditionExpectation {
    const message = createBaseDataQualityRule_TableConditionExpectation();
    message.sqlExpression = object.sqlExpression ?? "";
    return message;
  },
};

function createBaseResourceAccessSpec(): ResourceAccessSpec {
  return { readers: [], writers: [], owners: [] };
}

export const ResourceAccessSpec: MessageFns<ResourceAccessSpec> = {
  encode(message: ResourceAccessSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.readers) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.writers) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.owners) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ResourceAccessSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseResourceAccessSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.readers.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.writers.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.owners.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ResourceAccessSpec {
    return {
      readers: globalThis.Array.isArray(object?.readers) ? object.readers.map((e: any) => globalThis.String(e)) : [],
      writers: globalThis.Array.isArray(object?.writers) ? object.writers.map((e: any) => globalThis.String(e)) : [],
      owners: globalThis.Array.isArray(object?.owners) ? object.owners.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: ResourceAccessSpec): unknown {
    const obj: any = {};
    if (message.readers?.length) {
      obj.readers = message.readers;
    }
    if (message.writers?.length) {
      obj.writers = message.writers;
    }
    if (message.owners?.length) {
      obj.owners = message.owners;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ResourceAccessSpec>, I>>(base?: I): ResourceAccessSpec {
    return ResourceAccessSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ResourceAccessSpec>, I>>(object: I): ResourceAccessSpec {
    const message = createBaseResourceAccessSpec();
    message.readers = object.readers?.map((e) => e) || [];
    message.writers = object.writers?.map((e) => e) || [];
    message.owners = object.owners?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataAccessSpec(): DataAccessSpec {
  return { readers: [] };
}

export const DataAccessSpec: MessageFns<DataAccessSpec> = {
  encode(message: DataAccessSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.readers) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAccessSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAccessSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.readers.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAccessSpec {
    return {
      readers: globalThis.Array.isArray(object?.readers) ? object.readers.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: DataAccessSpec): unknown {
    const obj: any = {};
    if (message.readers?.length) {
      obj.readers = message.readers;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAccessSpec>, I>>(base?: I): DataAccessSpec {
    return DataAccessSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAccessSpec>, I>>(object: I): DataAccessSpec {
    const message = createBaseDataAccessSpec();
    message.readers = object.readers?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataTaxonomy(): DataTaxonomy {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    displayName: "",
    labels: {},
    attributeCount: 0,
    etag: "",
  };
}

export const DataTaxonomy: MessageFns<DataTaxonomy> = {
  encode(message: DataTaxonomy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      DataTaxonomy_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.attributeCount !== 0) {
      writer.uint32(72).int32(message.attributeCount);
    }
    if (message.etag !== "") {
      writer.uint32(82).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataTaxonomy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataTaxonomy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = DataTaxonomy_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.attributeCount = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataTaxonomy {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      attributeCount: isSet(object.attributeCount) ? globalThis.Number(object.attributeCount) : 0,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: DataTaxonomy): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.attributeCount !== 0) {
      obj.attributeCount = Math.round(message.attributeCount);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataTaxonomy>, I>>(base?: I): DataTaxonomy {
    return DataTaxonomy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataTaxonomy>, I>>(object: I): DataTaxonomy {
    const message = createBaseDataTaxonomy();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.attributeCount = object.attributeCount ?? 0;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseDataTaxonomy_LabelsEntry(): DataTaxonomy_LabelsEntry {
  return { key: "", value: "" };
}

export const DataTaxonomy_LabelsEntry: MessageFns<DataTaxonomy_LabelsEntry> = {
  encode(message: DataTaxonomy_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataTaxonomy_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataTaxonomy_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataTaxonomy_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DataTaxonomy_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataTaxonomy_LabelsEntry>, I>>(base?: I): DataTaxonomy_LabelsEntry {
    return DataTaxonomy_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataTaxonomy_LabelsEntry>, I>>(object: I): DataTaxonomy_LabelsEntry {
    const message = createBaseDataTaxonomy_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDataAttribute(): DataAttribute {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    displayName: "",
    labels: {},
    parentId: "",
    attributeCount: 0,
    etag: "",
    resourceAccessSpec: undefined,
    dataAccessSpec: undefined,
  };
}

export const DataAttribute: MessageFns<DataAttribute> = {
  encode(message: DataAttribute, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      DataAttribute_LabelsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    if (message.parentId !== "") {
      writer.uint32(66).string(message.parentId);
    }
    if (message.attributeCount !== 0) {
      writer.uint32(72).int32(message.attributeCount);
    }
    if (message.etag !== "") {
      writer.uint32(82).string(message.etag);
    }
    if (message.resourceAccessSpec !== undefined) {
      ResourceAccessSpec.encode(message.resourceAccessSpec, writer.uint32(802).fork()).join();
    }
    if (message.dataAccessSpec !== undefined) {
      DataAccessSpec.encode(message.dataAccessSpec, writer.uint32(810).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttribute {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttribute();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          const entry7 = DataAttribute_LabelsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.labels[entry7.key] = entry7.value;
          }
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.parentId = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.attributeCount = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.resourceAccessSpec = ResourceAccessSpec.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.dataAccessSpec = DataAccessSpec.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttribute {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      parentId: isSet(object.parentId) ? globalThis.String(object.parentId) : "",
      attributeCount: isSet(object.attributeCount) ? globalThis.Number(object.attributeCount) : 0,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      resourceAccessSpec: isSet(object.resourceAccessSpec)
        ? ResourceAccessSpec.fromJSON(object.resourceAccessSpec)
        : undefined,
      dataAccessSpec: isSet(object.dataAccessSpec) ? DataAccessSpec.fromJSON(object.dataAccessSpec) : undefined,
    };
  },

  toJSON(message: DataAttribute): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.parentId !== "") {
      obj.parentId = message.parentId;
    }
    if (message.attributeCount !== 0) {
      obj.attributeCount = Math.round(message.attributeCount);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.resourceAccessSpec !== undefined) {
      obj.resourceAccessSpec = ResourceAccessSpec.toJSON(message.resourceAccessSpec);
    }
    if (message.dataAccessSpec !== undefined) {
      obj.dataAccessSpec = DataAccessSpec.toJSON(message.dataAccessSpec);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttribute>, I>>(base?: I): DataAttribute {
    return DataAttribute.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttribute>, I>>(object: I): DataAttribute {
    const message = createBaseDataAttribute();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.parentId = object.parentId ?? "";
    message.attributeCount = object.attributeCount ?? 0;
    message.etag = object.etag ?? "";
    message.resourceAccessSpec = (object.resourceAccessSpec !== undefined && object.resourceAccessSpec !== null)
      ? ResourceAccessSpec.fromPartial(object.resourceAccessSpec)
      : undefined;
    message.dataAccessSpec = (object.dataAccessSpec !== undefined && object.dataAccessSpec !== null)
      ? DataAccessSpec.fromPartial(object.dataAccessSpec)
      : undefined;
    return message;
  },
};

function createBaseDataAttribute_LabelsEntry(): DataAttribute_LabelsEntry {
  return { key: "", value: "" };
}

export const DataAttribute_LabelsEntry: MessageFns<DataAttribute_LabelsEntry> = {
  encode(message: DataAttribute_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttribute_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttribute_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttribute_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DataAttribute_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttribute_LabelsEntry>, I>>(base?: I): DataAttribute_LabelsEntry {
    return DataAttribute_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttribute_LabelsEntry>, I>>(object: I): DataAttribute_LabelsEntry {
    const message = createBaseDataAttribute_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDataAttributeBinding(): DataAttributeBinding {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    displayName: "",
    labels: {},
    etag: "",
    resource: undefined,
    attributes: [],
    paths: [],
  };
}

export const DataAttributeBinding: MessageFns<DataAttributeBinding> = {
  encode(message: DataAttributeBinding, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      DataAttributeBinding_LabelsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    if (message.resource !== undefined) {
      writer.uint32(802).string(message.resource);
    }
    for (const v of message.attributes) {
      writer.uint32(882).string(v!);
    }
    for (const v of message.paths) {
      DataAttributeBinding_Path.encode(v!, writer.uint32(962).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttributeBinding {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttributeBinding();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          const entry7 = DataAttributeBinding_LabelsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.labels[entry7.key] = entry7.value;
          }
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.resource = reader.string();
          continue;
        }
        case 110: {
          if (tag !== 882) {
            break;
          }

          message.attributes.push(reader.string());
          continue;
        }
        case 120: {
          if (tag !== 962) {
            break;
          }

          message.paths.push(DataAttributeBinding_Path.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttributeBinding {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      resource: isSet(object.resource) ? globalThis.String(object.resource) : undefined,
      attributes: globalThis.Array.isArray(object?.attributes)
        ? object.attributes.map((e: any) => globalThis.String(e))
        : [],
      paths: globalThis.Array.isArray(object?.paths)
        ? object.paths.map((e: any) => DataAttributeBinding_Path.fromJSON(e))
        : [],
    };
  },

  toJSON(message: DataAttributeBinding): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.resource !== undefined) {
      obj.resource = message.resource;
    }
    if (message.attributes?.length) {
      obj.attributes = message.attributes;
    }
    if (message.paths?.length) {
      obj.paths = message.paths.map((e) => DataAttributeBinding_Path.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttributeBinding>, I>>(base?: I): DataAttributeBinding {
    return DataAttributeBinding.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttributeBinding>, I>>(object: I): DataAttributeBinding {
    const message = createBaseDataAttributeBinding();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.etag = object.etag ?? "";
    message.resource = object.resource ?? undefined;
    message.attributes = object.attributes?.map((e) => e) || [];
    message.paths = object.paths?.map((e) => DataAttributeBinding_Path.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDataAttributeBinding_Path(): DataAttributeBinding_Path {
  return { name: "", attributes: [] };
}

export const DataAttributeBinding_Path: MessageFns<DataAttributeBinding_Path> = {
  encode(message: DataAttributeBinding_Path, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    for (const v of message.attributes) {
      writer.uint32(18).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttributeBinding_Path {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttributeBinding_Path();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.attributes.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttributeBinding_Path {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      attributes: globalThis.Array.isArray(object?.attributes)
        ? object.attributes.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: DataAttributeBinding_Path): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.attributes?.length) {
      obj.attributes = message.attributes;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttributeBinding_Path>, I>>(base?: I): DataAttributeBinding_Path {
    return DataAttributeBinding_Path.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttributeBinding_Path>, I>>(object: I): DataAttributeBinding_Path {
    const message = createBaseDataAttributeBinding_Path();
    message.name = object.name ?? "";
    message.attributes = object.attributes?.map((e) => e) || [];
    return message;
  },
};

function createBaseDataAttributeBinding_LabelsEntry(): DataAttributeBinding_LabelsEntry {
  return { key: "", value: "" };
}

export const DataAttributeBinding_LabelsEntry: MessageFns<DataAttributeBinding_LabelsEntry> = {
  encode(message: DataAttributeBinding_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttributeBinding_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttributeBinding_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttributeBinding_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DataAttributeBinding_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttributeBinding_LabelsEntry>, I>>(
    base?: I,
  ): DataAttributeBinding_LabelsEntry {
    return DataAttributeBinding_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttributeBinding_LabelsEntry>, I>>(
    object: I,
  ): DataAttributeBinding_LabelsEntry {
    const message = createBaseDataAttributeBinding_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDataScan(): DataScan {
  return {
    name: "",
    uid: "",
    description: "",
    displayName: "",
    labels: {},
    state: 0,
    createTime: undefined,
    updateTime: undefined,
    data: undefined,
    executionSpec: undefined,
    executionStatus: undefined,
    type: 0,
    dataQualitySpec: undefined,
    dataProfileSpec: undefined,
    dataQualityResult: undefined,
    dataProfileResult: undefined,
  };
}

export const DataScan: MessageFns<DataScan> = {
  encode(message: DataScan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(34).string(message.displayName);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      DataScan_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(66).fork()).join();
    }
    if (message.data !== undefined) {
      DataSource.encode(message.data, writer.uint32(74).fork()).join();
    }
    if (message.executionSpec !== undefined) {
      DataScan_ExecutionSpec.encode(message.executionSpec, writer.uint32(82).fork()).join();
    }
    if (message.executionStatus !== undefined) {
      DataScan_ExecutionStatus.encode(message.executionStatus, writer.uint32(90).fork()).join();
    }
    if (message.type !== 0) {
      writer.uint32(96).int32(message.type);
    }
    if (message.dataQualitySpec !== undefined) {
      DataQualitySpec.encode(message.dataQualitySpec, writer.uint32(802).fork()).join();
    }
    if (message.dataProfileSpec !== undefined) {
      DataProfileSpec.encode(message.dataProfileSpec, writer.uint32(810).fork()).join();
    }
    if (message.dataQualityResult !== undefined) {
      DataQualityResult.encode(message.dataQualityResult, writer.uint32(1602).fork()).join();
    }
    if (message.dataProfileResult !== undefined) {
      DataProfileResult.encode(message.dataProfileResult, writer.uint32(1610).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = DataScan_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.data = DataSource.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.executionSpec = DataScan_ExecutionSpec.decode(reader, reader.uint32());
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.executionStatus = DataScan_ExecutionStatus.decode(reader, reader.uint32());
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.dataQualitySpec = DataQualitySpec.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.dataProfileSpec = DataProfileSpec.decode(reader, reader.uint32());
          continue;
        }
        case 200: {
          if (tag !== 1602) {
            break;
          }

          message.dataQualityResult = DataQualityResult.decode(reader, reader.uint32());
          continue;
        }
        case 201: {
          if (tag !== 1610) {
            break;
          }

          message.dataProfileResult = DataProfileResult.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScan {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      data: isSet(object.data) ? DataSource.fromJSON(object.data) : undefined,
      executionSpec: isSet(object.executionSpec) ? DataScan_ExecutionSpec.fromJSON(object.executionSpec) : undefined,
      executionStatus: isSet(object.executionStatus)
        ? DataScan_ExecutionStatus.fromJSON(object.executionStatus)
        : undefined,
      type: isSet(object.type) ? dataScanTypeFromJSON(object.type) : 0,
      dataQualitySpec: isSet(object.dataQualitySpec) ? DataQualitySpec.fromJSON(object.dataQualitySpec) : undefined,
      dataProfileSpec: isSet(object.dataProfileSpec) ? DataProfileSpec.fromJSON(object.dataProfileSpec) : undefined,
      dataQualityResult: isSet(object.dataQualityResult)
        ? DataQualityResult.fromJSON(object.dataQualityResult)
        : undefined,
      dataProfileResult: isSet(object.dataProfileResult)
        ? DataProfileResult.fromJSON(object.dataProfileResult)
        : undefined,
    };
  },

  toJSON(message: DataScan): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.data !== undefined) {
      obj.data = DataSource.toJSON(message.data);
    }
    if (message.executionSpec !== undefined) {
      obj.executionSpec = DataScan_ExecutionSpec.toJSON(message.executionSpec);
    }
    if (message.executionStatus !== undefined) {
      obj.executionStatus = DataScan_ExecutionStatus.toJSON(message.executionStatus);
    }
    if (message.type !== 0) {
      obj.type = dataScanTypeToJSON(message.type);
    }
    if (message.dataQualitySpec !== undefined) {
      obj.dataQualitySpec = DataQualitySpec.toJSON(message.dataQualitySpec);
    }
    if (message.dataProfileSpec !== undefined) {
      obj.dataProfileSpec = DataProfileSpec.toJSON(message.dataProfileSpec);
    }
    if (message.dataQualityResult !== undefined) {
      obj.dataQualityResult = DataQualityResult.toJSON(message.dataQualityResult);
    }
    if (message.dataProfileResult !== undefined) {
      obj.dataProfileResult = DataProfileResult.toJSON(message.dataProfileResult);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataScan>, I>>(base?: I): DataScan {
    return DataScan.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataScan>, I>>(object: I): DataScan {
    const message = createBaseDataScan();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.state = object.state ?? 0;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.data = (object.data !== undefined && object.data !== null)
      ? DataSource.fromPartial(object.data)
      : undefined;
    message.executionSpec = (object.executionSpec !== undefined && object.executionSpec !== null)
      ? DataScan_ExecutionSpec.fromPartial(object.executionSpec)
      : undefined;
    message.executionStatus = (object.executionStatus !== undefined && object.executionStatus !== null)
      ? DataScan_ExecutionStatus.fromPartial(object.executionStatus)
      : undefined;
    message.type = object.type ?? 0;
    message.dataQualitySpec = (object.dataQualitySpec !== undefined && object.dataQualitySpec !== null)
      ? DataQualitySpec.fromPartial(object.dataQualitySpec)
      : undefined;
    message.dataProfileSpec = (object.dataProfileSpec !== undefined && object.dataProfileSpec !== null)
      ? DataProfileSpec.fromPartial(object.dataProfileSpec)
      : undefined;
    message.dataQualityResult = (object.dataQualityResult !== undefined && object.dataQualityResult !== null)
      ? DataQualityResult.fromPartial(object.dataQualityResult)
      : undefined;
    message.dataProfileResult = (object.dataProfileResult !== undefined && object.dataProfileResult !== null)
      ? DataProfileResult.fromPartial(object.dataProfileResult)
      : undefined;
    return message;
  },
};

function createBaseDataScan_ExecutionSpec(): DataScan_ExecutionSpec {
  return { trigger: undefined, field: undefined };
}

export const DataScan_ExecutionSpec: MessageFns<DataScan_ExecutionSpec> = {
  encode(message: DataScan_ExecutionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trigger !== undefined) {
      Trigger.encode(message.trigger, writer.uint32(10).fork()).join();
    }
    if (message.field !== undefined) {
      writer.uint32(802).string(message.field);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScan_ExecutionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScan_ExecutionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.trigger = Trigger.decode(reader, reader.uint32());
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.field = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScan_ExecutionSpec {
    return {
      trigger: isSet(object.trigger) ? Trigger.fromJSON(object.trigger) : undefined,
      field: isSet(object.field) ? globalThis.String(object.field) : undefined,
    };
  },

  toJSON(message: DataScan_ExecutionSpec): unknown {
    const obj: any = {};
    if (message.trigger !== undefined) {
      obj.trigger = Trigger.toJSON(message.trigger);
    }
    if (message.field !== undefined) {
      obj.field = message.field;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataScan_ExecutionSpec>, I>>(base?: I): DataScan_ExecutionSpec {
    return DataScan_ExecutionSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataScan_ExecutionSpec>, I>>(object: I): DataScan_ExecutionSpec {
    const message = createBaseDataScan_ExecutionSpec();
    message.trigger = (object.trigger !== undefined && object.trigger !== null)
      ? Trigger.fromPartial(object.trigger)
      : undefined;
    message.field = object.field ?? undefined;
    return message;
  },
};

function createBaseDataScan_ExecutionStatus(): DataScan_ExecutionStatus {
  return { latestJobStartTime: undefined, latestJobEndTime: undefined };
}

export const DataScan_ExecutionStatus: MessageFns<DataScan_ExecutionStatus> = {
  encode(message: DataScan_ExecutionStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.latestJobStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.latestJobStartTime), writer.uint32(34).fork()).join();
    }
    if (message.latestJobEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.latestJobEndTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScan_ExecutionStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScan_ExecutionStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.latestJobStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.latestJobEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScan_ExecutionStatus {
    return {
      latestJobStartTime: isSet(object.latestJobStartTime) ? fromJsonTimestamp(object.latestJobStartTime) : undefined,
      latestJobEndTime: isSet(object.latestJobEndTime) ? fromJsonTimestamp(object.latestJobEndTime) : undefined,
    };
  },

  toJSON(message: DataScan_ExecutionStatus): unknown {
    const obj: any = {};
    if (message.latestJobStartTime !== undefined) {
      obj.latestJobStartTime = message.latestJobStartTime.toISOString();
    }
    if (message.latestJobEndTime !== undefined) {
      obj.latestJobEndTime = message.latestJobEndTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataScan_ExecutionStatus>, I>>(base?: I): DataScan_ExecutionStatus {
    return DataScan_ExecutionStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataScan_ExecutionStatus>, I>>(object: I): DataScan_ExecutionStatus {
    const message = createBaseDataScan_ExecutionStatus();
    message.latestJobStartTime = object.latestJobStartTime ?? undefined;
    message.latestJobEndTime = object.latestJobEndTime ?? undefined;
    return message;
  },
};

function createBaseDataScan_LabelsEntry(): DataScan_LabelsEntry {
  return { key: "", value: "" };
}

export const DataScan_LabelsEntry: MessageFns<DataScan_LabelsEntry> = {
  encode(message: DataScan_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScan_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScan_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScan_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DataScan_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataScan_LabelsEntry>, I>>(base?: I): DataScan_LabelsEntry {
    return DataScan_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataScan_LabelsEntry>, I>>(object: I): DataScan_LabelsEntry {
    const message = createBaseDataScan_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTask(): Task {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    displayName: "",
    state: 0,
    labels: {},
    triggerSpec: undefined,
    executionSpec: undefined,
    executionStatus: undefined,
    spark: undefined,
    notebook: undefined,
  };
}

export const Task: MessageFns<Task> = {
  encode(message: Task, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(50).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Task_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.triggerSpec !== undefined) {
      Task_TriggerSpec.encode(message.triggerSpec, writer.uint32(802).fork()).join();
    }
    if (message.executionSpec !== undefined) {
      Task_ExecutionSpec.encode(message.executionSpec, writer.uint32(810).fork()).join();
    }
    if (message.executionStatus !== undefined) {
      Task_ExecutionStatus.encode(message.executionStatus, writer.uint32(1610).fork()).join();
    }
    if (message.spark !== undefined) {
      Task_SparkTaskConfig.encode(message.spark, writer.uint32(2402).fork()).join();
    }
    if (message.notebook !== undefined) {
      Task_NotebookTaskConfig.encode(message.notebook, writer.uint32(2418).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = Task_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.triggerSpec = Task_TriggerSpec.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.executionSpec = Task_ExecutionSpec.decode(reader, reader.uint32());
          continue;
        }
        case 201: {
          if (tag !== 1610) {
            break;
          }

          message.executionStatus = Task_ExecutionStatus.decode(reader, reader.uint32());
          continue;
        }
        case 300: {
          if (tag !== 2402) {
            break;
          }

          message.spark = Task_SparkTaskConfig.decode(reader, reader.uint32());
          continue;
        }
        case 302: {
          if (tag !== 2418) {
            break;
          }

          message.notebook = Task_NotebookTaskConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? stateFromJSON(object.state) : 0,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      triggerSpec: isSet(object.triggerSpec) ? Task_TriggerSpec.fromJSON(object.triggerSpec) : undefined,
      executionSpec: isSet(object.executionSpec) ? Task_ExecutionSpec.fromJSON(object.executionSpec) : undefined,
      executionStatus: isSet(object.executionStatus)
        ? Task_ExecutionStatus.fromJSON(object.executionStatus)
        : undefined,
      spark: isSet(object.spark) ? Task_SparkTaskConfig.fromJSON(object.spark) : undefined,
      notebook: isSet(object.notebook) ? Task_NotebookTaskConfig.fromJSON(object.notebook) : undefined,
    };
  },

  toJSON(message: Task): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = stateToJSON(message.state);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.triggerSpec !== undefined) {
      obj.triggerSpec = Task_TriggerSpec.toJSON(message.triggerSpec);
    }
    if (message.executionSpec !== undefined) {
      obj.executionSpec = Task_ExecutionSpec.toJSON(message.executionSpec);
    }
    if (message.executionStatus !== undefined) {
      obj.executionStatus = Task_ExecutionStatus.toJSON(message.executionStatus);
    }
    if (message.spark !== undefined) {
      obj.spark = Task_SparkTaskConfig.toJSON(message.spark);
    }
    if (message.notebook !== undefined) {
      obj.notebook = Task_NotebookTaskConfig.toJSON(message.notebook);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task>, I>>(base?: I): Task {
    return Task.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task>, I>>(object: I): Task {
    const message = createBaseTask();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.triggerSpec = (object.triggerSpec !== undefined && object.triggerSpec !== null)
      ? Task_TriggerSpec.fromPartial(object.triggerSpec)
      : undefined;
    message.executionSpec = (object.executionSpec !== undefined && object.executionSpec !== null)
      ? Task_ExecutionSpec.fromPartial(object.executionSpec)
      : undefined;
    message.executionStatus = (object.executionStatus !== undefined && object.executionStatus !== null)
      ? Task_ExecutionStatus.fromPartial(object.executionStatus)
      : undefined;
    message.spark = (object.spark !== undefined && object.spark !== null)
      ? Task_SparkTaskConfig.fromPartial(object.spark)
      : undefined;
    message.notebook = (object.notebook !== undefined && object.notebook !== null)
      ? Task_NotebookTaskConfig.fromPartial(object.notebook)
      : undefined;
    return message;
  },
};

function createBaseTask_InfrastructureSpec(): Task_InfrastructureSpec {
  return { batch: undefined, containerImage: undefined, vpcNetwork: undefined };
}

export const Task_InfrastructureSpec: MessageFns<Task_InfrastructureSpec> = {
  encode(message: Task_InfrastructureSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.batch !== undefined) {
      Task_InfrastructureSpec_BatchComputeResources.encode(message.batch, writer.uint32(418).fork()).join();
    }
    if (message.containerImage !== undefined) {
      Task_InfrastructureSpec_ContainerImageRuntime.encode(message.containerImage, writer.uint32(810).fork()).join();
    }
    if (message.vpcNetwork !== undefined) {
      Task_InfrastructureSpec_VpcNetwork.encode(message.vpcNetwork, writer.uint32(1202).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 52: {
          if (tag !== 418) {
            break;
          }

          message.batch = Task_InfrastructureSpec_BatchComputeResources.decode(reader, reader.uint32());
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.containerImage = Task_InfrastructureSpec_ContainerImageRuntime.decode(reader, reader.uint32());
          continue;
        }
        case 150: {
          if (tag !== 1202) {
            break;
          }

          message.vpcNetwork = Task_InfrastructureSpec_VpcNetwork.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec {
    return {
      batch: isSet(object.batch) ? Task_InfrastructureSpec_BatchComputeResources.fromJSON(object.batch) : undefined,
      containerImage: isSet(object.containerImage)
        ? Task_InfrastructureSpec_ContainerImageRuntime.fromJSON(object.containerImage)
        : undefined,
      vpcNetwork: isSet(object.vpcNetwork) ? Task_InfrastructureSpec_VpcNetwork.fromJSON(object.vpcNetwork) : undefined,
    };
  },

  toJSON(message: Task_InfrastructureSpec): unknown {
    const obj: any = {};
    if (message.batch !== undefined) {
      obj.batch = Task_InfrastructureSpec_BatchComputeResources.toJSON(message.batch);
    }
    if (message.containerImage !== undefined) {
      obj.containerImage = Task_InfrastructureSpec_ContainerImageRuntime.toJSON(message.containerImage);
    }
    if (message.vpcNetwork !== undefined) {
      obj.vpcNetwork = Task_InfrastructureSpec_VpcNetwork.toJSON(message.vpcNetwork);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_InfrastructureSpec>, I>>(base?: I): Task_InfrastructureSpec {
    return Task_InfrastructureSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_InfrastructureSpec>, I>>(object: I): Task_InfrastructureSpec {
    const message = createBaseTask_InfrastructureSpec();
    message.batch = (object.batch !== undefined && object.batch !== null)
      ? Task_InfrastructureSpec_BatchComputeResources.fromPartial(object.batch)
      : undefined;
    message.containerImage = (object.containerImage !== undefined && object.containerImage !== null)
      ? Task_InfrastructureSpec_ContainerImageRuntime.fromPartial(object.containerImage)
      : undefined;
    message.vpcNetwork = (object.vpcNetwork !== undefined && object.vpcNetwork !== null)
      ? Task_InfrastructureSpec_VpcNetwork.fromPartial(object.vpcNetwork)
      : undefined;
    return message;
  },
};

function createBaseTask_InfrastructureSpec_BatchComputeResources(): Task_InfrastructureSpec_BatchComputeResources {
  return { executorsCount: 0, maxExecutorsCount: 0 };
}

export const Task_InfrastructureSpec_BatchComputeResources: MessageFns<Task_InfrastructureSpec_BatchComputeResources> =
  {
    encode(
      message: Task_InfrastructureSpec_BatchComputeResources,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.executorsCount !== 0) {
        writer.uint32(8).int32(message.executorsCount);
      }
      if (message.maxExecutorsCount !== 0) {
        writer.uint32(16).int32(message.maxExecutorsCount);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_BatchComputeResources {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      const end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseTask_InfrastructureSpec_BatchComputeResources();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 8) {
              break;
            }

            message.executorsCount = reader.int32();
            continue;
          }
          case 2: {
            if (tag !== 16) {
              break;
            }

            message.maxExecutorsCount = reader.int32();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Task_InfrastructureSpec_BatchComputeResources {
      return {
        executorsCount: isSet(object.executorsCount) ? globalThis.Number(object.executorsCount) : 0,
        maxExecutorsCount: isSet(object.maxExecutorsCount) ? globalThis.Number(object.maxExecutorsCount) : 0,
      };
    },

    toJSON(message: Task_InfrastructureSpec_BatchComputeResources): unknown {
      const obj: any = {};
      if (message.executorsCount !== 0) {
        obj.executorsCount = Math.round(message.executorsCount);
      }
      if (message.maxExecutorsCount !== 0) {
        obj.maxExecutorsCount = Math.round(message.maxExecutorsCount);
      }
      return obj;
    },

    create<I extends Exact<DeepPartial<Task_InfrastructureSpec_BatchComputeResources>, I>>(
      base?: I,
    ): Task_InfrastructureSpec_BatchComputeResources {
      return Task_InfrastructureSpec_BatchComputeResources.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<Task_InfrastructureSpec_BatchComputeResources>, I>>(
      object: I,
    ): Task_InfrastructureSpec_BatchComputeResources {
      const message = createBaseTask_InfrastructureSpec_BatchComputeResources();
      message.executorsCount = object.executorsCount ?? 0;
      message.maxExecutorsCount = object.maxExecutorsCount ?? 0;
      return message;
    },
  };

function createBaseTask_InfrastructureSpec_ContainerImageRuntime(): Task_InfrastructureSpec_ContainerImageRuntime {
  return { image: "", javaJars: [], pythonPackages: [], properties: {} };
}

export const Task_InfrastructureSpec_ContainerImageRuntime: MessageFns<Task_InfrastructureSpec_ContainerImageRuntime> =
  {
    encode(
      message: Task_InfrastructureSpec_ContainerImageRuntime,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.image !== "") {
        writer.uint32(10).string(message.image);
      }
      for (const v of message.javaJars) {
        writer.uint32(18).string(v!);
      }
      for (const v of message.pythonPackages) {
        writer.uint32(26).string(v!);
      }
      Object.entries(message.properties).forEach(([key, value]) => {
        Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.encode(
          { key: key as any, value },
          writer.uint32(34).fork(),
        ).join();
      });
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_ContainerImageRuntime {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      const end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.image = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.javaJars.push(reader.string());
            continue;
          }
          case 3: {
            if (tag !== 26) {
              break;
            }

            message.pythonPackages.push(reader.string());
            continue;
          }
          case 4: {
            if (tag !== 34) {
              break;
            }

            const entry4 = Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.decode(
              reader,
              reader.uint32(),
            );
            if (entry4.value !== undefined) {
              message.properties[entry4.key] = entry4.value;
            }
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Task_InfrastructureSpec_ContainerImageRuntime {
      return {
        image: isSet(object.image) ? globalThis.String(object.image) : "",
        javaJars: globalThis.Array.isArray(object?.javaJars)
          ? object.javaJars.map((e: any) => globalThis.String(e))
          : [],
        pythonPackages: globalThis.Array.isArray(object?.pythonPackages)
          ? object.pythonPackages.map((e: any) => globalThis.String(e))
          : [],
        properties: isObject(object.properties)
          ? Object.entries(object.properties).reduce<{ [key: string]: string }>((acc, [key, value]) => {
            acc[key] = String(value);
            return acc;
          }, {})
          : {},
      };
    },

    toJSON(message: Task_InfrastructureSpec_ContainerImageRuntime): unknown {
      const obj: any = {};
      if (message.image !== "") {
        obj.image = message.image;
      }
      if (message.javaJars?.length) {
        obj.javaJars = message.javaJars;
      }
      if (message.pythonPackages?.length) {
        obj.pythonPackages = message.pythonPackages;
      }
      if (message.properties) {
        const entries = Object.entries(message.properties);
        if (entries.length > 0) {
          obj.properties = {};
          entries.forEach(([k, v]) => {
            obj.properties[k] = v;
          });
        }
      }
      return obj;
    },

    create<I extends Exact<DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime>, I>>(
      base?: I,
    ): Task_InfrastructureSpec_ContainerImageRuntime {
      return Task_InfrastructureSpec_ContainerImageRuntime.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime>, I>>(
      object: I,
    ): Task_InfrastructureSpec_ContainerImageRuntime {
      const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime();
      message.image = object.image ?? "";
      message.javaJars = object.javaJars?.map((e) => e) || [];
      message.pythonPackages = object.pythonPackages?.map((e) => e) || [];
      message.properties = Object.entries(object.properties ?? {}).reduce<{ [key: string]: string }>(
        (acc, [key, value]) => {
          if (value !== undefined) {
            acc[key] = globalThis.String(value);
          }
          return acc;
        },
        {},
      );
      return message;
    },
  };

function createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry(): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
  return { key: "", value: "" };
}

export const Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry: MessageFns<
  Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry
> = {
  encode(
    message: Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(
    input: BinaryReader | Uint8Array,
    length?: number,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry>, I>>(
    base?: I,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    return Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry>, I>>(
    object: I,
  ): Task_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry {
    const message = createBaseTask_InfrastructureSpec_ContainerImageRuntime_PropertiesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTask_InfrastructureSpec_VpcNetwork(): Task_InfrastructureSpec_VpcNetwork {
  return { network: undefined, subNetwork: undefined, networkTags: [] };
}

export const Task_InfrastructureSpec_VpcNetwork: MessageFns<Task_InfrastructureSpec_VpcNetwork> = {
  encode(message: Task_InfrastructureSpec_VpcNetwork, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.network !== undefined) {
      writer.uint32(10).string(message.network);
    }
    if (message.subNetwork !== undefined) {
      writer.uint32(18).string(message.subNetwork);
    }
    for (const v of message.networkTags) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_InfrastructureSpec_VpcNetwork {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_InfrastructureSpec_VpcNetwork();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.network = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.subNetwork = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.networkTags.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_InfrastructureSpec_VpcNetwork {
    return {
      network: isSet(object.network) ? globalThis.String(object.network) : undefined,
      subNetwork: isSet(object.subNetwork) ? globalThis.String(object.subNetwork) : undefined,
      networkTags: globalThis.Array.isArray(object?.networkTags)
        ? object.networkTags.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Task_InfrastructureSpec_VpcNetwork): unknown {
    const obj: any = {};
    if (message.network !== undefined) {
      obj.network = message.network;
    }
    if (message.subNetwork !== undefined) {
      obj.subNetwork = message.subNetwork;
    }
    if (message.networkTags?.length) {
      obj.networkTags = message.networkTags;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_InfrastructureSpec_VpcNetwork>, I>>(
    base?: I,
  ): Task_InfrastructureSpec_VpcNetwork {
    return Task_InfrastructureSpec_VpcNetwork.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_InfrastructureSpec_VpcNetwork>, I>>(
    object: I,
  ): Task_InfrastructureSpec_VpcNetwork {
    const message = createBaseTask_InfrastructureSpec_VpcNetwork();
    message.network = object.network ?? undefined;
    message.subNetwork = object.subNetwork ?? undefined;
    message.networkTags = object.networkTags?.map((e) => e) || [];
    return message;
  },
};

function createBaseTask_TriggerSpec(): Task_TriggerSpec {
  return { type: 0, startTime: undefined, disabled: false, maxRetries: 0, schedule: undefined };
}

export const Task_TriggerSpec: MessageFns<Task_TriggerSpec> = {
  encode(message: Task_TriggerSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(50).fork()).join();
    }
    if (message.disabled !== false) {
      writer.uint32(32).bool(message.disabled);
    }
    if (message.maxRetries !== 0) {
      writer.uint32(56).int32(message.maxRetries);
    }
    if (message.schedule !== undefined) {
      writer.uint32(802).string(message.schedule);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_TriggerSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_TriggerSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.disabled = reader.bool();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.maxRetries = reader.int32();
          continue;
        }
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.schedule = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_TriggerSpec {
    return {
      type: isSet(object.type) ? task_TriggerSpec_TypeFromJSON(object.type) : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      disabled: isSet(object.disabled) ? globalThis.Boolean(object.disabled) : false,
      maxRetries: isSet(object.maxRetries) ? globalThis.Number(object.maxRetries) : 0,
      schedule: isSet(object.schedule) ? globalThis.String(object.schedule) : undefined,
    };
  },

  toJSON(message: Task_TriggerSpec): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = task_TriggerSpec_TypeToJSON(message.type);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.disabled !== false) {
      obj.disabled = message.disabled;
    }
    if (message.maxRetries !== 0) {
      obj.maxRetries = Math.round(message.maxRetries);
    }
    if (message.schedule !== undefined) {
      obj.schedule = message.schedule;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_TriggerSpec>, I>>(base?: I): Task_TriggerSpec {
    return Task_TriggerSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_TriggerSpec>, I>>(object: I): Task_TriggerSpec {
    const message = createBaseTask_TriggerSpec();
    message.type = object.type ?? 0;
    message.startTime = object.startTime ?? undefined;
    message.disabled = object.disabled ?? false;
    message.maxRetries = object.maxRetries ?? 0;
    message.schedule = object.schedule ?? undefined;
    return message;
  },
};

function createBaseTask_ExecutionSpec(): Task_ExecutionSpec {
  return { args: {}, serviceAccount: "", project: "", maxJobExecutionLifetime: undefined, kmsKey: "" };
}

export const Task_ExecutionSpec: MessageFns<Task_ExecutionSpec> = {
  encode(message: Task_ExecutionSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.args).forEach(([key, value]) => {
      Task_ExecutionSpec_ArgsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    if (message.project !== "") {
      writer.uint32(58).string(message.project);
    }
    if (message.maxJobExecutionLifetime !== undefined) {
      Duration.encode(message.maxJobExecutionLifetime, writer.uint32(66).fork()).join();
    }
    if (message.kmsKey !== "") {
      writer.uint32(74).string(message.kmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Task_ExecutionSpec_ArgsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.args[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.project = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.maxJobExecutionLifetime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionSpec {
    return {
      args: isObject(object.args)
        ? Object.entries(object.args).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      maxJobExecutionLifetime: isSet(object.maxJobExecutionLifetime)
        ? Duration.fromJSON(object.maxJobExecutionLifetime)
        : undefined,
      kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "",
    };
  },

  toJSON(message: Task_ExecutionSpec): unknown {
    const obj: any = {};
    if (message.args) {
      const entries = Object.entries(message.args);
      if (entries.length > 0) {
        obj.args = {};
        entries.forEach(([k, v]) => {
          obj.args[k] = v;
        });
      }
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.maxJobExecutionLifetime !== undefined) {
      obj.maxJobExecutionLifetime = Duration.toJSON(message.maxJobExecutionLifetime);
    }
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_ExecutionSpec>, I>>(base?: I): Task_ExecutionSpec {
    return Task_ExecutionSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_ExecutionSpec>, I>>(object: I): Task_ExecutionSpec {
    const message = createBaseTask_ExecutionSpec();
    message.args = Object.entries(object.args ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.serviceAccount = object.serviceAccount ?? "";
    message.project = object.project ?? "";
    message.maxJobExecutionLifetime =
      (object.maxJobExecutionLifetime !== undefined && object.maxJobExecutionLifetime !== null)
        ? Duration.fromPartial(object.maxJobExecutionLifetime)
        : undefined;
    message.kmsKey = object.kmsKey ?? "";
    return message;
  },
};

function createBaseTask_ExecutionSpec_ArgsEntry(): Task_ExecutionSpec_ArgsEntry {
  return { key: "", value: "" };
}

export const Task_ExecutionSpec_ArgsEntry: MessageFns<Task_ExecutionSpec_ArgsEntry> = {
  encode(message: Task_ExecutionSpec_ArgsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionSpec_ArgsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionSpec_ArgsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionSpec_ArgsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_ExecutionSpec_ArgsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_ExecutionSpec_ArgsEntry>, I>>(base?: I): Task_ExecutionSpec_ArgsEntry {
    return Task_ExecutionSpec_ArgsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_ExecutionSpec_ArgsEntry>, I>>(object: I): Task_ExecutionSpec_ArgsEntry {
    const message = createBaseTask_ExecutionSpec_ArgsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTask_SparkTaskConfig(): Task_SparkTaskConfig {
  return {
    mainJarFileUri: undefined,
    mainClass: undefined,
    pythonScriptFile: undefined,
    sqlScriptFile: undefined,
    sqlScript: undefined,
    fileUris: [],
    archiveUris: [],
    infrastructureSpec: undefined,
  };
}

export const Task_SparkTaskConfig: MessageFns<Task_SparkTaskConfig> = {
  encode(message: Task_SparkTaskConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mainJarFileUri !== undefined) {
      writer.uint32(802).string(message.mainJarFileUri);
    }
    if (message.mainClass !== undefined) {
      writer.uint32(810).string(message.mainClass);
    }
    if (message.pythonScriptFile !== undefined) {
      writer.uint32(818).string(message.pythonScriptFile);
    }
    if (message.sqlScriptFile !== undefined) {
      writer.uint32(834).string(message.sqlScriptFile);
    }
    if (message.sqlScript !== undefined) {
      writer.uint32(842).string(message.sqlScript);
    }
    for (const v of message.fileUris) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.archiveUris) {
      writer.uint32(34).string(v!);
    }
    if (message.infrastructureSpec !== undefined) {
      Task_InfrastructureSpec.encode(message.infrastructureSpec, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_SparkTaskConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_SparkTaskConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 100: {
          if (tag !== 802) {
            break;
          }

          message.mainJarFileUri = reader.string();
          continue;
        }
        case 101: {
          if (tag !== 810) {
            break;
          }

          message.mainClass = reader.string();
          continue;
        }
        case 102: {
          if (tag !== 818) {
            break;
          }

          message.pythonScriptFile = reader.string();
          continue;
        }
        case 104: {
          if (tag !== 834) {
            break;
          }

          message.sqlScriptFile = reader.string();
          continue;
        }
        case 105: {
          if (tag !== 842) {
            break;
          }

          message.sqlScript = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.fileUris.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.archiveUris.push(reader.string());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.infrastructureSpec = Task_InfrastructureSpec.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_SparkTaskConfig {
    return {
      mainJarFileUri: isSet(object.mainJarFileUri) ? globalThis.String(object.mainJarFileUri) : undefined,
      mainClass: isSet(object.mainClass) ? globalThis.String(object.mainClass) : undefined,
      pythonScriptFile: isSet(object.pythonScriptFile) ? globalThis.String(object.pythonScriptFile) : undefined,
      sqlScriptFile: isSet(object.sqlScriptFile) ? globalThis.String(object.sqlScriptFile) : undefined,
      sqlScript: isSet(object.sqlScript) ? globalThis.String(object.sqlScript) : undefined,
      fileUris: globalThis.Array.isArray(object?.fileUris) ? object.fileUris.map((e: any) => globalThis.String(e)) : [],
      archiveUris: globalThis.Array.isArray(object?.archiveUris)
        ? object.archiveUris.map((e: any) => globalThis.String(e))
        : [],
      infrastructureSpec: isSet(object.infrastructureSpec)
        ? Task_InfrastructureSpec.fromJSON(object.infrastructureSpec)
        : undefined,
    };
  },

  toJSON(message: Task_SparkTaskConfig): unknown {
    const obj: any = {};
    if (message.mainJarFileUri !== undefined) {
      obj.mainJarFileUri = message.mainJarFileUri;
    }
    if (message.mainClass !== undefined) {
      obj.mainClass = message.mainClass;
    }
    if (message.pythonScriptFile !== undefined) {
      obj.pythonScriptFile = message.pythonScriptFile;
    }
    if (message.sqlScriptFile !== undefined) {
      obj.sqlScriptFile = message.sqlScriptFile;
    }
    if (message.sqlScript !== undefined) {
      obj.sqlScript = message.sqlScript;
    }
    if (message.fileUris?.length) {
      obj.fileUris = message.fileUris;
    }
    if (message.archiveUris?.length) {
      obj.archiveUris = message.archiveUris;
    }
    if (message.infrastructureSpec !== undefined) {
      obj.infrastructureSpec = Task_InfrastructureSpec.toJSON(message.infrastructureSpec);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_SparkTaskConfig>, I>>(base?: I): Task_SparkTaskConfig {
    return Task_SparkTaskConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_SparkTaskConfig>, I>>(object: I): Task_SparkTaskConfig {
    const message = createBaseTask_SparkTaskConfig();
    message.mainJarFileUri = object.mainJarFileUri ?? undefined;
    message.mainClass = object.mainClass ?? undefined;
    message.pythonScriptFile = object.pythonScriptFile ?? undefined;
    message.sqlScriptFile = object.sqlScriptFile ?? undefined;
    message.sqlScript = object.sqlScript ?? undefined;
    message.fileUris = object.fileUris?.map((e) => e) || [];
    message.archiveUris = object.archiveUris?.map((e) => e) || [];
    message.infrastructureSpec = (object.infrastructureSpec !== undefined && object.infrastructureSpec !== null)
      ? Task_InfrastructureSpec.fromPartial(object.infrastructureSpec)
      : undefined;
    return message;
  },
};

function createBaseTask_NotebookTaskConfig(): Task_NotebookTaskConfig {
  return { notebook: "", infrastructureSpec: undefined, fileUris: [], archiveUris: [] };
}

export const Task_NotebookTaskConfig: MessageFns<Task_NotebookTaskConfig> = {
  encode(message: Task_NotebookTaskConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.notebook !== "") {
      writer.uint32(34).string(message.notebook);
    }
    if (message.infrastructureSpec !== undefined) {
      Task_InfrastructureSpec.encode(message.infrastructureSpec, writer.uint32(26).fork()).join();
    }
    for (const v of message.fileUris) {
      writer.uint32(42).string(v!);
    }
    for (const v of message.archiveUris) {
      writer.uint32(50).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_NotebookTaskConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_NotebookTaskConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.notebook = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.infrastructureSpec = Task_InfrastructureSpec.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.fileUris.push(reader.string());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.archiveUris.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_NotebookTaskConfig {
    return {
      notebook: isSet(object.notebook) ? globalThis.String(object.notebook) : "",
      infrastructureSpec: isSet(object.infrastructureSpec)
        ? Task_InfrastructureSpec.fromJSON(object.infrastructureSpec)
        : undefined,
      fileUris: globalThis.Array.isArray(object?.fileUris) ? object.fileUris.map((e: any) => globalThis.String(e)) : [],
      archiveUris: globalThis.Array.isArray(object?.archiveUris)
        ? object.archiveUris.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Task_NotebookTaskConfig): unknown {
    const obj: any = {};
    if (message.notebook !== "") {
      obj.notebook = message.notebook;
    }
    if (message.infrastructureSpec !== undefined) {
      obj.infrastructureSpec = Task_InfrastructureSpec.toJSON(message.infrastructureSpec);
    }
    if (message.fileUris?.length) {
      obj.fileUris = message.fileUris;
    }
    if (message.archiveUris?.length) {
      obj.archiveUris = message.archiveUris;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_NotebookTaskConfig>, I>>(base?: I): Task_NotebookTaskConfig {
    return Task_NotebookTaskConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_NotebookTaskConfig>, I>>(object: I): Task_NotebookTaskConfig {
    const message = createBaseTask_NotebookTaskConfig();
    message.notebook = object.notebook ?? "";
    message.infrastructureSpec = (object.infrastructureSpec !== undefined && object.infrastructureSpec !== null)
      ? Task_InfrastructureSpec.fromPartial(object.infrastructureSpec)
      : undefined;
    message.fileUris = object.fileUris?.map((e) => e) || [];
    message.archiveUris = object.archiveUris?.map((e) => e) || [];
    return message;
  },
};

function createBaseTask_ExecutionStatus(): Task_ExecutionStatus {
  return { updateTime: undefined, latestJob: undefined };
}

export const Task_ExecutionStatus: MessageFns<Task_ExecutionStatus> = {
  encode(message: Task_ExecutionStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.latestJob !== undefined) {
      Job.encode(message.latestJob, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_ExecutionStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_ExecutionStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.latestJob = Job.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_ExecutionStatus {
    return {
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      latestJob: isSet(object.latestJob) ? Job.fromJSON(object.latestJob) : undefined,
    };
  },

  toJSON(message: Task_ExecutionStatus): unknown {
    const obj: any = {};
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.latestJob !== undefined) {
      obj.latestJob = Job.toJSON(message.latestJob);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_ExecutionStatus>, I>>(base?: I): Task_ExecutionStatus {
    return Task_ExecutionStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_ExecutionStatus>, I>>(object: I): Task_ExecutionStatus {
    const message = createBaseTask_ExecutionStatus();
    message.updateTime = object.updateTime ?? undefined;
    message.latestJob = (object.latestJob !== undefined && object.latestJob !== null)
      ? Job.fromPartial(object.latestJob)
      : undefined;
    return message;
  },
};

function createBaseTask_LabelsEntry(): Task_LabelsEntry {
  return { key: "", value: "" };
}

export const Task_LabelsEntry: MessageFns<Task_LabelsEntry> = {
  encode(message: Task_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Task_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTask_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Task_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Task_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Task_LabelsEntry>, I>>(base?: I): Task_LabelsEntry {
    return Task_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Task_LabelsEntry>, I>>(object: I): Task_LabelsEntry {
    const message = createBaseTask_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseJob(): Job {
  return {
    name: "",
    uid: "",
    startTime: undefined,
    endTime: undefined,
    state: 0,
    retryCount: 0,
    service: 0,
    serviceJob: "",
    message: "",
  };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(26).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(34).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.retryCount !== 0) {
      writer.uint32(48).uint32(message.retryCount);
    }
    if (message.service !== 0) {
      writer.uint32(56).int32(message.service);
    }
    if (message.serviceJob !== "") {
      writer.uint32(66).string(message.serviceJob);
    }
    if (message.message !== "") {
      writer.uint32(74).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.retryCount = reader.uint32();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.service = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.serviceJob = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.message = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? job_StateFromJSON(object.state) : 0,
      retryCount: isSet(object.retryCount) ? globalThis.Number(object.retryCount) : 0,
      service: isSet(object.service) ? job_ServiceFromJSON(object.service) : 0,
      serviceJob: isSet(object.serviceJob) ? globalThis.String(object.serviceJob) : "",
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = job_StateToJSON(message.state);
    }
    if (message.retryCount !== 0) {
      obj.retryCount = Math.round(message.retryCount);
    }
    if (message.service !== 0) {
      obj.service = job_ServiceToJSON(message.service);
    }
    if (message.serviceJob !== "") {
      obj.serviceJob = message.serviceJob;
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Job>, I>>(base?: I): Job {
    return Job.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Job>, I>>(object: I): Job {
    const message = createBaseJob();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.retryCount = object.retryCount ?? 0;
    message.service = object.service ?? 0;
    message.serviceJob = object.serviceJob ?? "";
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseTaskEventData(): TaskEventData {
  return { payload: undefined };
}

export const TaskEventData: MessageFns<TaskEventData> = {
  encode(message: TaskEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Task.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TaskEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTaskEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Task.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TaskEventData {
    return { payload: isSet(object.payload) ? Task.fromJSON(object.payload) : undefined };
  },

  toJSON(message: TaskEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Task.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TaskEventData>, I>>(base?: I): TaskEventData {
    return TaskEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TaskEventData>, I>>(object: I): TaskEventData {
    const message = createBaseTaskEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Task.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseZoneEventData(): ZoneEventData {
  return { payload: undefined };
}

export const ZoneEventData: MessageFns<ZoneEventData> = {
  encode(message: ZoneEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Zone.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ZoneEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseZoneEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Zone.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ZoneEventData {
    return { payload: isSet(object.payload) ? Zone.fromJSON(object.payload) : undefined };
  },

  toJSON(message: ZoneEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Zone.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ZoneEventData>, I>>(base?: I): ZoneEventData {
    return ZoneEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ZoneEventData>, I>>(object: I): ZoneEventData {
    const message = createBaseZoneEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Zone.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseAssetEventData(): AssetEventData {
  return { payload: undefined };
}

export const AssetEventData: MessageFns<AssetEventData> = {
  encode(message: AssetEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Asset.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AssetEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAssetEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Asset.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AssetEventData {
    return { payload: isSet(object.payload) ? Asset.fromJSON(object.payload) : undefined };
  },

  toJSON(message: AssetEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Asset.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AssetEventData>, I>>(base?: I): AssetEventData {
    return AssetEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AssetEventData>, I>>(object: I): AssetEventData {
    const message = createBaseAssetEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Asset.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseEnvironmentEventData(): EnvironmentEventData {
  return { payload: undefined };
}

export const EnvironmentEventData: MessageFns<EnvironmentEventData> = {
  encode(message: EnvironmentEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Environment.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EnvironmentEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEnvironmentEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Environment.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EnvironmentEventData {
    return { payload: isSet(object.payload) ? Environment.fromJSON(object.payload) : undefined };
  },

  toJSON(message: EnvironmentEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Environment.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EnvironmentEventData>, I>>(base?: I): EnvironmentEventData {
    return EnvironmentEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EnvironmentEventData>, I>>(object: I): EnvironmentEventData {
    const message = createBaseEnvironmentEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Environment.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseDataTaxonomyEventData(): DataTaxonomyEventData {
  return { payload: undefined };
}

export const DataTaxonomyEventData: MessageFns<DataTaxonomyEventData> = {
  encode(message: DataTaxonomyEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DataTaxonomy.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataTaxonomyEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataTaxonomyEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DataTaxonomy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataTaxonomyEventData {
    return { payload: isSet(object.payload) ? DataTaxonomy.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DataTaxonomyEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DataTaxonomy.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataTaxonomyEventData>, I>>(base?: I): DataTaxonomyEventData {
    return DataTaxonomyEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataTaxonomyEventData>, I>>(object: I): DataTaxonomyEventData {
    const message = createBaseDataTaxonomyEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DataTaxonomy.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseDataAttributeBindingEventData(): DataAttributeBindingEventData {
  return { payload: undefined };
}

export const DataAttributeBindingEventData: MessageFns<DataAttributeBindingEventData> = {
  encode(message: DataAttributeBindingEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DataAttributeBinding.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttributeBindingEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttributeBindingEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DataAttributeBinding.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttributeBindingEventData {
    return { payload: isSet(object.payload) ? DataAttributeBinding.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DataAttributeBindingEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DataAttributeBinding.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttributeBindingEventData>, I>>(base?: I): DataAttributeBindingEventData {
    return DataAttributeBindingEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttributeBindingEventData>, I>>(
    object: I,
  ): DataAttributeBindingEventData {
    const message = createBaseDataAttributeBindingEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DataAttributeBinding.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseDataScanEventData(): DataScanEventData {
  return { payload: undefined };
}

export const DataScanEventData: MessageFns<DataScanEventData> = {
  encode(message: DataScanEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DataScan.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataScanEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataScanEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DataScan.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataScanEventData {
    return { payload: isSet(object.payload) ? DataScan.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DataScanEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DataScan.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataScanEventData>, I>>(base?: I): DataScanEventData {
    return DataScanEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataScanEventData>, I>>(object: I): DataScanEventData {
    const message = createBaseDataScanEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DataScan.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseLakeEventData(): LakeEventData {
  return { payload: undefined };
}

export const LakeEventData: MessageFns<LakeEventData> = {
  encode(message: LakeEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Lake.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): LakeEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseLakeEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Lake.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): LakeEventData {
    return { payload: isSet(object.payload) ? Lake.fromJSON(object.payload) : undefined };
  },

  toJSON(message: LakeEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Lake.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<LakeEventData>, I>>(base?: I): LakeEventData {
    return LakeEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<LakeEventData>, I>>(object: I): LakeEventData {
    const message = createBaseLakeEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Lake.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseDataAttributeEventData(): DataAttributeEventData {
  return { payload: undefined };
}

export const DataAttributeEventData: MessageFns<DataAttributeEventData> = {
  encode(message: DataAttributeEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DataAttribute.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DataAttributeEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDataAttributeEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DataAttribute.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DataAttributeEventData {
    return { payload: isSet(object.payload) ? DataAttribute.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DataAttributeEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DataAttribute.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DataAttributeEventData>, I>>(base?: I): DataAttributeEventData {
    return DataAttributeEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DataAttributeEventData>, I>>(object: I): DataAttributeEventData {
    const message = createBaseDataAttributeEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DataAttribute.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
