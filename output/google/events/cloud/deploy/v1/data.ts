// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/deploy/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration";
import { Timestamp } from "../../../../protobuf/timestamp";

export const protobufPackage = "google.events.cloud.deploy.v1";

/** The support state of a specific Skaffold version. */
export enum SkaffoldSupportState {
  /** SKAFFOLD_SUPPORT_STATE_UNSPECIFIED - Default value. This value is unused. */
  SKAFFOLD_SUPPORT_STATE_UNSPECIFIED = 0,
  /** SKAFFOLD_SUPPORT_STATE_SUPPORTED - This Skaffold version is currently supported. */
  SKAFFOLD_SUPPORT_STATE_SUPPORTED = 1,
  /** SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE - This Skaffold version is in maintenance mode. */
  SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE = 2,
  /** SKAFFOLD_SUPPORT_STATE_UNSUPPORTED - This Skaffold version is no longer supported. */
  SKAFFOLD_SUPPORT_STATE_UNSUPPORTED = 3,
  UNRECOGNIZED = -1,
}

export function skaffoldSupportStateFromJSON(object: any): SkaffoldSupportState {
  switch (object) {
    case 0:
    case "SKAFFOLD_SUPPORT_STATE_UNSPECIFIED":
      return SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_UNSPECIFIED;
    case 1:
    case "SKAFFOLD_SUPPORT_STATE_SUPPORTED":
      return SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_SUPPORTED;
    case 2:
    case "SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE":
      return SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE;
    case 3:
    case "SKAFFOLD_SUPPORT_STATE_UNSUPPORTED":
      return SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_UNSUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SkaffoldSupportState.UNRECOGNIZED;
  }
}

export function skaffoldSupportStateToJSON(object: SkaffoldSupportState): string {
  switch (object) {
    case SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_UNSPECIFIED:
      return "SKAFFOLD_SUPPORT_STATE_UNSPECIFIED";
    case SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_SUPPORTED:
      return "SKAFFOLD_SUPPORT_STATE_SUPPORTED";
    case SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE:
      return "SKAFFOLD_SUPPORT_STATE_MAINTENANCE_MODE";
    case SkaffoldSupportState.SKAFFOLD_SUPPORT_STATE_UNSUPPORTED:
      return "SKAFFOLD_SUPPORT_STATE_UNSUPPORTED";
    case SkaffoldSupportState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The pattern of how wait time is increased. */
export enum BackoffMode {
  /** BACKOFF_MODE_UNSPECIFIED - No WaitMode is specified. */
  BACKOFF_MODE_UNSPECIFIED = 0,
  /** BACKOFF_MODE_LINEAR - Increases the wait time linearly. */
  BACKOFF_MODE_LINEAR = 1,
  /** BACKOFF_MODE_EXPONENTIAL - Increases the wait time exponentially. */
  BACKOFF_MODE_EXPONENTIAL = 2,
  UNRECOGNIZED = -1,
}

export function backoffModeFromJSON(object: any): BackoffMode {
  switch (object) {
    case 0:
    case "BACKOFF_MODE_UNSPECIFIED":
      return BackoffMode.BACKOFF_MODE_UNSPECIFIED;
    case 1:
    case "BACKOFF_MODE_LINEAR":
      return BackoffMode.BACKOFF_MODE_LINEAR;
    case 2:
    case "BACKOFF_MODE_EXPONENTIAL":
      return BackoffMode.BACKOFF_MODE_EXPONENTIAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BackoffMode.UNRECOGNIZED;
  }
}

export function backoffModeToJSON(object: BackoffMode): string {
  switch (object) {
    case BackoffMode.BACKOFF_MODE_UNSPECIFIED:
      return "BACKOFF_MODE_UNSPECIFIED";
    case BackoffMode.BACKOFF_MODE_LINEAR:
      return "BACKOFF_MODE_LINEAR";
    case BackoffMode.BACKOFF_MODE_EXPONENTIAL:
      return "BACKOFF_MODE_EXPONENTIAL";
    case BackoffMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A `DeliveryPipeline` resource in the Cloud Deploy API.
 *
 * A `DeliveryPipeline` defines a pipeline through which a Skaffold
 * configuration can progress.
 */
export interface DeliveryPipeline {
  /**
   * Optional. Name of the `DeliveryPipeline`. Format is
   * `projects/{project}/locations/{location}/deliveryPipelines/[a-z][a-z0-9\-]{0,62}`.
   */
  name: string;
  /** Output only. Unique identifier of the `DeliveryPipeline`. */
  uid: string;
  /** Description of the `DeliveryPipeline`. Max length is 255 characters. */
  description: string;
  /**
   * User annotations. These attributes can only be set and used by the
   * user, and not by Cloud Deploy.
   */
  annotations: { [key: string]: string };
  /**
   * Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 128 bytes.
   */
  labels: { [key: string]: string };
  /** Output only. Time at which the pipeline was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Most recent time at which the pipeline was updated. */
  updateTime?:
    | Date
    | undefined;
  /**
   * SerialPipeline defines a sequential set of stages for a
   * `DeliveryPipeline`.
   */
  serialPipeline?:
    | SerialPipeline
    | undefined;
  /** Output only. Information around the state of the Delivery Pipeline. */
  condition?:
    | PipelineCondition
    | undefined;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * When suspended, no new releases or rollouts can be created,
   * but in-progress ones will complete.
   */
  suspended: boolean;
}

export interface DeliveryPipeline_AnnotationsEntry {
  key: string;
  value: string;
}

export interface DeliveryPipeline_LabelsEntry {
  key: string;
  value: string;
}

/** SerialPipeline defines a sequential set of stages for a `DeliveryPipeline`. */
export interface SerialPipeline {
  /**
   * Each stage specifies configuration for a `Target`. The ordering
   * of this list defines the promotion flow.
   */
  stages: Stage[];
}

/** Stage specifies a location to which to deploy. */
export interface Stage {
  /**
   * The target_id to which this stage points. This field refers exclusively to
   * the last segment of a target name. For example, this field would just be
   * `my-target` (rather than
   * `projects/project/locations/location/targets/my-target`). The location of
   * the `Target` is inferred to be the same as the location of the
   * `DeliveryPipeline` that contains this `Stage`.
   */
  targetId: string;
  /**
   * Skaffold profiles to use when rendering the manifest for this stage's
   * `Target`.
   */
  profiles: string[];
  /** Optional. The strategy to use for a `Rollout` to this stage. */
  strategy?:
    | Strategy
    | undefined;
  /** Optional. The deploy parameters to use for the target in this stage. */
  deployParameters: DeployParameters[];
}

/** DeployParameters contains deploy parameters information. */
export interface DeployParameters {
  /** Required. Values are deploy parameters in key-value pairs. */
  values: { [key: string]: string };
  /**
   * Optional. Deploy parameters are applied to targets with match labels.
   * If unspecified, deploy parameters are applied to all targets (including
   * child targets of a multi-target).
   */
  matchTargetLabels: { [key: string]: string };
}

export interface DeployParameters_ValuesEntry {
  key: string;
  value: string;
}

export interface DeployParameters_MatchTargetLabelsEntry {
  key: string;
  value: string;
}

/** Strategy contains deployment strategy information. */
export interface Strategy {
  /**
   * Standard deployment strategy executes a single deploy and allows
   * verifying the deployment.
   */
  standard?:
    | Standard
    | undefined;
  /**
   * Canary deployment strategy provides progressive percentage based
   * deployments to a Target.
   */
  canary?: Canary | undefined;
}

/** Predeploy contains the predeploy job configuration information. */
export interface Predeploy {
  /**
   * Optional. A sequence of Skaffold custom actions to invoke during execution
   * of the predeploy job.
   */
  actions: string[];
}

/** Postdeploy contains the postdeploy job configuration information. */
export interface Postdeploy {
  /**
   * Optional. A sequence of Skaffold custom actions to invoke during execution
   * of the postdeploy job.
   */
  actions: string[];
}

/** Standard represents the standard deployment strategy. */
export interface Standard {
  /** Whether to verify a deployment. */
  verify: boolean;
  /**
   * Optional. Configuration for the predeploy job. If this is not configured,
   * predeploy job will not be present.
   */
  predeploy?:
    | Predeploy
    | undefined;
  /**
   * Optional. Configuration for the postdeploy job. If this is not configured,
   * postdeploy job will not be present.
   */
  postdeploy?: Postdeploy | undefined;
}

/** Canary represents the canary deployment strategy. */
export interface Canary {
  /**
   * Optional. Runtime specific configurations for the deployment strategy. The
   * runtime configuration is used to determine how Cloud Deploy will split
   * traffic to enable a progressive deployment.
   */
  runtimeConfig?:
    | RuntimeConfig
    | undefined;
  /** Configures the progressive based deployment for a Target. */
  canaryDeployment?:
    | CanaryDeployment
    | undefined;
  /**
   * Configures the progressive based deployment for a Target, but allows
   * customizing at the phase level where a phase represents each of the
   * percentage deployments.
   */
  customCanaryDeployment?: CustomCanaryDeployment | undefined;
}

/** CanaryDeployment represents the canary deployment configuration */
export interface CanaryDeployment {
  /**
   * Required. The percentage based deployments that will occur as a part of a
   * `Rollout`. List is expected in ascending order and each integer n is
   * 0 <= n < 100.
   */
  percentages: number[];
  /** Whether to run verify tests after each percentage deployment. */
  verify: boolean;
  /**
   * Optional. Configuration for the predeploy job of the first phase. If this
   * is not configured, there will be no predeploy job for this phase.
   */
  predeploy?:
    | Predeploy
    | undefined;
  /**
   * Optional. Configuration for the postdeploy job of the last phase. If this
   * is not configured, there will be no postdeploy job for this phase.
   */
  postdeploy?: Postdeploy | undefined;
}

/**
 * CustomCanaryDeployment represents the custom canary deployment
 * configuration.
 */
export interface CustomCanaryDeployment {
  /**
   * Required. Configuration for each phase in the canary deployment in the
   * order executed.
   */
  phaseConfigs: CustomCanaryDeployment_PhaseConfig[];
}

/**
 * PhaseConfig represents the configuration for a phase in the custom
 * canary deployment.
 */
export interface CustomCanaryDeployment_PhaseConfig {
  /**
   * Required. The ID to assign to the `Rollout` phase.
   * This value must consist of lower-case letters, numbers, and hyphens,
   * start with a letter and end with a letter or a number, and have a max
   * length of 63 characters. In other words, it must match the following
   * regex: `^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$`.
   */
  phaseId: string;
  /** Required. Percentage deployment for the phase. */
  percentage: number;
  /**
   * Skaffold profiles to use when rendering the manifest for this phase.
   * These are in addition to the profiles list specified in the
   * `DeliveryPipeline` stage.
   */
  profiles: string[];
  /** Whether to run verify tests after the deployment. */
  verify: boolean;
  /**
   * Optional. Configuration for the predeploy job of this phase. If this is
   * not configured, there will be no predeploy job for this phase.
   */
  predeploy?:
    | Predeploy
    | undefined;
  /**
   * Optional. Configuration for the postdeploy job of this phase. If this is
   * not configured, there will be no postdeploy job for this phase.
   */
  postdeploy?: Postdeploy | undefined;
}

/** KubernetesConfig contains the Kubernetes runtime configuration. */
export interface KubernetesConfig {
  /** Kubernetes Gateway API service mesh configuration. */
  gatewayServiceMesh?:
    | KubernetesConfig_GatewayServiceMesh
    | undefined;
  /** Kubernetes Service networking configuration. */
  serviceNetworking?: KubernetesConfig_ServiceNetworking | undefined;
}

/** Information about the Kubernetes Gateway API service mesh configuration. */
export interface KubernetesConfig_GatewayServiceMesh {
  /** Required. Name of the Gateway API HTTPRoute. */
  httpRoute: string;
  /** Required. Name of the Kubernetes Service. */
  service: string;
  /**
   * Required. Name of the Kubernetes Deployment whose traffic is managed by
   * the specified HTTPRoute and Service.
   */
  deployment: string;
  /**
   * Optional. The time to wait for route updates to propagate. The maximum
   * configurable time is 3 hours, in seconds format. If unspecified, there is
   * no wait time.
   */
  routeUpdateWaitTime?:
    | Duration
    | undefined;
  /**
   * Optional. The amount of time to migrate traffic back from the canary
   * Service to the original Service during the stable phase deployment. If
   * specified, must be between 15s and 3600s. If unspecified, there is no
   * cutback time.
   */
  stableCutbackDuration?: Duration | undefined;
}

/** Information about the Kubernetes Service networking configuration. */
export interface KubernetesConfig_ServiceNetworking {
  /** Required. Name of the Kubernetes Service. */
  service: string;
  /**
   * Required. Name of the Kubernetes Deployment whose traffic is managed by
   * the specified Service.
   */
  deployment: string;
  /**
   * Optional. Whether to disable Pod overprovisioning. If Pod
   * overprovisioning is disabled then Cloud Deploy will limit the number of
   * total Pods used for the deployment strategy to the number of Pods the
   * Deployment has on the cluster.
   */
  disablePodOverprovisioning: boolean;
}

/** CloudRunConfig contains the Cloud Run runtime configuration. */
export interface CloudRunConfig {
  /**
   * Whether Cloud Deploy should update the traffic stanza in a Cloud Run
   * Service on the user's behalf to facilitate traffic splitting. This is
   * required to be true for CanaryDeployments, but optional for
   * CustomCanaryDeployments.
   */
  automaticTrafficControl: boolean;
  /**
   * Optional. A list of tags that are added to the canary revision while the
   * canary phase is in progress.
   */
  canaryRevisionTags: string[];
  /**
   * Optional. A list of tags that are added to the prior revision while the
   * canary phase is in progress.
   */
  priorRevisionTags: string[];
  /**
   * Optional. A list of tags that are added to the final stable revision when
   * the stable phase is applied.
   */
  stableRevisionTags: string[];
}

/**
 * RuntimeConfig contains the runtime specific configurations for a deployment
 * strategy.
 */
export interface RuntimeConfig {
  /** Kubernetes runtime configuration. */
  kubernetes?:
    | KubernetesConfig
    | undefined;
  /** Cloud Run runtime configuration. */
  cloudRun?: CloudRunConfig | undefined;
}

/**
 * PipelineReadyCondition contains information around the status of the
 * Pipeline.
 */
export interface PipelineReadyCondition {
  /**
   * True if the Pipeline is in a valid state. Otherwise at least one condition
   * in `PipelineCondition` is in an invalid state. Iterate over those
   * conditions and see which condition(s) has status = false to find out what
   * is wrong with the Pipeline.
   */
  status: boolean;
  /** Last time the condition was updated. */
  updateTime?: Date | undefined;
}

/**
 * `TargetsPresentCondition` contains information on any Targets referenced in
 * the Delivery Pipeline that do not actually exist.
 */
export interface TargetsPresentCondition {
  /** True if there aren't any missing Targets. */
  status: boolean;
  /**
   * The list of Target names that do not exist. For example,
   * `projects/{project_id}/locations/{location_name}/targets/{target_name}`.
   */
  missingTargets: string[];
  /** Last time the condition was updated. */
  updateTime?: Date | undefined;
}

/**
 * TargetsTypeCondition contains information on whether the Targets defined in
 * the Delivery Pipeline are of the same type.
 */
export interface TargetsTypeCondition {
  /**
   * True if the targets are all a comparable type. For example this is true if
   * all targets are GKE clusters. This is false if some targets are Cloud Run
   * targets and others are GKE clusters.
   */
  status: boolean;
  /** Human readable error message. */
  errorDetails: string;
}

/** PipelineCondition contains all conditions relevant to a Delivery Pipeline. */
export interface PipelineCondition {
  /** Details around the Pipeline's overall status. */
  pipelineReadyCondition?:
    | PipelineReadyCondition
    | undefined;
  /** Details around targets enumerated in the pipeline. */
  targetsPresentCondition?:
    | TargetsPresentCondition
    | undefined;
  /**
   * Details on the whether the targets enumerated in the pipeline are of the
   * same type.
   */
  targetsTypeCondition?: TargetsTypeCondition | undefined;
}

/**
 * A `Target` resource in the Cloud Deploy API.
 *
 * A `Target` defines a location to which a Skaffold configuration
 * can be deployed.
 */
export interface Target {
  /**
   * Optional. Name of the `Target`. Format is
   * `projects/{project}/locations/{location}/targets/[a-z][a-z0-9\-]{0,62}`.
   */
  name: string;
  /** Output only. Resource id of the `Target`. */
  targetId: string;
  /** Output only. Unique identifier of the `Target`. */
  uid: string;
  /** Optional. Description of the `Target`. Max length is 255 characters. */
  description: string;
  /**
   * Optional. User annotations. These attributes can only be set and used by
   * the user, and not by Cloud Deploy. See
   * https://google.aip.dev/128#annotations for more details such as format and
   * size limitations.
   */
  annotations: { [key: string]: string };
  /**
   * Optional. Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 128 bytes.
   */
  labels: { [key: string]: string };
  /** Optional. Whether or not the `Target` requires approval. */
  requireApproval: boolean;
  /** Output only. Time at which the `Target` was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Most recent time at which the `Target` was updated. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Information specifying a GKE Cluster. */
  gke?:
    | GkeCluster
    | undefined;
  /** Optional. Information specifying an Anthos Cluster. */
  anthosCluster?:
    | AnthosCluster
    | undefined;
  /** Optional. Information specifying a Cloud Run deployment target. */
  run?:
    | CloudRunLocation
    | undefined;
  /** Optional. Information specifying a multiTarget. */
  multiTarget?:
    | MultiTarget
    | undefined;
  /** Optional. Information specifying a Custom Target. */
  customTarget?:
    | CustomTarget
    | undefined;
  /**
   * Optional. This checksum is computed by the server based on the value of
   * other fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Configurations for all execution that relates to this `Target`.
   * Each `ExecutionEnvironmentUsage` value may only be used in a single
   * configuration; using the same value multiple times is an error.
   * When one or more configurations are specified, they must include the
   * `RENDER` and `DEPLOY` `ExecutionEnvironmentUsage` values.
   * When no configurations are specified, execution will use the default
   * specified in `DefaultPool`.
   */
  executionConfigs: ExecutionConfig[];
  /** Optional. The deploy parameters to use for this target. */
  deployParameters: { [key: string]: string };
}

export interface Target_AnnotationsEntry {
  key: string;
  value: string;
}

export interface Target_LabelsEntry {
  key: string;
  value: string;
}

export interface Target_DeployParametersEntry {
  key: string;
  value: string;
}

/** Configuration of the environment to use when calling Skaffold. */
export interface ExecutionConfig {
  /** Required. Usages when this configuration should be applied. */
  usages: ExecutionConfig_ExecutionEnvironmentUsage[];
  /** Optional. Use default Cloud Build pool. */
  defaultPool?:
    | DefaultPool
    | undefined;
  /** Optional. Use private Cloud Build pool. */
  privatePool?:
    | PrivatePool
    | undefined;
  /**
   * Optional. The resource name of the `WorkerPool`, with the format
   * `projects/{project}/locations/{location}/workerPools/{worker_pool}`.
   * If this optional field is unspecified, the default Cloud Build pool will be
   * used.
   */
  workerPool: string;
  /**
   * Optional. Google service account to use for execution. If unspecified,
   * the project execution service account
   * (<PROJECT_NUMBER>-compute@developer.gserviceaccount.com) is used.
   */
  serviceAccount: string;
  /**
   * Optional. Cloud Storage location in which to store execution outputs. This
   * can either be a bucket ("gs://my-bucket") or a path within a bucket
   * ("gs://my-bucket/my-dir").
   * If unspecified, a default bucket located in the same region will be used.
   */
  artifactStorage: string;
  /**
   * Optional. Execution timeout for a Cloud Build Execution. This must be
   * between 10m and 24h in seconds format. If unspecified, a default timeout of
   * 1h is used.
   */
  executionTimeout?: Duration | undefined;
}

/** Possible usages of this configuration. */
export enum ExecutionConfig_ExecutionEnvironmentUsage {
  /** EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED - Default value. This value is unused. */
  EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED = 0,
  /** RENDER - Use for rendering. */
  RENDER = 1,
  /** DEPLOY - Use for deploying and deployment hooks. */
  DEPLOY = 2,
  /** VERIFY - Use for deployment verification. */
  VERIFY = 3,
  /** PREDEPLOY - Use for predeploy job execution. */
  PREDEPLOY = 4,
  /** POSTDEPLOY - Use for postdeploy job execution. */
  POSTDEPLOY = 5,
  UNRECOGNIZED = -1,
}

export function executionConfig_ExecutionEnvironmentUsageFromJSON(
  object: any,
): ExecutionConfig_ExecutionEnvironmentUsage {
  switch (object) {
    case 0:
    case "EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED":
      return ExecutionConfig_ExecutionEnvironmentUsage.EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED;
    case 1:
    case "RENDER":
      return ExecutionConfig_ExecutionEnvironmentUsage.RENDER;
    case 2:
    case "DEPLOY":
      return ExecutionConfig_ExecutionEnvironmentUsage.DEPLOY;
    case 3:
    case "VERIFY":
      return ExecutionConfig_ExecutionEnvironmentUsage.VERIFY;
    case 4:
    case "PREDEPLOY":
      return ExecutionConfig_ExecutionEnvironmentUsage.PREDEPLOY;
    case 5:
    case "POSTDEPLOY":
      return ExecutionConfig_ExecutionEnvironmentUsage.POSTDEPLOY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ExecutionConfig_ExecutionEnvironmentUsage.UNRECOGNIZED;
  }
}

export function executionConfig_ExecutionEnvironmentUsageToJSON(
  object: ExecutionConfig_ExecutionEnvironmentUsage,
): string {
  switch (object) {
    case ExecutionConfig_ExecutionEnvironmentUsage.EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED:
      return "EXECUTION_ENVIRONMENT_USAGE_UNSPECIFIED";
    case ExecutionConfig_ExecutionEnvironmentUsage.RENDER:
      return "RENDER";
    case ExecutionConfig_ExecutionEnvironmentUsage.DEPLOY:
      return "DEPLOY";
    case ExecutionConfig_ExecutionEnvironmentUsage.VERIFY:
      return "VERIFY";
    case ExecutionConfig_ExecutionEnvironmentUsage.PREDEPLOY:
      return "PREDEPLOY";
    case ExecutionConfig_ExecutionEnvironmentUsage.POSTDEPLOY:
      return "POSTDEPLOY";
    case ExecutionConfig_ExecutionEnvironmentUsage.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Execution using the default Cloud Build pool. */
export interface DefaultPool {
  /**
   * Optional. Google service account to use for execution. If unspecified,
   * the project execution service account
   * (<PROJECT_NUMBER>-compute@developer.gserviceaccount.com) will be used.
   */
  serviceAccount: string;
  /**
   * Optional. Cloud Storage location where execution outputs should be stored.
   * This can either be a bucket ("gs://my-bucket") or a path within a bucket
   * ("gs://my-bucket/my-dir").
   * If unspecified, a default bucket located in the same region will be used.
   */
  artifactStorage: string;
}

/** Execution using a private Cloud Build pool. */
export interface PrivatePool {
  /**
   * Required. Resource name of the Cloud Build worker pool to use. The format
   * is `projects/{project}/locations/{location}/workerPools/{pool}`.
   */
  workerPool: string;
  /**
   * Optional. Google service account to use for execution. If unspecified,
   * the project execution service account
   * (<PROJECT_NUMBER>-compute@developer.gserviceaccount.com) will be used.
   */
  serviceAccount: string;
  /**
   * Optional. Cloud Storage location where execution outputs should be stored.
   * This can either be a bucket ("gs://my-bucket") or a path within a bucket
   * ("gs://my-bucket/my-dir").
   * If unspecified, a default bucket located in the same region will be used.
   */
  artifactStorage: string;
}

/** Information specifying a GKE Cluster. */
export interface GkeCluster {
  /**
   * Information specifying a GKE Cluster. Format is
   * `projects/{project_id}/locations/{location_id}/clusters/{cluster_id}`.
   */
  cluster: string;
  /**
   * Optional. If true, `cluster` is accessed using the private IP address of
   * the control plane endpoint. Otherwise, the default IP address of the
   * control plane endpoint is used. The default IP address is the private IP
   * address for clusters with private control-plane endpoints and the public IP
   * address otherwise.
   *
   * Only specify this option when `cluster` is a [private GKE
   * cluster](https://cloud.google.com/kubernetes-engine/docs/concepts/private-cluster-concept).
   */
  internalIp: boolean;
}

/** Information specifying an Anthos Cluster. */
export interface AnthosCluster {
  /**
   * Membership of the GKE Hub-registered cluster to which to apply the Skaffold
   * configuration. Format is
   * `projects/{project}/locations/{location}/memberships/{membership_name}`.
   */
  membership: string;
}

/** Information specifying where to deploy a Cloud Run Service. */
export interface CloudRunLocation {
  /**
   * Required. The location for the Cloud Run Service. Format must be
   * `projects/{project}/locations/{location}`.
   */
  location: string;
}

/** Information specifying a multiTarget. */
export interface MultiTarget {
  /** Required. The target_ids of this multiTarget. */
  targetIds: string[];
}

/** Information specifying a Custom Target. */
export interface CustomTarget {
  /**
   * Required. The name of the CustomTargetType. Format must be
   * `projects/{project}/locations/{location}/customTargetTypes/{custom_target_type}`.
   */
  customTargetType: string;
}

/**
 * A `CustomTargetType` resource in the Cloud Deploy API.
 *
 * A `CustomTargetType` defines a type of custom target that can be referenced
 * in a `Target` in order to facilitate deploying to other systems besides the
 * supported runtimes.
 */
export interface CustomTargetType {
  /**
   * Optional. Name of the `CustomTargetType`. Format is
   * `projects/{project}/locations/{location}/customTargetTypes/[a-z][a-z0-9\-]{0,62}`.
   */
  name: string;
  /** Output only. Resource id of the `CustomTargetType`. */
  customTargetTypeId: string;
  /** Output only. Unique identifier of the `CustomTargetType`. */
  uid: string;
  /**
   * Optional. Description of the `CustomTargetType`. Max length is 255
   * characters.
   */
  description: string;
  /**
   * Optional. User annotations. These attributes can only be set and used by
   * the user, and not by Cloud Deploy. See
   * https://google.aip.dev/128#annotations for more details such as format and
   * size limitations.
   */
  annotations: { [key: string]: string };
  /**
   * Optional. Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 128 bytes.
   */
  labels: { [key: string]: string };
  /** Output only. Time at which the `CustomTargetType` was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Most recent time at which the `CustomTargetType` was updated. */
  updateTime?:
    | Date
    | undefined;
  /**
   * Optional. This checksum is computed by the server based on the value of
   * other fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Configures render and deploy for the `CustomTargetType` using Skaffold
   * custom actions.
   */
  customActions?: CustomTargetSkaffoldActions | undefined;
}

export interface CustomTargetType_AnnotationsEntry {
  key: string;
  value: string;
}

export interface CustomTargetType_LabelsEntry {
  key: string;
  value: string;
}

/**
 * CustomTargetSkaffoldActions represents the `CustomTargetType` configuration
 * using Skaffold custom actions.
 */
export interface CustomTargetSkaffoldActions {
  /**
   * Optional. The Skaffold custom action responsible for render operations. If
   * not provided then Cloud Deploy will perform the render operations via
   * `skaffold render`.
   */
  renderAction: string;
  /** Required. The Skaffold custom action responsible for deploy operations. */
  deployAction: string;
  /**
   * Optional. List of Skaffold modules Cloud Deploy will include in the
   * Skaffold Config as required before performing diagnose.
   */
  includeSkaffoldModules: SkaffoldModules[];
}

/** Skaffold Config modules and their remote source. */
export interface SkaffoldModules {
  /** Optional. The Skaffold Config modules to use from the specified source. */
  configs: string[];
  /** Remote git repository containing the Skaffold Config modules. */
  git?:
    | SkaffoldModules_SkaffoldGitSource
    | undefined;
  /** Cloud Storage bucket containing the Skaffold Config modules. */
  googleCloudStorage?: SkaffoldModules_SkaffoldGCSSource | undefined;
}

/** Git repository containing Skaffold Config modules. */
export interface SkaffoldModules_SkaffoldGitSource {
  /** Required. Git repository the package should be cloned from. */
  repo: string;
  /** Optional. Relative path from the repository root to the Skaffold file. */
  path: string;
  /** Optional. Git ref the package should be cloned from. */
  ref: string;
}

/** Cloud Storage bucket containing Skaffold Config modules. */
export interface SkaffoldModules_SkaffoldGCSSource {
  /**
   * Required. Cloud Storage source paths to copy recursively. For example,
   * providing "gs://my-bucket/dir/configs/*" will result in Skaffold copying
   * all files within the "dir/configs" directory in the bucket "my-bucket".
   */
  source: string;
  /** Optional. Relative path from the source to the Skaffold file. */
  path: string;
}

/** Contains criteria for selecting Targets. */
export interface TargetAttribute {
  /**
   * ID of the `Target`. The value of this field could be one of the
   * following:
   * * The last segment of a target name. It only needs the ID to determine
   * which target is being referred to
   * * "*", all targets in a location.
   */
  id: string;
  /** Target labels. */
  labels: { [key: string]: string };
}

export interface TargetAttribute_LabelsEntry {
  key: string;
  value: string;
}

/**
 * A `Release` resource in the Cloud Deploy API.
 *
 * A `Release` defines a specific Skaffold configuration instance
 * that can be deployed.
 */
export interface Release {
  /**
   * Optional. Name of the `Release`. Format is
   * `projects/{project}/locations/{location}/deliveryPipelines/{deliveryPipeline}/releases/[a-z][a-z0-9\-]{0,62}`.
   */
  name: string;
  /** Output only. Unique identifier of the `Release`. */
  uid: string;
  /** Description of the `Release`. Max length is 255 characters. */
  description: string;
  /**
   * User annotations. These attributes can only be set and used by the
   * user, and not by Cloud Deploy. See https://google.aip.dev/128#annotations
   * for more details such as format and size limitations.
   */
  annotations: { [key: string]: string };
  /**
   * Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 128 bytes.
   */
  labels: { [key: string]: string };
  /** Output only. Indicates whether this is an abandoned release. */
  abandoned: boolean;
  /** Output only. Time at which the `Release` was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Time at which the render began. */
  renderStartTime?:
    | Date
    | undefined;
  /** Output only. Time at which the render completed. */
  renderEndTime?:
    | Date
    | undefined;
  /** Cloud Storage URI of tar.gz archive containing Skaffold configuration. */
  skaffoldConfigUri: string;
  /** Filepath of the Skaffold config inside of the config URI. */
  skaffoldConfigPath: string;
  /** List of artifacts to pass through to Skaffold command. */
  buildArtifacts: BuildArtifact[];
  /**
   * Output only. Snapshot of the parent pipeline taken at release creation
   * time.
   */
  deliveryPipelineSnapshot?:
    | DeliveryPipeline
    | undefined;
  /** Output only. Snapshot of the targets taken at release creation time. */
  targetSnapshots: Target[];
  /**
   * Output only. Snapshot of the custom target types referenced by the targets
   * taken at release creation time.
   */
  customTargetTypeSnapshots: CustomTargetType[];
  /** Output only. Current state of the render operation. */
  renderState: Release_RenderState;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * The Skaffold version to use when operating on this release, such as
   * "1.20.0". Not all versions are valid; Cloud Deploy supports a specific set
   * of versions.
   *
   * If unset, the most recent supported Skaffold version will be used.
   */
  skaffoldVersion: string;
  /**
   * Output only. Map from target ID to the target artifacts created
   * during the render operation.
   */
  targetArtifacts: { [key: string]: TargetArtifact };
  /**
   * Output only. Map from target ID to details of the render operation for that
   * target.
   */
  targetRenders: { [key: string]: Release_TargetRender };
  /** Output only. Information around the state of the Release. */
  condition?:
    | Release_ReleaseCondition
    | undefined;
  /** Optional. The deploy parameters to use for all targets in this release. */
  deployParameters: { [key: string]: string };
}

/** Valid states of the render operation. */
export enum Release_RenderState {
  /** RENDER_STATE_UNSPECIFIED - The render state is unspecified. */
  RENDER_STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - All rendering operations have completed successfully. */
  SUCCEEDED = 1,
  /** FAILED - All rendering operations have completed, and one or more have failed. */
  FAILED = 2,
  /** IN_PROGRESS - Rendering has started and is not complete. */
  IN_PROGRESS = 3,
  UNRECOGNIZED = -1,
}

export function release_RenderStateFromJSON(object: any): Release_RenderState {
  switch (object) {
    case 0:
    case "RENDER_STATE_UNSPECIFIED":
      return Release_RenderState.RENDER_STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return Release_RenderState.SUCCEEDED;
    case 2:
    case "FAILED":
      return Release_RenderState.FAILED;
    case 3:
    case "IN_PROGRESS":
      return Release_RenderState.IN_PROGRESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Release_RenderState.UNRECOGNIZED;
  }
}

export function release_RenderStateToJSON(object: Release_RenderState): string {
  switch (object) {
    case Release_RenderState.RENDER_STATE_UNSPECIFIED:
      return "RENDER_STATE_UNSPECIFIED";
    case Release_RenderState.SUCCEEDED:
      return "SUCCEEDED";
    case Release_RenderState.FAILED:
      return "FAILED";
    case Release_RenderState.IN_PROGRESS:
      return "IN_PROGRESS";
    case Release_RenderState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Details of rendering for a single target. */
export interface Release_TargetRender {
  /**
   * Output only. The resource name of the Cloud Build `Build` object that is
   * used to render the manifest for this target. Format is
   * `projects/{project}/locations/{location}/builds/{build}`.
   */
  renderingBuild: string;
  /** Output only. Current state of the render operation for this Target. */
  renderingState: Release_TargetRender_TargetRenderState;
  /** Output only. Metadata related to the `Release` render for this Target. */
  metadata?:
    | RenderMetadata
    | undefined;
  /**
   * Output only. Reason this render failed. This will always be unspecified
   * while the render in progress.
   */
  failureCause: Release_TargetRender_FailureCause;
  /**
   * Output only. Additional information about the render failure, if
   * available.
   */
  failureMessage: string;
}

/** Valid states of the render operation. */
export enum Release_TargetRender_TargetRenderState {
  /** TARGET_RENDER_STATE_UNSPECIFIED - The render operation state is unspecified. */
  TARGET_RENDER_STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - The render operation has completed successfully. */
  SUCCEEDED = 1,
  /** FAILED - The render operation has failed. */
  FAILED = 2,
  /** IN_PROGRESS - The render operation is in progress. */
  IN_PROGRESS = 3,
  UNRECOGNIZED = -1,
}

export function release_TargetRender_TargetRenderStateFromJSON(object: any): Release_TargetRender_TargetRenderState {
  switch (object) {
    case 0:
    case "TARGET_RENDER_STATE_UNSPECIFIED":
      return Release_TargetRender_TargetRenderState.TARGET_RENDER_STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return Release_TargetRender_TargetRenderState.SUCCEEDED;
    case 2:
    case "FAILED":
      return Release_TargetRender_TargetRenderState.FAILED;
    case 3:
    case "IN_PROGRESS":
      return Release_TargetRender_TargetRenderState.IN_PROGRESS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Release_TargetRender_TargetRenderState.UNRECOGNIZED;
  }
}

export function release_TargetRender_TargetRenderStateToJSON(object: Release_TargetRender_TargetRenderState): string {
  switch (object) {
    case Release_TargetRender_TargetRenderState.TARGET_RENDER_STATE_UNSPECIFIED:
      return "TARGET_RENDER_STATE_UNSPECIFIED";
    case Release_TargetRender_TargetRenderState.SUCCEEDED:
      return "SUCCEEDED";
    case Release_TargetRender_TargetRenderState.FAILED:
      return "FAILED";
    case Release_TargetRender_TargetRenderState.IN_PROGRESS:
      return "IN_PROGRESS";
    case Release_TargetRender_TargetRenderState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Well-known rendering failures. */
export enum Release_TargetRender_FailureCause {
  /** FAILURE_CAUSE_UNSPECIFIED - No reason for failure is specified. */
  FAILURE_CAUSE_UNSPECIFIED = 0,
  /**
   * CLOUD_BUILD_UNAVAILABLE - Cloud Build is not available, either because it is not enabled or
   * because Cloud Deploy has insufficient permissions. See [required
   * permission](https://cloud.google.com/deploy/docs/cloud-deploy-service-account#required_permissions).
   */
  CLOUD_BUILD_UNAVAILABLE = 1,
  /**
   * EXECUTION_FAILED - The render operation did not complete successfully; check Cloud Build
   * logs.
   */
  EXECUTION_FAILED = 2,
  /**
   * CLOUD_BUILD_REQUEST_FAILED - Cloud Build failed to fulfill Cloud Deploy's request. See
   * failure_message for additional details.
   */
  CLOUD_BUILD_REQUEST_FAILED = 3,
  /**
   * VERIFICATION_CONFIG_NOT_FOUND - The render operation did not complete successfully because the
   * verification stanza required for verify was not found on the Skaffold
   * configuration.
   */
  VERIFICATION_CONFIG_NOT_FOUND = 4,
  /**
   * CUSTOM_ACTION_NOT_FOUND - The render operation did not complete successfully because the custom
   * action required for predeploy or postdeploy was not found in the
   * Skaffold configuration. See failure_message for additional details.
   */
  CUSTOM_ACTION_NOT_FOUND = 5,
  /**
   * DEPLOYMENT_STRATEGY_NOT_SUPPORTED - Release failed during rendering because the release configuration is
   * not supported with the specified deployment strategy.
   */
  DEPLOYMENT_STRATEGY_NOT_SUPPORTED = 6,
  /** RENDER_FEATURE_NOT_SUPPORTED - The render operation had a feature configured that is not supported. */
  RENDER_FEATURE_NOT_SUPPORTED = 7,
  UNRECOGNIZED = -1,
}

export function release_TargetRender_FailureCauseFromJSON(object: any): Release_TargetRender_FailureCause {
  switch (object) {
    case 0:
    case "FAILURE_CAUSE_UNSPECIFIED":
      return Release_TargetRender_FailureCause.FAILURE_CAUSE_UNSPECIFIED;
    case 1:
    case "CLOUD_BUILD_UNAVAILABLE":
      return Release_TargetRender_FailureCause.CLOUD_BUILD_UNAVAILABLE;
    case 2:
    case "EXECUTION_FAILED":
      return Release_TargetRender_FailureCause.EXECUTION_FAILED;
    case 3:
    case "CLOUD_BUILD_REQUEST_FAILED":
      return Release_TargetRender_FailureCause.CLOUD_BUILD_REQUEST_FAILED;
    case 4:
    case "VERIFICATION_CONFIG_NOT_FOUND":
      return Release_TargetRender_FailureCause.VERIFICATION_CONFIG_NOT_FOUND;
    case 5:
    case "CUSTOM_ACTION_NOT_FOUND":
      return Release_TargetRender_FailureCause.CUSTOM_ACTION_NOT_FOUND;
    case 6:
    case "DEPLOYMENT_STRATEGY_NOT_SUPPORTED":
      return Release_TargetRender_FailureCause.DEPLOYMENT_STRATEGY_NOT_SUPPORTED;
    case 7:
    case "RENDER_FEATURE_NOT_SUPPORTED":
      return Release_TargetRender_FailureCause.RENDER_FEATURE_NOT_SUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Release_TargetRender_FailureCause.UNRECOGNIZED;
  }
}

export function release_TargetRender_FailureCauseToJSON(object: Release_TargetRender_FailureCause): string {
  switch (object) {
    case Release_TargetRender_FailureCause.FAILURE_CAUSE_UNSPECIFIED:
      return "FAILURE_CAUSE_UNSPECIFIED";
    case Release_TargetRender_FailureCause.CLOUD_BUILD_UNAVAILABLE:
      return "CLOUD_BUILD_UNAVAILABLE";
    case Release_TargetRender_FailureCause.EXECUTION_FAILED:
      return "EXECUTION_FAILED";
    case Release_TargetRender_FailureCause.CLOUD_BUILD_REQUEST_FAILED:
      return "CLOUD_BUILD_REQUEST_FAILED";
    case Release_TargetRender_FailureCause.VERIFICATION_CONFIG_NOT_FOUND:
      return "VERIFICATION_CONFIG_NOT_FOUND";
    case Release_TargetRender_FailureCause.CUSTOM_ACTION_NOT_FOUND:
      return "CUSTOM_ACTION_NOT_FOUND";
    case Release_TargetRender_FailureCause.DEPLOYMENT_STRATEGY_NOT_SUPPORTED:
      return "DEPLOYMENT_STRATEGY_NOT_SUPPORTED";
    case Release_TargetRender_FailureCause.RENDER_FEATURE_NOT_SUPPORTED:
      return "RENDER_FEATURE_NOT_SUPPORTED";
    case Release_TargetRender_FailureCause.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * ReleaseReadyCondition contains information around the status of the
 * Release. If a release is not ready, you cannot create a rollout with the
 * release.
 */
export interface Release_ReleaseReadyCondition {
  /**
   * True if the Release is in a valid state. Otherwise at least one condition
   * in `ReleaseCondition` is in an invalid state. Iterate over those
   * conditions and see which condition(s) has status = false to find out what
   * is wrong with the Release.
   */
  status: boolean;
}

/**
 * SkaffoldSupportedCondition contains information about when support for the
 * release's version of Skaffold ends.
 */
export interface Release_SkaffoldSupportedCondition {
  /** True if the version of Skaffold used by this release is supported. */
  status: boolean;
  /** The Skaffold support state for this release's version of Skaffold. */
  skaffoldSupportState: SkaffoldSupportState;
  /**
   * The time at which this release's version of Skaffold will enter
   * maintenance mode.
   */
  maintenanceModeTime?:
    | Date
    | undefined;
  /**
   * The time at which this release's version of Skaffold will no longer be
   * supported.
   */
  supportExpirationTime?: Date | undefined;
}

/** ReleaseCondition contains all conditions relevant to a Release. */
export interface Release_ReleaseCondition {
  /** Details around the Releases's overall status. */
  releaseReadyCondition?:
    | Release_ReleaseReadyCondition
    | undefined;
  /**
   * Details around the support state of the release's Skaffold
   * version.
   */
  skaffoldSupportedCondition?: Release_SkaffoldSupportedCondition | undefined;
}

export interface Release_AnnotationsEntry {
  key: string;
  value: string;
}

export interface Release_LabelsEntry {
  key: string;
  value: string;
}

export interface Release_TargetArtifactsEntry {
  key: string;
  value?: TargetArtifact | undefined;
}

export interface Release_TargetRendersEntry {
  key: string;
  value?: Release_TargetRender | undefined;
}

export interface Release_DeployParametersEntry {
  key: string;
  value: string;
}

/** Description of an a image to use during Skaffold rendering. */
export interface BuildArtifact {
  /** Image name in Skaffold configuration. */
  image: string;
  /**
   * Image tag to use. This will generally be the full path to an image, such
   * as "gcr.io/my-project/busybox:1.2.3" or
   * "gcr.io/my-project/busybox@sha256:abc123".
   */
  tag: string;
}

/** The artifacts produced by a target render operation. */
export interface TargetArtifact {
  /**
   * Output only. URI of a directory containing the artifacts. This contains
   * deployment configuration used by Skaffold during a rollout, and all
   * paths are relative to this location.
   */
  artifactUri?:
    | string
    | undefined;
  /**
   * Output only. File path of the resolved Skaffold configuration relative to
   * the URI.
   */
  skaffoldConfigPath: string;
  /** Output only. File path of the rendered manifest relative to the URI. */
  manifestPath: string;
  /** Output only. Map from the phase ID to the phase artifacts for the `Target`. */
  phaseArtifacts: { [key: string]: TargetArtifact_PhaseArtifact };
}

/** Contains the paths to the artifacts, relative to the URI, for a phase. */
export interface TargetArtifact_PhaseArtifact {
  /**
   * Output only. File path of the resolved Skaffold configuration relative to
   * the URI.
   */
  skaffoldConfigPath: string;
  /** Output only. File path of the rendered manifest relative to the URI. */
  manifestPath: string;
  /**
   * Output only. File path of the directory of rendered job manifests
   * relative to the URI. This is only set if it is applicable.
   */
  jobManifestsPath: string;
}

export interface TargetArtifact_PhaseArtifactsEntry {
  key: string;
  value?: TargetArtifact_PhaseArtifact | undefined;
}

/**
 * CloudRunRenderMetadata contains Cloud Run information associated with a
 * `Release` render.
 */
export interface CloudRunRenderMetadata {
  /**
   * Output only. The name of the Cloud Run Service in the rendered manifest.
   * Format is `projects/{project}/locations/{location}/services/{service}`.
   */
  service: string;
}

/** RenderMetadata includes information associated with a `Release` render. */
export interface RenderMetadata {
  /** Output only. Metadata associated with rendering for Cloud Run. */
  cloudRun?:
    | CloudRunRenderMetadata
    | undefined;
  /** Output only. Custom metadata provided by user-defined render operation. */
  custom?: CustomMetadata | undefined;
}

/**
 * A `Rollout` resource in the Cloud Deploy API.
 *
 * A `Rollout` contains information around a specific deployment to a `Target`.
 */
export interface Rollout {
  /**
   * Optional. Name of the `Rollout`. Format is
   * `projects/{project}/locations/{location}/deliveryPipelines/{deliveryPipeline}/releases/{release}/rollouts/[a-z][a-z0-9\-]{0,62}`.
   */
  name: string;
  /** Output only. Unique identifier of the `Rollout`. */
  uid: string;
  /**
   * Description of the `Rollout` for user purposes. Max length is 255
   * characters.
   */
  description: string;
  /**
   * User annotations. These attributes can only be set and used by the
   * user, and not by Cloud Deploy. See https://google.aip.dev/128#annotations
   * for more details such as format and size limitations.
   */
  annotations: { [key: string]: string };
  /**
   * Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 128 bytes.
   */
  labels: { [key: string]: string };
  /** Output only. Time at which the `Rollout` was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Time at which the `Rollout` was approved. */
  approveTime?:
    | Date
    | undefined;
  /** Output only. Time at which the `Rollout` was enqueued. */
  enqueueTime?:
    | Date
    | undefined;
  /** Output only. Time at which the `Rollout` started deploying. */
  deployStartTime?:
    | Date
    | undefined;
  /** Output only. Time at which the `Rollout` finished deploying. */
  deployEndTime?:
    | Date
    | undefined;
  /** Required. The ID of Target to which this `Rollout` is deploying. */
  targetId: string;
  /** Output only. Approval state of the `Rollout`. */
  approvalState: Rollout_ApprovalState;
  /** Output only. Current state of the `Rollout`. */
  state: Rollout_State;
  /**
   * Output only. Additional information about the rollout failure, if
   * available.
   */
  failureReason: string;
  /**
   * Output only. The resource name of the Cloud Build `Build` object that is
   * used to deploy the Rollout. Format is
   * `projects/{project}/locations/{location}/builds/{build}`.
   */
  deployingBuild: string;
  /**
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /**
   * Output only. The reason this rollout failed. This will always be
   * unspecified while the rollout is in progress.
   */
  deployFailureCause: Rollout_FailureCause;
  /** Output only. The phases that represent the workflows of this `Rollout`. */
  phases: Phase[];
  /** Output only. Metadata contains information about the rollout. */
  metadata?:
    | Metadata
    | undefined;
  /**
   * Output only. Name of the `ControllerRollout`. Format is
   * `projects/{project}/locations/{location}/deliveryPipelines/{deliveryPipeline}/releases/{release}/rollouts/[a-z][a-z0-9\-]{0,62}`.
   */
  controllerRollout: string;
  /**
   * Output only. Name of the `Rollout` that is rolled back by this `Rollout`.
   * Empty if this `Rollout` wasn't created as a rollback.
   */
  rollbackOfRollout: string;
  /** Output only. Names of `Rollouts` that rolled back this `Rollout`. */
  rolledBackByRollouts: string[];
}

/** Valid approval states of a `Rollout`. */
export enum Rollout_ApprovalState {
  /** APPROVAL_STATE_UNSPECIFIED - The `Rollout` has an unspecified approval state. */
  APPROVAL_STATE_UNSPECIFIED = 0,
  /** NEEDS_APPROVAL - The `Rollout` requires approval. */
  NEEDS_APPROVAL = 1,
  /** DOES_NOT_NEED_APPROVAL - The `Rollout` does not require approval. */
  DOES_NOT_NEED_APPROVAL = 2,
  /** APPROVED - The `Rollout` has been approved. */
  APPROVED = 3,
  /** REJECTED - The `Rollout` has been rejected. */
  REJECTED = 4,
  UNRECOGNIZED = -1,
}

export function rollout_ApprovalStateFromJSON(object: any): Rollout_ApprovalState {
  switch (object) {
    case 0:
    case "APPROVAL_STATE_UNSPECIFIED":
      return Rollout_ApprovalState.APPROVAL_STATE_UNSPECIFIED;
    case 1:
    case "NEEDS_APPROVAL":
      return Rollout_ApprovalState.NEEDS_APPROVAL;
    case 2:
    case "DOES_NOT_NEED_APPROVAL":
      return Rollout_ApprovalState.DOES_NOT_NEED_APPROVAL;
    case 3:
    case "APPROVED":
      return Rollout_ApprovalState.APPROVED;
    case 4:
    case "REJECTED":
      return Rollout_ApprovalState.REJECTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Rollout_ApprovalState.UNRECOGNIZED;
  }
}

export function rollout_ApprovalStateToJSON(object: Rollout_ApprovalState): string {
  switch (object) {
    case Rollout_ApprovalState.APPROVAL_STATE_UNSPECIFIED:
      return "APPROVAL_STATE_UNSPECIFIED";
    case Rollout_ApprovalState.NEEDS_APPROVAL:
      return "NEEDS_APPROVAL";
    case Rollout_ApprovalState.DOES_NOT_NEED_APPROVAL:
      return "DOES_NOT_NEED_APPROVAL";
    case Rollout_ApprovalState.APPROVED:
      return "APPROVED";
    case Rollout_ApprovalState.REJECTED:
      return "REJECTED";
    case Rollout_ApprovalState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Valid states of a `Rollout`. */
export enum Rollout_State {
  /** STATE_UNSPECIFIED - The `Rollout` has an unspecified state. */
  STATE_UNSPECIFIED = 0,
  /** SUCCEEDED - The `Rollout` has completed successfully. */
  SUCCEEDED = 1,
  /** FAILED - The `Rollout` has failed. */
  FAILED = 2,
  /** IN_PROGRESS - The `Rollout` is being deployed. */
  IN_PROGRESS = 3,
  /** PENDING_APPROVAL - The `Rollout` needs approval. */
  PENDING_APPROVAL = 4,
  /** APPROVAL_REJECTED - An approver rejected the `Rollout`. */
  APPROVAL_REJECTED = 5,
  /**
   * PENDING - The `Rollout` is waiting for an earlier Rollout(s) to complete on this
   * `Target`.
   */
  PENDING = 6,
  /** PENDING_RELEASE - The `Rollout` is waiting for the `Release` to be fully rendered. */
  PENDING_RELEASE = 7,
  /** CANCELLING - The `Rollout` is in the process of being cancelled. */
  CANCELLING = 8,
  /** CANCELLED - The `Rollout` has been cancelled. */
  CANCELLED = 9,
  /** HALTED - The `Rollout` is halted. */
  HALTED = 10,
  UNRECOGNIZED = -1,
}

export function rollout_StateFromJSON(object: any): Rollout_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Rollout_State.STATE_UNSPECIFIED;
    case 1:
    case "SUCCEEDED":
      return Rollout_State.SUCCEEDED;
    case 2:
    case "FAILED":
      return Rollout_State.FAILED;
    case 3:
    case "IN_PROGRESS":
      return Rollout_State.IN_PROGRESS;
    case 4:
    case "PENDING_APPROVAL":
      return Rollout_State.PENDING_APPROVAL;
    case 5:
    case "APPROVAL_REJECTED":
      return Rollout_State.APPROVAL_REJECTED;
    case 6:
    case "PENDING":
      return Rollout_State.PENDING;
    case 7:
    case "PENDING_RELEASE":
      return Rollout_State.PENDING_RELEASE;
    case 8:
    case "CANCELLING":
      return Rollout_State.CANCELLING;
    case 9:
    case "CANCELLED":
      return Rollout_State.CANCELLED;
    case 10:
    case "HALTED":
      return Rollout_State.HALTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Rollout_State.UNRECOGNIZED;
  }
}

export function rollout_StateToJSON(object: Rollout_State): string {
  switch (object) {
    case Rollout_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Rollout_State.SUCCEEDED:
      return "SUCCEEDED";
    case Rollout_State.FAILED:
      return "FAILED";
    case Rollout_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Rollout_State.PENDING_APPROVAL:
      return "PENDING_APPROVAL";
    case Rollout_State.APPROVAL_REJECTED:
      return "APPROVAL_REJECTED";
    case Rollout_State.PENDING:
      return "PENDING";
    case Rollout_State.PENDING_RELEASE:
      return "PENDING_RELEASE";
    case Rollout_State.CANCELLING:
      return "CANCELLING";
    case Rollout_State.CANCELLED:
      return "CANCELLED";
    case Rollout_State.HALTED:
      return "HALTED";
    case Rollout_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Well-known rollout failures. */
export enum Rollout_FailureCause {
  /** FAILURE_CAUSE_UNSPECIFIED - No reason for failure is specified. */
  FAILURE_CAUSE_UNSPECIFIED = 0,
  /**
   * CLOUD_BUILD_UNAVAILABLE - Cloud Build is not available, either because it is not enabled or because
   * Cloud Deploy has insufficient permissions. See [required
   * permission](https://cloud.google.com/deploy/docs/cloud-deploy-service-account#required_permissions).
   */
  CLOUD_BUILD_UNAVAILABLE = 1,
  /**
   * EXECUTION_FAILED - The deploy operation did not complete successfully; check Cloud Build
   * logs.
   */
  EXECUTION_FAILED = 2,
  /** DEADLINE_EXCEEDED - Deployment did not complete within the alloted time. */
  DEADLINE_EXCEEDED = 3,
  /** RELEASE_FAILED - Release is in a failed state. */
  RELEASE_FAILED = 4,
  /** RELEASE_ABANDONED - Release is abandoned. */
  RELEASE_ABANDONED = 5,
  /** VERIFICATION_CONFIG_NOT_FOUND - No Skaffold verify configuration was found. */
  VERIFICATION_CONFIG_NOT_FOUND = 6,
  /**
   * CLOUD_BUILD_REQUEST_FAILED - Cloud Build failed to fulfill Cloud Deploy's request. See failure_message
   * for additional details.
   */
  CLOUD_BUILD_REQUEST_FAILED = 7,
  /** OPERATION_FEATURE_NOT_SUPPORTED - A Rollout operation had a feature configured that is not supported. */
  OPERATION_FEATURE_NOT_SUPPORTED = 8,
  UNRECOGNIZED = -1,
}

export function rollout_FailureCauseFromJSON(object: any): Rollout_FailureCause {
  switch (object) {
    case 0:
    case "FAILURE_CAUSE_UNSPECIFIED":
      return Rollout_FailureCause.FAILURE_CAUSE_UNSPECIFIED;
    case 1:
    case "CLOUD_BUILD_UNAVAILABLE":
      return Rollout_FailureCause.CLOUD_BUILD_UNAVAILABLE;
    case 2:
    case "EXECUTION_FAILED":
      return Rollout_FailureCause.EXECUTION_FAILED;
    case 3:
    case "DEADLINE_EXCEEDED":
      return Rollout_FailureCause.DEADLINE_EXCEEDED;
    case 4:
    case "RELEASE_FAILED":
      return Rollout_FailureCause.RELEASE_FAILED;
    case 5:
    case "RELEASE_ABANDONED":
      return Rollout_FailureCause.RELEASE_ABANDONED;
    case 6:
    case "VERIFICATION_CONFIG_NOT_FOUND":
      return Rollout_FailureCause.VERIFICATION_CONFIG_NOT_FOUND;
    case 7:
    case "CLOUD_BUILD_REQUEST_FAILED":
      return Rollout_FailureCause.CLOUD_BUILD_REQUEST_FAILED;
    case 8:
    case "OPERATION_FEATURE_NOT_SUPPORTED":
      return Rollout_FailureCause.OPERATION_FEATURE_NOT_SUPPORTED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Rollout_FailureCause.UNRECOGNIZED;
  }
}

export function rollout_FailureCauseToJSON(object: Rollout_FailureCause): string {
  switch (object) {
    case Rollout_FailureCause.FAILURE_CAUSE_UNSPECIFIED:
      return "FAILURE_CAUSE_UNSPECIFIED";
    case Rollout_FailureCause.CLOUD_BUILD_UNAVAILABLE:
      return "CLOUD_BUILD_UNAVAILABLE";
    case Rollout_FailureCause.EXECUTION_FAILED:
      return "EXECUTION_FAILED";
    case Rollout_FailureCause.DEADLINE_EXCEEDED:
      return "DEADLINE_EXCEEDED";
    case Rollout_FailureCause.RELEASE_FAILED:
      return "RELEASE_FAILED";
    case Rollout_FailureCause.RELEASE_ABANDONED:
      return "RELEASE_ABANDONED";
    case Rollout_FailureCause.VERIFICATION_CONFIG_NOT_FOUND:
      return "VERIFICATION_CONFIG_NOT_FOUND";
    case Rollout_FailureCause.CLOUD_BUILD_REQUEST_FAILED:
      return "CLOUD_BUILD_REQUEST_FAILED";
    case Rollout_FailureCause.OPERATION_FEATURE_NOT_SUPPORTED:
      return "OPERATION_FEATURE_NOT_SUPPORTED";
    case Rollout_FailureCause.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Rollout_AnnotationsEntry {
  key: string;
  value: string;
}

export interface Rollout_LabelsEntry {
  key: string;
  value: string;
}

/** Metadata includes information associated with a `Rollout`. */
export interface Metadata {
  /**
   * Output only. The name of the Cloud Run Service that is associated with a
   * `Rollout`.
   */
  cloudRun?:
    | CloudRunMetadata
    | undefined;
  /**
   * Output only. AutomationRolloutMetadata contains the information about the
   * interactions between Automation service and this rollout.
   */
  automation?:
    | AutomationRolloutMetadata
    | undefined;
  /** Output only. Custom metadata provided by user-defined `Rollout` operations. */
  custom?: CustomMetadata | undefined;
}

/** CloudRunMetadata contains information from a Cloud Run deployment. */
export interface CloudRunMetadata {
  /**
   * Output only. The name of the Cloud Run Service that is associated with a
   * `Rollout`. Format is
   * `projects/{project}/locations/{location}/services/{service}`.
   */
  service: string;
  /**
   * Output only. The Cloud Run Service urls that are associated with a
   * `Rollout`.
   */
  serviceUrls: string[];
  /** Output only. The Cloud Run Revision id associated with a `Rollout`. */
  revision: string;
  /**
   * Output only. The name of the Cloud Run job that is associated with a
   * `Rollout`. Format is
   * `projects/{project}/locations/{location}/jobs/{job_name}`.
   */
  job: string;
}

/**
 * AutomationRolloutMetadata contains Automation-related actions that
 * were performed on a rollout.
 */
export interface AutomationRolloutMetadata {
  /**
   * Output only. The ID of the AutomationRun initiated by a promote release
   * rule.
   */
  promoteAutomationRun: string;
  /**
   * Output only. The IDs of the AutomationRuns initiated by an advance rollout
   * rule.
   */
  advanceAutomationRuns: string[];
  /**
   * Output only. The IDs of the AutomationRuns initiated by a repair rollout
   * rule.
   */
  repairAutomationRuns: string[];
  /** Output only. The current AutomationRun repairing the rollout. */
  currentRepairAutomationRun: string;
}

/** CustomMetadata contains information from a user-defined operation. */
export interface CustomMetadata {
  /** Output only. Key-value pairs provided by the user-defined operation. */
  values: { [key: string]: string };
}

export interface CustomMetadata_ValuesEntry {
  key: string;
  value: string;
}

/**
 * Phase represents a collection of jobs that are logically grouped together
 * for a `Rollout`.
 */
export interface Phase {
  /** Output only. The ID of the Phase. */
  id: string;
  /** Output only. Current state of the Phase. */
  state: Phase_State;
  /**
   * Output only. Additional information on why the Phase was skipped, if
   * available.
   */
  skipMessage: string;
  /** Output only. Deployment job composition. */
  deploymentJobs?:
    | DeploymentJobs
    | undefined;
  /** Output only. ChildRollout job composition. */
  childRolloutJobs?: ChildRolloutJobs | undefined;
}

/** Valid states of a Phase. */
export enum Phase_State {
  /** STATE_UNSPECIFIED - The Phase has an unspecified state. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The Phase is waiting for an earlier Phase(s) to complete. */
  PENDING = 1,
  /** IN_PROGRESS - The Phase is in progress. */
  IN_PROGRESS = 2,
  /** SUCCEEDED - The Phase has succeeded. */
  SUCCEEDED = 3,
  /** FAILED - The Phase has failed. */
  FAILED = 4,
  /** ABORTED - The Phase was aborted. */
  ABORTED = 5,
  /** SKIPPED - The Phase was skipped. */
  SKIPPED = 6,
  UNRECOGNIZED = -1,
}

export function phase_StateFromJSON(object: any): Phase_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Phase_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return Phase_State.PENDING;
    case 2:
    case "IN_PROGRESS":
      return Phase_State.IN_PROGRESS;
    case 3:
    case "SUCCEEDED":
      return Phase_State.SUCCEEDED;
    case 4:
    case "FAILED":
      return Phase_State.FAILED;
    case 5:
    case "ABORTED":
      return Phase_State.ABORTED;
    case 6:
    case "SKIPPED":
      return Phase_State.SKIPPED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Phase_State.UNRECOGNIZED;
  }
}

export function phase_StateToJSON(object: Phase_State): string {
  switch (object) {
    case Phase_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Phase_State.PENDING:
      return "PENDING";
    case Phase_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Phase_State.SUCCEEDED:
      return "SUCCEEDED";
    case Phase_State.FAILED:
      return "FAILED";
    case Phase_State.ABORTED:
      return "ABORTED";
    case Phase_State.SKIPPED:
      return "SKIPPED";
    case Phase_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Deployment job composition. */
export interface DeploymentJobs {
  /** Output only. The deploy Job. This is the deploy job in the phase. */
  deployJob?:
    | Job
    | undefined;
  /** Output only. The verify Job. Runs after a deploy if the deploy succeeds. */
  verifyJob?:
    | Job
    | undefined;
  /** Output only. The predeploy Job, which is the first job on the phase. */
  predeployJob?:
    | Job
    | undefined;
  /** Output only. The postdeploy Job, which is the last job on the phase. */
  postdeployJob?: Job | undefined;
}

/** ChildRollouts job composition */
export interface ChildRolloutJobs {
  /** Output only. List of CreateChildRolloutJobs */
  createRolloutJobs: Job[];
  /** Output only. List of AdvanceChildRolloutJobs */
  advanceRolloutJobs: Job[];
}

/** Job represents an operation for a `Rollout`. */
export interface Job {
  /** Output only. The ID of the Job. */
  id: string;
  /** Output only. The current state of the Job. */
  state: Job_State;
  /**
   * Output only. Additional information on why the Job was skipped, if
   * available.
   */
  skipMessage: string;
  /**
   * Output only. The name of the `JobRun` responsible for the most recent
   * invocation of this Job.
   */
  jobRun: string;
  /** Output only. A deploy Job. */
  deployJob?:
    | DeployJob
    | undefined;
  /** Output only. A verify Job. */
  verifyJob?:
    | VerifyJob
    | undefined;
  /** Output only. A predeploy Job. */
  predeployJob?:
    | PredeployJob
    | undefined;
  /** Output only. A postdeploy Job. */
  postdeployJob?:
    | PostdeployJob
    | undefined;
  /** Output only. A createChildRollout Job. */
  createChildRolloutJob?:
    | CreateChildRolloutJob
    | undefined;
  /** Output only. An advanceChildRollout Job. */
  advanceChildRolloutJob?: AdvanceChildRolloutJob | undefined;
}

/** Valid states of a Job. */
export enum Job_State {
  /** STATE_UNSPECIFIED - The Job has an unspecified state. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The Job is waiting for an earlier Phase(s) or Job(s) to complete. */
  PENDING = 1,
  /** DISABLED - The Job is disabled. */
  DISABLED = 2,
  /** IN_PROGRESS - The Job is in progress. */
  IN_PROGRESS = 3,
  /** SUCCEEDED - The Job succeeded. */
  SUCCEEDED = 4,
  /** FAILED - The Job failed. */
  FAILED = 5,
  /** ABORTED - The Job was aborted. */
  ABORTED = 6,
  /** SKIPPED - The Job was skipped. */
  SKIPPED = 7,
  /** IGNORED - The Job was ignored. */
  IGNORED = 8,
  UNRECOGNIZED = -1,
}

export function job_StateFromJSON(object: any): Job_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Job_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return Job_State.PENDING;
    case 2:
    case "DISABLED":
      return Job_State.DISABLED;
    case 3:
    case "IN_PROGRESS":
      return Job_State.IN_PROGRESS;
    case 4:
    case "SUCCEEDED":
      return Job_State.SUCCEEDED;
    case 5:
    case "FAILED":
      return Job_State.FAILED;
    case 6:
    case "ABORTED":
      return Job_State.ABORTED;
    case 7:
    case "SKIPPED":
      return Job_State.SKIPPED;
    case 8:
    case "IGNORED":
      return Job_State.IGNORED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Job_State.UNRECOGNIZED;
  }
}

export function job_StateToJSON(object: Job_State): string {
  switch (object) {
    case Job_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Job_State.PENDING:
      return "PENDING";
    case Job_State.DISABLED:
      return "DISABLED";
    case Job_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Job_State.SUCCEEDED:
      return "SUCCEEDED";
    case Job_State.FAILED:
      return "FAILED";
    case Job_State.ABORTED:
      return "ABORTED";
    case Job_State.SKIPPED:
      return "SKIPPED";
    case Job_State.IGNORED:
      return "IGNORED";
    case Job_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A deploy Job. */
export interface DeployJob {
}

/** A verify Job. */
export interface VerifyJob {
}

/** A predeploy Job. */
export interface PredeployJob {
  /** Output only. The custom actions that the predeploy Job executes. */
  actions: string[];
}

/** A postdeploy Job. */
export interface PostdeployJob {
  /** Output only. The custom actions that the postdeploy Job executes. */
  actions: string[];
}

/** A createChildRollout Job. */
export interface CreateChildRolloutJob {
}

/** An advanceChildRollout Job. */
export interface AdvanceChildRolloutJob {
}

/**
 * An `Automation` resource in the Cloud Deploy API.
 *
 * An `Automation` enables the automation of manually driven actions for
 * a Delivery Pipeline, which includes Release promotion among Targets,
 * Rollout repair and Rollout deployment strategy advancement. The intention
 * of Automation is to reduce manual intervention in the continuous delivery
 * process.
 */
export interface Automation {
  /**
   * Output only. Name of the `Automation`. Format is
   * `projects/{project}/locations/{location}/deliveryPipelines/{delivery_pipeline}/automations/{automation}`.
   */
  name: string;
  /** Output only. Unique identifier of the `Automation`. */
  uid: string;
  /** Optional. Description of the `Automation`. Max length is 255 characters. */
  description: string;
  /** Output only. Time at which the automation was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. Time at which the automation was updated. */
  updateTime?:
    | Date
    | undefined;
  /**
   * Optional. User annotations. These attributes can only be set and used by
   * the user, and not by Cloud Deploy. Annotations must meet the following
   * constraints:
   *
   * * Annotations are key/value pairs.
   * * Valid annotation keys have two segments: an optional prefix and name,
   * separated by a slash (`/`).
   * * The name segment is required and must be 63 characters or less,
   * beginning and ending with an alphanumeric character (`[a-z0-9A-Z]`) with
   * dashes (`-`), underscores (`_`), dots (`.`), and alphanumerics between.
   * * The prefix is optional. If specified, the prefix must be a DNS subdomain:
   * a series of DNS labels separated by dots(`.`), not longer than 253
   * characters in total, followed by a slash (`/`).
   *
   * See
   * https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/#syntax-and-character-set
   * for more details.
   */
  annotations: { [key: string]: string };
  /**
   * Optional. Labels are attributes that can be set and used by both the
   * user and by Cloud Deploy. Labels must meet the following constraints:
   *
   * * Keys and values can contain only lowercase letters, numeric characters,
   * underscores, and dashes.
   * * All characters must use UTF-8 encoding, and international characters are
   * allowed.
   * * Keys must start with a lowercase letter or international character.
   * * Each resource is limited to a maximum of 64 labels.
   *
   * Both keys and values are additionally constrained to be <= 63 characters.
   */
  labels: { [key: string]: string };
  /**
   * Optional. The weak etag of the `Automation` resource.
   * This checksum is computed by the server based on the value of other
   * fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   */
  etag: string;
  /** Optional. When Suspended, automation is deactivated from execution. */
  suspended: boolean;
  /**
   * Required. Email address of the user-managed IAM service account that
   * creates Cloud Deploy release and rollout resources.
   */
  serviceAccount: string;
  /** Required. Selected resources to which the automation will be applied. */
  selector?:
    | AutomationResourceSelector
    | undefined;
  /**
   * Required. List of Automation rules associated with the Automation resource.
   * Must have at least one rule and limited to 250 rules per Delivery Pipeline.
   * Note: the order of the rules here is not the same as the order of
   * execution.
   */
  rules: AutomationRule[];
}

export interface Automation_AnnotationsEntry {
  key: string;
  value: string;
}

export interface Automation_LabelsEntry {
  key: string;
  value: string;
}

/**
 * AutomationResourceSelector contains the information to select the resources
 * to which an Automation is going to be applied.
 */
export interface AutomationResourceSelector {
  /** Contains attributes about a target. */
  targets: TargetAttribute[];
}

/** `AutomationRule` defines the automation activities. */
export interface AutomationRule {
  /**
   * Optional. `PromoteReleaseRule` will automatically promote a release from
   * the current target to a specified target.
   */
  promoteReleaseRule?:
    | PromoteReleaseRule
    | undefined;
  /**
   * Optional. The `AdvanceRolloutRule` will automatically advance a
   * successful Rollout.
   */
  advanceRolloutRule?:
    | AdvanceRolloutRule
    | undefined;
  /**
   * Optional. The `RepairRolloutRule` will automatically repair a failed
   * rollout.
   */
  repairRolloutRule?: RepairRolloutRule | undefined;
}

/**
 * `PromoteRelease` rule will automatically promote a release from the current
 * target to a specified target.
 */
export interface PromoteReleaseRule {
  /**
   * Required. ID of the rule. This id must be unique in the `Automation`
   * resource to which this rule belongs. The format is `[a-z][a-z0-9\-]{0,62}`.
   */
  id: string;
  /**
   * Optional. How long the release need to be paused until being promoted to
   * the next target.
   */
  wait?:
    | Duration
    | undefined;
  /**
   * Optional. The ID of the stage in the pipeline to which this `Release` is
   * deploying. If unspecified, default it to the next stage in the promotion
   * flow. The value of this field could be one of the following:
   *
   * * The last segment of a target name. It only needs the ID to determine
   * if the target is one of the stages in the promotion sequence defined
   * in the pipeline.
   * * "@next", the next target in the promotion sequence.
   */
  destinationTargetId: string;
  /** Output only. Information around the state of the Automation rule. */
  condition?:
    | AutomationRuleCondition
    | undefined;
  /**
   * Optional. The starting phase of the rollout created by this operation.
   * Default to the first phase.
   */
  destinationPhase: string;
}

/**
 * The `AdvanceRollout` automation rule will automatically advance a successful
 * Rollout to the next phase.
 */
export interface AdvanceRolloutRule {
  /**
   * Required. ID of the rule. This id must be unique in the `Automation`
   * resource to which this rule belongs. The format is `[a-z][a-z0-9\-]{0,62}`.
   */
  id: string;
  /**
   * Optional. Proceeds only after phase name matched any one in the list.
   * This value must consist of lower-case letters, numbers, and hyphens,
   * start with a letter and end with a letter or a number, and have a max
   * length of 63 characters. In other words, it must match the following
   * regex: `^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$`.
   */
  sourcePhases: string[];
  /** Optional. How long to wait after a rollout is finished. */
  wait?:
    | Duration
    | undefined;
  /** Output only. Information around the state of the Automation rule. */
  condition?: AutomationRuleCondition | undefined;
}

/**
 * The `RepairRolloutRule` automation rule will automatically repair a failed
 * `Rollout`.
 */
export interface RepairRolloutRule {
  /**
   * Required. ID of the rule. This id must be unique in the `Automation`
   * resource to which this rule belongs. The format is `[a-z][a-z0-9\-]{0,62}`.
   */
  id: string;
  /**
   * Optional. Phases within which jobs are subject to automatic repair actions
   * on failure. Proceeds only after phase name matched any one in the list, or
   * for all phases if unspecified. This value must consist of lower-case
   * letters, numbers, and hyphens, start with a letter and end with a letter or
   * a number, and have a max length of 63 characters. In other words, it must
   * match the following regex: `^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$`.
   */
  sourcePhases: string[];
  /**
   * Optional. Jobs to repair. Proceeds only after job name matched any one in
   * the list, or for all jobs if unspecified or empty. The phase that includes
   * the job must match the phase ID specified in `source_phase`. This value
   * must consist of lower-case letters, numbers, and hyphens, start with a
   * letter and end with a letter or a number, and have a max length of 63
   * characters. In other words, it must match the following regex:
   * `^[a-z]([a-z0-9-]{0,61}[a-z0-9])?$`.
   */
  jobs: string[];
  /** Required. Defines the types of automatic repair actions for failed jobs. */
  repairModes: RepairMode[];
  /** Output only. Information around the state of the 'Automation' rule. */
  condition?: AutomationRuleCondition | undefined;
}

/** Configuration of the repair action. */
export interface RepairMode {
  /** Optional. Retries a failed job. */
  retry?:
    | Retry
    | undefined;
  /** Optional. Rolls back a `Rollout`. */
  rollback?: Rollback | undefined;
}

/** Retries the failed job. */
export interface Retry {
  /**
   * Required. Total number of retries. Retry is skipped if set to 0; The
   * minimum value is 1, and the maximum value is 10.
   */
  attempts: Long;
  /**
   * Optional. How long to wait for the first retry. Default is 0, and the
   * maximum value is 14d.
   */
  wait?:
    | Duration
    | undefined;
  /**
   * Optional. The pattern of how wait time will be increased. Default is
   * linear. Backoff mode will be ignored if `wait` is 0.
   */
  backoffMode: BackoffMode;
}

/** Rolls back a `Rollout`. */
export interface Rollback {
  /**
   * Optional. The starting phase ID for the `Rollout`. If unspecified, the
   * `Rollout` will start in the stable phase.
   */
  destinationPhase: string;
}

/**
 * `AutomationRuleCondition` contains conditions relevant to an
 * `Automation` rule.
 */
export interface AutomationRuleCondition {
  /** Optional. Details around targets enumerated in the rule. */
  targetsPresentCondition?: TargetsPresentCondition | undefined;
}

/** The data within all DeliveryPipeline events. */
export interface DeliveryPipelineEventData {
  /** Optional. The DeliveryPipeline event payload. Unset for deletion events. */
  payload?: DeliveryPipeline | undefined;
}

/** The data within all Target events. */
export interface TargetEventData {
  /** Optional. The Target event payload. Unset for deletion events. */
  payload?: Target | undefined;
}

/** The data within all CustomTargetType events. */
export interface CustomTargetTypeEventData {
  /** Optional. The CustomTargetType event payload. Unset for deletion events. */
  payload?: CustomTargetType | undefined;
}

/** The data within all Release events. */
export interface ReleaseEventData {
  /** The Release event payload. */
  payload?: Release | undefined;
}

/** The data within all Rollout events. */
export interface RolloutEventData {
  /** The Rollout event payload. */
  payload?: Rollout | undefined;
}

/** The data within all Automation events. */
export interface AutomationEventData {
  /** Optional. The Automation event payload. Unset for deletion events. */
  payload?: Automation | undefined;
}

function createBaseDeliveryPipeline(): DeliveryPipeline {
  return {
    name: "",
    uid: "",
    description: "",
    annotations: {},
    labels: {},
    createTime: undefined,
    updateTime: undefined,
    serialPipeline: undefined,
    condition: undefined,
    etag: "",
    suspended: false,
  };
}

export const DeliveryPipeline: MessageFns<DeliveryPipeline> = {
  encode(message: DeliveryPipeline, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      DeliveryPipeline_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      DeliveryPipeline_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    if (message.serialPipeline !== undefined) {
      SerialPipeline.encode(message.serialPipeline, writer.uint32(66).fork()).join();
    }
    if (message.condition !== undefined) {
      PipelineCondition.encode(message.condition, writer.uint32(90).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(82).string(message.etag);
    }
    if (message.suspended !== false) {
      writer.uint32(96).bool(message.suspended);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeliveryPipeline {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeliveryPipeline();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = DeliveryPipeline_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.annotations[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = DeliveryPipeline_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.serialPipeline = SerialPipeline.decode(reader, reader.uint32());
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.condition = PipelineCondition.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.suspended = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeliveryPipeline {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      serialPipeline: isSet(object.serialPipeline) ? SerialPipeline.fromJSON(object.serialPipeline) : undefined,
      condition: isSet(object.condition) ? PipelineCondition.fromJSON(object.condition) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      suspended: isSet(object.suspended) ? globalThis.Boolean(object.suspended) : false,
    };
  },

  toJSON(message: DeliveryPipeline): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.serialPipeline !== undefined) {
      obj.serialPipeline = SerialPipeline.toJSON(message.serialPipeline);
    }
    if (message.condition !== undefined) {
      obj.condition = PipelineCondition.toJSON(message.condition);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.suspended !== false) {
      obj.suspended = message.suspended;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeliveryPipeline>, I>>(base?: I): DeliveryPipeline {
    return DeliveryPipeline.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeliveryPipeline>, I>>(object: I): DeliveryPipeline {
    const message = createBaseDeliveryPipeline();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.serialPipeline = (object.serialPipeline !== undefined && object.serialPipeline !== null)
      ? SerialPipeline.fromPartial(object.serialPipeline)
      : undefined;
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? PipelineCondition.fromPartial(object.condition)
      : undefined;
    message.etag = object.etag ?? "";
    message.suspended = object.suspended ?? false;
    return message;
  },
};

function createBaseDeliveryPipeline_AnnotationsEntry(): DeliveryPipeline_AnnotationsEntry {
  return { key: "", value: "" };
}

export const DeliveryPipeline_AnnotationsEntry: MessageFns<DeliveryPipeline_AnnotationsEntry> = {
  encode(message: DeliveryPipeline_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeliveryPipeline_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeliveryPipeline_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeliveryPipeline_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DeliveryPipeline_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeliveryPipeline_AnnotationsEntry>, I>>(
    base?: I,
  ): DeliveryPipeline_AnnotationsEntry {
    return DeliveryPipeline_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeliveryPipeline_AnnotationsEntry>, I>>(
    object: I,
  ): DeliveryPipeline_AnnotationsEntry {
    const message = createBaseDeliveryPipeline_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDeliveryPipeline_LabelsEntry(): DeliveryPipeline_LabelsEntry {
  return { key: "", value: "" };
}

export const DeliveryPipeline_LabelsEntry: MessageFns<DeliveryPipeline_LabelsEntry> = {
  encode(message: DeliveryPipeline_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeliveryPipeline_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeliveryPipeline_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeliveryPipeline_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DeliveryPipeline_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeliveryPipeline_LabelsEntry>, I>>(base?: I): DeliveryPipeline_LabelsEntry {
    return DeliveryPipeline_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeliveryPipeline_LabelsEntry>, I>>(object: I): DeliveryPipeline_LabelsEntry {
    const message = createBaseDeliveryPipeline_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSerialPipeline(): SerialPipeline {
  return { stages: [] };
}

export const SerialPipeline: MessageFns<SerialPipeline> = {
  encode(message: SerialPipeline, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.stages) {
      Stage.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SerialPipeline {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSerialPipeline();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.stages.push(Stage.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SerialPipeline {
    return { stages: globalThis.Array.isArray(object?.stages) ? object.stages.map((e: any) => Stage.fromJSON(e)) : [] };
  },

  toJSON(message: SerialPipeline): unknown {
    const obj: any = {};
    if (message.stages?.length) {
      obj.stages = message.stages.map((e) => Stage.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SerialPipeline>, I>>(base?: I): SerialPipeline {
    return SerialPipeline.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SerialPipeline>, I>>(object: I): SerialPipeline {
    const message = createBaseSerialPipeline();
    message.stages = object.stages?.map((e) => Stage.fromPartial(e)) || [];
    return message;
  },
};

function createBaseStage(): Stage {
  return { targetId: "", profiles: [], strategy: undefined, deployParameters: [] };
}

export const Stage: MessageFns<Stage> = {
  encode(message: Stage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.targetId !== "") {
      writer.uint32(10).string(message.targetId);
    }
    for (const v of message.profiles) {
      writer.uint32(18).string(v!);
    }
    if (message.strategy !== undefined) {
      Strategy.encode(message.strategy, writer.uint32(42).fork()).join();
    }
    for (const v of message.deployParameters) {
      DeployParameters.encode(v!, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Stage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.targetId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.profiles.push(reader.string());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.strategy = Strategy.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.deployParameters.push(DeployParameters.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Stage {
    return {
      targetId: isSet(object.targetId) ? globalThis.String(object.targetId) : "",
      profiles: globalThis.Array.isArray(object?.profiles) ? object.profiles.map((e: any) => globalThis.String(e)) : [],
      strategy: isSet(object.strategy) ? Strategy.fromJSON(object.strategy) : undefined,
      deployParameters: globalThis.Array.isArray(object?.deployParameters)
        ? object.deployParameters.map((e: any) => DeployParameters.fromJSON(e))
        : [],
    };
  },

  toJSON(message: Stage): unknown {
    const obj: any = {};
    if (message.targetId !== "") {
      obj.targetId = message.targetId;
    }
    if (message.profiles?.length) {
      obj.profiles = message.profiles;
    }
    if (message.strategy !== undefined) {
      obj.strategy = Strategy.toJSON(message.strategy);
    }
    if (message.deployParameters?.length) {
      obj.deployParameters = message.deployParameters.map((e) => DeployParameters.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Stage>, I>>(base?: I): Stage {
    return Stage.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Stage>, I>>(object: I): Stage {
    const message = createBaseStage();
    message.targetId = object.targetId ?? "";
    message.profiles = object.profiles?.map((e) => e) || [];
    message.strategy = (object.strategy !== undefined && object.strategy !== null)
      ? Strategy.fromPartial(object.strategy)
      : undefined;
    message.deployParameters = object.deployParameters?.map((e) => DeployParameters.fromPartial(e)) || [];
    return message;
  },
};

function createBaseDeployParameters(): DeployParameters {
  return { values: {}, matchTargetLabels: {} };
}

export const DeployParameters: MessageFns<DeployParameters> = {
  encode(message: DeployParameters, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.values).forEach(([key, value]) => {
      DeployParameters_ValuesEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    Object.entries(message.matchTargetLabels).forEach(([key, value]) => {
      DeployParameters_MatchTargetLabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployParameters {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployParameters();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = DeployParameters_ValuesEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.values[entry1.key] = entry1.value;
          }
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          const entry2 = DeployParameters_MatchTargetLabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.matchTargetLabels[entry2.key] = entry2.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployParameters {
    return {
      values: isObject(object.values)
        ? Object.entries(object.values).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      matchTargetLabels: isObject(object.matchTargetLabels)
        ? Object.entries(object.matchTargetLabels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: DeployParameters): unknown {
    const obj: any = {};
    if (message.values) {
      const entries = Object.entries(message.values);
      if (entries.length > 0) {
        obj.values = {};
        entries.forEach(([k, v]) => {
          obj.values[k] = v;
        });
      }
    }
    if (message.matchTargetLabels) {
      const entries = Object.entries(message.matchTargetLabels);
      if (entries.length > 0) {
        obj.matchTargetLabels = {};
        entries.forEach(([k, v]) => {
          obj.matchTargetLabels[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeployParameters>, I>>(base?: I): DeployParameters {
    return DeployParameters.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeployParameters>, I>>(object: I): DeployParameters {
    const message = createBaseDeployParameters();
    message.values = Object.entries(object.values ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.matchTargetLabels = Object.entries(object.matchTargetLabels ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseDeployParameters_ValuesEntry(): DeployParameters_ValuesEntry {
  return { key: "", value: "" };
}

export const DeployParameters_ValuesEntry: MessageFns<DeployParameters_ValuesEntry> = {
  encode(message: DeployParameters_ValuesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployParameters_ValuesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployParameters_ValuesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployParameters_ValuesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DeployParameters_ValuesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeployParameters_ValuesEntry>, I>>(base?: I): DeployParameters_ValuesEntry {
    return DeployParameters_ValuesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeployParameters_ValuesEntry>, I>>(object: I): DeployParameters_ValuesEntry {
    const message = createBaseDeployParameters_ValuesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDeployParameters_MatchTargetLabelsEntry(): DeployParameters_MatchTargetLabelsEntry {
  return { key: "", value: "" };
}

export const DeployParameters_MatchTargetLabelsEntry: MessageFns<DeployParameters_MatchTargetLabelsEntry> = {
  encode(message: DeployParameters_MatchTargetLabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployParameters_MatchTargetLabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployParameters_MatchTargetLabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeployParameters_MatchTargetLabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: DeployParameters_MatchTargetLabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeployParameters_MatchTargetLabelsEntry>, I>>(
    base?: I,
  ): DeployParameters_MatchTargetLabelsEntry {
    return DeployParameters_MatchTargetLabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeployParameters_MatchTargetLabelsEntry>, I>>(
    object: I,
  ): DeployParameters_MatchTargetLabelsEntry {
    const message = createBaseDeployParameters_MatchTargetLabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStrategy(): Strategy {
  return { standard: undefined, canary: undefined };
}

export const Strategy: MessageFns<Strategy> = {
  encode(message: Strategy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.standard !== undefined) {
      Standard.encode(message.standard, writer.uint32(10).fork()).join();
    }
    if (message.canary !== undefined) {
      Canary.encode(message.canary, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Strategy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStrategy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.standard = Standard.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.canary = Canary.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Strategy {
    return {
      standard: isSet(object.standard) ? Standard.fromJSON(object.standard) : undefined,
      canary: isSet(object.canary) ? Canary.fromJSON(object.canary) : undefined,
    };
  },

  toJSON(message: Strategy): unknown {
    const obj: any = {};
    if (message.standard !== undefined) {
      obj.standard = Standard.toJSON(message.standard);
    }
    if (message.canary !== undefined) {
      obj.canary = Canary.toJSON(message.canary);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Strategy>, I>>(base?: I): Strategy {
    return Strategy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Strategy>, I>>(object: I): Strategy {
    const message = createBaseStrategy();
    message.standard = (object.standard !== undefined && object.standard !== null)
      ? Standard.fromPartial(object.standard)
      : undefined;
    message.canary = (object.canary !== undefined && object.canary !== null)
      ? Canary.fromPartial(object.canary)
      : undefined;
    return message;
  },
};

function createBasePredeploy(): Predeploy {
  return { actions: [] };
}

export const Predeploy: MessageFns<Predeploy> = {
  encode(message: Predeploy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.actions) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Predeploy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePredeploy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.actions.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Predeploy {
    return {
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: Predeploy): unknown {
    const obj: any = {};
    if (message.actions?.length) {
      obj.actions = message.actions;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Predeploy>, I>>(base?: I): Predeploy {
    return Predeploy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Predeploy>, I>>(object: I): Predeploy {
    const message = createBasePredeploy();
    message.actions = object.actions?.map((e) => e) || [];
    return message;
  },
};

function createBasePostdeploy(): Postdeploy {
  return { actions: [] };
}

export const Postdeploy: MessageFns<Postdeploy> = {
  encode(message: Postdeploy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.actions) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Postdeploy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostdeploy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.actions.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Postdeploy {
    return {
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: Postdeploy): unknown {
    const obj: any = {};
    if (message.actions?.length) {
      obj.actions = message.actions;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Postdeploy>, I>>(base?: I): Postdeploy {
    return Postdeploy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Postdeploy>, I>>(object: I): Postdeploy {
    const message = createBasePostdeploy();
    message.actions = object.actions?.map((e) => e) || [];
    return message;
  },
};

function createBaseStandard(): Standard {
  return { verify: false, predeploy: undefined, postdeploy: undefined };
}

export const Standard: MessageFns<Standard> = {
  encode(message: Standard, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.verify !== false) {
      writer.uint32(8).bool(message.verify);
    }
    if (message.predeploy !== undefined) {
      Predeploy.encode(message.predeploy, writer.uint32(18).fork()).join();
    }
    if (message.postdeploy !== undefined) {
      Postdeploy.encode(message.postdeploy, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Standard {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStandard();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.verify = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.predeploy = Predeploy.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.postdeploy = Postdeploy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Standard {
    return {
      verify: isSet(object.verify) ? globalThis.Boolean(object.verify) : false,
      predeploy: isSet(object.predeploy) ? Predeploy.fromJSON(object.predeploy) : undefined,
      postdeploy: isSet(object.postdeploy) ? Postdeploy.fromJSON(object.postdeploy) : undefined,
    };
  },

  toJSON(message: Standard): unknown {
    const obj: any = {};
    if (message.verify !== false) {
      obj.verify = message.verify;
    }
    if (message.predeploy !== undefined) {
      obj.predeploy = Predeploy.toJSON(message.predeploy);
    }
    if (message.postdeploy !== undefined) {
      obj.postdeploy = Postdeploy.toJSON(message.postdeploy);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Standard>, I>>(base?: I): Standard {
    return Standard.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Standard>, I>>(object: I): Standard {
    const message = createBaseStandard();
    message.verify = object.verify ?? false;
    message.predeploy = (object.predeploy !== undefined && object.predeploy !== null)
      ? Predeploy.fromPartial(object.predeploy)
      : undefined;
    message.postdeploy = (object.postdeploy !== undefined && object.postdeploy !== null)
      ? Postdeploy.fromPartial(object.postdeploy)
      : undefined;
    return message;
  },
};

function createBaseCanary(): Canary {
  return { runtimeConfig: undefined, canaryDeployment: undefined, customCanaryDeployment: undefined };
}

export const Canary: MessageFns<Canary> = {
  encode(message: Canary, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.runtimeConfig !== undefined) {
      RuntimeConfig.encode(message.runtimeConfig, writer.uint32(10).fork()).join();
    }
    if (message.canaryDeployment !== undefined) {
      CanaryDeployment.encode(message.canaryDeployment, writer.uint32(18).fork()).join();
    }
    if (message.customCanaryDeployment !== undefined) {
      CustomCanaryDeployment.encode(message.customCanaryDeployment, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Canary {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCanary();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.runtimeConfig = RuntimeConfig.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.canaryDeployment = CanaryDeployment.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.customCanaryDeployment = CustomCanaryDeployment.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Canary {
    return {
      runtimeConfig: isSet(object.runtimeConfig) ? RuntimeConfig.fromJSON(object.runtimeConfig) : undefined,
      canaryDeployment: isSet(object.canaryDeployment) ? CanaryDeployment.fromJSON(object.canaryDeployment) : undefined,
      customCanaryDeployment: isSet(object.customCanaryDeployment)
        ? CustomCanaryDeployment.fromJSON(object.customCanaryDeployment)
        : undefined,
    };
  },

  toJSON(message: Canary): unknown {
    const obj: any = {};
    if (message.runtimeConfig !== undefined) {
      obj.runtimeConfig = RuntimeConfig.toJSON(message.runtimeConfig);
    }
    if (message.canaryDeployment !== undefined) {
      obj.canaryDeployment = CanaryDeployment.toJSON(message.canaryDeployment);
    }
    if (message.customCanaryDeployment !== undefined) {
      obj.customCanaryDeployment = CustomCanaryDeployment.toJSON(message.customCanaryDeployment);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Canary>, I>>(base?: I): Canary {
    return Canary.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Canary>, I>>(object: I): Canary {
    const message = createBaseCanary();
    message.runtimeConfig = (object.runtimeConfig !== undefined && object.runtimeConfig !== null)
      ? RuntimeConfig.fromPartial(object.runtimeConfig)
      : undefined;
    message.canaryDeployment = (object.canaryDeployment !== undefined && object.canaryDeployment !== null)
      ? CanaryDeployment.fromPartial(object.canaryDeployment)
      : undefined;
    message.customCanaryDeployment =
      (object.customCanaryDeployment !== undefined && object.customCanaryDeployment !== null)
        ? CustomCanaryDeployment.fromPartial(object.customCanaryDeployment)
        : undefined;
    return message;
  },
};

function createBaseCanaryDeployment(): CanaryDeployment {
  return { percentages: [], verify: false, predeploy: undefined, postdeploy: undefined };
}

export const CanaryDeployment: MessageFns<CanaryDeployment> = {
  encode(message: CanaryDeployment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.percentages) {
      writer.int32(v);
    }
    writer.join();
    if (message.verify !== false) {
      writer.uint32(16).bool(message.verify);
    }
    if (message.predeploy !== undefined) {
      Predeploy.encode(message.predeploy, writer.uint32(26).fork()).join();
    }
    if (message.postdeploy !== undefined) {
      Postdeploy.encode(message.postdeploy, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CanaryDeployment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCanaryDeployment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag === 8) {
            message.percentages.push(reader.int32());

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.percentages.push(reader.int32());
            }

            continue;
          }

          break;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.verify = reader.bool();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.predeploy = Predeploy.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.postdeploy = Postdeploy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CanaryDeployment {
    return {
      percentages: globalThis.Array.isArray(object?.percentages)
        ? object.percentages.map((e: any) => globalThis.Number(e))
        : [],
      verify: isSet(object.verify) ? globalThis.Boolean(object.verify) : false,
      predeploy: isSet(object.predeploy) ? Predeploy.fromJSON(object.predeploy) : undefined,
      postdeploy: isSet(object.postdeploy) ? Postdeploy.fromJSON(object.postdeploy) : undefined,
    };
  },

  toJSON(message: CanaryDeployment): unknown {
    const obj: any = {};
    if (message.percentages?.length) {
      obj.percentages = message.percentages.map((e) => Math.round(e));
    }
    if (message.verify !== false) {
      obj.verify = message.verify;
    }
    if (message.predeploy !== undefined) {
      obj.predeploy = Predeploy.toJSON(message.predeploy);
    }
    if (message.postdeploy !== undefined) {
      obj.postdeploy = Postdeploy.toJSON(message.postdeploy);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CanaryDeployment>, I>>(base?: I): CanaryDeployment {
    return CanaryDeployment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CanaryDeployment>, I>>(object: I): CanaryDeployment {
    const message = createBaseCanaryDeployment();
    message.percentages = object.percentages?.map((e) => e) || [];
    message.verify = object.verify ?? false;
    message.predeploy = (object.predeploy !== undefined && object.predeploy !== null)
      ? Predeploy.fromPartial(object.predeploy)
      : undefined;
    message.postdeploy = (object.postdeploy !== undefined && object.postdeploy !== null)
      ? Postdeploy.fromPartial(object.postdeploy)
      : undefined;
    return message;
  },
};

function createBaseCustomCanaryDeployment(): CustomCanaryDeployment {
  return { phaseConfigs: [] };
}

export const CustomCanaryDeployment: MessageFns<CustomCanaryDeployment> = {
  encode(message: CustomCanaryDeployment, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.phaseConfigs) {
      CustomCanaryDeployment_PhaseConfig.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomCanaryDeployment {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomCanaryDeployment();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.phaseConfigs.push(CustomCanaryDeployment_PhaseConfig.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomCanaryDeployment {
    return {
      phaseConfigs: globalThis.Array.isArray(object?.phaseConfigs)
        ? object.phaseConfigs.map((e: any) => CustomCanaryDeployment_PhaseConfig.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CustomCanaryDeployment): unknown {
    const obj: any = {};
    if (message.phaseConfigs?.length) {
      obj.phaseConfigs = message.phaseConfigs.map((e) => CustomCanaryDeployment_PhaseConfig.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomCanaryDeployment>, I>>(base?: I): CustomCanaryDeployment {
    return CustomCanaryDeployment.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomCanaryDeployment>, I>>(object: I): CustomCanaryDeployment {
    const message = createBaseCustomCanaryDeployment();
    message.phaseConfigs = object.phaseConfigs?.map((e) => CustomCanaryDeployment_PhaseConfig.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCustomCanaryDeployment_PhaseConfig(): CustomCanaryDeployment_PhaseConfig {
  return { phaseId: "", percentage: 0, profiles: [], verify: false, predeploy: undefined, postdeploy: undefined };
}

export const CustomCanaryDeployment_PhaseConfig: MessageFns<CustomCanaryDeployment_PhaseConfig> = {
  encode(message: CustomCanaryDeployment_PhaseConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.phaseId !== "") {
      writer.uint32(10).string(message.phaseId);
    }
    if (message.percentage !== 0) {
      writer.uint32(16).int32(message.percentage);
    }
    for (const v of message.profiles) {
      writer.uint32(26).string(v!);
    }
    if (message.verify !== false) {
      writer.uint32(32).bool(message.verify);
    }
    if (message.predeploy !== undefined) {
      Predeploy.encode(message.predeploy, writer.uint32(42).fork()).join();
    }
    if (message.postdeploy !== undefined) {
      Postdeploy.encode(message.postdeploy, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomCanaryDeployment_PhaseConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomCanaryDeployment_PhaseConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.phaseId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.percentage = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.profiles.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.verify = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.predeploy = Predeploy.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.postdeploy = Postdeploy.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomCanaryDeployment_PhaseConfig {
    return {
      phaseId: isSet(object.phaseId) ? globalThis.String(object.phaseId) : "",
      percentage: isSet(object.percentage) ? globalThis.Number(object.percentage) : 0,
      profiles: globalThis.Array.isArray(object?.profiles) ? object.profiles.map((e: any) => globalThis.String(e)) : [],
      verify: isSet(object.verify) ? globalThis.Boolean(object.verify) : false,
      predeploy: isSet(object.predeploy) ? Predeploy.fromJSON(object.predeploy) : undefined,
      postdeploy: isSet(object.postdeploy) ? Postdeploy.fromJSON(object.postdeploy) : undefined,
    };
  },

  toJSON(message: CustomCanaryDeployment_PhaseConfig): unknown {
    const obj: any = {};
    if (message.phaseId !== "") {
      obj.phaseId = message.phaseId;
    }
    if (message.percentage !== 0) {
      obj.percentage = Math.round(message.percentage);
    }
    if (message.profiles?.length) {
      obj.profiles = message.profiles;
    }
    if (message.verify !== false) {
      obj.verify = message.verify;
    }
    if (message.predeploy !== undefined) {
      obj.predeploy = Predeploy.toJSON(message.predeploy);
    }
    if (message.postdeploy !== undefined) {
      obj.postdeploy = Postdeploy.toJSON(message.postdeploy);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomCanaryDeployment_PhaseConfig>, I>>(
    base?: I,
  ): CustomCanaryDeployment_PhaseConfig {
    return CustomCanaryDeployment_PhaseConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomCanaryDeployment_PhaseConfig>, I>>(
    object: I,
  ): CustomCanaryDeployment_PhaseConfig {
    const message = createBaseCustomCanaryDeployment_PhaseConfig();
    message.phaseId = object.phaseId ?? "";
    message.percentage = object.percentage ?? 0;
    message.profiles = object.profiles?.map((e) => e) || [];
    message.verify = object.verify ?? false;
    message.predeploy = (object.predeploy !== undefined && object.predeploy !== null)
      ? Predeploy.fromPartial(object.predeploy)
      : undefined;
    message.postdeploy = (object.postdeploy !== undefined && object.postdeploy !== null)
      ? Postdeploy.fromPartial(object.postdeploy)
      : undefined;
    return message;
  },
};

function createBaseKubernetesConfig(): KubernetesConfig {
  return { gatewayServiceMesh: undefined, serviceNetworking: undefined };
}

export const KubernetesConfig: MessageFns<KubernetesConfig> = {
  encode(message: KubernetesConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gatewayServiceMesh !== undefined) {
      KubernetesConfig_GatewayServiceMesh.encode(message.gatewayServiceMesh, writer.uint32(10).fork()).join();
    }
    if (message.serviceNetworking !== undefined) {
      KubernetesConfig_ServiceNetworking.encode(message.serviceNetworking, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KubernetesConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKubernetesConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gatewayServiceMesh = KubernetesConfig_GatewayServiceMesh.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.serviceNetworking = KubernetesConfig_ServiceNetworking.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KubernetesConfig {
    return {
      gatewayServiceMesh: isSet(object.gatewayServiceMesh)
        ? KubernetesConfig_GatewayServiceMesh.fromJSON(object.gatewayServiceMesh)
        : undefined,
      serviceNetworking: isSet(object.serviceNetworking)
        ? KubernetesConfig_ServiceNetworking.fromJSON(object.serviceNetworking)
        : undefined,
    };
  },

  toJSON(message: KubernetesConfig): unknown {
    const obj: any = {};
    if (message.gatewayServiceMesh !== undefined) {
      obj.gatewayServiceMesh = KubernetesConfig_GatewayServiceMesh.toJSON(message.gatewayServiceMesh);
    }
    if (message.serviceNetworking !== undefined) {
      obj.serviceNetworking = KubernetesConfig_ServiceNetworking.toJSON(message.serviceNetworking);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<KubernetesConfig>, I>>(base?: I): KubernetesConfig {
    return KubernetesConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<KubernetesConfig>, I>>(object: I): KubernetesConfig {
    const message = createBaseKubernetesConfig();
    message.gatewayServiceMesh = (object.gatewayServiceMesh !== undefined && object.gatewayServiceMesh !== null)
      ? KubernetesConfig_GatewayServiceMesh.fromPartial(object.gatewayServiceMesh)
      : undefined;
    message.serviceNetworking = (object.serviceNetworking !== undefined && object.serviceNetworking !== null)
      ? KubernetesConfig_ServiceNetworking.fromPartial(object.serviceNetworking)
      : undefined;
    return message;
  },
};

function createBaseKubernetesConfig_GatewayServiceMesh(): KubernetesConfig_GatewayServiceMesh {
  return {
    httpRoute: "",
    service: "",
    deployment: "",
    routeUpdateWaitTime: undefined,
    stableCutbackDuration: undefined,
  };
}

export const KubernetesConfig_GatewayServiceMesh: MessageFns<KubernetesConfig_GatewayServiceMesh> = {
  encode(message: KubernetesConfig_GatewayServiceMesh, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.httpRoute !== "") {
      writer.uint32(10).string(message.httpRoute);
    }
    if (message.service !== "") {
      writer.uint32(18).string(message.service);
    }
    if (message.deployment !== "") {
      writer.uint32(26).string(message.deployment);
    }
    if (message.routeUpdateWaitTime !== undefined) {
      Duration.encode(message.routeUpdateWaitTime, writer.uint32(34).fork()).join();
    }
    if (message.stableCutbackDuration !== undefined) {
      Duration.encode(message.stableCutbackDuration, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KubernetesConfig_GatewayServiceMesh {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKubernetesConfig_GatewayServiceMesh();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.httpRoute = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.service = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.deployment = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.routeUpdateWaitTime = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.stableCutbackDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KubernetesConfig_GatewayServiceMesh {
    return {
      httpRoute: isSet(object.httpRoute) ? globalThis.String(object.httpRoute) : "",
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      deployment: isSet(object.deployment) ? globalThis.String(object.deployment) : "",
      routeUpdateWaitTime: isSet(object.routeUpdateWaitTime)
        ? Duration.fromJSON(object.routeUpdateWaitTime)
        : undefined,
      stableCutbackDuration: isSet(object.stableCutbackDuration)
        ? Duration.fromJSON(object.stableCutbackDuration)
        : undefined,
    };
  },

  toJSON(message: KubernetesConfig_GatewayServiceMesh): unknown {
    const obj: any = {};
    if (message.httpRoute !== "") {
      obj.httpRoute = message.httpRoute;
    }
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.deployment !== "") {
      obj.deployment = message.deployment;
    }
    if (message.routeUpdateWaitTime !== undefined) {
      obj.routeUpdateWaitTime = Duration.toJSON(message.routeUpdateWaitTime);
    }
    if (message.stableCutbackDuration !== undefined) {
      obj.stableCutbackDuration = Duration.toJSON(message.stableCutbackDuration);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<KubernetesConfig_GatewayServiceMesh>, I>>(
    base?: I,
  ): KubernetesConfig_GatewayServiceMesh {
    return KubernetesConfig_GatewayServiceMesh.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<KubernetesConfig_GatewayServiceMesh>, I>>(
    object: I,
  ): KubernetesConfig_GatewayServiceMesh {
    const message = createBaseKubernetesConfig_GatewayServiceMesh();
    message.httpRoute = object.httpRoute ?? "";
    message.service = object.service ?? "";
    message.deployment = object.deployment ?? "";
    message.routeUpdateWaitTime = (object.routeUpdateWaitTime !== undefined && object.routeUpdateWaitTime !== null)
      ? Duration.fromPartial(object.routeUpdateWaitTime)
      : undefined;
    message.stableCutbackDuration =
      (object.stableCutbackDuration !== undefined && object.stableCutbackDuration !== null)
        ? Duration.fromPartial(object.stableCutbackDuration)
        : undefined;
    return message;
  },
};

function createBaseKubernetesConfig_ServiceNetworking(): KubernetesConfig_ServiceNetworking {
  return { service: "", deployment: "", disablePodOverprovisioning: false };
}

export const KubernetesConfig_ServiceNetworking: MessageFns<KubernetesConfig_ServiceNetworking> = {
  encode(message: KubernetesConfig_ServiceNetworking, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.deployment !== "") {
      writer.uint32(18).string(message.deployment);
    }
    if (message.disablePodOverprovisioning !== false) {
      writer.uint32(24).bool(message.disablePodOverprovisioning);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KubernetesConfig_ServiceNetworking {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKubernetesConfig_ServiceNetworking();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.deployment = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.disablePodOverprovisioning = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KubernetesConfig_ServiceNetworking {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      deployment: isSet(object.deployment) ? globalThis.String(object.deployment) : "",
      disablePodOverprovisioning: isSet(object.disablePodOverprovisioning)
        ? globalThis.Boolean(object.disablePodOverprovisioning)
        : false,
    };
  },

  toJSON(message: KubernetesConfig_ServiceNetworking): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.deployment !== "") {
      obj.deployment = message.deployment;
    }
    if (message.disablePodOverprovisioning !== false) {
      obj.disablePodOverprovisioning = message.disablePodOverprovisioning;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<KubernetesConfig_ServiceNetworking>, I>>(
    base?: I,
  ): KubernetesConfig_ServiceNetworking {
    return KubernetesConfig_ServiceNetworking.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<KubernetesConfig_ServiceNetworking>, I>>(
    object: I,
  ): KubernetesConfig_ServiceNetworking {
    const message = createBaseKubernetesConfig_ServiceNetworking();
    message.service = object.service ?? "";
    message.deployment = object.deployment ?? "";
    message.disablePodOverprovisioning = object.disablePodOverprovisioning ?? false;
    return message;
  },
};

function createBaseCloudRunConfig(): CloudRunConfig {
  return { automaticTrafficControl: false, canaryRevisionTags: [], priorRevisionTags: [], stableRevisionTags: [] };
}

export const CloudRunConfig: MessageFns<CloudRunConfig> = {
  encode(message: CloudRunConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.automaticTrafficControl !== false) {
      writer.uint32(8).bool(message.automaticTrafficControl);
    }
    for (const v of message.canaryRevisionTags) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.priorRevisionTags) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.stableRevisionTags) {
      writer.uint32(34).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudRunConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudRunConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.automaticTrafficControl = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.canaryRevisionTags.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.priorRevisionTags.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.stableRevisionTags.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudRunConfig {
    return {
      automaticTrafficControl: isSet(object.automaticTrafficControl)
        ? globalThis.Boolean(object.automaticTrafficControl)
        : false,
      canaryRevisionTags: globalThis.Array.isArray(object?.canaryRevisionTags)
        ? object.canaryRevisionTags.map((e: any) => globalThis.String(e))
        : [],
      priorRevisionTags: globalThis.Array.isArray(object?.priorRevisionTags)
        ? object.priorRevisionTags.map((e: any) => globalThis.String(e))
        : [],
      stableRevisionTags: globalThis.Array.isArray(object?.stableRevisionTags)
        ? object.stableRevisionTags.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: CloudRunConfig): unknown {
    const obj: any = {};
    if (message.automaticTrafficControl !== false) {
      obj.automaticTrafficControl = message.automaticTrafficControl;
    }
    if (message.canaryRevisionTags?.length) {
      obj.canaryRevisionTags = message.canaryRevisionTags;
    }
    if (message.priorRevisionTags?.length) {
      obj.priorRevisionTags = message.priorRevisionTags;
    }
    if (message.stableRevisionTags?.length) {
      obj.stableRevisionTags = message.stableRevisionTags;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloudRunConfig>, I>>(base?: I): CloudRunConfig {
    return CloudRunConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloudRunConfig>, I>>(object: I): CloudRunConfig {
    const message = createBaseCloudRunConfig();
    message.automaticTrafficControl = object.automaticTrafficControl ?? false;
    message.canaryRevisionTags = object.canaryRevisionTags?.map((e) => e) || [];
    message.priorRevisionTags = object.priorRevisionTags?.map((e) => e) || [];
    message.stableRevisionTags = object.stableRevisionTags?.map((e) => e) || [];
    return message;
  },
};

function createBaseRuntimeConfig(): RuntimeConfig {
  return { kubernetes: undefined, cloudRun: undefined };
}

export const RuntimeConfig: MessageFns<RuntimeConfig> = {
  encode(message: RuntimeConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kubernetes !== undefined) {
      KubernetesConfig.encode(message.kubernetes, writer.uint32(10).fork()).join();
    }
    if (message.cloudRun !== undefined) {
      CloudRunConfig.encode(message.cloudRun, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RuntimeConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRuntimeConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.kubernetes = KubernetesConfig.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cloudRun = CloudRunConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RuntimeConfig {
    return {
      kubernetes: isSet(object.kubernetes) ? KubernetesConfig.fromJSON(object.kubernetes) : undefined,
      cloudRun: isSet(object.cloudRun) ? CloudRunConfig.fromJSON(object.cloudRun) : undefined,
    };
  },

  toJSON(message: RuntimeConfig): unknown {
    const obj: any = {};
    if (message.kubernetes !== undefined) {
      obj.kubernetes = KubernetesConfig.toJSON(message.kubernetes);
    }
    if (message.cloudRun !== undefined) {
      obj.cloudRun = CloudRunConfig.toJSON(message.cloudRun);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RuntimeConfig>, I>>(base?: I): RuntimeConfig {
    return RuntimeConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RuntimeConfig>, I>>(object: I): RuntimeConfig {
    const message = createBaseRuntimeConfig();
    message.kubernetes = (object.kubernetes !== undefined && object.kubernetes !== null)
      ? KubernetesConfig.fromPartial(object.kubernetes)
      : undefined;
    message.cloudRun = (object.cloudRun !== undefined && object.cloudRun !== null)
      ? CloudRunConfig.fromPartial(object.cloudRun)
      : undefined;
    return message;
  },
};

function createBasePipelineReadyCondition(): PipelineReadyCondition {
  return { status: false, updateTime: undefined };
}

export const PipelineReadyCondition: MessageFns<PipelineReadyCondition> = {
  encode(message: PipelineReadyCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== false) {
      writer.uint32(24).bool(message.status);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipelineReadyCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineReadyCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.status = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipelineReadyCondition {
    return {
      status: isSet(object.status) ? globalThis.Boolean(object.status) : false,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: PipelineReadyCondition): unknown {
    const obj: any = {};
    if (message.status !== false) {
      obj.status = message.status;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PipelineReadyCondition>, I>>(base?: I): PipelineReadyCondition {
    return PipelineReadyCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PipelineReadyCondition>, I>>(object: I): PipelineReadyCondition {
    const message = createBasePipelineReadyCondition();
    message.status = object.status ?? false;
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseTargetsPresentCondition(): TargetsPresentCondition {
  return { status: false, missingTargets: [], updateTime: undefined };
}

export const TargetsPresentCondition: MessageFns<TargetsPresentCondition> = {
  encode(message: TargetsPresentCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== false) {
      writer.uint32(8).bool(message.status);
    }
    for (const v of message.missingTargets) {
      writer.uint32(18).string(v!);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetsPresentCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetsPresentCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.missingTargets.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetsPresentCondition {
    return {
      status: isSet(object.status) ? globalThis.Boolean(object.status) : false,
      missingTargets: globalThis.Array.isArray(object?.missingTargets)
        ? object.missingTargets.map((e: any) => globalThis.String(e))
        : [],
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: TargetsPresentCondition): unknown {
    const obj: any = {};
    if (message.status !== false) {
      obj.status = message.status;
    }
    if (message.missingTargets?.length) {
      obj.missingTargets = message.missingTargets;
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetsPresentCondition>, I>>(base?: I): TargetsPresentCondition {
    return TargetsPresentCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetsPresentCondition>, I>>(object: I): TargetsPresentCondition {
    const message = createBaseTargetsPresentCondition();
    message.status = object.status ?? false;
    message.missingTargets = object.missingTargets?.map((e) => e) || [];
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseTargetsTypeCondition(): TargetsTypeCondition {
  return { status: false, errorDetails: "" };
}

export const TargetsTypeCondition: MessageFns<TargetsTypeCondition> = {
  encode(message: TargetsTypeCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== false) {
      writer.uint32(8).bool(message.status);
    }
    if (message.errorDetails !== "") {
      writer.uint32(18).string(message.errorDetails);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetsTypeCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetsTypeCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.errorDetails = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetsTypeCondition {
    return {
      status: isSet(object.status) ? globalThis.Boolean(object.status) : false,
      errorDetails: isSet(object.errorDetails) ? globalThis.String(object.errorDetails) : "",
    };
  },

  toJSON(message: TargetsTypeCondition): unknown {
    const obj: any = {};
    if (message.status !== false) {
      obj.status = message.status;
    }
    if (message.errorDetails !== "") {
      obj.errorDetails = message.errorDetails;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetsTypeCondition>, I>>(base?: I): TargetsTypeCondition {
    return TargetsTypeCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetsTypeCondition>, I>>(object: I): TargetsTypeCondition {
    const message = createBaseTargetsTypeCondition();
    message.status = object.status ?? false;
    message.errorDetails = object.errorDetails ?? "";
    return message;
  },
};

function createBasePipelineCondition(): PipelineCondition {
  return { pipelineReadyCondition: undefined, targetsPresentCondition: undefined, targetsTypeCondition: undefined };
}

export const PipelineCondition: MessageFns<PipelineCondition> = {
  encode(message: PipelineCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.pipelineReadyCondition !== undefined) {
      PipelineReadyCondition.encode(message.pipelineReadyCondition, writer.uint32(10).fork()).join();
    }
    if (message.targetsPresentCondition !== undefined) {
      TargetsPresentCondition.encode(message.targetsPresentCondition, writer.uint32(26).fork()).join();
    }
    if (message.targetsTypeCondition !== undefined) {
      TargetsTypeCondition.encode(message.targetsTypeCondition, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PipelineCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePipelineCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.pipelineReadyCondition = PipelineReadyCondition.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.targetsPresentCondition = TargetsPresentCondition.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.targetsTypeCondition = TargetsTypeCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PipelineCondition {
    return {
      pipelineReadyCondition: isSet(object.pipelineReadyCondition)
        ? PipelineReadyCondition.fromJSON(object.pipelineReadyCondition)
        : undefined,
      targetsPresentCondition: isSet(object.targetsPresentCondition)
        ? TargetsPresentCondition.fromJSON(object.targetsPresentCondition)
        : undefined,
      targetsTypeCondition: isSet(object.targetsTypeCondition)
        ? TargetsTypeCondition.fromJSON(object.targetsTypeCondition)
        : undefined,
    };
  },

  toJSON(message: PipelineCondition): unknown {
    const obj: any = {};
    if (message.pipelineReadyCondition !== undefined) {
      obj.pipelineReadyCondition = PipelineReadyCondition.toJSON(message.pipelineReadyCondition);
    }
    if (message.targetsPresentCondition !== undefined) {
      obj.targetsPresentCondition = TargetsPresentCondition.toJSON(message.targetsPresentCondition);
    }
    if (message.targetsTypeCondition !== undefined) {
      obj.targetsTypeCondition = TargetsTypeCondition.toJSON(message.targetsTypeCondition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PipelineCondition>, I>>(base?: I): PipelineCondition {
    return PipelineCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PipelineCondition>, I>>(object: I): PipelineCondition {
    const message = createBasePipelineCondition();
    message.pipelineReadyCondition =
      (object.pipelineReadyCondition !== undefined && object.pipelineReadyCondition !== null)
        ? PipelineReadyCondition.fromPartial(object.pipelineReadyCondition)
        : undefined;
    message.targetsPresentCondition =
      (object.targetsPresentCondition !== undefined && object.targetsPresentCondition !== null)
        ? TargetsPresentCondition.fromPartial(object.targetsPresentCondition)
        : undefined;
    message.targetsTypeCondition = (object.targetsTypeCondition !== undefined && object.targetsTypeCondition !== null)
      ? TargetsTypeCondition.fromPartial(object.targetsTypeCondition)
      : undefined;
    return message;
  },
};

function createBaseTarget(): Target {
  return {
    name: "",
    targetId: "",
    uid: "",
    description: "",
    annotations: {},
    labels: {},
    requireApproval: false,
    createTime: undefined,
    updateTime: undefined,
    gke: undefined,
    anthosCluster: undefined,
    run: undefined,
    multiTarget: undefined,
    customTarget: undefined,
    etag: "",
    executionConfigs: [],
    deployParameters: {},
  };
}

export const Target: MessageFns<Target> = {
  encode(message: Target, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.targetId !== "") {
      writer.uint32(18).string(message.targetId);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(34).string(message.description);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      Target_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      Target_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.requireApproval !== false) {
      writer.uint32(104).bool(message.requireApproval);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(66).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(74).fork()).join();
    }
    if (message.gke !== undefined) {
      GkeCluster.encode(message.gke, writer.uint32(122).fork()).join();
    }
    if (message.anthosCluster !== undefined) {
      AnthosCluster.encode(message.anthosCluster, writer.uint32(138).fork()).join();
    }
    if (message.run !== undefined) {
      CloudRunLocation.encode(message.run, writer.uint32(146).fork()).join();
    }
    if (message.multiTarget !== undefined) {
      MultiTarget.encode(message.multiTarget, writer.uint32(154).fork()).join();
    }
    if (message.customTarget !== undefined) {
      CustomTarget.encode(message.customTarget, writer.uint32(170).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(98).string(message.etag);
    }
    for (const v of message.executionConfigs) {
      ExecutionConfig.encode(v!, writer.uint32(130).fork()).join();
    }
    Object.entries(message.deployParameters).forEach(([key, value]) => {
      Target_DeployParametersEntry.encode({ key: key as any, value }, writer.uint32(162).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.targetId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Target_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.annotations[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Target_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.requireApproval = reader.bool();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.gke = GkeCluster.decode(reader, reader.uint32());
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.anthosCluster = AnthosCluster.decode(reader, reader.uint32());
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.run = CloudRunLocation.decode(reader, reader.uint32());
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.multiTarget = MultiTarget.decode(reader, reader.uint32());
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.customTarget = CustomTarget.decode(reader, reader.uint32());
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.executionConfigs.push(ExecutionConfig.decode(reader, reader.uint32()));
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          const entry20 = Target_DeployParametersEntry.decode(reader, reader.uint32());
          if (entry20.value !== undefined) {
            message.deployParameters[entry20.key] = entry20.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      targetId: isSet(object.targetId) ? globalThis.String(object.targetId) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      requireApproval: isSet(object.requireApproval) ? globalThis.Boolean(object.requireApproval) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      gke: isSet(object.gke) ? GkeCluster.fromJSON(object.gke) : undefined,
      anthosCluster: isSet(object.anthosCluster) ? AnthosCluster.fromJSON(object.anthosCluster) : undefined,
      run: isSet(object.run) ? CloudRunLocation.fromJSON(object.run) : undefined,
      multiTarget: isSet(object.multiTarget) ? MultiTarget.fromJSON(object.multiTarget) : undefined,
      customTarget: isSet(object.customTarget) ? CustomTarget.fromJSON(object.customTarget) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      executionConfigs: globalThis.Array.isArray(object?.executionConfigs)
        ? object.executionConfigs.map((e: any) => ExecutionConfig.fromJSON(e))
        : [],
      deployParameters: isObject(object.deployParameters)
        ? Object.entries(object.deployParameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Target): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.targetId !== "") {
      obj.targetId = message.targetId;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.requireApproval !== false) {
      obj.requireApproval = message.requireApproval;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.gke !== undefined) {
      obj.gke = GkeCluster.toJSON(message.gke);
    }
    if (message.anthosCluster !== undefined) {
      obj.anthosCluster = AnthosCluster.toJSON(message.anthosCluster);
    }
    if (message.run !== undefined) {
      obj.run = CloudRunLocation.toJSON(message.run);
    }
    if (message.multiTarget !== undefined) {
      obj.multiTarget = MultiTarget.toJSON(message.multiTarget);
    }
    if (message.customTarget !== undefined) {
      obj.customTarget = CustomTarget.toJSON(message.customTarget);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.executionConfigs?.length) {
      obj.executionConfigs = message.executionConfigs.map((e) => ExecutionConfig.toJSON(e));
    }
    if (message.deployParameters) {
      const entries = Object.entries(message.deployParameters);
      if (entries.length > 0) {
        obj.deployParameters = {};
        entries.forEach(([k, v]) => {
          obj.deployParameters[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Target>, I>>(base?: I): Target {
    return Target.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Target>, I>>(object: I): Target {
    const message = createBaseTarget();
    message.name = object.name ?? "";
    message.targetId = object.targetId ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.requireApproval = object.requireApproval ?? false;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.gke = (object.gke !== undefined && object.gke !== null) ? GkeCluster.fromPartial(object.gke) : undefined;
    message.anthosCluster = (object.anthosCluster !== undefined && object.anthosCluster !== null)
      ? AnthosCluster.fromPartial(object.anthosCluster)
      : undefined;
    message.run = (object.run !== undefined && object.run !== null)
      ? CloudRunLocation.fromPartial(object.run)
      : undefined;
    message.multiTarget = (object.multiTarget !== undefined && object.multiTarget !== null)
      ? MultiTarget.fromPartial(object.multiTarget)
      : undefined;
    message.customTarget = (object.customTarget !== undefined && object.customTarget !== null)
      ? CustomTarget.fromPartial(object.customTarget)
      : undefined;
    message.etag = object.etag ?? "";
    message.executionConfigs = object.executionConfigs?.map((e) => ExecutionConfig.fromPartial(e)) || [];
    message.deployParameters = Object.entries(object.deployParameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseTarget_AnnotationsEntry(): Target_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Target_AnnotationsEntry: MessageFns<Target_AnnotationsEntry> = {
  encode(message: Target_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Target_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Target_AnnotationsEntry>, I>>(base?: I): Target_AnnotationsEntry {
    return Target_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Target_AnnotationsEntry>, I>>(object: I): Target_AnnotationsEntry {
    const message = createBaseTarget_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTarget_LabelsEntry(): Target_LabelsEntry {
  return { key: "", value: "" };
}

export const Target_LabelsEntry: MessageFns<Target_LabelsEntry> = {
  encode(message: Target_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Target_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Target_LabelsEntry>, I>>(base?: I): Target_LabelsEntry {
    return Target_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Target_LabelsEntry>, I>>(object: I): Target_LabelsEntry {
    const message = createBaseTarget_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseTarget_DeployParametersEntry(): Target_DeployParametersEntry {
  return { key: "", value: "" };
}

export const Target_DeployParametersEntry: MessageFns<Target_DeployParametersEntry> = {
  encode(message: Target_DeployParametersEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Target_DeployParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTarget_DeployParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Target_DeployParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Target_DeployParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Target_DeployParametersEntry>, I>>(base?: I): Target_DeployParametersEntry {
    return Target_DeployParametersEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Target_DeployParametersEntry>, I>>(object: I): Target_DeployParametersEntry {
    const message = createBaseTarget_DeployParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseExecutionConfig(): ExecutionConfig {
  return {
    usages: [],
    defaultPool: undefined,
    privatePool: undefined,
    workerPool: "",
    serviceAccount: "",
    artifactStorage: "",
    executionTimeout: undefined,
  };
}

export const ExecutionConfig: MessageFns<ExecutionConfig> = {
  encode(message: ExecutionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    writer.uint32(10).fork();
    for (const v of message.usages) {
      writer.int32(v);
    }
    writer.join();
    if (message.defaultPool !== undefined) {
      DefaultPool.encode(message.defaultPool, writer.uint32(18).fork()).join();
    }
    if (message.privatePool !== undefined) {
      PrivatePool.encode(message.privatePool, writer.uint32(26).fork()).join();
    }
    if (message.workerPool !== "") {
      writer.uint32(34).string(message.workerPool);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    if (message.artifactStorage !== "") {
      writer.uint32(50).string(message.artifactStorage);
    }
    if (message.executionTimeout !== undefined) {
      Duration.encode(message.executionTimeout, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ExecutionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseExecutionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag === 8) {
            message.usages.push(reader.int32() as any);

            continue;
          }

          if (tag === 10) {
            const end2 = reader.uint32() + reader.pos;
            while (reader.pos < end2) {
              message.usages.push(reader.int32() as any);
            }

            continue;
          }

          break;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.defaultPool = DefaultPool.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.privatePool = PrivatePool.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.artifactStorage = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.executionTimeout = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ExecutionConfig {
    return {
      usages: globalThis.Array.isArray(object?.usages)
        ? object.usages.map((e: any) => executionConfig_ExecutionEnvironmentUsageFromJSON(e))
        : [],
      defaultPool: isSet(object.defaultPool) ? DefaultPool.fromJSON(object.defaultPool) : undefined,
      privatePool: isSet(object.privatePool) ? PrivatePool.fromJSON(object.privatePool) : undefined,
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      artifactStorage: isSet(object.artifactStorage) ? globalThis.String(object.artifactStorage) : "",
      executionTimeout: isSet(object.executionTimeout) ? Duration.fromJSON(object.executionTimeout) : undefined,
    };
  },

  toJSON(message: ExecutionConfig): unknown {
    const obj: any = {};
    if (message.usages?.length) {
      obj.usages = message.usages.map((e) => executionConfig_ExecutionEnvironmentUsageToJSON(e));
    }
    if (message.defaultPool !== undefined) {
      obj.defaultPool = DefaultPool.toJSON(message.defaultPool);
    }
    if (message.privatePool !== undefined) {
      obj.privatePool = PrivatePool.toJSON(message.privatePool);
    }
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.artifactStorage !== "") {
      obj.artifactStorage = message.artifactStorage;
    }
    if (message.executionTimeout !== undefined) {
      obj.executionTimeout = Duration.toJSON(message.executionTimeout);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ExecutionConfig>, I>>(base?: I): ExecutionConfig {
    return ExecutionConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ExecutionConfig>, I>>(object: I): ExecutionConfig {
    const message = createBaseExecutionConfig();
    message.usages = object.usages?.map((e) => e) || [];
    message.defaultPool = (object.defaultPool !== undefined && object.defaultPool !== null)
      ? DefaultPool.fromPartial(object.defaultPool)
      : undefined;
    message.privatePool = (object.privatePool !== undefined && object.privatePool !== null)
      ? PrivatePool.fromPartial(object.privatePool)
      : undefined;
    message.workerPool = object.workerPool ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    message.artifactStorage = object.artifactStorage ?? "";
    message.executionTimeout = (object.executionTimeout !== undefined && object.executionTimeout !== null)
      ? Duration.fromPartial(object.executionTimeout)
      : undefined;
    return message;
  },
};

function createBaseDefaultPool(): DefaultPool {
  return { serviceAccount: "", artifactStorage: "" };
}

export const DefaultPool: MessageFns<DefaultPool> = {
  encode(message: DefaultPool, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.serviceAccount !== "") {
      writer.uint32(10).string(message.serviceAccount);
    }
    if (message.artifactStorage !== "") {
      writer.uint32(18).string(message.artifactStorage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DefaultPool {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDefaultPool();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.artifactStorage = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DefaultPool {
    return {
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      artifactStorage: isSet(object.artifactStorage) ? globalThis.String(object.artifactStorage) : "",
    };
  },

  toJSON(message: DefaultPool): unknown {
    const obj: any = {};
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.artifactStorage !== "") {
      obj.artifactStorage = message.artifactStorage;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DefaultPool>, I>>(base?: I): DefaultPool {
    return DefaultPool.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DefaultPool>, I>>(object: I): DefaultPool {
    const message = createBaseDefaultPool();
    message.serviceAccount = object.serviceAccount ?? "";
    message.artifactStorage = object.artifactStorage ?? "";
    return message;
  },
};

function createBasePrivatePool(): PrivatePool {
  return { workerPool: "", serviceAccount: "", artifactStorage: "" };
}

export const PrivatePool: MessageFns<PrivatePool> = {
  encode(message: PrivatePool, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.workerPool !== "") {
      writer.uint32(10).string(message.workerPool);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(18).string(message.serviceAccount);
    }
    if (message.artifactStorage !== "") {
      writer.uint32(26).string(message.artifactStorage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PrivatePool {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePrivatePool();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.artifactStorage = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PrivatePool {
    return {
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      artifactStorage: isSet(object.artifactStorage) ? globalThis.String(object.artifactStorage) : "",
    };
  },

  toJSON(message: PrivatePool): unknown {
    const obj: any = {};
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.artifactStorage !== "") {
      obj.artifactStorage = message.artifactStorage;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PrivatePool>, I>>(base?: I): PrivatePool {
    return PrivatePool.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PrivatePool>, I>>(object: I): PrivatePool {
    const message = createBasePrivatePool();
    message.workerPool = object.workerPool ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    message.artifactStorage = object.artifactStorage ?? "";
    return message;
  },
};

function createBaseGkeCluster(): GkeCluster {
  return { cluster: "", internalIp: false };
}

export const GkeCluster: MessageFns<GkeCluster> = {
  encode(message: GkeCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cluster !== "") {
      writer.uint32(10).string(message.cluster);
    }
    if (message.internalIp !== false) {
      writer.uint32(16).bool(message.internalIp);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GkeCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGkeCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.internalIp = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GkeCluster {
    return {
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      internalIp: isSet(object.internalIp) ? globalThis.Boolean(object.internalIp) : false,
    };
  },

  toJSON(message: GkeCluster): unknown {
    const obj: any = {};
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.internalIp !== false) {
      obj.internalIp = message.internalIp;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GkeCluster>, I>>(base?: I): GkeCluster {
    return GkeCluster.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GkeCluster>, I>>(object: I): GkeCluster {
    const message = createBaseGkeCluster();
    message.cluster = object.cluster ?? "";
    message.internalIp = object.internalIp ?? false;
    return message;
  },
};

function createBaseAnthosCluster(): AnthosCluster {
  return { membership: "" };
}

export const AnthosCluster: MessageFns<AnthosCluster> = {
  encode(message: AnthosCluster, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.membership !== "") {
      writer.uint32(10).string(message.membership);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AnthosCluster {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAnthosCluster();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.membership = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AnthosCluster {
    return { membership: isSet(object.membership) ? globalThis.String(object.membership) : "" };
  },

  toJSON(message: AnthosCluster): unknown {
    const obj: any = {};
    if (message.membership !== "") {
      obj.membership = message.membership;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AnthosCluster>, I>>(base?: I): AnthosCluster {
    return AnthosCluster.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AnthosCluster>, I>>(object: I): AnthosCluster {
    const message = createBaseAnthosCluster();
    message.membership = object.membership ?? "";
    return message;
  },
};

function createBaseCloudRunLocation(): CloudRunLocation {
  return { location: "" };
}

export const CloudRunLocation: MessageFns<CloudRunLocation> = {
  encode(message: CloudRunLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.location !== "") {
      writer.uint32(10).string(message.location);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudRunLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudRunLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.location = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudRunLocation {
    return { location: isSet(object.location) ? globalThis.String(object.location) : "" };
  },

  toJSON(message: CloudRunLocation): unknown {
    const obj: any = {};
    if (message.location !== "") {
      obj.location = message.location;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloudRunLocation>, I>>(base?: I): CloudRunLocation {
    return CloudRunLocation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloudRunLocation>, I>>(object: I): CloudRunLocation {
    const message = createBaseCloudRunLocation();
    message.location = object.location ?? "";
    return message;
  },
};

function createBaseMultiTarget(): MultiTarget {
  return { targetIds: [] };
}

export const MultiTarget: MessageFns<MultiTarget> = {
  encode(message: MultiTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.targetIds) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MultiTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMultiTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.targetIds.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MultiTarget {
    return {
      targetIds: globalThis.Array.isArray(object?.targetIds)
        ? object.targetIds.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: MultiTarget): unknown {
    const obj: any = {};
    if (message.targetIds?.length) {
      obj.targetIds = message.targetIds;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MultiTarget>, I>>(base?: I): MultiTarget {
    return MultiTarget.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MultiTarget>, I>>(object: I): MultiTarget {
    const message = createBaseMultiTarget();
    message.targetIds = object.targetIds?.map((e) => e) || [];
    return message;
  },
};

function createBaseCustomTarget(): CustomTarget {
  return { customTargetType: "" };
}

export const CustomTarget: MessageFns<CustomTarget> = {
  encode(message: CustomTarget, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.customTargetType !== "") {
      writer.uint32(10).string(message.customTargetType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTarget {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTarget();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.customTargetType = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTarget {
    return { customTargetType: isSet(object.customTargetType) ? globalThis.String(object.customTargetType) : "" };
  },

  toJSON(message: CustomTarget): unknown {
    const obj: any = {};
    if (message.customTargetType !== "") {
      obj.customTargetType = message.customTargetType;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTarget>, I>>(base?: I): CustomTarget {
    return CustomTarget.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTarget>, I>>(object: I): CustomTarget {
    const message = createBaseCustomTarget();
    message.customTargetType = object.customTargetType ?? "";
    return message;
  },
};

function createBaseCustomTargetType(): CustomTargetType {
  return {
    name: "",
    customTargetTypeId: "",
    uid: "",
    description: "",
    annotations: {},
    labels: {},
    createTime: undefined,
    updateTime: undefined,
    etag: "",
    customActions: undefined,
  };
}

export const CustomTargetType: MessageFns<CustomTargetType> = {
  encode(message: CustomTargetType, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.customTargetTypeId !== "") {
      writer.uint32(18).string(message.customTargetTypeId);
    }
    if (message.uid !== "") {
      writer.uint32(26).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(34).string(message.description);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      CustomTargetType_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      CustomTargetType_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(58).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(66).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(74).string(message.etag);
    }
    if (message.customActions !== undefined) {
      CustomTargetSkaffoldActions.encode(message.customActions, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTargetType {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTargetType();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.customTargetTypeId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = CustomTargetType_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.annotations[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = CustomTargetType_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.customActions = CustomTargetSkaffoldActions.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTargetType {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      customTargetTypeId: isSet(object.customTargetTypeId) ? globalThis.String(object.customTargetTypeId) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      customActions: isSet(object.customActions)
        ? CustomTargetSkaffoldActions.fromJSON(object.customActions)
        : undefined,
    };
  },

  toJSON(message: CustomTargetType): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.customTargetTypeId !== "") {
      obj.customTargetTypeId = message.customTargetTypeId;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.customActions !== undefined) {
      obj.customActions = CustomTargetSkaffoldActions.toJSON(message.customActions);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTargetType>, I>>(base?: I): CustomTargetType {
    return CustomTargetType.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTargetType>, I>>(object: I): CustomTargetType {
    const message = createBaseCustomTargetType();
    message.name = object.name ?? "";
    message.customTargetTypeId = object.customTargetTypeId ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.etag = object.etag ?? "";
    message.customActions = (object.customActions !== undefined && object.customActions !== null)
      ? CustomTargetSkaffoldActions.fromPartial(object.customActions)
      : undefined;
    return message;
  },
};

function createBaseCustomTargetType_AnnotationsEntry(): CustomTargetType_AnnotationsEntry {
  return { key: "", value: "" };
}

export const CustomTargetType_AnnotationsEntry: MessageFns<CustomTargetType_AnnotationsEntry> = {
  encode(message: CustomTargetType_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTargetType_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTargetType_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTargetType_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomTargetType_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTargetType_AnnotationsEntry>, I>>(
    base?: I,
  ): CustomTargetType_AnnotationsEntry {
    return CustomTargetType_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTargetType_AnnotationsEntry>, I>>(
    object: I,
  ): CustomTargetType_AnnotationsEntry {
    const message = createBaseCustomTargetType_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCustomTargetType_LabelsEntry(): CustomTargetType_LabelsEntry {
  return { key: "", value: "" };
}

export const CustomTargetType_LabelsEntry: MessageFns<CustomTargetType_LabelsEntry> = {
  encode(message: CustomTargetType_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTargetType_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTargetType_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTargetType_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomTargetType_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTargetType_LabelsEntry>, I>>(base?: I): CustomTargetType_LabelsEntry {
    return CustomTargetType_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTargetType_LabelsEntry>, I>>(object: I): CustomTargetType_LabelsEntry {
    const message = createBaseCustomTargetType_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCustomTargetSkaffoldActions(): CustomTargetSkaffoldActions {
  return { renderAction: "", deployAction: "", includeSkaffoldModules: [] };
}

export const CustomTargetSkaffoldActions: MessageFns<CustomTargetSkaffoldActions> = {
  encode(message: CustomTargetSkaffoldActions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.renderAction !== "") {
      writer.uint32(10).string(message.renderAction);
    }
    if (message.deployAction !== "") {
      writer.uint32(18).string(message.deployAction);
    }
    for (const v of message.includeSkaffoldModules) {
      SkaffoldModules.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTargetSkaffoldActions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTargetSkaffoldActions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.renderAction = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.deployAction = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.includeSkaffoldModules.push(SkaffoldModules.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTargetSkaffoldActions {
    return {
      renderAction: isSet(object.renderAction) ? globalThis.String(object.renderAction) : "",
      deployAction: isSet(object.deployAction) ? globalThis.String(object.deployAction) : "",
      includeSkaffoldModules: globalThis.Array.isArray(object?.includeSkaffoldModules)
        ? object.includeSkaffoldModules.map((e: any) => SkaffoldModules.fromJSON(e))
        : [],
    };
  },

  toJSON(message: CustomTargetSkaffoldActions): unknown {
    const obj: any = {};
    if (message.renderAction !== "") {
      obj.renderAction = message.renderAction;
    }
    if (message.deployAction !== "") {
      obj.deployAction = message.deployAction;
    }
    if (message.includeSkaffoldModules?.length) {
      obj.includeSkaffoldModules = message.includeSkaffoldModules.map((e) => SkaffoldModules.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTargetSkaffoldActions>, I>>(base?: I): CustomTargetSkaffoldActions {
    return CustomTargetSkaffoldActions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTargetSkaffoldActions>, I>>(object: I): CustomTargetSkaffoldActions {
    const message = createBaseCustomTargetSkaffoldActions();
    message.renderAction = object.renderAction ?? "";
    message.deployAction = object.deployAction ?? "";
    message.includeSkaffoldModules = object.includeSkaffoldModules?.map((e) => SkaffoldModules.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSkaffoldModules(): SkaffoldModules {
  return { configs: [], git: undefined, googleCloudStorage: undefined };
}

export const SkaffoldModules: MessageFns<SkaffoldModules> = {
  encode(message: SkaffoldModules, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.configs) {
      writer.uint32(10).string(v!);
    }
    if (message.git !== undefined) {
      SkaffoldModules_SkaffoldGitSource.encode(message.git, writer.uint32(18).fork()).join();
    }
    if (message.googleCloudStorage !== undefined) {
      SkaffoldModules_SkaffoldGCSSource.encode(message.googleCloudStorage, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SkaffoldModules {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSkaffoldModules();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.configs.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.git = SkaffoldModules_SkaffoldGitSource.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.googleCloudStorage = SkaffoldModules_SkaffoldGCSSource.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SkaffoldModules {
    return {
      configs: globalThis.Array.isArray(object?.configs) ? object.configs.map((e: any) => globalThis.String(e)) : [],
      git: isSet(object.git) ? SkaffoldModules_SkaffoldGitSource.fromJSON(object.git) : undefined,
      googleCloudStorage: isSet(object.googleCloudStorage)
        ? SkaffoldModules_SkaffoldGCSSource.fromJSON(object.googleCloudStorage)
        : undefined,
    };
  },

  toJSON(message: SkaffoldModules): unknown {
    const obj: any = {};
    if (message.configs?.length) {
      obj.configs = message.configs;
    }
    if (message.git !== undefined) {
      obj.git = SkaffoldModules_SkaffoldGitSource.toJSON(message.git);
    }
    if (message.googleCloudStorage !== undefined) {
      obj.googleCloudStorage = SkaffoldModules_SkaffoldGCSSource.toJSON(message.googleCloudStorage);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SkaffoldModules>, I>>(base?: I): SkaffoldModules {
    return SkaffoldModules.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SkaffoldModules>, I>>(object: I): SkaffoldModules {
    const message = createBaseSkaffoldModules();
    message.configs = object.configs?.map((e) => e) || [];
    message.git = (object.git !== undefined && object.git !== null)
      ? SkaffoldModules_SkaffoldGitSource.fromPartial(object.git)
      : undefined;
    message.googleCloudStorage = (object.googleCloudStorage !== undefined && object.googleCloudStorage !== null)
      ? SkaffoldModules_SkaffoldGCSSource.fromPartial(object.googleCloudStorage)
      : undefined;
    return message;
  },
};

function createBaseSkaffoldModules_SkaffoldGitSource(): SkaffoldModules_SkaffoldGitSource {
  return { repo: "", path: "", ref: "" };
}

export const SkaffoldModules_SkaffoldGitSource: MessageFns<SkaffoldModules_SkaffoldGitSource> = {
  encode(message: SkaffoldModules_SkaffoldGitSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.repo !== "") {
      writer.uint32(10).string(message.repo);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    if (message.ref !== "") {
      writer.uint32(26).string(message.ref);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SkaffoldModules_SkaffoldGitSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSkaffoldModules_SkaffoldGitSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.repo = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.ref = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SkaffoldModules_SkaffoldGitSource {
    return {
      repo: isSet(object.repo) ? globalThis.String(object.repo) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      ref: isSet(object.ref) ? globalThis.String(object.ref) : "",
    };
  },

  toJSON(message: SkaffoldModules_SkaffoldGitSource): unknown {
    const obj: any = {};
    if (message.repo !== "") {
      obj.repo = message.repo;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.ref !== "") {
      obj.ref = message.ref;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SkaffoldModules_SkaffoldGitSource>, I>>(
    base?: I,
  ): SkaffoldModules_SkaffoldGitSource {
    return SkaffoldModules_SkaffoldGitSource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SkaffoldModules_SkaffoldGitSource>, I>>(
    object: I,
  ): SkaffoldModules_SkaffoldGitSource {
    const message = createBaseSkaffoldModules_SkaffoldGitSource();
    message.repo = object.repo ?? "";
    message.path = object.path ?? "";
    message.ref = object.ref ?? "";
    return message;
  },
};

function createBaseSkaffoldModules_SkaffoldGCSSource(): SkaffoldModules_SkaffoldGCSSource {
  return { source: "", path: "" };
}

export const SkaffoldModules_SkaffoldGCSSource: MessageFns<SkaffoldModules_SkaffoldGCSSource> = {
  encode(message: SkaffoldModules_SkaffoldGCSSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.source !== "") {
      writer.uint32(10).string(message.source);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SkaffoldModules_SkaffoldGCSSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSkaffoldModules_SkaffoldGCSSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.source = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SkaffoldModules_SkaffoldGCSSource {
    return {
      source: isSet(object.source) ? globalThis.String(object.source) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: SkaffoldModules_SkaffoldGCSSource): unknown {
    const obj: any = {};
    if (message.source !== "") {
      obj.source = message.source;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SkaffoldModules_SkaffoldGCSSource>, I>>(
    base?: I,
  ): SkaffoldModules_SkaffoldGCSSource {
    return SkaffoldModules_SkaffoldGCSSource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SkaffoldModules_SkaffoldGCSSource>, I>>(
    object: I,
  ): SkaffoldModules_SkaffoldGCSSource {
    const message = createBaseSkaffoldModules_SkaffoldGCSSource();
    message.source = object.source ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseTargetAttribute(): TargetAttribute {
  return { id: "", labels: {} };
}

export const TargetAttribute: MessageFns<TargetAttribute> = {
  encode(message: TargetAttribute, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      TargetAttribute_LabelsEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetAttribute {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetAttribute();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          const entry2 = TargetAttribute_LabelsEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.labels[entry2.key] = entry2.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetAttribute {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: TargetAttribute): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetAttribute>, I>>(base?: I): TargetAttribute {
    return TargetAttribute.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetAttribute>, I>>(object: I): TargetAttribute {
    const message = createBaseTargetAttribute();
    message.id = object.id ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseTargetAttribute_LabelsEntry(): TargetAttribute_LabelsEntry {
  return { key: "", value: "" };
}

export const TargetAttribute_LabelsEntry: MessageFns<TargetAttribute_LabelsEntry> = {
  encode(message: TargetAttribute_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetAttribute_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetAttribute_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetAttribute_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: TargetAttribute_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetAttribute_LabelsEntry>, I>>(base?: I): TargetAttribute_LabelsEntry {
    return TargetAttribute_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetAttribute_LabelsEntry>, I>>(object: I): TargetAttribute_LabelsEntry {
    const message = createBaseTargetAttribute_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRelease(): Release {
  return {
    name: "",
    uid: "",
    description: "",
    annotations: {},
    labels: {},
    abandoned: false,
    createTime: undefined,
    renderStartTime: undefined,
    renderEndTime: undefined,
    skaffoldConfigUri: "",
    skaffoldConfigPath: "",
    buildArtifacts: [],
    deliveryPipelineSnapshot: undefined,
    targetSnapshots: [],
    customTargetTypeSnapshots: [],
    renderState: 0,
    etag: "",
    skaffoldVersion: "",
    targetArtifacts: {},
    targetRenders: {},
    condition: undefined,
    deployParameters: {},
  };
}

export const Release: MessageFns<Release> = {
  encode(message: Release, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      Release_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      Release_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.abandoned !== false) {
      writer.uint32(184).bool(message.abandoned);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.renderStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.renderStartTime), writer.uint32(58).fork()).join();
    }
    if (message.renderEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.renderEndTime), writer.uint32(66).fork()).join();
    }
    if (message.skaffoldConfigUri !== "") {
      writer.uint32(138).string(message.skaffoldConfigUri);
    }
    if (message.skaffoldConfigPath !== "") {
      writer.uint32(74).string(message.skaffoldConfigPath);
    }
    for (const v of message.buildArtifacts) {
      BuildArtifact.encode(v!, writer.uint32(82).fork()).join();
    }
    if (message.deliveryPipelineSnapshot !== undefined) {
      DeliveryPipeline.encode(message.deliveryPipelineSnapshot, writer.uint32(90).fork()).join();
    }
    for (const v of message.targetSnapshots) {
      Target.encode(v!, writer.uint32(98).fork()).join();
    }
    for (const v of message.customTargetTypeSnapshots) {
      CustomTargetType.encode(v!, writer.uint32(218).fork()).join();
    }
    if (message.renderState !== 0) {
      writer.uint32(104).int32(message.renderState);
    }
    if (message.etag !== "") {
      writer.uint32(130).string(message.etag);
    }
    if (message.skaffoldVersion !== "") {
      writer.uint32(154).string(message.skaffoldVersion);
    }
    Object.entries(message.targetArtifacts).forEach(([key, value]) => {
      Release_TargetArtifactsEntry.encode({ key: key as any, value }, writer.uint32(162).fork()).join();
    });
    Object.entries(message.targetRenders).forEach(([key, value]) => {
      Release_TargetRendersEntry.encode({ key: key as any, value }, writer.uint32(178).fork()).join();
    });
    if (message.condition !== undefined) {
      Release_ReleaseCondition.encode(message.condition, writer.uint32(194).fork()).join();
    }
    Object.entries(message.deployParameters).forEach(([key, value]) => {
      Release_DeployParametersEntry.encode({ key: key as any, value }, writer.uint32(202).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Release_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.annotations[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Release_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
        }
        case 23: {
          if (tag !== 184) {
            break;
          }

          message.abandoned = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.renderStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.renderEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.skaffoldConfigUri = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.skaffoldConfigPath = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.buildArtifacts.push(BuildArtifact.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.deliveryPipelineSnapshot = DeliveryPipeline.decode(reader, reader.uint32());
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.targetSnapshots.push(Target.decode(reader, reader.uint32()));
          continue;
        }
        case 27: {
          if (tag !== 218) {
            break;
          }

          message.customTargetTypeSnapshots.push(CustomTargetType.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.renderState = reader.int32() as any;
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.skaffoldVersion = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          const entry20 = Release_TargetArtifactsEntry.decode(reader, reader.uint32());
          if (entry20.value !== undefined) {
            message.targetArtifacts[entry20.key] = entry20.value;
          }
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          const entry22 = Release_TargetRendersEntry.decode(reader, reader.uint32());
          if (entry22.value !== undefined) {
            message.targetRenders[entry22.key] = entry22.value;
          }
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.condition = Release_ReleaseCondition.decode(reader, reader.uint32());
          continue;
        }
        case 25: {
          if (tag !== 202) {
            break;
          }

          const entry25 = Release_DeployParametersEntry.decode(reader, reader.uint32());
          if (entry25.value !== undefined) {
            message.deployParameters[entry25.key] = entry25.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      abandoned: isSet(object.abandoned) ? globalThis.Boolean(object.abandoned) : false,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      renderStartTime: isSet(object.renderStartTime) ? fromJsonTimestamp(object.renderStartTime) : undefined,
      renderEndTime: isSet(object.renderEndTime) ? fromJsonTimestamp(object.renderEndTime) : undefined,
      skaffoldConfigUri: isSet(object.skaffoldConfigUri) ? globalThis.String(object.skaffoldConfigUri) : "",
      skaffoldConfigPath: isSet(object.skaffoldConfigPath) ? globalThis.String(object.skaffoldConfigPath) : "",
      buildArtifacts: globalThis.Array.isArray(object?.buildArtifacts)
        ? object.buildArtifacts.map((e: any) => BuildArtifact.fromJSON(e))
        : [],
      deliveryPipelineSnapshot: isSet(object.deliveryPipelineSnapshot)
        ? DeliveryPipeline.fromJSON(object.deliveryPipelineSnapshot)
        : undefined,
      targetSnapshots: globalThis.Array.isArray(object?.targetSnapshots)
        ? object.targetSnapshots.map((e: any) => Target.fromJSON(e))
        : [],
      customTargetTypeSnapshots: globalThis.Array.isArray(object?.customTargetTypeSnapshots)
        ? object.customTargetTypeSnapshots.map((e: any) => CustomTargetType.fromJSON(e))
        : [],
      renderState: isSet(object.renderState) ? release_RenderStateFromJSON(object.renderState) : 0,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      skaffoldVersion: isSet(object.skaffoldVersion) ? globalThis.String(object.skaffoldVersion) : "",
      targetArtifacts: isObject(object.targetArtifacts)
        ? Object.entries(object.targetArtifacts).reduce<{ [key: string]: TargetArtifact }>((acc, [key, value]) => {
          acc[key] = TargetArtifact.fromJSON(value);
          return acc;
        }, {})
        : {},
      targetRenders: isObject(object.targetRenders)
        ? Object.entries(object.targetRenders).reduce<{ [key: string]: Release_TargetRender }>((acc, [key, value]) => {
          acc[key] = Release_TargetRender.fromJSON(value);
          return acc;
        }, {})
        : {},
      condition: isSet(object.condition) ? Release_ReleaseCondition.fromJSON(object.condition) : undefined,
      deployParameters: isObject(object.deployParameters)
        ? Object.entries(object.deployParameters).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: Release): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.abandoned !== false) {
      obj.abandoned = message.abandoned;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.renderStartTime !== undefined) {
      obj.renderStartTime = message.renderStartTime.toISOString();
    }
    if (message.renderEndTime !== undefined) {
      obj.renderEndTime = message.renderEndTime.toISOString();
    }
    if (message.skaffoldConfigUri !== "") {
      obj.skaffoldConfigUri = message.skaffoldConfigUri;
    }
    if (message.skaffoldConfigPath !== "") {
      obj.skaffoldConfigPath = message.skaffoldConfigPath;
    }
    if (message.buildArtifacts?.length) {
      obj.buildArtifacts = message.buildArtifacts.map((e) => BuildArtifact.toJSON(e));
    }
    if (message.deliveryPipelineSnapshot !== undefined) {
      obj.deliveryPipelineSnapshot = DeliveryPipeline.toJSON(message.deliveryPipelineSnapshot);
    }
    if (message.targetSnapshots?.length) {
      obj.targetSnapshots = message.targetSnapshots.map((e) => Target.toJSON(e));
    }
    if (message.customTargetTypeSnapshots?.length) {
      obj.customTargetTypeSnapshots = message.customTargetTypeSnapshots.map((e) => CustomTargetType.toJSON(e));
    }
    if (message.renderState !== 0) {
      obj.renderState = release_RenderStateToJSON(message.renderState);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.skaffoldVersion !== "") {
      obj.skaffoldVersion = message.skaffoldVersion;
    }
    if (message.targetArtifacts) {
      const entries = Object.entries(message.targetArtifacts);
      if (entries.length > 0) {
        obj.targetArtifacts = {};
        entries.forEach(([k, v]) => {
          obj.targetArtifacts[k] = TargetArtifact.toJSON(v);
        });
      }
    }
    if (message.targetRenders) {
      const entries = Object.entries(message.targetRenders);
      if (entries.length > 0) {
        obj.targetRenders = {};
        entries.forEach(([k, v]) => {
          obj.targetRenders[k] = Release_TargetRender.toJSON(v);
        });
      }
    }
    if (message.condition !== undefined) {
      obj.condition = Release_ReleaseCondition.toJSON(message.condition);
    }
    if (message.deployParameters) {
      const entries = Object.entries(message.deployParameters);
      if (entries.length > 0) {
        obj.deployParameters = {};
        entries.forEach(([k, v]) => {
          obj.deployParameters[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release>, I>>(base?: I): Release {
    return Release.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release>, I>>(object: I): Release {
    const message = createBaseRelease();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.abandoned = object.abandoned ?? false;
    message.createTime = object.createTime ?? undefined;
    message.renderStartTime = object.renderStartTime ?? undefined;
    message.renderEndTime = object.renderEndTime ?? undefined;
    message.skaffoldConfigUri = object.skaffoldConfigUri ?? "";
    message.skaffoldConfigPath = object.skaffoldConfigPath ?? "";
    message.buildArtifacts = object.buildArtifacts?.map((e) => BuildArtifact.fromPartial(e)) || [];
    message.deliveryPipelineSnapshot =
      (object.deliveryPipelineSnapshot !== undefined && object.deliveryPipelineSnapshot !== null)
        ? DeliveryPipeline.fromPartial(object.deliveryPipelineSnapshot)
        : undefined;
    message.targetSnapshots = object.targetSnapshots?.map((e) => Target.fromPartial(e)) || [];
    message.customTargetTypeSnapshots = object.customTargetTypeSnapshots?.map((e) => CustomTargetType.fromPartial(e)) ||
      [];
    message.renderState = object.renderState ?? 0;
    message.etag = object.etag ?? "";
    message.skaffoldVersion = object.skaffoldVersion ?? "";
    message.targetArtifacts = Object.entries(object.targetArtifacts ?? {}).reduce<{ [key: string]: TargetArtifact }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = TargetArtifact.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.targetRenders = Object.entries(object.targetRenders ?? {}).reduce<{ [key: string]: Release_TargetRender }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = Release_TargetRender.fromPartial(value);
        }
        return acc;
      },
      {},
    );
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? Release_ReleaseCondition.fromPartial(object.condition)
      : undefined;
    message.deployParameters = Object.entries(object.deployParameters ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    return message;
  },
};

function createBaseRelease_TargetRender(): Release_TargetRender {
  return { renderingBuild: "", renderingState: 0, metadata: undefined, failureCause: 0, failureMessage: "" };
}

export const Release_TargetRender: MessageFns<Release_TargetRender> = {
  encode(message: Release_TargetRender, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.renderingBuild !== "") {
      writer.uint32(10).string(message.renderingBuild);
    }
    if (message.renderingState !== 0) {
      writer.uint32(16).int32(message.renderingState);
    }
    if (message.metadata !== undefined) {
      RenderMetadata.encode(message.metadata, writer.uint32(50).fork()).join();
    }
    if (message.failureCause !== 0) {
      writer.uint32(32).int32(message.failureCause);
    }
    if (message.failureMessage !== "") {
      writer.uint32(42).string(message.failureMessage);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_TargetRender {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_TargetRender();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.renderingBuild = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.renderingState = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.metadata = RenderMetadata.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.failureCause = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.failureMessage = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_TargetRender {
    return {
      renderingBuild: isSet(object.renderingBuild) ? globalThis.String(object.renderingBuild) : "",
      renderingState: isSet(object.renderingState)
        ? release_TargetRender_TargetRenderStateFromJSON(object.renderingState)
        : 0,
      metadata: isSet(object.metadata) ? RenderMetadata.fromJSON(object.metadata) : undefined,
      failureCause: isSet(object.failureCause) ? release_TargetRender_FailureCauseFromJSON(object.failureCause) : 0,
      failureMessage: isSet(object.failureMessage) ? globalThis.String(object.failureMessage) : "",
    };
  },

  toJSON(message: Release_TargetRender): unknown {
    const obj: any = {};
    if (message.renderingBuild !== "") {
      obj.renderingBuild = message.renderingBuild;
    }
    if (message.renderingState !== 0) {
      obj.renderingState = release_TargetRender_TargetRenderStateToJSON(message.renderingState);
    }
    if (message.metadata !== undefined) {
      obj.metadata = RenderMetadata.toJSON(message.metadata);
    }
    if (message.failureCause !== 0) {
      obj.failureCause = release_TargetRender_FailureCauseToJSON(message.failureCause);
    }
    if (message.failureMessage !== "") {
      obj.failureMessage = message.failureMessage;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_TargetRender>, I>>(base?: I): Release_TargetRender {
    return Release_TargetRender.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_TargetRender>, I>>(object: I): Release_TargetRender {
    const message = createBaseRelease_TargetRender();
    message.renderingBuild = object.renderingBuild ?? "";
    message.renderingState = object.renderingState ?? 0;
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? RenderMetadata.fromPartial(object.metadata)
      : undefined;
    message.failureCause = object.failureCause ?? 0;
    message.failureMessage = object.failureMessage ?? "";
    return message;
  },
};

function createBaseRelease_ReleaseReadyCondition(): Release_ReleaseReadyCondition {
  return { status: false };
}

export const Release_ReleaseReadyCondition: MessageFns<Release_ReleaseReadyCondition> = {
  encode(message: Release_ReleaseReadyCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== false) {
      writer.uint32(8).bool(message.status);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_ReleaseReadyCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_ReleaseReadyCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_ReleaseReadyCondition {
    return { status: isSet(object.status) ? globalThis.Boolean(object.status) : false };
  },

  toJSON(message: Release_ReleaseReadyCondition): unknown {
    const obj: any = {};
    if (message.status !== false) {
      obj.status = message.status;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_ReleaseReadyCondition>, I>>(base?: I): Release_ReleaseReadyCondition {
    return Release_ReleaseReadyCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_ReleaseReadyCondition>, I>>(
    object: I,
  ): Release_ReleaseReadyCondition {
    const message = createBaseRelease_ReleaseReadyCondition();
    message.status = object.status ?? false;
    return message;
  },
};

function createBaseRelease_SkaffoldSupportedCondition(): Release_SkaffoldSupportedCondition {
  return { status: false, skaffoldSupportState: 0, maintenanceModeTime: undefined, supportExpirationTime: undefined };
}

export const Release_SkaffoldSupportedCondition: MessageFns<Release_SkaffoldSupportedCondition> = {
  encode(message: Release_SkaffoldSupportedCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.status !== false) {
      writer.uint32(8).bool(message.status);
    }
    if (message.skaffoldSupportState !== 0) {
      writer.uint32(16).int32(message.skaffoldSupportState);
    }
    if (message.maintenanceModeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.maintenanceModeTime), writer.uint32(26).fork()).join();
    }
    if (message.supportExpirationTime !== undefined) {
      Timestamp.encode(toTimestamp(message.supportExpirationTime), writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_SkaffoldSupportedCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_SkaffoldSupportedCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.status = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.skaffoldSupportState = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.maintenanceModeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.supportExpirationTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_SkaffoldSupportedCondition {
    return {
      status: isSet(object.status) ? globalThis.Boolean(object.status) : false,
      skaffoldSupportState: isSet(object.skaffoldSupportState)
        ? skaffoldSupportStateFromJSON(object.skaffoldSupportState)
        : 0,
      maintenanceModeTime: isSet(object.maintenanceModeTime)
        ? fromJsonTimestamp(object.maintenanceModeTime)
        : undefined,
      supportExpirationTime: isSet(object.supportExpirationTime)
        ? fromJsonTimestamp(object.supportExpirationTime)
        : undefined,
    };
  },

  toJSON(message: Release_SkaffoldSupportedCondition): unknown {
    const obj: any = {};
    if (message.status !== false) {
      obj.status = message.status;
    }
    if (message.skaffoldSupportState !== 0) {
      obj.skaffoldSupportState = skaffoldSupportStateToJSON(message.skaffoldSupportState);
    }
    if (message.maintenanceModeTime !== undefined) {
      obj.maintenanceModeTime = message.maintenanceModeTime.toISOString();
    }
    if (message.supportExpirationTime !== undefined) {
      obj.supportExpirationTime = message.supportExpirationTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_SkaffoldSupportedCondition>, I>>(
    base?: I,
  ): Release_SkaffoldSupportedCondition {
    return Release_SkaffoldSupportedCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_SkaffoldSupportedCondition>, I>>(
    object: I,
  ): Release_SkaffoldSupportedCondition {
    const message = createBaseRelease_SkaffoldSupportedCondition();
    message.status = object.status ?? false;
    message.skaffoldSupportState = object.skaffoldSupportState ?? 0;
    message.maintenanceModeTime = object.maintenanceModeTime ?? undefined;
    message.supportExpirationTime = object.supportExpirationTime ?? undefined;
    return message;
  },
};

function createBaseRelease_ReleaseCondition(): Release_ReleaseCondition {
  return { releaseReadyCondition: undefined, skaffoldSupportedCondition: undefined };
}

export const Release_ReleaseCondition: MessageFns<Release_ReleaseCondition> = {
  encode(message: Release_ReleaseCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.releaseReadyCondition !== undefined) {
      Release_ReleaseReadyCondition.encode(message.releaseReadyCondition, writer.uint32(10).fork()).join();
    }
    if (message.skaffoldSupportedCondition !== undefined) {
      Release_SkaffoldSupportedCondition.encode(message.skaffoldSupportedCondition, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_ReleaseCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_ReleaseCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.releaseReadyCondition = Release_ReleaseReadyCondition.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.skaffoldSupportedCondition = Release_SkaffoldSupportedCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_ReleaseCondition {
    return {
      releaseReadyCondition: isSet(object.releaseReadyCondition)
        ? Release_ReleaseReadyCondition.fromJSON(object.releaseReadyCondition)
        : undefined,
      skaffoldSupportedCondition: isSet(object.skaffoldSupportedCondition)
        ? Release_SkaffoldSupportedCondition.fromJSON(object.skaffoldSupportedCondition)
        : undefined,
    };
  },

  toJSON(message: Release_ReleaseCondition): unknown {
    const obj: any = {};
    if (message.releaseReadyCondition !== undefined) {
      obj.releaseReadyCondition = Release_ReleaseReadyCondition.toJSON(message.releaseReadyCondition);
    }
    if (message.skaffoldSupportedCondition !== undefined) {
      obj.skaffoldSupportedCondition = Release_SkaffoldSupportedCondition.toJSON(message.skaffoldSupportedCondition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_ReleaseCondition>, I>>(base?: I): Release_ReleaseCondition {
    return Release_ReleaseCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_ReleaseCondition>, I>>(object: I): Release_ReleaseCondition {
    const message = createBaseRelease_ReleaseCondition();
    message.releaseReadyCondition =
      (object.releaseReadyCondition !== undefined && object.releaseReadyCondition !== null)
        ? Release_ReleaseReadyCondition.fromPartial(object.releaseReadyCondition)
        : undefined;
    message.skaffoldSupportedCondition =
      (object.skaffoldSupportedCondition !== undefined && object.skaffoldSupportedCondition !== null)
        ? Release_SkaffoldSupportedCondition.fromPartial(object.skaffoldSupportedCondition)
        : undefined;
    return message;
  },
};

function createBaseRelease_AnnotationsEntry(): Release_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Release_AnnotationsEntry: MessageFns<Release_AnnotationsEntry> = {
  encode(message: Release_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Release_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_AnnotationsEntry>, I>>(base?: I): Release_AnnotationsEntry {
    return Release_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_AnnotationsEntry>, I>>(object: I): Release_AnnotationsEntry {
    const message = createBaseRelease_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRelease_LabelsEntry(): Release_LabelsEntry {
  return { key: "", value: "" };
}

export const Release_LabelsEntry: MessageFns<Release_LabelsEntry> = {
  encode(message: Release_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Release_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_LabelsEntry>, I>>(base?: I): Release_LabelsEntry {
    return Release_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_LabelsEntry>, I>>(object: I): Release_LabelsEntry {
    const message = createBaseRelease_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRelease_TargetArtifactsEntry(): Release_TargetArtifactsEntry {
  return { key: "", value: undefined };
}

export const Release_TargetArtifactsEntry: MessageFns<Release_TargetArtifactsEntry> = {
  encode(message: Release_TargetArtifactsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      TargetArtifact.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_TargetArtifactsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_TargetArtifactsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = TargetArtifact.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_TargetArtifactsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? TargetArtifact.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: Release_TargetArtifactsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = TargetArtifact.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_TargetArtifactsEntry>, I>>(base?: I): Release_TargetArtifactsEntry {
    return Release_TargetArtifactsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_TargetArtifactsEntry>, I>>(object: I): Release_TargetArtifactsEntry {
    const message = createBaseRelease_TargetArtifactsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? TargetArtifact.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseRelease_TargetRendersEntry(): Release_TargetRendersEntry {
  return { key: "", value: undefined };
}

export const Release_TargetRendersEntry: MessageFns<Release_TargetRendersEntry> = {
  encode(message: Release_TargetRendersEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      Release_TargetRender.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_TargetRendersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_TargetRendersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = Release_TargetRender.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_TargetRendersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? Release_TargetRender.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: Release_TargetRendersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = Release_TargetRender.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_TargetRendersEntry>, I>>(base?: I): Release_TargetRendersEntry {
    return Release_TargetRendersEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_TargetRendersEntry>, I>>(object: I): Release_TargetRendersEntry {
    const message = createBaseRelease_TargetRendersEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? Release_TargetRender.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseRelease_DeployParametersEntry(): Release_DeployParametersEntry {
  return { key: "", value: "" };
}

export const Release_DeployParametersEntry: MessageFns<Release_DeployParametersEntry> = {
  encode(message: Release_DeployParametersEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Release_DeployParametersEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRelease_DeployParametersEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Release_DeployParametersEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Release_DeployParametersEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Release_DeployParametersEntry>, I>>(base?: I): Release_DeployParametersEntry {
    return Release_DeployParametersEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Release_DeployParametersEntry>, I>>(
    object: I,
  ): Release_DeployParametersEntry {
    const message = createBaseRelease_DeployParametersEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBuildArtifact(): BuildArtifact {
  return { image: "", tag: "" };
}

export const BuildArtifact: MessageFns<BuildArtifact> = {
  encode(message: BuildArtifact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.image !== "") {
      writer.uint32(26).string(message.image);
    }
    if (message.tag !== "") {
      writer.uint32(18).string(message.tag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildArtifact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildArtifact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.image = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.tag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildArtifact {
    return {
      image: isSet(object.image) ? globalThis.String(object.image) : "",
      tag: isSet(object.tag) ? globalThis.String(object.tag) : "",
    };
  },

  toJSON(message: BuildArtifact): unknown {
    const obj: any = {};
    if (message.image !== "") {
      obj.image = message.image;
    }
    if (message.tag !== "") {
      obj.tag = message.tag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BuildArtifact>, I>>(base?: I): BuildArtifact {
    return BuildArtifact.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BuildArtifact>, I>>(object: I): BuildArtifact {
    const message = createBaseBuildArtifact();
    message.image = object.image ?? "";
    message.tag = object.tag ?? "";
    return message;
  },
};

function createBaseTargetArtifact(): TargetArtifact {
  return { artifactUri: undefined, skaffoldConfigPath: "", manifestPath: "", phaseArtifacts: {} };
}

export const TargetArtifact: MessageFns<TargetArtifact> = {
  encode(message: TargetArtifact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.artifactUri !== undefined) {
      writer.uint32(34).string(message.artifactUri);
    }
    if (message.skaffoldConfigPath !== "") {
      writer.uint32(18).string(message.skaffoldConfigPath);
    }
    if (message.manifestPath !== "") {
      writer.uint32(26).string(message.manifestPath);
    }
    Object.entries(message.phaseArtifacts).forEach(([key, value]) => {
      TargetArtifact_PhaseArtifactsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetArtifact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetArtifact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.artifactUri = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.skaffoldConfigPath = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.manifestPath = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = TargetArtifact_PhaseArtifactsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.phaseArtifacts[entry5.key] = entry5.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetArtifact {
    return {
      artifactUri: isSet(object.artifactUri) ? globalThis.String(object.artifactUri) : undefined,
      skaffoldConfigPath: isSet(object.skaffoldConfigPath) ? globalThis.String(object.skaffoldConfigPath) : "",
      manifestPath: isSet(object.manifestPath) ? globalThis.String(object.manifestPath) : "",
      phaseArtifacts: isObject(object.phaseArtifacts)
        ? Object.entries(object.phaseArtifacts).reduce<{ [key: string]: TargetArtifact_PhaseArtifact }>(
          (acc, [key, value]) => {
            acc[key] = TargetArtifact_PhaseArtifact.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: TargetArtifact): unknown {
    const obj: any = {};
    if (message.artifactUri !== undefined) {
      obj.artifactUri = message.artifactUri;
    }
    if (message.skaffoldConfigPath !== "") {
      obj.skaffoldConfigPath = message.skaffoldConfigPath;
    }
    if (message.manifestPath !== "") {
      obj.manifestPath = message.manifestPath;
    }
    if (message.phaseArtifacts) {
      const entries = Object.entries(message.phaseArtifacts);
      if (entries.length > 0) {
        obj.phaseArtifacts = {};
        entries.forEach(([k, v]) => {
          obj.phaseArtifacts[k] = TargetArtifact_PhaseArtifact.toJSON(v);
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetArtifact>, I>>(base?: I): TargetArtifact {
    return TargetArtifact.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetArtifact>, I>>(object: I): TargetArtifact {
    const message = createBaseTargetArtifact();
    message.artifactUri = object.artifactUri ?? undefined;
    message.skaffoldConfigPath = object.skaffoldConfigPath ?? "";
    message.manifestPath = object.manifestPath ?? "";
    message.phaseArtifacts = Object.entries(object.phaseArtifacts ?? {}).reduce<
      { [key: string]: TargetArtifact_PhaseArtifact }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = TargetArtifact_PhaseArtifact.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseTargetArtifact_PhaseArtifact(): TargetArtifact_PhaseArtifact {
  return { skaffoldConfigPath: "", manifestPath: "", jobManifestsPath: "" };
}

export const TargetArtifact_PhaseArtifact: MessageFns<TargetArtifact_PhaseArtifact> = {
  encode(message: TargetArtifact_PhaseArtifact, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.skaffoldConfigPath !== "") {
      writer.uint32(10).string(message.skaffoldConfigPath);
    }
    if (message.manifestPath !== "") {
      writer.uint32(26).string(message.manifestPath);
    }
    if (message.jobManifestsPath !== "") {
      writer.uint32(34).string(message.jobManifestsPath);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetArtifact_PhaseArtifact {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetArtifact_PhaseArtifact();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.skaffoldConfigPath = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.manifestPath = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.jobManifestsPath = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetArtifact_PhaseArtifact {
    return {
      skaffoldConfigPath: isSet(object.skaffoldConfigPath) ? globalThis.String(object.skaffoldConfigPath) : "",
      manifestPath: isSet(object.manifestPath) ? globalThis.String(object.manifestPath) : "",
      jobManifestsPath: isSet(object.jobManifestsPath) ? globalThis.String(object.jobManifestsPath) : "",
    };
  },

  toJSON(message: TargetArtifact_PhaseArtifact): unknown {
    const obj: any = {};
    if (message.skaffoldConfigPath !== "") {
      obj.skaffoldConfigPath = message.skaffoldConfigPath;
    }
    if (message.manifestPath !== "") {
      obj.manifestPath = message.manifestPath;
    }
    if (message.jobManifestsPath !== "") {
      obj.jobManifestsPath = message.jobManifestsPath;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetArtifact_PhaseArtifact>, I>>(base?: I): TargetArtifact_PhaseArtifact {
    return TargetArtifact_PhaseArtifact.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetArtifact_PhaseArtifact>, I>>(object: I): TargetArtifact_PhaseArtifact {
    const message = createBaseTargetArtifact_PhaseArtifact();
    message.skaffoldConfigPath = object.skaffoldConfigPath ?? "";
    message.manifestPath = object.manifestPath ?? "";
    message.jobManifestsPath = object.jobManifestsPath ?? "";
    return message;
  },
};

function createBaseTargetArtifact_PhaseArtifactsEntry(): TargetArtifact_PhaseArtifactsEntry {
  return { key: "", value: undefined };
}

export const TargetArtifact_PhaseArtifactsEntry: MessageFns<TargetArtifact_PhaseArtifactsEntry> = {
  encode(message: TargetArtifact_PhaseArtifactsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      TargetArtifact_PhaseArtifact.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetArtifact_PhaseArtifactsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetArtifact_PhaseArtifactsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = TargetArtifact_PhaseArtifact.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetArtifact_PhaseArtifactsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? TargetArtifact_PhaseArtifact.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: TargetArtifact_PhaseArtifactsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = TargetArtifact_PhaseArtifact.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetArtifact_PhaseArtifactsEntry>, I>>(
    base?: I,
  ): TargetArtifact_PhaseArtifactsEntry {
    return TargetArtifact_PhaseArtifactsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetArtifact_PhaseArtifactsEntry>, I>>(
    object: I,
  ): TargetArtifact_PhaseArtifactsEntry {
    const message = createBaseTargetArtifact_PhaseArtifactsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? TargetArtifact_PhaseArtifact.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseCloudRunRenderMetadata(): CloudRunRenderMetadata {
  return { service: "" };
}

export const CloudRunRenderMetadata: MessageFns<CloudRunRenderMetadata> = {
  encode(message: CloudRunRenderMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudRunRenderMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudRunRenderMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudRunRenderMetadata {
    return { service: isSet(object.service) ? globalThis.String(object.service) : "" };
  },

  toJSON(message: CloudRunRenderMetadata): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloudRunRenderMetadata>, I>>(base?: I): CloudRunRenderMetadata {
    return CloudRunRenderMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloudRunRenderMetadata>, I>>(object: I): CloudRunRenderMetadata {
    const message = createBaseCloudRunRenderMetadata();
    message.service = object.service ?? "";
    return message;
  },
};

function createBaseRenderMetadata(): RenderMetadata {
  return { cloudRun: undefined, custom: undefined };
}

export const RenderMetadata: MessageFns<RenderMetadata> = {
  encode(message: RenderMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudRun !== undefined) {
      CloudRunRenderMetadata.encode(message.cloudRun, writer.uint32(10).fork()).join();
    }
    if (message.custom !== undefined) {
      CustomMetadata.encode(message.custom, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RenderMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRenderMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cloudRun = CloudRunRenderMetadata.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.custom = CustomMetadata.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RenderMetadata {
    return {
      cloudRun: isSet(object.cloudRun) ? CloudRunRenderMetadata.fromJSON(object.cloudRun) : undefined,
      custom: isSet(object.custom) ? CustomMetadata.fromJSON(object.custom) : undefined,
    };
  },

  toJSON(message: RenderMetadata): unknown {
    const obj: any = {};
    if (message.cloudRun !== undefined) {
      obj.cloudRun = CloudRunRenderMetadata.toJSON(message.cloudRun);
    }
    if (message.custom !== undefined) {
      obj.custom = CustomMetadata.toJSON(message.custom);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RenderMetadata>, I>>(base?: I): RenderMetadata {
    return RenderMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RenderMetadata>, I>>(object: I): RenderMetadata {
    const message = createBaseRenderMetadata();
    message.cloudRun = (object.cloudRun !== undefined && object.cloudRun !== null)
      ? CloudRunRenderMetadata.fromPartial(object.cloudRun)
      : undefined;
    message.custom = (object.custom !== undefined && object.custom !== null)
      ? CustomMetadata.fromPartial(object.custom)
      : undefined;
    return message;
  },
};

function createBaseRollout(): Rollout {
  return {
    name: "",
    uid: "",
    description: "",
    annotations: {},
    labels: {},
    createTime: undefined,
    approveTime: undefined,
    enqueueTime: undefined,
    deployStartTime: undefined,
    deployEndTime: undefined,
    targetId: "",
    approvalState: 0,
    state: 0,
    failureReason: "",
    deployingBuild: "",
    etag: "",
    deployFailureCause: 0,
    phases: [],
    metadata: undefined,
    controllerRollout: "",
    rollbackOfRollout: "",
    rolledBackByRollouts: [],
  };
}

export const Rollout: MessageFns<Rollout> = {
  encode(message: Rollout, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      Rollout_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      Rollout_LabelsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.approveTime !== undefined) {
      Timestamp.encode(toTimestamp(message.approveTime), writer.uint32(58).fork()).join();
    }
    if (message.enqueueTime !== undefined) {
      Timestamp.encode(toTimestamp(message.enqueueTime), writer.uint32(66).fork()).join();
    }
    if (message.deployStartTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deployStartTime), writer.uint32(74).fork()).join();
    }
    if (message.deployEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deployEndTime), writer.uint32(82).fork()).join();
    }
    if (message.targetId !== "") {
      writer.uint32(146).string(message.targetId);
    }
    if (message.approvalState !== 0) {
      writer.uint32(96).int32(message.approvalState);
    }
    if (message.state !== 0) {
      writer.uint32(104).int32(message.state);
    }
    if (message.failureReason !== "") {
      writer.uint32(114).string(message.failureReason);
    }
    if (message.deployingBuild !== "") {
      writer.uint32(138).string(message.deployingBuild);
    }
    if (message.etag !== "") {
      writer.uint32(130).string(message.etag);
    }
    if (message.deployFailureCause !== 0) {
      writer.uint32(152).int32(message.deployFailureCause);
    }
    for (const v of message.phases) {
      Phase.encode(v!, writer.uint32(186).fork()).join();
    }
    if (message.metadata !== undefined) {
      Metadata.encode(message.metadata, writer.uint32(194).fork()).join();
    }
    if (message.controllerRollout !== "") {
      writer.uint32(202).string(message.controllerRollout);
    }
    if (message.rollbackOfRollout !== "") {
      writer.uint32(210).string(message.rollbackOfRollout);
    }
    for (const v of message.rolledBackByRollouts) {
      writer.uint32(218).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Rollout {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollout();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Rollout_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.annotations[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Rollout_LabelsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.labels[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.approveTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.enqueueTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.deployStartTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.deployEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.targetId = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.approvalState = reader.int32() as any;
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.failureReason = reader.string();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.deployingBuild = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 19: {
          if (tag !== 152) {
            break;
          }

          message.deployFailureCause = reader.int32() as any;
          continue;
        }
        case 23: {
          if (tag !== 186) {
            break;
          }

          message.phases.push(Phase.decode(reader, reader.uint32()));
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.metadata = Metadata.decode(reader, reader.uint32());
          continue;
        }
        case 25: {
          if (tag !== 202) {
            break;
          }

          message.controllerRollout = reader.string();
          continue;
        }
        case 26: {
          if (tag !== 210) {
            break;
          }

          message.rollbackOfRollout = reader.string();
          continue;
        }
        case 27: {
          if (tag !== 218) {
            break;
          }

          message.rolledBackByRollouts.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Rollout {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      approveTime: isSet(object.approveTime) ? fromJsonTimestamp(object.approveTime) : undefined,
      enqueueTime: isSet(object.enqueueTime) ? fromJsonTimestamp(object.enqueueTime) : undefined,
      deployStartTime: isSet(object.deployStartTime) ? fromJsonTimestamp(object.deployStartTime) : undefined,
      deployEndTime: isSet(object.deployEndTime) ? fromJsonTimestamp(object.deployEndTime) : undefined,
      targetId: isSet(object.targetId) ? globalThis.String(object.targetId) : "",
      approvalState: isSet(object.approvalState) ? rollout_ApprovalStateFromJSON(object.approvalState) : 0,
      state: isSet(object.state) ? rollout_StateFromJSON(object.state) : 0,
      failureReason: isSet(object.failureReason) ? globalThis.String(object.failureReason) : "",
      deployingBuild: isSet(object.deployingBuild) ? globalThis.String(object.deployingBuild) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      deployFailureCause: isSet(object.deployFailureCause)
        ? rollout_FailureCauseFromJSON(object.deployFailureCause)
        : 0,
      phases: globalThis.Array.isArray(object?.phases) ? object.phases.map((e: any) => Phase.fromJSON(e)) : [],
      metadata: isSet(object.metadata) ? Metadata.fromJSON(object.metadata) : undefined,
      controllerRollout: isSet(object.controllerRollout) ? globalThis.String(object.controllerRollout) : "",
      rollbackOfRollout: isSet(object.rollbackOfRollout) ? globalThis.String(object.rollbackOfRollout) : "",
      rolledBackByRollouts: globalThis.Array.isArray(object?.rolledBackByRollouts)
        ? object.rolledBackByRollouts.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Rollout): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.approveTime !== undefined) {
      obj.approveTime = message.approveTime.toISOString();
    }
    if (message.enqueueTime !== undefined) {
      obj.enqueueTime = message.enqueueTime.toISOString();
    }
    if (message.deployStartTime !== undefined) {
      obj.deployStartTime = message.deployStartTime.toISOString();
    }
    if (message.deployEndTime !== undefined) {
      obj.deployEndTime = message.deployEndTime.toISOString();
    }
    if (message.targetId !== "") {
      obj.targetId = message.targetId;
    }
    if (message.approvalState !== 0) {
      obj.approvalState = rollout_ApprovalStateToJSON(message.approvalState);
    }
    if (message.state !== 0) {
      obj.state = rollout_StateToJSON(message.state);
    }
    if (message.failureReason !== "") {
      obj.failureReason = message.failureReason;
    }
    if (message.deployingBuild !== "") {
      obj.deployingBuild = message.deployingBuild;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.deployFailureCause !== 0) {
      obj.deployFailureCause = rollout_FailureCauseToJSON(message.deployFailureCause);
    }
    if (message.phases?.length) {
      obj.phases = message.phases.map((e) => Phase.toJSON(e));
    }
    if (message.metadata !== undefined) {
      obj.metadata = Metadata.toJSON(message.metadata);
    }
    if (message.controllerRollout !== "") {
      obj.controllerRollout = message.controllerRollout;
    }
    if (message.rollbackOfRollout !== "") {
      obj.rollbackOfRollout = message.rollbackOfRollout;
    }
    if (message.rolledBackByRollouts?.length) {
      obj.rolledBackByRollouts = message.rolledBackByRollouts;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Rollout>, I>>(base?: I): Rollout {
    return Rollout.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Rollout>, I>>(object: I): Rollout {
    const message = createBaseRollout();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.createTime = object.createTime ?? undefined;
    message.approveTime = object.approveTime ?? undefined;
    message.enqueueTime = object.enqueueTime ?? undefined;
    message.deployStartTime = object.deployStartTime ?? undefined;
    message.deployEndTime = object.deployEndTime ?? undefined;
    message.targetId = object.targetId ?? "";
    message.approvalState = object.approvalState ?? 0;
    message.state = object.state ?? 0;
    message.failureReason = object.failureReason ?? "";
    message.deployingBuild = object.deployingBuild ?? "";
    message.etag = object.etag ?? "";
    message.deployFailureCause = object.deployFailureCause ?? 0;
    message.phases = object.phases?.map((e) => Phase.fromPartial(e)) || [];
    message.metadata = (object.metadata !== undefined && object.metadata !== null)
      ? Metadata.fromPartial(object.metadata)
      : undefined;
    message.controllerRollout = object.controllerRollout ?? "";
    message.rollbackOfRollout = object.rollbackOfRollout ?? "";
    message.rolledBackByRollouts = object.rolledBackByRollouts?.map((e) => e) || [];
    return message;
  },
};

function createBaseRollout_AnnotationsEntry(): Rollout_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Rollout_AnnotationsEntry: MessageFns<Rollout_AnnotationsEntry> = {
  encode(message: Rollout_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Rollout_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollout_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Rollout_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Rollout_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Rollout_AnnotationsEntry>, I>>(base?: I): Rollout_AnnotationsEntry {
    return Rollout_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Rollout_AnnotationsEntry>, I>>(object: I): Rollout_AnnotationsEntry {
    const message = createBaseRollout_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRollout_LabelsEntry(): Rollout_LabelsEntry {
  return { key: "", value: "" };
}

export const Rollout_LabelsEntry: MessageFns<Rollout_LabelsEntry> = {
  encode(message: Rollout_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Rollout_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollout_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Rollout_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Rollout_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Rollout_LabelsEntry>, I>>(base?: I): Rollout_LabelsEntry {
    return Rollout_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Rollout_LabelsEntry>, I>>(object: I): Rollout_LabelsEntry {
    const message = createBaseRollout_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMetadata(): Metadata {
  return { cloudRun: undefined, automation: undefined, custom: undefined };
}

export const Metadata: MessageFns<Metadata> = {
  encode(message: Metadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudRun !== undefined) {
      CloudRunMetadata.encode(message.cloudRun, writer.uint32(10).fork()).join();
    }
    if (message.automation !== undefined) {
      AutomationRolloutMetadata.encode(message.automation, writer.uint32(18).fork()).join();
    }
    if (message.custom !== undefined) {
      CustomMetadata.encode(message.custom, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Metadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cloudRun = CloudRunMetadata.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.automation = AutomationRolloutMetadata.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.custom = CustomMetadata.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Metadata {
    return {
      cloudRun: isSet(object.cloudRun) ? CloudRunMetadata.fromJSON(object.cloudRun) : undefined,
      automation: isSet(object.automation) ? AutomationRolloutMetadata.fromJSON(object.automation) : undefined,
      custom: isSet(object.custom) ? CustomMetadata.fromJSON(object.custom) : undefined,
    };
  },

  toJSON(message: Metadata): unknown {
    const obj: any = {};
    if (message.cloudRun !== undefined) {
      obj.cloudRun = CloudRunMetadata.toJSON(message.cloudRun);
    }
    if (message.automation !== undefined) {
      obj.automation = AutomationRolloutMetadata.toJSON(message.automation);
    }
    if (message.custom !== undefined) {
      obj.custom = CustomMetadata.toJSON(message.custom);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Metadata>, I>>(base?: I): Metadata {
    return Metadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Metadata>, I>>(object: I): Metadata {
    const message = createBaseMetadata();
    message.cloudRun = (object.cloudRun !== undefined && object.cloudRun !== null)
      ? CloudRunMetadata.fromPartial(object.cloudRun)
      : undefined;
    message.automation = (object.automation !== undefined && object.automation !== null)
      ? AutomationRolloutMetadata.fromPartial(object.automation)
      : undefined;
    message.custom = (object.custom !== undefined && object.custom !== null)
      ? CustomMetadata.fromPartial(object.custom)
      : undefined;
    return message;
  },
};

function createBaseCloudRunMetadata(): CloudRunMetadata {
  return { service: "", serviceUrls: [], revision: "", job: "" };
}

export const CloudRunMetadata: MessageFns<CloudRunMetadata> = {
  encode(message: CloudRunMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    for (const v of message.serviceUrls) {
      writer.uint32(18).string(v!);
    }
    if (message.revision !== "") {
      writer.uint32(26).string(message.revision);
    }
    if (message.job !== "") {
      writer.uint32(34).string(message.job);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudRunMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudRunMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.serviceUrls.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.revision = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.job = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudRunMetadata {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      serviceUrls: globalThis.Array.isArray(object?.serviceUrls)
        ? object.serviceUrls.map((e: any) => globalThis.String(e))
        : [],
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
      job: isSet(object.job) ? globalThis.String(object.job) : "",
    };
  },

  toJSON(message: CloudRunMetadata): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.serviceUrls?.length) {
      obj.serviceUrls = message.serviceUrls;
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    if (message.job !== "") {
      obj.job = message.job;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloudRunMetadata>, I>>(base?: I): CloudRunMetadata {
    return CloudRunMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloudRunMetadata>, I>>(object: I): CloudRunMetadata {
    const message = createBaseCloudRunMetadata();
    message.service = object.service ?? "";
    message.serviceUrls = object.serviceUrls?.map((e) => e) || [];
    message.revision = object.revision ?? "";
    message.job = object.job ?? "";
    return message;
  },
};

function createBaseAutomationRolloutMetadata(): AutomationRolloutMetadata {
  return {
    promoteAutomationRun: "",
    advanceAutomationRuns: [],
    repairAutomationRuns: [],
    currentRepairAutomationRun: "",
  };
}

export const AutomationRolloutMetadata: MessageFns<AutomationRolloutMetadata> = {
  encode(message: AutomationRolloutMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.promoteAutomationRun !== "") {
      writer.uint32(10).string(message.promoteAutomationRun);
    }
    for (const v of message.advanceAutomationRuns) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.repairAutomationRuns) {
      writer.uint32(26).string(v!);
    }
    if (message.currentRepairAutomationRun !== "") {
      writer.uint32(34).string(message.currentRepairAutomationRun);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomationRolloutMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomationRolloutMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.promoteAutomationRun = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.advanceAutomationRuns.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.repairAutomationRuns.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.currentRepairAutomationRun = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutomationRolloutMetadata {
    return {
      promoteAutomationRun: isSet(object.promoteAutomationRun) ? globalThis.String(object.promoteAutomationRun) : "",
      advanceAutomationRuns: globalThis.Array.isArray(object?.advanceAutomationRuns)
        ? object.advanceAutomationRuns.map((e: any) => globalThis.String(e))
        : [],
      repairAutomationRuns: globalThis.Array.isArray(object?.repairAutomationRuns)
        ? object.repairAutomationRuns.map((e: any) => globalThis.String(e))
        : [],
      currentRepairAutomationRun: isSet(object.currentRepairAutomationRun)
        ? globalThis.String(object.currentRepairAutomationRun)
        : "",
    };
  },

  toJSON(message: AutomationRolloutMetadata): unknown {
    const obj: any = {};
    if (message.promoteAutomationRun !== "") {
      obj.promoteAutomationRun = message.promoteAutomationRun;
    }
    if (message.advanceAutomationRuns?.length) {
      obj.advanceAutomationRuns = message.advanceAutomationRuns;
    }
    if (message.repairAutomationRuns?.length) {
      obj.repairAutomationRuns = message.repairAutomationRuns;
    }
    if (message.currentRepairAutomationRun !== "") {
      obj.currentRepairAutomationRun = message.currentRepairAutomationRun;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AutomationRolloutMetadata>, I>>(base?: I): AutomationRolloutMetadata {
    return AutomationRolloutMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AutomationRolloutMetadata>, I>>(object: I): AutomationRolloutMetadata {
    const message = createBaseAutomationRolloutMetadata();
    message.promoteAutomationRun = object.promoteAutomationRun ?? "";
    message.advanceAutomationRuns = object.advanceAutomationRuns?.map((e) => e) || [];
    message.repairAutomationRuns = object.repairAutomationRuns?.map((e) => e) || [];
    message.currentRepairAutomationRun = object.currentRepairAutomationRun ?? "";
    return message;
  },
};

function createBaseCustomMetadata(): CustomMetadata {
  return { values: {} };
}

export const CustomMetadata: MessageFns<CustomMetadata> = {
  encode(message: CustomMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    Object.entries(message.values).forEach(([key, value]) => {
      CustomMetadata_ValuesEntry.encode({ key: key as any, value }, writer.uint32(10).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          const entry1 = CustomMetadata_ValuesEntry.decode(reader, reader.uint32());
          if (entry1.value !== undefined) {
            message.values[entry1.key] = entry1.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomMetadata {
    return {
      values: isObject(object.values)
        ? Object.entries(object.values).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
    };
  },

  toJSON(message: CustomMetadata): unknown {
    const obj: any = {};
    if (message.values) {
      const entries = Object.entries(message.values);
      if (entries.length > 0) {
        obj.values = {};
        entries.forEach(([k, v]) => {
          obj.values[k] = v;
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomMetadata>, I>>(base?: I): CustomMetadata {
    return CustomMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomMetadata>, I>>(object: I): CustomMetadata {
    const message = createBaseCustomMetadata();
    message.values = Object.entries(object.values ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseCustomMetadata_ValuesEntry(): CustomMetadata_ValuesEntry {
  return { key: "", value: "" };
}

export const CustomMetadata_ValuesEntry: MessageFns<CustomMetadata_ValuesEntry> = {
  encode(message: CustomMetadata_ValuesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomMetadata_ValuesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomMetadata_ValuesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomMetadata_ValuesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: CustomMetadata_ValuesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomMetadata_ValuesEntry>, I>>(base?: I): CustomMetadata_ValuesEntry {
    return CustomMetadata_ValuesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomMetadata_ValuesEntry>, I>>(object: I): CustomMetadata_ValuesEntry {
    const message = createBaseCustomMetadata_ValuesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBasePhase(): Phase {
  return { id: "", state: 0, skipMessage: "", deploymentJobs: undefined, childRolloutJobs: undefined };
}

export const Phase: MessageFns<Phase> = {
  encode(message: Phase, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.skipMessage !== "") {
      writer.uint32(50).string(message.skipMessage);
    }
    if (message.deploymentJobs !== undefined) {
      DeploymentJobs.encode(message.deploymentJobs, writer.uint32(34).fork()).join();
    }
    if (message.childRolloutJobs !== undefined) {
      ChildRolloutJobs.encode(message.childRolloutJobs, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Phase {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePhase();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.skipMessage = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.deploymentJobs = DeploymentJobs.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.childRolloutJobs = ChildRolloutJobs.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Phase {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      state: isSet(object.state) ? phase_StateFromJSON(object.state) : 0,
      skipMessage: isSet(object.skipMessage) ? globalThis.String(object.skipMessage) : "",
      deploymentJobs: isSet(object.deploymentJobs) ? DeploymentJobs.fromJSON(object.deploymentJobs) : undefined,
      childRolloutJobs: isSet(object.childRolloutJobs) ? ChildRolloutJobs.fromJSON(object.childRolloutJobs) : undefined,
    };
  },

  toJSON(message: Phase): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.state !== 0) {
      obj.state = phase_StateToJSON(message.state);
    }
    if (message.skipMessage !== "") {
      obj.skipMessage = message.skipMessage;
    }
    if (message.deploymentJobs !== undefined) {
      obj.deploymentJobs = DeploymentJobs.toJSON(message.deploymentJobs);
    }
    if (message.childRolloutJobs !== undefined) {
      obj.childRolloutJobs = ChildRolloutJobs.toJSON(message.childRolloutJobs);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Phase>, I>>(base?: I): Phase {
    return Phase.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Phase>, I>>(object: I): Phase {
    const message = createBasePhase();
    message.id = object.id ?? "";
    message.state = object.state ?? 0;
    message.skipMessage = object.skipMessage ?? "";
    message.deploymentJobs = (object.deploymentJobs !== undefined && object.deploymentJobs !== null)
      ? DeploymentJobs.fromPartial(object.deploymentJobs)
      : undefined;
    message.childRolloutJobs = (object.childRolloutJobs !== undefined && object.childRolloutJobs !== null)
      ? ChildRolloutJobs.fromPartial(object.childRolloutJobs)
      : undefined;
    return message;
  },
};

function createBaseDeploymentJobs(): DeploymentJobs {
  return { deployJob: undefined, verifyJob: undefined, predeployJob: undefined, postdeployJob: undefined };
}

export const DeploymentJobs: MessageFns<DeploymentJobs> = {
  encode(message: DeploymentJobs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.deployJob !== undefined) {
      Job.encode(message.deployJob, writer.uint32(10).fork()).join();
    }
    if (message.verifyJob !== undefined) {
      Job.encode(message.verifyJob, writer.uint32(18).fork()).join();
    }
    if (message.predeployJob !== undefined) {
      Job.encode(message.predeployJob, writer.uint32(26).fork()).join();
    }
    if (message.postdeployJob !== undefined) {
      Job.encode(message.postdeployJob, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeploymentJobs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeploymentJobs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.deployJob = Job.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.verifyJob = Job.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.predeployJob = Job.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.postdeployJob = Job.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeploymentJobs {
    return {
      deployJob: isSet(object.deployJob) ? Job.fromJSON(object.deployJob) : undefined,
      verifyJob: isSet(object.verifyJob) ? Job.fromJSON(object.verifyJob) : undefined,
      predeployJob: isSet(object.predeployJob) ? Job.fromJSON(object.predeployJob) : undefined,
      postdeployJob: isSet(object.postdeployJob) ? Job.fromJSON(object.postdeployJob) : undefined,
    };
  },

  toJSON(message: DeploymentJobs): unknown {
    const obj: any = {};
    if (message.deployJob !== undefined) {
      obj.deployJob = Job.toJSON(message.deployJob);
    }
    if (message.verifyJob !== undefined) {
      obj.verifyJob = Job.toJSON(message.verifyJob);
    }
    if (message.predeployJob !== undefined) {
      obj.predeployJob = Job.toJSON(message.predeployJob);
    }
    if (message.postdeployJob !== undefined) {
      obj.postdeployJob = Job.toJSON(message.postdeployJob);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeploymentJobs>, I>>(base?: I): DeploymentJobs {
    return DeploymentJobs.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeploymentJobs>, I>>(object: I): DeploymentJobs {
    const message = createBaseDeploymentJobs();
    message.deployJob = (object.deployJob !== undefined && object.deployJob !== null)
      ? Job.fromPartial(object.deployJob)
      : undefined;
    message.verifyJob = (object.verifyJob !== undefined && object.verifyJob !== null)
      ? Job.fromPartial(object.verifyJob)
      : undefined;
    message.predeployJob = (object.predeployJob !== undefined && object.predeployJob !== null)
      ? Job.fromPartial(object.predeployJob)
      : undefined;
    message.postdeployJob = (object.postdeployJob !== undefined && object.postdeployJob !== null)
      ? Job.fromPartial(object.postdeployJob)
      : undefined;
    return message;
  },
};

function createBaseChildRolloutJobs(): ChildRolloutJobs {
  return { createRolloutJobs: [], advanceRolloutJobs: [] };
}

export const ChildRolloutJobs: MessageFns<ChildRolloutJobs> = {
  encode(message: ChildRolloutJobs, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.createRolloutJobs) {
      Job.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.advanceRolloutJobs) {
      Job.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ChildRolloutJobs {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseChildRolloutJobs();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.createRolloutJobs.push(Job.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.advanceRolloutJobs.push(Job.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ChildRolloutJobs {
    return {
      createRolloutJobs: globalThis.Array.isArray(object?.createRolloutJobs)
        ? object.createRolloutJobs.map((e: any) => Job.fromJSON(e))
        : [],
      advanceRolloutJobs: globalThis.Array.isArray(object?.advanceRolloutJobs)
        ? object.advanceRolloutJobs.map((e: any) => Job.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ChildRolloutJobs): unknown {
    const obj: any = {};
    if (message.createRolloutJobs?.length) {
      obj.createRolloutJobs = message.createRolloutJobs.map((e) => Job.toJSON(e));
    }
    if (message.advanceRolloutJobs?.length) {
      obj.advanceRolloutJobs = message.advanceRolloutJobs.map((e) => Job.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ChildRolloutJobs>, I>>(base?: I): ChildRolloutJobs {
    return ChildRolloutJobs.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ChildRolloutJobs>, I>>(object: I): ChildRolloutJobs {
    const message = createBaseChildRolloutJobs();
    message.createRolloutJobs = object.createRolloutJobs?.map((e) => Job.fromPartial(e)) || [];
    message.advanceRolloutJobs = object.advanceRolloutJobs?.map((e) => Job.fromPartial(e)) || [];
    return message;
  },
};

function createBaseJob(): Job {
  return {
    id: "",
    state: 0,
    skipMessage: "",
    jobRun: "",
    deployJob: undefined,
    verifyJob: undefined,
    predeployJob: undefined,
    postdeployJob: undefined,
    createChildRolloutJob: undefined,
    advanceChildRolloutJob: undefined,
  };
}

export const Job: MessageFns<Job> = {
  encode(message: Job, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.skipMessage !== "") {
      writer.uint32(66).string(message.skipMessage);
    }
    if (message.jobRun !== "") {
      writer.uint32(26).string(message.jobRun);
    }
    if (message.deployJob !== undefined) {
      DeployJob.encode(message.deployJob, writer.uint32(34).fork()).join();
    }
    if (message.verifyJob !== undefined) {
      VerifyJob.encode(message.verifyJob, writer.uint32(42).fork()).join();
    }
    if (message.predeployJob !== undefined) {
      PredeployJob.encode(message.predeployJob, writer.uint32(74).fork()).join();
    }
    if (message.postdeployJob !== undefined) {
      PostdeployJob.encode(message.postdeployJob, writer.uint32(82).fork()).join();
    }
    if (message.createChildRolloutJob !== undefined) {
      CreateChildRolloutJob.encode(message.createChildRolloutJob, writer.uint32(50).fork()).join();
    }
    if (message.advanceChildRolloutJob !== undefined) {
      AdvanceChildRolloutJob.encode(message.advanceChildRolloutJob, writer.uint32(58).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Job {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.skipMessage = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.jobRun = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.deployJob = DeployJob.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.verifyJob = VerifyJob.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.predeployJob = PredeployJob.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.postdeployJob = PostdeployJob.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createChildRolloutJob = CreateChildRolloutJob.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.advanceChildRolloutJob = AdvanceChildRolloutJob.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Job {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      state: isSet(object.state) ? job_StateFromJSON(object.state) : 0,
      skipMessage: isSet(object.skipMessage) ? globalThis.String(object.skipMessage) : "",
      jobRun: isSet(object.jobRun) ? globalThis.String(object.jobRun) : "",
      deployJob: isSet(object.deployJob) ? DeployJob.fromJSON(object.deployJob) : undefined,
      verifyJob: isSet(object.verifyJob) ? VerifyJob.fromJSON(object.verifyJob) : undefined,
      predeployJob: isSet(object.predeployJob) ? PredeployJob.fromJSON(object.predeployJob) : undefined,
      postdeployJob: isSet(object.postdeployJob) ? PostdeployJob.fromJSON(object.postdeployJob) : undefined,
      createChildRolloutJob: isSet(object.createChildRolloutJob)
        ? CreateChildRolloutJob.fromJSON(object.createChildRolloutJob)
        : undefined,
      advanceChildRolloutJob: isSet(object.advanceChildRolloutJob)
        ? AdvanceChildRolloutJob.fromJSON(object.advanceChildRolloutJob)
        : undefined,
    };
  },

  toJSON(message: Job): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.state !== 0) {
      obj.state = job_StateToJSON(message.state);
    }
    if (message.skipMessage !== "") {
      obj.skipMessage = message.skipMessage;
    }
    if (message.jobRun !== "") {
      obj.jobRun = message.jobRun;
    }
    if (message.deployJob !== undefined) {
      obj.deployJob = DeployJob.toJSON(message.deployJob);
    }
    if (message.verifyJob !== undefined) {
      obj.verifyJob = VerifyJob.toJSON(message.verifyJob);
    }
    if (message.predeployJob !== undefined) {
      obj.predeployJob = PredeployJob.toJSON(message.predeployJob);
    }
    if (message.postdeployJob !== undefined) {
      obj.postdeployJob = PostdeployJob.toJSON(message.postdeployJob);
    }
    if (message.createChildRolloutJob !== undefined) {
      obj.createChildRolloutJob = CreateChildRolloutJob.toJSON(message.createChildRolloutJob);
    }
    if (message.advanceChildRolloutJob !== undefined) {
      obj.advanceChildRolloutJob = AdvanceChildRolloutJob.toJSON(message.advanceChildRolloutJob);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Job>, I>>(base?: I): Job {
    return Job.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Job>, I>>(object: I): Job {
    const message = createBaseJob();
    message.id = object.id ?? "";
    message.state = object.state ?? 0;
    message.skipMessage = object.skipMessage ?? "";
    message.jobRun = object.jobRun ?? "";
    message.deployJob = (object.deployJob !== undefined && object.deployJob !== null)
      ? DeployJob.fromPartial(object.deployJob)
      : undefined;
    message.verifyJob = (object.verifyJob !== undefined && object.verifyJob !== null)
      ? VerifyJob.fromPartial(object.verifyJob)
      : undefined;
    message.predeployJob = (object.predeployJob !== undefined && object.predeployJob !== null)
      ? PredeployJob.fromPartial(object.predeployJob)
      : undefined;
    message.postdeployJob = (object.postdeployJob !== undefined && object.postdeployJob !== null)
      ? PostdeployJob.fromPartial(object.postdeployJob)
      : undefined;
    message.createChildRolloutJob =
      (object.createChildRolloutJob !== undefined && object.createChildRolloutJob !== null)
        ? CreateChildRolloutJob.fromPartial(object.createChildRolloutJob)
        : undefined;
    message.advanceChildRolloutJob =
      (object.advanceChildRolloutJob !== undefined && object.advanceChildRolloutJob !== null)
        ? AdvanceChildRolloutJob.fromPartial(object.advanceChildRolloutJob)
        : undefined;
    return message;
  },
};

function createBaseDeployJob(): DeployJob {
  return {};
}

export const DeployJob: MessageFns<DeployJob> = {
  encode(_: DeployJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeployJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeployJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DeployJob {
    return {};
  },

  toJSON(_: DeployJob): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<DeployJob>, I>>(base?: I): DeployJob {
    return DeployJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeployJob>, I>>(_: I): DeployJob {
    const message = createBaseDeployJob();
    return message;
  },
};

function createBaseVerifyJob(): VerifyJob {
  return {};
}

export const VerifyJob: MessageFns<VerifyJob> = {
  encode(_: VerifyJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VerifyJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVerifyJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): VerifyJob {
    return {};
  },

  toJSON(_: VerifyJob): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<VerifyJob>, I>>(base?: I): VerifyJob {
    return VerifyJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VerifyJob>, I>>(_: I): VerifyJob {
    const message = createBaseVerifyJob();
    return message;
  },
};

function createBasePredeployJob(): PredeployJob {
  return { actions: [] };
}

export const PredeployJob: MessageFns<PredeployJob> = {
  encode(message: PredeployJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.actions) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PredeployJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePredeployJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.actions.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PredeployJob {
    return {
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: PredeployJob): unknown {
    const obj: any = {};
    if (message.actions?.length) {
      obj.actions = message.actions;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PredeployJob>, I>>(base?: I): PredeployJob {
    return PredeployJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PredeployJob>, I>>(object: I): PredeployJob {
    const message = createBasePredeployJob();
    message.actions = object.actions?.map((e) => e) || [];
    return message;
  },
};

function createBasePostdeployJob(): PostdeployJob {
  return { actions: [] };
}

export const PostdeployJob: MessageFns<PostdeployJob> = {
  encode(message: PostdeployJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.actions) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostdeployJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostdeployJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.actions.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostdeployJob {
    return {
      actions: globalThis.Array.isArray(object?.actions) ? object.actions.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: PostdeployJob): unknown {
    const obj: any = {};
    if (message.actions?.length) {
      obj.actions = message.actions;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PostdeployJob>, I>>(base?: I): PostdeployJob {
    return PostdeployJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PostdeployJob>, I>>(object: I): PostdeployJob {
    const message = createBasePostdeployJob();
    message.actions = object.actions?.map((e) => e) || [];
    return message;
  },
};

function createBaseCreateChildRolloutJob(): CreateChildRolloutJob {
  return {};
}

export const CreateChildRolloutJob: MessageFns<CreateChildRolloutJob> = {
  encode(_: CreateChildRolloutJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CreateChildRolloutJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCreateChildRolloutJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): CreateChildRolloutJob {
    return {};
  },

  toJSON(_: CreateChildRolloutJob): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<CreateChildRolloutJob>, I>>(base?: I): CreateChildRolloutJob {
    return CreateChildRolloutJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CreateChildRolloutJob>, I>>(_: I): CreateChildRolloutJob {
    const message = createBaseCreateChildRolloutJob();
    return message;
  },
};

function createBaseAdvanceChildRolloutJob(): AdvanceChildRolloutJob {
  return {};
}

export const AdvanceChildRolloutJob: MessageFns<AdvanceChildRolloutJob> = {
  encode(_: AdvanceChildRolloutJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AdvanceChildRolloutJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAdvanceChildRolloutJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AdvanceChildRolloutJob {
    return {};
  },

  toJSON(_: AdvanceChildRolloutJob): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<AdvanceChildRolloutJob>, I>>(base?: I): AdvanceChildRolloutJob {
    return AdvanceChildRolloutJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AdvanceChildRolloutJob>, I>>(_: I): AdvanceChildRolloutJob {
    const message = createBaseAdvanceChildRolloutJob();
    return message;
  },
};

function createBaseAutomation(): Automation {
  return {
    name: "",
    uid: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    annotations: {},
    labels: {},
    etag: "",
    suspended: false,
    serviceAccount: "",
    selector: undefined,
    rules: [],
  };
}

export const Automation: MessageFns<Automation> = {
  encode(message: Automation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    Object.entries(message.annotations).forEach(([key, value]) => {
      Automation_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    Object.entries(message.labels).forEach(([key, value]) => {
      Automation_LabelsEntry.encode({ key: key as any, value }, writer.uint32(58).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(66).string(message.etag);
    }
    if (message.suspended !== false) {
      writer.uint32(72).bool(message.suspended);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(82).string(message.serviceAccount);
    }
    if (message.selector !== undefined) {
      AutomationResourceSelector.encode(message.selector, writer.uint32(90).fork()).join();
    }
    for (const v of message.rules) {
      AutomationRule.encode(v!, writer.uint32(114).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Automation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Automation_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.annotations[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          const entry7 = Automation_LabelsEntry.decode(reader, reader.uint32());
          if (entry7.value !== undefined) {
            message.labels[entry7.key] = entry7.value;
          }
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.suspended = reader.bool();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.selector = AutomationResourceSelector.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.rules.push(AutomationRule.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Automation {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      suspended: isSet(object.suspended) ? globalThis.Boolean(object.suspended) : false,
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      selector: isSet(object.selector) ? AutomationResourceSelector.fromJSON(object.selector) : undefined,
      rules: globalThis.Array.isArray(object?.rules) ? object.rules.map((e: any) => AutomationRule.fromJSON(e)) : [],
    };
  },

  toJSON(message: Automation): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.suspended !== false) {
      obj.suspended = message.suspended;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.selector !== undefined) {
      obj.selector = AutomationResourceSelector.toJSON(message.selector);
    }
    if (message.rules?.length) {
      obj.rules = message.rules.map((e) => AutomationRule.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Automation>, I>>(base?: I): Automation {
    return Automation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Automation>, I>>(object: I): Automation {
    const message = createBaseAutomation();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.etag = object.etag ?? "";
    message.suspended = object.suspended ?? false;
    message.serviceAccount = object.serviceAccount ?? "";
    message.selector = (object.selector !== undefined && object.selector !== null)
      ? AutomationResourceSelector.fromPartial(object.selector)
      : undefined;
    message.rules = object.rules?.map((e) => AutomationRule.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAutomation_AnnotationsEntry(): Automation_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Automation_AnnotationsEntry: MessageFns<Automation_AnnotationsEntry> = {
  encode(message: Automation_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Automation_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomation_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Automation_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Automation_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Automation_AnnotationsEntry>, I>>(base?: I): Automation_AnnotationsEntry {
    return Automation_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Automation_AnnotationsEntry>, I>>(object: I): Automation_AnnotationsEntry {
    const message = createBaseAutomation_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAutomation_LabelsEntry(): Automation_LabelsEntry {
  return { key: "", value: "" };
}

export const Automation_LabelsEntry: MessageFns<Automation_LabelsEntry> = {
  encode(message: Automation_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Automation_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomation_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Automation_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Automation_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Automation_LabelsEntry>, I>>(base?: I): Automation_LabelsEntry {
    return Automation_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Automation_LabelsEntry>, I>>(object: I): Automation_LabelsEntry {
    const message = createBaseAutomation_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAutomationResourceSelector(): AutomationResourceSelector {
  return { targets: [] };
}

export const AutomationResourceSelector: MessageFns<AutomationResourceSelector> = {
  encode(message: AutomationResourceSelector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.targets) {
      TargetAttribute.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomationResourceSelector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomationResourceSelector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.targets.push(TargetAttribute.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutomationResourceSelector {
    return {
      targets: globalThis.Array.isArray(object?.targets)
        ? object.targets.map((e: any) => TargetAttribute.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AutomationResourceSelector): unknown {
    const obj: any = {};
    if (message.targets?.length) {
      obj.targets = message.targets.map((e) => TargetAttribute.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AutomationResourceSelector>, I>>(base?: I): AutomationResourceSelector {
    return AutomationResourceSelector.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AutomationResourceSelector>, I>>(object: I): AutomationResourceSelector {
    const message = createBaseAutomationResourceSelector();
    message.targets = object.targets?.map((e) => TargetAttribute.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAutomationRule(): AutomationRule {
  return { promoteReleaseRule: undefined, advanceRolloutRule: undefined, repairRolloutRule: undefined };
}

export const AutomationRule: MessageFns<AutomationRule> = {
  encode(message: AutomationRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.promoteReleaseRule !== undefined) {
      PromoteReleaseRule.encode(message.promoteReleaseRule, writer.uint32(10).fork()).join();
    }
    if (message.advanceRolloutRule !== undefined) {
      AdvanceRolloutRule.encode(message.advanceRolloutRule, writer.uint32(18).fork()).join();
    }
    if (message.repairRolloutRule !== undefined) {
      RepairRolloutRule.encode(message.repairRolloutRule, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomationRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomationRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.promoteReleaseRule = PromoteReleaseRule.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.advanceRolloutRule = AdvanceRolloutRule.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.repairRolloutRule = RepairRolloutRule.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutomationRule {
    return {
      promoteReleaseRule: isSet(object.promoteReleaseRule)
        ? PromoteReleaseRule.fromJSON(object.promoteReleaseRule)
        : undefined,
      advanceRolloutRule: isSet(object.advanceRolloutRule)
        ? AdvanceRolloutRule.fromJSON(object.advanceRolloutRule)
        : undefined,
      repairRolloutRule: isSet(object.repairRolloutRule)
        ? RepairRolloutRule.fromJSON(object.repairRolloutRule)
        : undefined,
    };
  },

  toJSON(message: AutomationRule): unknown {
    const obj: any = {};
    if (message.promoteReleaseRule !== undefined) {
      obj.promoteReleaseRule = PromoteReleaseRule.toJSON(message.promoteReleaseRule);
    }
    if (message.advanceRolloutRule !== undefined) {
      obj.advanceRolloutRule = AdvanceRolloutRule.toJSON(message.advanceRolloutRule);
    }
    if (message.repairRolloutRule !== undefined) {
      obj.repairRolloutRule = RepairRolloutRule.toJSON(message.repairRolloutRule);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AutomationRule>, I>>(base?: I): AutomationRule {
    return AutomationRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AutomationRule>, I>>(object: I): AutomationRule {
    const message = createBaseAutomationRule();
    message.promoteReleaseRule = (object.promoteReleaseRule !== undefined && object.promoteReleaseRule !== null)
      ? PromoteReleaseRule.fromPartial(object.promoteReleaseRule)
      : undefined;
    message.advanceRolloutRule = (object.advanceRolloutRule !== undefined && object.advanceRolloutRule !== null)
      ? AdvanceRolloutRule.fromPartial(object.advanceRolloutRule)
      : undefined;
    message.repairRolloutRule = (object.repairRolloutRule !== undefined && object.repairRolloutRule !== null)
      ? RepairRolloutRule.fromPartial(object.repairRolloutRule)
      : undefined;
    return message;
  },
};

function createBasePromoteReleaseRule(): PromoteReleaseRule {
  return { id: "", wait: undefined, destinationTargetId: "", condition: undefined, destinationPhase: "" };
}

export const PromoteReleaseRule: MessageFns<PromoteReleaseRule> = {
  encode(message: PromoteReleaseRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    if (message.wait !== undefined) {
      Duration.encode(message.wait, writer.uint32(18).fork()).join();
    }
    if (message.destinationTargetId !== "") {
      writer.uint32(58).string(message.destinationTargetId);
    }
    if (message.condition !== undefined) {
      AutomationRuleCondition.encode(message.condition, writer.uint32(42).fork()).join();
    }
    if (message.destinationPhase !== "") {
      writer.uint32(66).string(message.destinationPhase);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PromoteReleaseRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePromoteReleaseRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.wait = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.destinationTargetId = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.condition = AutomationRuleCondition.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.destinationPhase = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PromoteReleaseRule {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      wait: isSet(object.wait) ? Duration.fromJSON(object.wait) : undefined,
      destinationTargetId: isSet(object.destinationTargetId) ? globalThis.String(object.destinationTargetId) : "",
      condition: isSet(object.condition) ? AutomationRuleCondition.fromJSON(object.condition) : undefined,
      destinationPhase: isSet(object.destinationPhase) ? globalThis.String(object.destinationPhase) : "",
    };
  },

  toJSON(message: PromoteReleaseRule): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.wait !== undefined) {
      obj.wait = Duration.toJSON(message.wait);
    }
    if (message.destinationTargetId !== "") {
      obj.destinationTargetId = message.destinationTargetId;
    }
    if (message.condition !== undefined) {
      obj.condition = AutomationRuleCondition.toJSON(message.condition);
    }
    if (message.destinationPhase !== "") {
      obj.destinationPhase = message.destinationPhase;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PromoteReleaseRule>, I>>(base?: I): PromoteReleaseRule {
    return PromoteReleaseRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PromoteReleaseRule>, I>>(object: I): PromoteReleaseRule {
    const message = createBasePromoteReleaseRule();
    message.id = object.id ?? "";
    message.wait = (object.wait !== undefined && object.wait !== null) ? Duration.fromPartial(object.wait) : undefined;
    message.destinationTargetId = object.destinationTargetId ?? "";
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? AutomationRuleCondition.fromPartial(object.condition)
      : undefined;
    message.destinationPhase = object.destinationPhase ?? "";
    return message;
  },
};

function createBaseAdvanceRolloutRule(): AdvanceRolloutRule {
  return { id: "", sourcePhases: [], wait: undefined, condition: undefined };
}

export const AdvanceRolloutRule: MessageFns<AdvanceRolloutRule> = {
  encode(message: AdvanceRolloutRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    for (const v of message.sourcePhases) {
      writer.uint32(50).string(v!);
    }
    if (message.wait !== undefined) {
      Duration.encode(message.wait, writer.uint32(26).fork()).join();
    }
    if (message.condition !== undefined) {
      AutomationRuleCondition.encode(message.condition, writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AdvanceRolloutRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAdvanceRolloutRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.sourcePhases.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.wait = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.condition = AutomationRuleCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AdvanceRolloutRule {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      sourcePhases: globalThis.Array.isArray(object?.sourcePhases)
        ? object.sourcePhases.map((e: any) => globalThis.String(e))
        : [],
      wait: isSet(object.wait) ? Duration.fromJSON(object.wait) : undefined,
      condition: isSet(object.condition) ? AutomationRuleCondition.fromJSON(object.condition) : undefined,
    };
  },

  toJSON(message: AdvanceRolloutRule): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.sourcePhases?.length) {
      obj.sourcePhases = message.sourcePhases;
    }
    if (message.wait !== undefined) {
      obj.wait = Duration.toJSON(message.wait);
    }
    if (message.condition !== undefined) {
      obj.condition = AutomationRuleCondition.toJSON(message.condition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AdvanceRolloutRule>, I>>(base?: I): AdvanceRolloutRule {
    return AdvanceRolloutRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AdvanceRolloutRule>, I>>(object: I): AdvanceRolloutRule {
    const message = createBaseAdvanceRolloutRule();
    message.id = object.id ?? "";
    message.sourcePhases = object.sourcePhases?.map((e) => e) || [];
    message.wait = (object.wait !== undefined && object.wait !== null) ? Duration.fromPartial(object.wait) : undefined;
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? AutomationRuleCondition.fromPartial(object.condition)
      : undefined;
    return message;
  },
};

function createBaseRepairRolloutRule(): RepairRolloutRule {
  return { id: "", sourcePhases: [], jobs: [], repairModes: [], condition: undefined };
}

export const RepairRolloutRule: MessageFns<RepairRolloutRule> = {
  encode(message: RepairRolloutRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.id !== "") {
      writer.uint32(10).string(message.id);
    }
    for (const v of message.sourcePhases) {
      writer.uint32(18).string(v!);
    }
    for (const v of message.jobs) {
      writer.uint32(26).string(v!);
    }
    for (const v of message.repairModes) {
      RepairMode.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.condition !== undefined) {
      AutomationRuleCondition.encode(message.condition, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepairRolloutRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepairRolloutRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.id = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.sourcePhases.push(reader.string());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.jobs.push(reader.string());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.repairModes.push(RepairMode.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.condition = AutomationRuleCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepairRolloutRule {
    return {
      id: isSet(object.id) ? globalThis.String(object.id) : "",
      sourcePhases: globalThis.Array.isArray(object?.sourcePhases)
        ? object.sourcePhases.map((e: any) => globalThis.String(e))
        : [],
      jobs: globalThis.Array.isArray(object?.jobs) ? object.jobs.map((e: any) => globalThis.String(e)) : [],
      repairModes: globalThis.Array.isArray(object?.repairModes)
        ? object.repairModes.map((e: any) => RepairMode.fromJSON(e))
        : [],
      condition: isSet(object.condition) ? AutomationRuleCondition.fromJSON(object.condition) : undefined,
    };
  },

  toJSON(message: RepairRolloutRule): unknown {
    const obj: any = {};
    if (message.id !== "") {
      obj.id = message.id;
    }
    if (message.sourcePhases?.length) {
      obj.sourcePhases = message.sourcePhases;
    }
    if (message.jobs?.length) {
      obj.jobs = message.jobs;
    }
    if (message.repairModes?.length) {
      obj.repairModes = message.repairModes.map((e) => RepairMode.toJSON(e));
    }
    if (message.condition !== undefined) {
      obj.condition = AutomationRuleCondition.toJSON(message.condition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RepairRolloutRule>, I>>(base?: I): RepairRolloutRule {
    return RepairRolloutRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RepairRolloutRule>, I>>(object: I): RepairRolloutRule {
    const message = createBaseRepairRolloutRule();
    message.id = object.id ?? "";
    message.sourcePhases = object.sourcePhases?.map((e) => e) || [];
    message.jobs = object.jobs?.map((e) => e) || [];
    message.repairModes = object.repairModes?.map((e) => RepairMode.fromPartial(e)) || [];
    message.condition = (object.condition !== undefined && object.condition !== null)
      ? AutomationRuleCondition.fromPartial(object.condition)
      : undefined;
    return message;
  },
};

function createBaseRepairMode(): RepairMode {
  return { retry: undefined, rollback: undefined };
}

export const RepairMode: MessageFns<RepairMode> = {
  encode(message: RepairMode, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.retry !== undefined) {
      Retry.encode(message.retry, writer.uint32(10).fork()).join();
    }
    if (message.rollback !== undefined) {
      Rollback.encode(message.rollback, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepairMode {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepairMode();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.retry = Retry.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.rollback = Rollback.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepairMode {
    return {
      retry: isSet(object.retry) ? Retry.fromJSON(object.retry) : undefined,
      rollback: isSet(object.rollback) ? Rollback.fromJSON(object.rollback) : undefined,
    };
  },

  toJSON(message: RepairMode): unknown {
    const obj: any = {};
    if (message.retry !== undefined) {
      obj.retry = Retry.toJSON(message.retry);
    }
    if (message.rollback !== undefined) {
      obj.rollback = Rollback.toJSON(message.rollback);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RepairMode>, I>>(base?: I): RepairMode {
    return RepairMode.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RepairMode>, I>>(object: I): RepairMode {
    const message = createBaseRepairMode();
    message.retry = (object.retry !== undefined && object.retry !== null) ? Retry.fromPartial(object.retry) : undefined;
    message.rollback = (object.rollback !== undefined && object.rollback !== null)
      ? Rollback.fromPartial(object.rollback)
      : undefined;
    return message;
  },
};

function createBaseRetry(): Retry {
  return { attempts: Long.ZERO, wait: undefined, backoffMode: 0 };
}

export const Retry: MessageFns<Retry> = {
  encode(message: Retry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.attempts.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.attempts.toString());
    }
    if (message.wait !== undefined) {
      Duration.encode(message.wait, writer.uint32(18).fork()).join();
    }
    if (message.backoffMode !== 0) {
      writer.uint32(24).int32(message.backoffMode);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Retry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRetry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.attempts = Long.fromString(reader.int64().toString());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.wait = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.backoffMode = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Retry {
    return {
      attempts: isSet(object.attempts) ? Long.fromValue(object.attempts) : Long.ZERO,
      wait: isSet(object.wait) ? Duration.fromJSON(object.wait) : undefined,
      backoffMode: isSet(object.backoffMode) ? backoffModeFromJSON(object.backoffMode) : 0,
    };
  },

  toJSON(message: Retry): unknown {
    const obj: any = {};
    if (!message.attempts.equals(Long.ZERO)) {
      obj.attempts = (message.attempts || Long.ZERO).toString();
    }
    if (message.wait !== undefined) {
      obj.wait = Duration.toJSON(message.wait);
    }
    if (message.backoffMode !== 0) {
      obj.backoffMode = backoffModeToJSON(message.backoffMode);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Retry>, I>>(base?: I): Retry {
    return Retry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Retry>, I>>(object: I): Retry {
    const message = createBaseRetry();
    message.attempts = (object.attempts !== undefined && object.attempts !== null)
      ? Long.fromValue(object.attempts)
      : Long.ZERO;
    message.wait = (object.wait !== undefined && object.wait !== null) ? Duration.fromPartial(object.wait) : undefined;
    message.backoffMode = object.backoffMode ?? 0;
    return message;
  },
};

function createBaseRollback(): Rollback {
  return { destinationPhase: "" };
}

export const Rollback: MessageFns<Rollback> = {
  encode(message: Rollback, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationPhase !== "") {
      writer.uint32(10).string(message.destinationPhase);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Rollback {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRollback();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.destinationPhase = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Rollback {
    return { destinationPhase: isSet(object.destinationPhase) ? globalThis.String(object.destinationPhase) : "" };
  },

  toJSON(message: Rollback): unknown {
    const obj: any = {};
    if (message.destinationPhase !== "") {
      obj.destinationPhase = message.destinationPhase;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Rollback>, I>>(base?: I): Rollback {
    return Rollback.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Rollback>, I>>(object: I): Rollback {
    const message = createBaseRollback();
    message.destinationPhase = object.destinationPhase ?? "";
    return message;
  },
};

function createBaseAutomationRuleCondition(): AutomationRuleCondition {
  return { targetsPresentCondition: undefined };
}

export const AutomationRuleCondition: MessageFns<AutomationRuleCondition> = {
  encode(message: AutomationRuleCondition, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.targetsPresentCondition !== undefined) {
      TargetsPresentCondition.encode(message.targetsPresentCondition, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomationRuleCondition {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomationRuleCondition();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.targetsPresentCondition = TargetsPresentCondition.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutomationRuleCondition {
    return {
      targetsPresentCondition: isSet(object.targetsPresentCondition)
        ? TargetsPresentCondition.fromJSON(object.targetsPresentCondition)
        : undefined,
    };
  },

  toJSON(message: AutomationRuleCondition): unknown {
    const obj: any = {};
    if (message.targetsPresentCondition !== undefined) {
      obj.targetsPresentCondition = TargetsPresentCondition.toJSON(message.targetsPresentCondition);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AutomationRuleCondition>, I>>(base?: I): AutomationRuleCondition {
    return AutomationRuleCondition.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AutomationRuleCondition>, I>>(object: I): AutomationRuleCondition {
    const message = createBaseAutomationRuleCondition();
    message.targetsPresentCondition =
      (object.targetsPresentCondition !== undefined && object.targetsPresentCondition !== null)
        ? TargetsPresentCondition.fromPartial(object.targetsPresentCondition)
        : undefined;
    return message;
  },
};

function createBaseDeliveryPipelineEventData(): DeliveryPipelineEventData {
  return { payload: undefined };
}

export const DeliveryPipelineEventData: MessageFns<DeliveryPipelineEventData> = {
  encode(message: DeliveryPipelineEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DeliveryPipeline.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DeliveryPipelineEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDeliveryPipelineEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DeliveryPipeline.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DeliveryPipelineEventData {
    return { payload: isSet(object.payload) ? DeliveryPipeline.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DeliveryPipelineEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DeliveryPipeline.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DeliveryPipelineEventData>, I>>(base?: I): DeliveryPipelineEventData {
    return DeliveryPipelineEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DeliveryPipelineEventData>, I>>(object: I): DeliveryPipelineEventData {
    const message = createBaseDeliveryPipelineEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DeliveryPipeline.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseTargetEventData(): TargetEventData {
  return { payload: undefined };
}

export const TargetEventData: MessageFns<TargetEventData> = {
  encode(message: TargetEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Target.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Target.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetEventData {
    return { payload: isSet(object.payload) ? Target.fromJSON(object.payload) : undefined };
  },

  toJSON(message: TargetEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Target.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetEventData>, I>>(base?: I): TargetEventData {
    return TargetEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetEventData>, I>>(object: I): TargetEventData {
    const message = createBaseTargetEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Target.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseCustomTargetTypeEventData(): CustomTargetTypeEventData {
  return { payload: undefined };
}

export const CustomTargetTypeEventData: MessageFns<CustomTargetTypeEventData> = {
  encode(message: CustomTargetTypeEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      CustomTargetType.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CustomTargetTypeEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCustomTargetTypeEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = CustomTargetType.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CustomTargetTypeEventData {
    return { payload: isSet(object.payload) ? CustomTargetType.fromJSON(object.payload) : undefined };
  },

  toJSON(message: CustomTargetTypeEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = CustomTargetType.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CustomTargetTypeEventData>, I>>(base?: I): CustomTargetTypeEventData {
    return CustomTargetTypeEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CustomTargetTypeEventData>, I>>(object: I): CustomTargetTypeEventData {
    const message = createBaseCustomTargetTypeEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? CustomTargetType.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseReleaseEventData(): ReleaseEventData {
  return { payload: undefined };
}

export const ReleaseEventData: MessageFns<ReleaseEventData> = {
  encode(message: ReleaseEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Release.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReleaseEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReleaseEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Release.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReleaseEventData {
    return { payload: isSet(object.payload) ? Release.fromJSON(object.payload) : undefined };
  },

  toJSON(message: ReleaseEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Release.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ReleaseEventData>, I>>(base?: I): ReleaseEventData {
    return ReleaseEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ReleaseEventData>, I>>(object: I): ReleaseEventData {
    const message = createBaseReleaseEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Release.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseRolloutEventData(): RolloutEventData {
  return { payload: undefined };
}

export const RolloutEventData: MessageFns<RolloutEventData> = {
  encode(message: RolloutEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Rollout.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RolloutEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRolloutEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Rollout.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RolloutEventData {
    return { payload: isSet(object.payload) ? Rollout.fromJSON(object.payload) : undefined };
  },

  toJSON(message: RolloutEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Rollout.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RolloutEventData>, I>>(base?: I): RolloutEventData {
    return RolloutEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RolloutEventData>, I>>(object: I): RolloutEventData {
    const message = createBaseRolloutEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Rollout.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseAutomationEventData(): AutomationEventData {
  return { payload: undefined };
}

export const AutomationEventData: MessageFns<AutomationEventData> = {
  encode(message: AutomationEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Automation.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AutomationEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAutomationEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Automation.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AutomationEventData {
    return { payload: isSet(object.payload) ? Automation.fromJSON(object.payload) : undefined };
  },

  toJSON(message: AutomationEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Automation.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AutomationEventData>, I>>(base?: I): AutomationEventData {
    return AutomationEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AutomationEventData>, I>>(object: I): AutomationEventData {
    const message = createBaseAutomationEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Automation.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
