// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/functions/v2/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../../protobuf/timestamp";

export const protobufPackage = "google.events.cloud.functions.v2";

/** The environment the function is hosted on. */
export enum Environment {
  /** ENVIRONMENT_UNSPECIFIED - Unspecified */
  ENVIRONMENT_UNSPECIFIED = 0,
  /** GEN_1 - Gen 1 */
  GEN_1 = 1,
  /** GEN_2 - Gen 2 */
  GEN_2 = 2,
  UNRECOGNIZED = -1,
}

export function environmentFromJSON(object: any): Environment {
  switch (object) {
    case 0:
    case "ENVIRONMENT_UNSPECIFIED":
      return Environment.ENVIRONMENT_UNSPECIFIED;
    case 1:
    case "GEN_1":
      return Environment.GEN_1;
    case 2:
    case "GEN_2":
      return Environment.GEN_2;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Environment.UNRECOGNIZED;
  }
}

export function environmentToJSON(object: Environment): string {
  switch (object) {
    case Environment.ENVIRONMENT_UNSPECIFIED:
      return "ENVIRONMENT_UNSPECIFIED";
    case Environment.GEN_1:
      return "GEN_1";
    case Environment.GEN_2:
      return "GEN_2";
    case Environment.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Describes a Cloud Function that contains user computation executed in
 * response to an event. It encapsulates function and trigger configurations.
 */
export interface FunctionMessage {
  /**
   * A user-defined name of the function. Function names must be unique
   * globally and match pattern `projects/* /locations/* /functions/*`
   */
  name: string;
  /** Describe whether the function is gen1 or gen2. */
  environment: Environment;
  /** User-provided description of a function. */
  description: string;
  /**
   * Describes the Build step of the function that builds a container from the
   * given source.
   */
  buildConfig?:
    | BuildConfig
    | undefined;
  /**
   * Describes the Service being deployed. Currently deploys services to Cloud
   * Run (fully managed).
   */
  serviceConfig?:
    | ServiceConfig
    | undefined;
  /**
   * An Eventarc trigger managed by Google Cloud Functions that fires events in
   * response to a condition in another service.
   */
  eventTrigger?:
    | EventTrigger
    | undefined;
  /** Output only. State of the function. */
  state: Function_State;
  /** Output only. The last update timestamp of a Cloud Function. */
  updateTime?:
    | Date
    | undefined;
  /** Labels associated with this Cloud Function. */
  labels: { [key: string]: string };
  /** Output only. State Messages for this Cloud Function. */
  stateMessages: StateMessage[];
}

/** Describes the current state of the function. */
export enum Function_State {
  /** STATE_UNSPECIFIED - Not specified. Invalid state. */
  STATE_UNSPECIFIED = 0,
  /** ACTIVE - Function has been successfully deployed and is serving. */
  ACTIVE = 1,
  /** FAILED - Function deployment failed and the function is not serving. */
  FAILED = 2,
  /** DEPLOYING - Function is being created or updated. */
  DEPLOYING = 3,
  /** DELETING - Function is being deleted. */
  DELETING = 4,
  /**
   * UNKNOWN - Function deployment failed and the function serving state is undefined.
   * The function should be updated or deleted to move it out of this state.
   */
  UNKNOWN = 5,
  UNRECOGNIZED = -1,
}

export function function_StateFromJSON(object: any): Function_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Function_State.STATE_UNSPECIFIED;
    case 1:
    case "ACTIVE":
      return Function_State.ACTIVE;
    case 2:
    case "FAILED":
      return Function_State.FAILED;
    case 3:
    case "DEPLOYING":
      return Function_State.DEPLOYING;
    case 4:
    case "DELETING":
      return Function_State.DELETING;
    case 5:
    case "UNKNOWN":
      return Function_State.UNKNOWN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Function_State.UNRECOGNIZED;
  }
}

export function function_StateToJSON(object: Function_State): string {
  switch (object) {
    case Function_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Function_State.ACTIVE:
      return "ACTIVE";
    case Function_State.FAILED:
      return "FAILED";
    case Function_State.DEPLOYING:
      return "DEPLOYING";
    case Function_State.DELETING:
      return "DELETING";
    case Function_State.UNKNOWN:
      return "UNKNOWN";
    case Function_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Function_LabelsEntry {
  key: string;
  value: string;
}

/** Informational messages about the state of the Cloud Function or Operation. */
export interface StateMessage {
  /** Severity of the state message. */
  severity: StateMessage_Severity;
  /** One-word CamelCase type of the state message. */
  type: string;
  /** The message. */
  message: string;
}

/** Severity of the state message. */
export enum StateMessage_Severity {
  /** SEVERITY_UNSPECIFIED - Not specified. Invalid severity. */
  SEVERITY_UNSPECIFIED = 0,
  /** ERROR - ERROR-level severity. */
  ERROR = 1,
  /** WARNING - WARNING-level severity. */
  WARNING = 2,
  /** INFO - INFO-level severity. */
  INFO = 3,
  UNRECOGNIZED = -1,
}

export function stateMessage_SeverityFromJSON(object: any): StateMessage_Severity {
  switch (object) {
    case 0:
    case "SEVERITY_UNSPECIFIED":
      return StateMessage_Severity.SEVERITY_UNSPECIFIED;
    case 1:
    case "ERROR":
      return StateMessage_Severity.ERROR;
    case 2:
    case "WARNING":
      return StateMessage_Severity.WARNING;
    case 3:
    case "INFO":
      return StateMessage_Severity.INFO;
    case -1:
    case "UNRECOGNIZED":
    default:
      return StateMessage_Severity.UNRECOGNIZED;
  }
}

export function stateMessage_SeverityToJSON(object: StateMessage_Severity): string {
  switch (object) {
    case StateMessage_Severity.SEVERITY_UNSPECIFIED:
      return "SEVERITY_UNSPECIFIED";
    case StateMessage_Severity.ERROR:
      return "ERROR";
    case StateMessage_Severity.WARNING:
      return "WARNING";
    case StateMessage_Severity.INFO:
      return "INFO";
    case StateMessage_Severity.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Location of the source in an archive file in Google Cloud Storage. */
export interface StorageSource {
  /**
   * Google Cloud Storage bucket containing the source (see
   * [Bucket Name
   * Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)).
   */
  bucket: string;
  /**
   * Google Cloud Storage object containing the source.
   *
   * This object must be a gzipped archive file (`.tar.gz`) containing source to
   * build.
   */
  object: string;
  /**
   * Google Cloud Storage generation for the object. If the generation is
   * omitted, the latest generation will be used.
   */
  generation: Long;
}

/** Location of the source in a Google Cloud Source Repository. */
export interface RepoSource {
  /**
   * Regex matching branches to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  branchName?:
    | string
    | undefined;
  /**
   * Regex matching tags to build.
   *
   * The syntax of the regular expressions accepted is the syntax accepted by
   * RE2 and described at https://github.com/google/re2/wiki/Syntax
   */
  tagName?:
    | string
    | undefined;
  /** Explicit commit SHA to build. */
  commitSha?:
    | string
    | undefined;
  /**
   * ID of the project that owns the Cloud Source Repository. If omitted, the
   * project ID requesting the build is assumed.
   */
  projectId: string;
  /** Name of the Cloud Source Repository. */
  repoName: string;
  /**
   * Directory, relative to the source root, in which to run the build.
   *
   * This must be a relative path. If a step's `dir` is specified and is an
   * absolute path, this value is ignored for that step's execution.
   * eg. helloworld (no leading slash allowed)
   */
  dir: string;
  /**
   * Only trigger a build if the revision regex does NOT match the revision
   * regex.
   */
  invertRegex: boolean;
}

/** The location of the function source code. */
export interface Source {
  /** If provided, get the source from this location in Google Cloud Storage. */
  storageSource?:
    | StorageSource
    | undefined;
  /**
   * If provided, get the source from this location in a Cloud Source
   * Repository.
   */
  repoSource?: RepoSource | undefined;
}

/**
 * Provenance of the source. Ways to find the original source, or verify that
 * some source was used for this build.
 */
export interface SourceProvenance {
  /**
   * A copy of the build's `source.storage_source`, if exists, with any
   * generations resolved.
   */
  resolvedStorageSource?:
    | StorageSource
    | undefined;
  /**
   * A copy of the build's `source.repo_source`, if exists, with any
   * revisions resolved.
   */
  resolvedRepoSource?: RepoSource | undefined;
}

/**
 * Describes the Build step of the function that builds a container from the
 * given source.
 */
export interface BuildConfig {
  /**
   * Output only. The Cloud Build name of the latest successful deployment of
   * the function.
   */
  build: string;
  /**
   * The runtime in which to run the function. Required when deploying a new
   * function, optional when updating an existing function. For a complete
   * list of possible choices, see the
   * [`gcloud` command
   * reference](https://cloud.google.com/sdk/gcloud/reference/functions/deploy#--runtime).
   */
  runtime: string;
  /**
   * The name of the function (as defined in source code) that will be
   * executed. Defaults to the resource name suffix, if not specified. For
   * backward compatibility, if function with given name is not found, then the
   * system will try to use function named "function".
   * For Node.js this is name of a function exported by the module specified
   * in `source_location`.
   */
  entryPoint: string;
  /** The location of the function source code. */
  source?:
    | Source
    | undefined;
  /** Output only. A permanent fixed identifier for source. */
  sourceProvenance?:
    | SourceProvenance
    | undefined;
  /**
   * Name of the Cloud Build Custom Worker Pool that should be used to build the
   * function. The format of this field is
   * `projects/{project}/locations/{region}/workerPools/{workerPool}` where
   * {project} and {region} are the project id and region respectively where the
   * worker pool is defined and {workerPool} is the short name of the worker
   * pool.
   *
   * If the project id is not the same as the function, then the Cloud
   * Functions Service Agent
   * (service-<project_number>@gcf-admin-robot.iam.gserviceaccount.com) must be
   * granted the role Cloud Build Custom Workers Builder
   * (roles/cloudbuild.customworkers.builder) in the project.
   */
  workerPool: string;
  /** User-provided build-time environment variables for the function */
  environmentVariables: { [key: string]: string };
  /**
   * Optional. Docker Registry to use for this deployment. This configuration is
   * only applicable to 1st Gen functions, 2nd Gen functions can only use
   * Artifact Registry.
   *
   * If `docker_repository` field is specified, this field will be automatically
   * set as `ARTIFACT_REGISTRY`.
   * If unspecified, it currently defaults to `CONTAINER_REGISTRY`.
   * This field may be overridden by the backend for eligible deployments.
   */
  dockerRegistry: BuildConfig_DockerRegistry;
  /**
   * User managed repository created in Artifact Registry optionally with a
   * customer managed encryption key. This is the repository to which the
   * function docker image will be pushed after it is built by Cloud Build.
   * If unspecified, GCF will create and use a repository named 'gcf-artifacts'
   * for every deployed region.
   *
   * It must match the pattern
   * `projects/{project}/locations/{location}/repositories/{repository}`.
   *
   * Cross-project repositories are not supported.
   * Cross-location repositories are not supported.
   * Repository format must be 'DOCKER'.
   */
  dockerRepository: string;
  /** Specifies one of the Google provided buildpack stacks. */
  buildpackStack: string;
}

/** Docker Registry to use for storing function Docker images. */
export enum BuildConfig_DockerRegistry {
  /** DOCKER_REGISTRY_UNSPECIFIED - Unspecified. */
  DOCKER_REGISTRY_UNSPECIFIED = 0,
  /**
   * CONTAINER_REGISTRY - Docker images will be stored in multi-regional Container Registry
   * repositories named `gcf`.
   */
  CONTAINER_REGISTRY = 1,
  /**
   * ARTIFACT_REGISTRY - Docker images will be stored in regional Artifact Registry repositories.
   * By default, GCF will create and use repositories named `gcf-artifacts`
   * in every region in which a function is deployed. But the repository to
   * use can also be specified by the user using the `docker_repository`
   * field.
   */
  ARTIFACT_REGISTRY = 2,
  UNRECOGNIZED = -1,
}

export function buildConfig_DockerRegistryFromJSON(object: any): BuildConfig_DockerRegistry {
  switch (object) {
    case 0:
    case "DOCKER_REGISTRY_UNSPECIFIED":
      return BuildConfig_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED;
    case 1:
    case "CONTAINER_REGISTRY":
      return BuildConfig_DockerRegistry.CONTAINER_REGISTRY;
    case 2:
    case "ARTIFACT_REGISTRY":
      return BuildConfig_DockerRegistry.ARTIFACT_REGISTRY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BuildConfig_DockerRegistry.UNRECOGNIZED;
  }
}

export function buildConfig_DockerRegistryToJSON(object: BuildConfig_DockerRegistry): string {
  switch (object) {
    case BuildConfig_DockerRegistry.DOCKER_REGISTRY_UNSPECIFIED:
      return "DOCKER_REGISTRY_UNSPECIFIED";
    case BuildConfig_DockerRegistry.CONTAINER_REGISTRY:
      return "CONTAINER_REGISTRY";
    case BuildConfig_DockerRegistry.ARTIFACT_REGISTRY:
      return "ARTIFACT_REGISTRY";
    case BuildConfig_DockerRegistry.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface BuildConfig_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

/**
 * Describes the Service being deployed.
 * Currently Supported : Cloud Run (fully managed).
 * Next tag: 23
 */
export interface ServiceConfig {
  /**
   * Output only. Name of the service associated with a Function.
   * The format of this field is
   * `projects/{project}/locations/{region}/services/{service}`
   */
  service: string;
  /**
   * The function execution timeout. Execution is considered failed and
   * can be terminated if the function is not completed at the end of the
   * timeout period. Defaults to 60 seconds.
   */
  timeoutSeconds: number;
  /**
   * The amount of memory available for a function.
   * Defaults to 256M. Supported units are k, M, G, Mi, Gi. If no unit is
   * supplied the value is interpreted as bytes.
   * See
   * https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/api/resource/quantity.go
   * a full description.
   */
  availableMemory: string;
  /**
   * The number of CPUs used in a single container instance.
   * Default value is calculated from available memory.
   * Supports the same values as Cloud Run, see
   * https://cloud.google.com/run/docs/reference/rest/v1/Container#resourcerequirements
   * Example: "1" indicates 1 vCPU
   */
  availableCpu: string;
  /** Environment variables that shall be available during function execution. */
  environmentVariables: { [key: string]: string };
  /**
   * The limit on the maximum number of function instances that may coexist at a
   * given time.
   *
   * In some cases, such as rapid traffic surges, Cloud Functions may, for a
   * short period of time, create more instances than the specified max
   * instances limit. If your function cannot tolerate this temporary behavior,
   * you may want to factor in a safety margin and set a lower max instances
   * value than your function can tolerate.
   *
   * See the [Max
   * Instances](https://cloud.google.com/functions/docs/max-instances) Guide for
   * more details.
   */
  maxInstanceCount: number;
  /**
   * The limit on the minimum number of function instances that may coexist at a
   * given time.
   *
   * Function instances are kept in idle state for a short period after they
   * finished executing the request to reduce cold start time for subsequent
   * requests. Setting a minimum instance count will ensure that the given
   * number of instances are kept running in idle state always. This can help
   * with cold start times when jump in incoming request count occurs after the
   * idle instance would have been stopped in the default case.
   */
  minInstanceCount: number;
  /**
   * The Serverless VPC Access connector that this cloud function can connect
   * to. The format of this field is `projects/* /locations/* /connectors/*`.
   */
  vpcConnector: string;
  /**
   * The egress settings for the connector, controlling what traffic is diverted
   * through it.
   */
  vpcConnectorEgressSettings: ServiceConfig_VpcConnectorEgressSettings;
  /**
   * The ingress settings for the function, controlling what traffic can reach
   * it.
   */
  ingressSettings: ServiceConfig_IngressSettings;
  /** Output only. URI of the Service deployed. */
  uri: string;
  /**
   * The email of the service's service account. If empty, defaults to
   * `{project_number}-compute@developer.gserviceaccount.com`.
   */
  serviceAccountEmail: string;
  /**
   * Whether 100% of traffic is routed to the latest revision.
   * On CreateFunction and UpdateFunction, when set to true, the revision being
   * deployed will serve 100% of traffic, ignoring any traffic split settings,
   * if any. On GetFunction, true will be returned if the latest revision is
   * serving 100% of traffic.
   */
  allTrafficOnLatestRevision: boolean;
  /** Secret environment variables configuration. */
  secretEnvironmentVariables: SecretEnvVar[];
  /** Secret volumes configuration. */
  secretVolumes: SecretVolume[];
  /** Output only. The name of service revision. */
  revision: string;
  /**
   * Sets the maximum number of concurrent requests that each instance can
   * receive. Defaults to 1.
   */
  maxInstanceRequestConcurrency: number;
  /**
   * Security level configure whether the function only accepts https.
   * This configuration is only applicable to 1st Gen functions with Http
   * trigger. By default https is optional for 1st Gen functions; 2nd Gen
   * functions are https ONLY.
   */
  securityLevel: ServiceConfig_SecurityLevel;
}

/**
 * Available egress settings.
 *
 * This controls what traffic is diverted through the VPC Access Connector
 * resource. By default PRIVATE_RANGES_ONLY will be used.
 */
export enum ServiceConfig_VpcConnectorEgressSettings {
  /** VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED = 0,
  /** PRIVATE_RANGES_ONLY - Use the VPC Access Connector only for private IP space from RFC1918. */
  PRIVATE_RANGES_ONLY = 1,
  /**
   * ALL_TRAFFIC - Force the use of VPC Access Connector for all egress traffic from the
   * function.
   */
  ALL_TRAFFIC = 2,
  UNRECOGNIZED = -1,
}

export function serviceConfig_VpcConnectorEgressSettingsFromJSON(
  object: any,
): ServiceConfig_VpcConnectorEgressSettings {
  switch (object) {
    case 0:
    case "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED":
      return ServiceConfig_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "PRIVATE_RANGES_ONLY":
      return ServiceConfig_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY;
    case 2:
    case "ALL_TRAFFIC":
      return ServiceConfig_VpcConnectorEgressSettings.ALL_TRAFFIC;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_VpcConnectorEgressSettings.UNRECOGNIZED;
  }
}

export function serviceConfig_VpcConnectorEgressSettingsToJSON(
  object: ServiceConfig_VpcConnectorEgressSettings,
): string {
  switch (object) {
    case ServiceConfig_VpcConnectorEgressSettings.VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED:
      return "VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED";
    case ServiceConfig_VpcConnectorEgressSettings.PRIVATE_RANGES_ONLY:
      return "PRIVATE_RANGES_ONLY";
    case ServiceConfig_VpcConnectorEgressSettings.ALL_TRAFFIC:
      return "ALL_TRAFFIC";
    case ServiceConfig_VpcConnectorEgressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Available ingress settings.
 *
 * This controls what traffic can reach the function.
 *
 * If unspecified, ALLOW_ALL will be used.
 */
export enum ServiceConfig_IngressSettings {
  /** INGRESS_SETTINGS_UNSPECIFIED - Unspecified. */
  INGRESS_SETTINGS_UNSPECIFIED = 0,
  /** ALLOW_ALL - Allow HTTP traffic from public and private sources. */
  ALLOW_ALL = 1,
  /** ALLOW_INTERNAL_ONLY - Allow HTTP traffic from only private VPC sources. */
  ALLOW_INTERNAL_ONLY = 2,
  /** ALLOW_INTERNAL_AND_GCLB - Allow HTTP traffic from private VPC sources and through GCLB. */
  ALLOW_INTERNAL_AND_GCLB = 3,
  UNRECOGNIZED = -1,
}

export function serviceConfig_IngressSettingsFromJSON(object: any): ServiceConfig_IngressSettings {
  switch (object) {
    case 0:
    case "INGRESS_SETTINGS_UNSPECIFIED":
      return ServiceConfig_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED;
    case 1:
    case "ALLOW_ALL":
      return ServiceConfig_IngressSettings.ALLOW_ALL;
    case 2:
    case "ALLOW_INTERNAL_ONLY":
      return ServiceConfig_IngressSettings.ALLOW_INTERNAL_ONLY;
    case 3:
    case "ALLOW_INTERNAL_AND_GCLB":
      return ServiceConfig_IngressSettings.ALLOW_INTERNAL_AND_GCLB;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_IngressSettings.UNRECOGNIZED;
  }
}

export function serviceConfig_IngressSettingsToJSON(object: ServiceConfig_IngressSettings): string {
  switch (object) {
    case ServiceConfig_IngressSettings.INGRESS_SETTINGS_UNSPECIFIED:
      return "INGRESS_SETTINGS_UNSPECIFIED";
    case ServiceConfig_IngressSettings.ALLOW_ALL:
      return "ALLOW_ALL";
    case ServiceConfig_IngressSettings.ALLOW_INTERNAL_ONLY:
      return "ALLOW_INTERNAL_ONLY";
    case ServiceConfig_IngressSettings.ALLOW_INTERNAL_AND_GCLB:
      return "ALLOW_INTERNAL_AND_GCLB";
    case ServiceConfig_IngressSettings.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Available security level settings.
 *
 * This enforces security protocol on function URL.
 *
 * Security level is only ocnfigurable for 1st Gen functions, If unspecified,
 * SECURE_OPTIONAL will be used. 2nd Gen functions are SECURE_ALWAYS ONLY.
 */
export enum ServiceConfig_SecurityLevel {
  /** SECURITY_LEVEL_UNSPECIFIED - Unspecified. */
  SECURITY_LEVEL_UNSPECIFIED = 0,
  /**
   * SECURE_ALWAYS - Requests for a URL that match this handler that do not use HTTPS are
   * automatically redirected to the HTTPS URL with the same path. Query
   * parameters are reserved for the redirect.
   */
  SECURE_ALWAYS = 1,
  /**
   * SECURE_OPTIONAL - Both HTTP and HTTPS requests with URLs that match the handler succeed
   * without redirects. The application can examine the request to determine
   * which protocol was used and respond accordingly.
   */
  SECURE_OPTIONAL = 2,
  UNRECOGNIZED = -1,
}

export function serviceConfig_SecurityLevelFromJSON(object: any): ServiceConfig_SecurityLevel {
  switch (object) {
    case 0:
    case "SECURITY_LEVEL_UNSPECIFIED":
      return ServiceConfig_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED;
    case 1:
    case "SECURE_ALWAYS":
      return ServiceConfig_SecurityLevel.SECURE_ALWAYS;
    case 2:
    case "SECURE_OPTIONAL":
      return ServiceConfig_SecurityLevel.SECURE_OPTIONAL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ServiceConfig_SecurityLevel.UNRECOGNIZED;
  }
}

export function serviceConfig_SecurityLevelToJSON(object: ServiceConfig_SecurityLevel): string {
  switch (object) {
    case ServiceConfig_SecurityLevel.SECURITY_LEVEL_UNSPECIFIED:
      return "SECURITY_LEVEL_UNSPECIFIED";
    case ServiceConfig_SecurityLevel.SECURE_ALWAYS:
      return "SECURE_ALWAYS";
    case ServiceConfig_SecurityLevel.SECURE_OPTIONAL:
      return "SECURE_OPTIONAL";
    case ServiceConfig_SecurityLevel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface ServiceConfig_EnvironmentVariablesEntry {
  key: string;
  value: string;
}

/**
 * Configuration for a secret environment variable. It has the information
 * necessary to fetch the secret value from secret manager and expose it as an
 * environment variable.
 */
export interface SecretEnvVar {
  /** Name of the environment variable. */
  key: string;
  /**
   * Project identifier (preferably project number but can also be the
   * project ID) of the project that contains the secret. If not set, it is
   * assumed that the secret is in the same project as the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * recommended to use a numeric version for secret environment variables as
   * any updates to the secret value is not reflected until new instances
   * start.
   */
  version: string;
}

/**
 * Configuration for a secret volume. It has the information necessary to fetch
 * the secret value from secret manager and make it available as files mounted
 * at the requested paths within the application container.
 */
export interface SecretVolume {
  /**
   * The path within the container to mount the secret volume. For example,
   * setting the mount_path as `/etc/secrets` would mount the secret value files
   * under the `/etc/secrets` directory. This directory will also be completely
   * shadowed and unavailable to mount any other secrets.
   * Recommended mount path: /etc/secrets
   */
  mountPath: string;
  /**
   * Project identifier (preferably project number but can also be the project
   * ID) of the project that contains the secret. If not set, it is
   * assumed that the secret is in the same project as the function.
   */
  projectId: string;
  /** Name of the secret in secret manager (not the full resource name). */
  secret: string;
  /**
   * List of secret versions to mount for this secret. If empty, the `latest`
   * version of the secret will be made available in a file named after the
   * secret under the mount point.
   */
  versions: SecretVolume_SecretVersion[];
}

/** Configuration for a single version. */
export interface SecretVolume_SecretVersion {
  /**
   * Version of the secret (version number or the string 'latest'). It is
   * preferable to use `latest` version with secret volumes as secret value
   * changes are reflected immediately.
   */
  version: string;
  /**
   * Relative path of the file under the mount path where the secret value for
   * this version will be fetched and made available. For example, setting the
   * mount_path as '/etc/secrets' and path as `secret_foo` would mount the
   * secret value file at `/etc/secrets/secret_foo`.
   */
  path: string;
}

/**
 * Describes EventTrigger, used to request events to be sent from another
 * service.
 */
export interface EventTrigger {
  /**
   * Output only. The resource name of the Eventarc trigger. The format of this
   * field is `projects/{project}/locations/{region}/triggers/{trigger}`.
   */
  trigger: string;
  /**
   * The region that the trigger will be in. The trigger will only receive
   * events originating in this region. It can be the same
   * region as the function, a different region or multi-region, or the global
   * region. If not provided, defaults to the same region as the function.
   */
  triggerRegion: string;
  /**
   * Required. The type of event to observe. For example:
   * `google.cloud.audit.log.v1.written` or
   * `google.cloud.pubsub.topic.v1.messagePublished`.
   */
  eventType: string;
  /** Criteria used to filter events. */
  eventFilters: EventFilter[];
  /**
   * Optional. The name of a Pub/Sub topic in the same project that will be used
   * as the transport topic for the event delivery. Format:
   * `projects/{project}/topics/{topic}`.
   *
   * This is only valid for events of type
   * `google.cloud.pubsub.topic.v1.messagePublished`. The topic provided here
   * will not be deleted at function deletion.
   */
  pubsubTopic: string;
  /**
   * Optional. The email of the trigger's service account. The service account
   * must have permission to invoke Cloud Run services, the permission is
   * `run.routes.invoke`.
   * If empty, defaults to the Compute Engine default service account:
   * `{project_number}-compute@developer.gserviceaccount.com`.
   */
  serviceAccountEmail: string;
  /**
   * Optional. If unset, then defaults to ignoring failures (i.e. not retrying
   * them).
   */
  retryPolicy: EventTrigger_RetryPolicy;
  /**
   * Optional. The name of the channel associated with the trigger in
   * `projects/{project}/locations/{location}/channels/{channel}` format.
   * You must provide a channel to receive events from Eventarc SaaS partners.
   */
  channel: string;
}

/**
 * Describes the retry policy in case of function's execution failure.
 * Retried execution is charged as any other execution.
 */
export enum EventTrigger_RetryPolicy {
  /** RETRY_POLICY_UNSPECIFIED - Not specified. */
  RETRY_POLICY_UNSPECIFIED = 0,
  /** RETRY_POLICY_DO_NOT_RETRY - Do not retry. */
  RETRY_POLICY_DO_NOT_RETRY = 1,
  /**
   * RETRY_POLICY_RETRY - Retry on any failure, retry up to 7 days with an exponential backoff
   * (capped at 10 seconds).
   */
  RETRY_POLICY_RETRY = 2,
  UNRECOGNIZED = -1,
}

export function eventTrigger_RetryPolicyFromJSON(object: any): EventTrigger_RetryPolicy {
  switch (object) {
    case 0:
    case "RETRY_POLICY_UNSPECIFIED":
      return EventTrigger_RetryPolicy.RETRY_POLICY_UNSPECIFIED;
    case 1:
    case "RETRY_POLICY_DO_NOT_RETRY":
      return EventTrigger_RetryPolicy.RETRY_POLICY_DO_NOT_RETRY;
    case 2:
    case "RETRY_POLICY_RETRY":
      return EventTrigger_RetryPolicy.RETRY_POLICY_RETRY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return EventTrigger_RetryPolicy.UNRECOGNIZED;
  }
}

export function eventTrigger_RetryPolicyToJSON(object: EventTrigger_RetryPolicy): string {
  switch (object) {
    case EventTrigger_RetryPolicy.RETRY_POLICY_UNSPECIFIED:
      return "RETRY_POLICY_UNSPECIFIED";
    case EventTrigger_RetryPolicy.RETRY_POLICY_DO_NOT_RETRY:
      return "RETRY_POLICY_DO_NOT_RETRY";
    case EventTrigger_RetryPolicy.RETRY_POLICY_RETRY:
      return "RETRY_POLICY_RETRY";
    case EventTrigger_RetryPolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Filters events based on exact matches on the CloudEvents attributes. */
export interface EventFilter {
  /** Required. The name of a CloudEvents attribute. */
  attribute: string;
  /** Required. The value for the attribute. */
  value: string;
  /**
   * Optional. The operator used for matching the events with the value of the
   * filter. If not specified, only events that have an exact key-value pair
   * specified in the filter are matched. The only allowed value is
   * `match-path-pattern`.
   */
  operator: string;
}

/** The data within all Function events. */
export interface FunctionEventData {
  /** Optional. The Function event payload. Unset for deletion events. */
  payload?: FunctionMessage | undefined;
}

function createBaseFunctionMessage(): FunctionMessage {
  return {
    name: "",
    environment: 0,
    description: "",
    buildConfig: undefined,
    serviceConfig: undefined,
    eventTrigger: undefined,
    state: 0,
    updateTime: undefined,
    labels: {},
    stateMessages: [],
  };
}

export const FunctionMessage: MessageFns<FunctionMessage> = {
  encode(message: FunctionMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.environment !== 0) {
      writer.uint32(80).int32(message.environment);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.buildConfig !== undefined) {
      BuildConfig.encode(message.buildConfig, writer.uint32(26).fork()).join();
    }
    if (message.serviceConfig !== undefined) {
      ServiceConfig.encode(message.serviceConfig, writer.uint32(34).fork()).join();
    }
    if (message.eventTrigger !== undefined) {
      EventTrigger.encode(message.eventTrigger, writer.uint32(42).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(48).int32(message.state);
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(58).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Function_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    for (const v of message.stateMessages) {
      StateMessage.encode(v!, writer.uint32(74).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FunctionMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFunctionMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.environment = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.buildConfig = BuildConfig.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.serviceConfig = ServiceConfig.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.eventTrigger = EventTrigger.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = Function_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.stateMessages.push(StateMessage.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FunctionMessage {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      environment: isSet(object.environment) ? environmentFromJSON(object.environment) : 0,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      buildConfig: isSet(object.buildConfig) ? BuildConfig.fromJSON(object.buildConfig) : undefined,
      serviceConfig: isSet(object.serviceConfig) ? ServiceConfig.fromJSON(object.serviceConfig) : undefined,
      eventTrigger: isSet(object.eventTrigger) ? EventTrigger.fromJSON(object.eventTrigger) : undefined,
      state: isSet(object.state) ? function_StateFromJSON(object.state) : 0,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      stateMessages: globalThis.Array.isArray(object?.stateMessages)
        ? object.stateMessages.map((e: any) => StateMessage.fromJSON(e))
        : [],
    };
  },

  toJSON(message: FunctionMessage): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.environment !== 0) {
      obj.environment = environmentToJSON(message.environment);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.buildConfig !== undefined) {
      obj.buildConfig = BuildConfig.toJSON(message.buildConfig);
    }
    if (message.serviceConfig !== undefined) {
      obj.serviceConfig = ServiceConfig.toJSON(message.serviceConfig);
    }
    if (message.eventTrigger !== undefined) {
      obj.eventTrigger = EventTrigger.toJSON(message.eventTrigger);
    }
    if (message.state !== 0) {
      obj.state = function_StateToJSON(message.state);
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.stateMessages?.length) {
      obj.stateMessages = message.stateMessages.map((e) => StateMessage.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<FunctionMessage>, I>>(base?: I): FunctionMessage {
    return FunctionMessage.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<FunctionMessage>, I>>(object: I): FunctionMessage {
    const message = createBaseFunctionMessage();
    message.name = object.name ?? "";
    message.environment = object.environment ?? 0;
    message.description = object.description ?? "";
    message.buildConfig = (object.buildConfig !== undefined && object.buildConfig !== null)
      ? BuildConfig.fromPartial(object.buildConfig)
      : undefined;
    message.serviceConfig = (object.serviceConfig !== undefined && object.serviceConfig !== null)
      ? ServiceConfig.fromPartial(object.serviceConfig)
      : undefined;
    message.eventTrigger = (object.eventTrigger !== undefined && object.eventTrigger !== null)
      ? EventTrigger.fromPartial(object.eventTrigger)
      : undefined;
    message.state = object.state ?? 0;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.stateMessages = object.stateMessages?.map((e) => StateMessage.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFunction_LabelsEntry(): Function_LabelsEntry {
  return { key: "", value: "" };
}

export const Function_LabelsEntry: MessageFns<Function_LabelsEntry> = {
  encode(message: Function_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Function_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFunction_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Function_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Function_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Function_LabelsEntry>, I>>(base?: I): Function_LabelsEntry {
    return Function_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Function_LabelsEntry>, I>>(object: I): Function_LabelsEntry {
    const message = createBaseFunction_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseStateMessage(): StateMessage {
  return { severity: 0, type: "", message: "" };
}

export const StateMessage: MessageFns<StateMessage> = {
  encode(message: StateMessage, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.severity !== 0) {
      writer.uint32(8).int32(message.severity);
    }
    if (message.type !== "") {
      writer.uint32(18).string(message.type);
    }
    if (message.message !== "") {
      writer.uint32(26).string(message.message);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StateMessage {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStateMessage();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.severity = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.type = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.message = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StateMessage {
    return {
      severity: isSet(object.severity) ? stateMessage_SeverityFromJSON(object.severity) : 0,
      type: isSet(object.type) ? globalThis.String(object.type) : "",
      message: isSet(object.message) ? globalThis.String(object.message) : "",
    };
  },

  toJSON(message: StateMessage): unknown {
    const obj: any = {};
    if (message.severity !== 0) {
      obj.severity = stateMessage_SeverityToJSON(message.severity);
    }
    if (message.type !== "") {
      obj.type = message.type;
    }
    if (message.message !== "") {
      obj.message = message.message;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<StateMessage>, I>>(base?: I): StateMessage {
    return StateMessage.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<StateMessage>, I>>(object: I): StateMessage {
    const message = createBaseStateMessage();
    message.severity = object.severity ?? 0;
    message.type = object.type ?? "";
    message.message = object.message ?? "";
    return message;
  },
};

function createBaseStorageSource(): StorageSource {
  return { bucket: "", object: "", generation: Long.ZERO };
}

export const StorageSource: MessageFns<StorageSource> = {
  encode(message: StorageSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.bucket !== "") {
      writer.uint32(10).string(message.bucket);
    }
    if (message.object !== "") {
      writer.uint32(18).string(message.object);
    }
    if (!message.generation.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.generation.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): StorageSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseStorageSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.bucket = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.object = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.generation = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): StorageSource {
    return {
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      object: isSet(object.object) ? globalThis.String(object.object) : "",
      generation: isSet(object.generation) ? Long.fromValue(object.generation) : Long.ZERO,
    };
  },

  toJSON(message: StorageSource): unknown {
    const obj: any = {};
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.object !== "") {
      obj.object = message.object;
    }
    if (!message.generation.equals(Long.ZERO)) {
      obj.generation = (message.generation || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<StorageSource>, I>>(base?: I): StorageSource {
    return StorageSource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<StorageSource>, I>>(object: I): StorageSource {
    const message = createBaseStorageSource();
    message.bucket = object.bucket ?? "";
    message.object = object.object ?? "";
    message.generation = (object.generation !== undefined && object.generation !== null)
      ? Long.fromValue(object.generation)
      : Long.ZERO;
    return message;
  },
};

function createBaseRepoSource(): RepoSource {
  return {
    branchName: undefined,
    tagName: undefined,
    commitSha: undefined,
    projectId: "",
    repoName: "",
    dir: "",
    invertRegex: false,
  };
}

export const RepoSource: MessageFns<RepoSource> = {
  encode(message: RepoSource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.branchName !== undefined) {
      writer.uint32(26).string(message.branchName);
    }
    if (message.tagName !== undefined) {
      writer.uint32(34).string(message.tagName);
    }
    if (message.commitSha !== undefined) {
      writer.uint32(42).string(message.commitSha);
    }
    if (message.projectId !== "") {
      writer.uint32(10).string(message.projectId);
    }
    if (message.repoName !== "") {
      writer.uint32(18).string(message.repoName);
    }
    if (message.dir !== "") {
      writer.uint32(50).string(message.dir);
    }
    if (message.invertRegex !== false) {
      writer.uint32(56).bool(message.invertRegex);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RepoSource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRepoSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.branchName = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.tagName = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.commitSha = reader.string();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.projectId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.repoName = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.dir = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.invertRegex = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RepoSource {
    return {
      branchName: isSet(object.branchName) ? globalThis.String(object.branchName) : undefined,
      tagName: isSet(object.tagName) ? globalThis.String(object.tagName) : undefined,
      commitSha: isSet(object.commitSha) ? globalThis.String(object.commitSha) : undefined,
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      repoName: isSet(object.repoName) ? globalThis.String(object.repoName) : "",
      dir: isSet(object.dir) ? globalThis.String(object.dir) : "",
      invertRegex: isSet(object.invertRegex) ? globalThis.Boolean(object.invertRegex) : false,
    };
  },

  toJSON(message: RepoSource): unknown {
    const obj: any = {};
    if (message.branchName !== undefined) {
      obj.branchName = message.branchName;
    }
    if (message.tagName !== undefined) {
      obj.tagName = message.tagName;
    }
    if (message.commitSha !== undefined) {
      obj.commitSha = message.commitSha;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.repoName !== "") {
      obj.repoName = message.repoName;
    }
    if (message.dir !== "") {
      obj.dir = message.dir;
    }
    if (message.invertRegex !== false) {
      obj.invertRegex = message.invertRegex;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RepoSource>, I>>(base?: I): RepoSource {
    return RepoSource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RepoSource>, I>>(object: I): RepoSource {
    const message = createBaseRepoSource();
    message.branchName = object.branchName ?? undefined;
    message.tagName = object.tagName ?? undefined;
    message.commitSha = object.commitSha ?? undefined;
    message.projectId = object.projectId ?? "";
    message.repoName = object.repoName ?? "";
    message.dir = object.dir ?? "";
    message.invertRegex = object.invertRegex ?? false;
    return message;
  },
};

function createBaseSource(): Source {
  return { storageSource: undefined, repoSource: undefined };
}

export const Source: MessageFns<Source> = {
  encode(message: Source, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.storageSource !== undefined) {
      StorageSource.encode(message.storageSource, writer.uint32(10).fork()).join();
    }
    if (message.repoSource !== undefined) {
      RepoSource.encode(message.repoSource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.storageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.repoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source {
    return {
      storageSource: isSet(object.storageSource) ? StorageSource.fromJSON(object.storageSource) : undefined,
      repoSource: isSet(object.repoSource) ? RepoSource.fromJSON(object.repoSource) : undefined,
    };
  },

  toJSON(message: Source): unknown {
    const obj: any = {};
    if (message.storageSource !== undefined) {
      obj.storageSource = StorageSource.toJSON(message.storageSource);
    }
    if (message.repoSource !== undefined) {
      obj.repoSource = RepoSource.toJSON(message.repoSource);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Source>, I>>(base?: I): Source {
    return Source.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Source>, I>>(object: I): Source {
    const message = createBaseSource();
    message.storageSource = (object.storageSource !== undefined && object.storageSource !== null)
      ? StorageSource.fromPartial(object.storageSource)
      : undefined;
    message.repoSource = (object.repoSource !== undefined && object.repoSource !== null)
      ? RepoSource.fromPartial(object.repoSource)
      : undefined;
    return message;
  },
};

function createBaseSourceProvenance(): SourceProvenance {
  return { resolvedStorageSource: undefined, resolvedRepoSource: undefined };
}

export const SourceProvenance: MessageFns<SourceProvenance> = {
  encode(message: SourceProvenance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resolvedStorageSource !== undefined) {
      StorageSource.encode(message.resolvedStorageSource, writer.uint32(10).fork()).join();
    }
    if (message.resolvedRepoSource !== undefined) {
      RepoSource.encode(message.resolvedRepoSource, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceProvenance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceProvenance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.resolvedStorageSource = StorageSource.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.resolvedRepoSource = RepoSource.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceProvenance {
    return {
      resolvedStorageSource: isSet(object.resolvedStorageSource)
        ? StorageSource.fromJSON(object.resolvedStorageSource)
        : undefined,
      resolvedRepoSource: isSet(object.resolvedRepoSource) ? RepoSource.fromJSON(object.resolvedRepoSource) : undefined,
    };
  },

  toJSON(message: SourceProvenance): unknown {
    const obj: any = {};
    if (message.resolvedStorageSource !== undefined) {
      obj.resolvedStorageSource = StorageSource.toJSON(message.resolvedStorageSource);
    }
    if (message.resolvedRepoSource !== undefined) {
      obj.resolvedRepoSource = RepoSource.toJSON(message.resolvedRepoSource);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SourceProvenance>, I>>(base?: I): SourceProvenance {
    return SourceProvenance.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SourceProvenance>, I>>(object: I): SourceProvenance {
    const message = createBaseSourceProvenance();
    message.resolvedStorageSource =
      (object.resolvedStorageSource !== undefined && object.resolvedStorageSource !== null)
        ? StorageSource.fromPartial(object.resolvedStorageSource)
        : undefined;
    message.resolvedRepoSource = (object.resolvedRepoSource !== undefined && object.resolvedRepoSource !== null)
      ? RepoSource.fromPartial(object.resolvedRepoSource)
      : undefined;
    return message;
  },
};

function createBaseBuildConfig(): BuildConfig {
  return {
    build: "",
    runtime: "",
    entryPoint: "",
    source: undefined,
    sourceProvenance: undefined,
    workerPool: "",
    environmentVariables: {},
    dockerRegistry: 0,
    dockerRepository: "",
    buildpackStack: "",
  };
}

export const BuildConfig: MessageFns<BuildConfig> = {
  encode(message: BuildConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.build !== "") {
      writer.uint32(10).string(message.build);
    }
    if (message.runtime !== "") {
      writer.uint32(18).string(message.runtime);
    }
    if (message.entryPoint !== "") {
      writer.uint32(26).string(message.entryPoint);
    }
    if (message.source !== undefined) {
      Source.encode(message.source, writer.uint32(34).fork()).join();
    }
    if (message.sourceProvenance !== undefined) {
      SourceProvenance.encode(message.sourceProvenance, writer.uint32(66).fork()).join();
    }
    if (message.workerPool !== "") {
      writer.uint32(42).string(message.workerPool);
    }
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      BuildConfig_EnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.dockerRegistry !== 0) {
      writer.uint32(80).int32(message.dockerRegistry);
    }
    if (message.dockerRepository !== "") {
      writer.uint32(58).string(message.dockerRepository);
    }
    if (message.buildpackStack !== "") {
      writer.uint32(74).string(message.buildpackStack);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.build = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.runtime = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.entryPoint = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.source = Source.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.sourceProvenance = SourceProvenance.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.workerPool = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = BuildConfig_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.environmentVariables[entry6.key] = entry6.value;
          }
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.dockerRegistry = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.dockerRepository = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.buildpackStack = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildConfig {
    return {
      build: isSet(object.build) ? globalThis.String(object.build) : "",
      runtime: isSet(object.runtime) ? globalThis.String(object.runtime) : "",
      entryPoint: isSet(object.entryPoint) ? globalThis.String(object.entryPoint) : "",
      source: isSet(object.source) ? Source.fromJSON(object.source) : undefined,
      sourceProvenance: isSet(object.sourceProvenance) ? SourceProvenance.fromJSON(object.sourceProvenance) : undefined,
      workerPool: isSet(object.workerPool) ? globalThis.String(object.workerPool) : "",
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      dockerRegistry: isSet(object.dockerRegistry) ? buildConfig_DockerRegistryFromJSON(object.dockerRegistry) : 0,
      dockerRepository: isSet(object.dockerRepository) ? globalThis.String(object.dockerRepository) : "",
      buildpackStack: isSet(object.buildpackStack) ? globalThis.String(object.buildpackStack) : "",
    };
  },

  toJSON(message: BuildConfig): unknown {
    const obj: any = {};
    if (message.build !== "") {
      obj.build = message.build;
    }
    if (message.runtime !== "") {
      obj.runtime = message.runtime;
    }
    if (message.entryPoint !== "") {
      obj.entryPoint = message.entryPoint;
    }
    if (message.source !== undefined) {
      obj.source = Source.toJSON(message.source);
    }
    if (message.sourceProvenance !== undefined) {
      obj.sourceProvenance = SourceProvenance.toJSON(message.sourceProvenance);
    }
    if (message.workerPool !== "") {
      obj.workerPool = message.workerPool;
    }
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    if (message.dockerRegistry !== 0) {
      obj.dockerRegistry = buildConfig_DockerRegistryToJSON(message.dockerRegistry);
    }
    if (message.dockerRepository !== "") {
      obj.dockerRepository = message.dockerRepository;
    }
    if (message.buildpackStack !== "") {
      obj.buildpackStack = message.buildpackStack;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BuildConfig>, I>>(base?: I): BuildConfig {
    return BuildConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BuildConfig>, I>>(object: I): BuildConfig {
    const message = createBaseBuildConfig();
    message.build = object.build ?? "";
    message.runtime = object.runtime ?? "";
    message.entryPoint = object.entryPoint ?? "";
    message.source = (object.source !== undefined && object.source !== null)
      ? Source.fromPartial(object.source)
      : undefined;
    message.sourceProvenance = (object.sourceProvenance !== undefined && object.sourceProvenance !== null)
      ? SourceProvenance.fromPartial(object.sourceProvenance)
      : undefined;
    message.workerPool = object.workerPool ?? "";
    message.environmentVariables = Object.entries(object.environmentVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.dockerRegistry = object.dockerRegistry ?? 0;
    message.dockerRepository = object.dockerRepository ?? "";
    message.buildpackStack = object.buildpackStack ?? "";
    return message;
  },
};

function createBaseBuildConfig_EnvironmentVariablesEntry(): BuildConfig_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const BuildConfig_EnvironmentVariablesEntry: MessageFns<BuildConfig_EnvironmentVariablesEntry> = {
  encode(message: BuildConfig_EnvironmentVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BuildConfig_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBuildConfig_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BuildConfig_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: BuildConfig_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BuildConfig_EnvironmentVariablesEntry>, I>>(
    base?: I,
  ): BuildConfig_EnvironmentVariablesEntry {
    return BuildConfig_EnvironmentVariablesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BuildConfig_EnvironmentVariablesEntry>, I>>(
    object: I,
  ): BuildConfig_EnvironmentVariablesEntry {
    const message = createBaseBuildConfig_EnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseServiceConfig(): ServiceConfig {
  return {
    service: "",
    timeoutSeconds: 0,
    availableMemory: "",
    availableCpu: "",
    environmentVariables: {},
    maxInstanceCount: 0,
    minInstanceCount: 0,
    vpcConnector: "",
    vpcConnectorEgressSettings: 0,
    ingressSettings: 0,
    uri: "",
    serviceAccountEmail: "",
    allTrafficOnLatestRevision: false,
    secretEnvironmentVariables: [],
    secretVolumes: [],
    revision: "",
    maxInstanceRequestConcurrency: 0,
    securityLevel: 0,
  };
}

export const ServiceConfig: MessageFns<ServiceConfig> = {
  encode(message: ServiceConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.service !== "") {
      writer.uint32(10).string(message.service);
    }
    if (message.timeoutSeconds !== 0) {
      writer.uint32(16).int32(message.timeoutSeconds);
    }
    if (message.availableMemory !== "") {
      writer.uint32(106).string(message.availableMemory);
    }
    if (message.availableCpu !== "") {
      writer.uint32(178).string(message.availableCpu);
    }
    Object.entries(message.environmentVariables).forEach(([key, value]) => {
      ServiceConfig_EnvironmentVariablesEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.maxInstanceCount !== 0) {
      writer.uint32(40).int32(message.maxInstanceCount);
    }
    if (message.minInstanceCount !== 0) {
      writer.uint32(96).int32(message.minInstanceCount);
    }
    if (message.vpcConnector !== "") {
      writer.uint32(50).string(message.vpcConnector);
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      writer.uint32(56).int32(message.vpcConnectorEgressSettings);
    }
    if (message.ingressSettings !== 0) {
      writer.uint32(64).int32(message.ingressSettings);
    }
    if (message.uri !== "") {
      writer.uint32(74).string(message.uri);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(82).string(message.serviceAccountEmail);
    }
    if (message.allTrafficOnLatestRevision !== false) {
      writer.uint32(128).bool(message.allTrafficOnLatestRevision);
    }
    for (const v of message.secretEnvironmentVariables) {
      SecretEnvVar.encode(v!, writer.uint32(138).fork()).join();
    }
    for (const v of message.secretVolumes) {
      SecretVolume.encode(v!, writer.uint32(154).fork()).join();
    }
    if (message.revision !== "") {
      writer.uint32(146).string(message.revision);
    }
    if (message.maxInstanceRequestConcurrency !== 0) {
      writer.uint32(160).int32(message.maxInstanceRequestConcurrency);
    }
    if (message.securityLevel !== 0) {
      writer.uint32(168).int32(message.securityLevel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.service = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.timeoutSeconds = reader.int32();
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.availableMemory = reader.string();
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          message.availableCpu = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = ServiceConfig_EnvironmentVariablesEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.environmentVariables[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.maxInstanceCount = reader.int32();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.minInstanceCount = reader.int32();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.vpcConnector = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.vpcConnectorEgressSettings = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.ingressSettings = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.uri = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.allTrafficOnLatestRevision = reader.bool();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.secretEnvironmentVariables.push(SecretEnvVar.decode(reader, reader.uint32()));
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.secretVolumes.push(SecretVolume.decode(reader, reader.uint32()));
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.revision = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 160) {
            break;
          }

          message.maxInstanceRequestConcurrency = reader.int32();
          continue;
        }
        case 21: {
          if (tag !== 168) {
            break;
          }

          message.securityLevel = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceConfig {
    return {
      service: isSet(object.service) ? globalThis.String(object.service) : "",
      timeoutSeconds: isSet(object.timeoutSeconds) ? globalThis.Number(object.timeoutSeconds) : 0,
      availableMemory: isSet(object.availableMemory) ? globalThis.String(object.availableMemory) : "",
      availableCpu: isSet(object.availableCpu) ? globalThis.String(object.availableCpu) : "",
      environmentVariables: isObject(object.environmentVariables)
        ? Object.entries(object.environmentVariables).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      maxInstanceCount: isSet(object.maxInstanceCount) ? globalThis.Number(object.maxInstanceCount) : 0,
      minInstanceCount: isSet(object.minInstanceCount) ? globalThis.Number(object.minInstanceCount) : 0,
      vpcConnector: isSet(object.vpcConnector) ? globalThis.String(object.vpcConnector) : "",
      vpcConnectorEgressSettings: isSet(object.vpcConnectorEgressSettings)
        ? serviceConfig_VpcConnectorEgressSettingsFromJSON(object.vpcConnectorEgressSettings)
        : 0,
      ingressSettings: isSet(object.ingressSettings)
        ? serviceConfig_IngressSettingsFromJSON(object.ingressSettings)
        : 0,
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      allTrafficOnLatestRevision: isSet(object.allTrafficOnLatestRevision)
        ? globalThis.Boolean(object.allTrafficOnLatestRevision)
        : false,
      secretEnvironmentVariables: globalThis.Array.isArray(object?.secretEnvironmentVariables)
        ? object.secretEnvironmentVariables.map((e: any) => SecretEnvVar.fromJSON(e))
        : [],
      secretVolumes: globalThis.Array.isArray(object?.secretVolumes)
        ? object.secretVolumes.map((e: any) => SecretVolume.fromJSON(e))
        : [],
      revision: isSet(object.revision) ? globalThis.String(object.revision) : "",
      maxInstanceRequestConcurrency: isSet(object.maxInstanceRequestConcurrency)
        ? globalThis.Number(object.maxInstanceRequestConcurrency)
        : 0,
      securityLevel: isSet(object.securityLevel) ? serviceConfig_SecurityLevelFromJSON(object.securityLevel) : 0,
    };
  },

  toJSON(message: ServiceConfig): unknown {
    const obj: any = {};
    if (message.service !== "") {
      obj.service = message.service;
    }
    if (message.timeoutSeconds !== 0) {
      obj.timeoutSeconds = Math.round(message.timeoutSeconds);
    }
    if (message.availableMemory !== "") {
      obj.availableMemory = message.availableMemory;
    }
    if (message.availableCpu !== "") {
      obj.availableCpu = message.availableCpu;
    }
    if (message.environmentVariables) {
      const entries = Object.entries(message.environmentVariables);
      if (entries.length > 0) {
        obj.environmentVariables = {};
        entries.forEach(([k, v]) => {
          obj.environmentVariables[k] = v;
        });
      }
    }
    if (message.maxInstanceCount !== 0) {
      obj.maxInstanceCount = Math.round(message.maxInstanceCount);
    }
    if (message.minInstanceCount !== 0) {
      obj.minInstanceCount = Math.round(message.minInstanceCount);
    }
    if (message.vpcConnector !== "") {
      obj.vpcConnector = message.vpcConnector;
    }
    if (message.vpcConnectorEgressSettings !== 0) {
      obj.vpcConnectorEgressSettings = serviceConfig_VpcConnectorEgressSettingsToJSON(
        message.vpcConnectorEgressSettings,
      );
    }
    if (message.ingressSettings !== 0) {
      obj.ingressSettings = serviceConfig_IngressSettingsToJSON(message.ingressSettings);
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.allTrafficOnLatestRevision !== false) {
      obj.allTrafficOnLatestRevision = message.allTrafficOnLatestRevision;
    }
    if (message.secretEnvironmentVariables?.length) {
      obj.secretEnvironmentVariables = message.secretEnvironmentVariables.map((e) => SecretEnvVar.toJSON(e));
    }
    if (message.secretVolumes?.length) {
      obj.secretVolumes = message.secretVolumes.map((e) => SecretVolume.toJSON(e));
    }
    if (message.revision !== "") {
      obj.revision = message.revision;
    }
    if (message.maxInstanceRequestConcurrency !== 0) {
      obj.maxInstanceRequestConcurrency = Math.round(message.maxInstanceRequestConcurrency);
    }
    if (message.securityLevel !== 0) {
      obj.securityLevel = serviceConfig_SecurityLevelToJSON(message.securityLevel);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ServiceConfig>, I>>(base?: I): ServiceConfig {
    return ServiceConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ServiceConfig>, I>>(object: I): ServiceConfig {
    const message = createBaseServiceConfig();
    message.service = object.service ?? "";
    message.timeoutSeconds = object.timeoutSeconds ?? 0;
    message.availableMemory = object.availableMemory ?? "";
    message.availableCpu = object.availableCpu ?? "";
    message.environmentVariables = Object.entries(object.environmentVariables ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.maxInstanceCount = object.maxInstanceCount ?? 0;
    message.minInstanceCount = object.minInstanceCount ?? 0;
    message.vpcConnector = object.vpcConnector ?? "";
    message.vpcConnectorEgressSettings = object.vpcConnectorEgressSettings ?? 0;
    message.ingressSettings = object.ingressSettings ?? 0;
    message.uri = object.uri ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.allTrafficOnLatestRevision = object.allTrafficOnLatestRevision ?? false;
    message.secretEnvironmentVariables = object.secretEnvironmentVariables?.map((e) => SecretEnvVar.fromPartial(e)) ||
      [];
    message.secretVolumes = object.secretVolumes?.map((e) => SecretVolume.fromPartial(e)) || [];
    message.revision = object.revision ?? "";
    message.maxInstanceRequestConcurrency = object.maxInstanceRequestConcurrency ?? 0;
    message.securityLevel = object.securityLevel ?? 0;
    return message;
  },
};

function createBaseServiceConfig_EnvironmentVariablesEntry(): ServiceConfig_EnvironmentVariablesEntry {
  return { key: "", value: "" };
}

export const ServiceConfig_EnvironmentVariablesEntry: MessageFns<ServiceConfig_EnvironmentVariablesEntry> = {
  encode(message: ServiceConfig_EnvironmentVariablesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceConfig_EnvironmentVariablesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceConfig_EnvironmentVariablesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceConfig_EnvironmentVariablesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ServiceConfig_EnvironmentVariablesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ServiceConfig_EnvironmentVariablesEntry>, I>>(
    base?: I,
  ): ServiceConfig_EnvironmentVariablesEntry {
    return ServiceConfig_EnvironmentVariablesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ServiceConfig_EnvironmentVariablesEntry>, I>>(
    object: I,
  ): ServiceConfig_EnvironmentVariablesEntry {
    const message = createBaseServiceConfig_EnvironmentVariablesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSecretEnvVar(): SecretEnvVar {
  return { key: "", projectId: "", secret: "", version: "" };
}

export const SecretEnvVar: MessageFns<SecretEnvVar> = {
  encode(message: SecretEnvVar, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    if (message.version !== "") {
      writer.uint32(34).string(message.version);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretEnvVar {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretEnvVar();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.version = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretEnvVar {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
    };
  },

  toJSON(message: SecretEnvVar): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SecretEnvVar>, I>>(base?: I): SecretEnvVar {
    return SecretEnvVar.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SecretEnvVar>, I>>(object: I): SecretEnvVar {
    const message = createBaseSecretEnvVar();
    message.key = object.key ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.version = object.version ?? "";
    return message;
  },
};

function createBaseSecretVolume(): SecretVolume {
  return { mountPath: "", projectId: "", secret: "", versions: [] };
}

export const SecretVolume: MessageFns<SecretVolume> = {
  encode(message: SecretVolume, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.mountPath !== "") {
      writer.uint32(10).string(message.mountPath);
    }
    if (message.projectId !== "") {
      writer.uint32(18).string(message.projectId);
    }
    if (message.secret !== "") {
      writer.uint32(26).string(message.secret);
    }
    for (const v of message.versions) {
      SecretVolume_SecretVersion.encode(v!, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.mountPath = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.projectId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.secret = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.versions.push(SecretVolume_SecretVersion.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume {
    return {
      mountPath: isSet(object.mountPath) ? globalThis.String(object.mountPath) : "",
      projectId: isSet(object.projectId) ? globalThis.String(object.projectId) : "",
      secret: isSet(object.secret) ? globalThis.String(object.secret) : "",
      versions: globalThis.Array.isArray(object?.versions)
        ? object.versions.map((e: any) => SecretVolume_SecretVersion.fromJSON(e))
        : [],
    };
  },

  toJSON(message: SecretVolume): unknown {
    const obj: any = {};
    if (message.mountPath !== "") {
      obj.mountPath = message.mountPath;
    }
    if (message.projectId !== "") {
      obj.projectId = message.projectId;
    }
    if (message.secret !== "") {
      obj.secret = message.secret;
    }
    if (message.versions?.length) {
      obj.versions = message.versions.map((e) => SecretVolume_SecretVersion.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SecretVolume>, I>>(base?: I): SecretVolume {
    return SecretVolume.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SecretVolume>, I>>(object: I): SecretVolume {
    const message = createBaseSecretVolume();
    message.mountPath = object.mountPath ?? "";
    message.projectId = object.projectId ?? "";
    message.secret = object.secret ?? "";
    message.versions = object.versions?.map((e) => SecretVolume_SecretVersion.fromPartial(e)) || [];
    return message;
  },
};

function createBaseSecretVolume_SecretVersion(): SecretVolume_SecretVersion {
  return { version: "", path: "" };
}

export const SecretVolume_SecretVersion: MessageFns<SecretVolume_SecretVersion> = {
  encode(message: SecretVolume_SecretVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.path !== "") {
      writer.uint32(18).string(message.path);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SecretVolume_SecretVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecretVolume_SecretVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.path = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SecretVolume_SecretVersion {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      path: isSet(object.path) ? globalThis.String(object.path) : "",
    };
  },

  toJSON(message: SecretVolume_SecretVersion): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.path !== "") {
      obj.path = message.path;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SecretVolume_SecretVersion>, I>>(base?: I): SecretVolume_SecretVersion {
    return SecretVolume_SecretVersion.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SecretVolume_SecretVersion>, I>>(object: I): SecretVolume_SecretVersion {
    const message = createBaseSecretVolume_SecretVersion();
    message.version = object.version ?? "";
    message.path = object.path ?? "";
    return message;
  },
};

function createBaseEventTrigger(): EventTrigger {
  return {
    trigger: "",
    triggerRegion: "",
    eventType: "",
    eventFilters: [],
    pubsubTopic: "",
    serviceAccountEmail: "",
    retryPolicy: 0,
    channel: "",
  };
}

export const EventTrigger: MessageFns<EventTrigger> = {
  encode(message: EventTrigger, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.trigger !== "") {
      writer.uint32(10).string(message.trigger);
    }
    if (message.triggerRegion !== "") {
      writer.uint32(18).string(message.triggerRegion);
    }
    if (message.eventType !== "") {
      writer.uint32(26).string(message.eventType);
    }
    for (const v of message.eventFilters) {
      EventFilter.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.pubsubTopic !== "") {
      writer.uint32(42).string(message.pubsubTopic);
    }
    if (message.serviceAccountEmail !== "") {
      writer.uint32(50).string(message.serviceAccountEmail);
    }
    if (message.retryPolicy !== 0) {
      writer.uint32(56).int32(message.retryPolicy);
    }
    if (message.channel !== "") {
      writer.uint32(66).string(message.channel);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventTrigger {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventTrigger();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.trigger = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.triggerRegion = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.eventType = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.eventFilters.push(EventFilter.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.pubsubTopic = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.serviceAccountEmail = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.retryPolicy = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.channel = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventTrigger {
    return {
      trigger: isSet(object.trigger) ? globalThis.String(object.trigger) : "",
      triggerRegion: isSet(object.triggerRegion) ? globalThis.String(object.triggerRegion) : "",
      eventType: isSet(object.eventType) ? globalThis.String(object.eventType) : "",
      eventFilters: globalThis.Array.isArray(object?.eventFilters)
        ? object.eventFilters.map((e: any) => EventFilter.fromJSON(e))
        : [],
      pubsubTopic: isSet(object.pubsubTopic) ? globalThis.String(object.pubsubTopic) : "",
      serviceAccountEmail: isSet(object.serviceAccountEmail) ? globalThis.String(object.serviceAccountEmail) : "",
      retryPolicy: isSet(object.retryPolicy) ? eventTrigger_RetryPolicyFromJSON(object.retryPolicy) : 0,
      channel: isSet(object.channel) ? globalThis.String(object.channel) : "",
    };
  },

  toJSON(message: EventTrigger): unknown {
    const obj: any = {};
    if (message.trigger !== "") {
      obj.trigger = message.trigger;
    }
    if (message.triggerRegion !== "") {
      obj.triggerRegion = message.triggerRegion;
    }
    if (message.eventType !== "") {
      obj.eventType = message.eventType;
    }
    if (message.eventFilters?.length) {
      obj.eventFilters = message.eventFilters.map((e) => EventFilter.toJSON(e));
    }
    if (message.pubsubTopic !== "") {
      obj.pubsubTopic = message.pubsubTopic;
    }
    if (message.serviceAccountEmail !== "") {
      obj.serviceAccountEmail = message.serviceAccountEmail;
    }
    if (message.retryPolicy !== 0) {
      obj.retryPolicy = eventTrigger_RetryPolicyToJSON(message.retryPolicy);
    }
    if (message.channel !== "") {
      obj.channel = message.channel;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EventTrigger>, I>>(base?: I): EventTrigger {
    return EventTrigger.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EventTrigger>, I>>(object: I): EventTrigger {
    const message = createBaseEventTrigger();
    message.trigger = object.trigger ?? "";
    message.triggerRegion = object.triggerRegion ?? "";
    message.eventType = object.eventType ?? "";
    message.eventFilters = object.eventFilters?.map((e) => EventFilter.fromPartial(e)) || [];
    message.pubsubTopic = object.pubsubTopic ?? "";
    message.serviceAccountEmail = object.serviceAccountEmail ?? "";
    message.retryPolicy = object.retryPolicy ?? 0;
    message.channel = object.channel ?? "";
    return message;
  },
};

function createBaseEventFilter(): EventFilter {
  return { attribute: "", value: "", operator: "" };
}

export const EventFilter: MessageFns<EventFilter> = {
  encode(message: EventFilter, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.attribute !== "") {
      writer.uint32(10).string(message.attribute);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    if (message.operator !== "") {
      writer.uint32(26).string(message.operator);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EventFilter {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEventFilter();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.attribute = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.operator = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EventFilter {
    return {
      attribute: isSet(object.attribute) ? globalThis.String(object.attribute) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
      operator: isSet(object.operator) ? globalThis.String(object.operator) : "",
    };
  },

  toJSON(message: EventFilter): unknown {
    const obj: any = {};
    if (message.attribute !== "") {
      obj.attribute = message.attribute;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    if (message.operator !== "") {
      obj.operator = message.operator;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EventFilter>, I>>(base?: I): EventFilter {
    return EventFilter.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EventFilter>, I>>(object: I): EventFilter {
    const message = createBaseEventFilter();
    message.attribute = object.attribute ?? "";
    message.value = object.value ?? "";
    message.operator = object.operator ?? "";
    return message;
  },
};

function createBaseFunctionEventData(): FunctionEventData {
  return { payload: undefined };
}

export const FunctionEventData: MessageFns<FunctionEventData> = {
  encode(message: FunctionEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      FunctionMessage.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FunctionEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFunctionEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = FunctionMessage.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FunctionEventData {
    return { payload: isSet(object.payload) ? FunctionMessage.fromJSON(object.payload) : undefined };
  },

  toJSON(message: FunctionEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = FunctionMessage.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<FunctionEventData>, I>>(base?: I): FunctionEventData {
    return FunctionEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<FunctionEventData>, I>>(object: I): FunctionEventData {
    const message = createBaseFunctionEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? FunctionMessage.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
