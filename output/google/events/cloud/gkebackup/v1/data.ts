// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/gkebackup/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../../protobuf/timestamp";

export const protobufPackage = "google.events.cloud.gkebackup.v1";

/** A list of Kubernetes Namespaces */
export interface Namespaces {
  /** A list of Kubernetes Namespaces */
  namespaces: string[];
}

/** A reference to a namespaced resource in Kubernetes. */
export interface NamespacedName {
  /** The Namespace of the Kubernetes resource. */
  namespace: string;
  /** The name of the Kubernetes resource. */
  name: string;
}

/** A list of namespaced Kubernetes resources. */
export interface NamespacedNames {
  /** A list of namespaced Kubernetes resources. */
  namespacedNames: NamespacedName[];
}

/**
 * Defined a customer managed encryption key that will be used to encrypt Backup
 * artifacts.
 */
export interface EncryptionKey {
  /**
   * Google Cloud KMS encryption key. Format:
   * `projects/* /locations/* /keyRings/* /cryptoKeys/*`
   */
  gcpKmsEncryptionKey: string;
}

/**
 * Represents a request to perform a single point-in-time capture of
 * some portion of the state of a GKE cluster, the record of the backup
 * operation itself, and an anchor for the underlying artifacts that
 * comprise the Backup (the config backup and VolumeBackups).
 * Next id: 28
 */
export interface Backup {
  /**
   * Output only. The fully qualified name of the Backup.
   * `projects/* /locations/* /backupPlans/* /backups/*`
   */
  name: string;
  /**
   * Output only. Server generated global unique identifier of
   * [UUID4](https://en.wikipedia.org/wiki/Universally_unique_identifier)
   */
  uid: string;
  /** Output only. The timestamp when this Backup resource was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The timestamp when this Backup resource was last updated. */
  updateTime?:
    | Date
    | undefined;
  /**
   * Output only. This flag indicates whether this Backup resource was created
   * manually by a user or via a schedule in the BackupPlan. A value of True
   * means that the Backup was created manually.
   */
  manual: boolean;
  /** A set of custom labels supplied by user. */
  labels: { [key: string]: string };
  /**
   * Minimum age for this Backup (in days). If this field is set to a non-zero
   * value, the Backup will be "locked" against deletion (either manual or
   * automatic deletion) for the number of days provided (measured from the
   * creation time of the Backup).  MUST be an integer value between 0-90
   * (inclusive).
   *
   * Defaults to parent BackupPlan's
   * [backup_delete_lock_days][google.cloud.gkebackup.v1.BackupPlan.RetentionPolicy.backup_delete_lock_days]
   * setting and may only be increased
   * (either at creation time or in a subsequent update).
   */
  deleteLockDays: number;
  /**
   * Output only. The time at which an existing delete lock will expire for this
   * backup (calculated from create_time +
   * [delete_lock_days][google.cloud.gkebackup.v1.Backup.delete_lock_days]).
   */
  deleteLockExpireTime?:
    | Date
    | undefined;
  /**
   * The age (in days) after which this Backup will be automatically deleted.
   * Must be an integer value >= 0:
   *
   * - If 0, no automatic deletion will occur for this Backup.
   * - If not 0, this must be >=
   * [delete_lock_days][google.cloud.gkebackup.v1.Backup.delete_lock_days] and
   * <= 365.
   *
   * Once a Backup is created, this value may only be increased.
   *
   * Defaults to the parent BackupPlan's
   * [backup_retain_days][google.cloud.gkebackup.v1.BackupPlan.RetentionPolicy.backup_retain_days]
   * value.
   */
  retainDays: number;
  /**
   * Output only. The time at which this Backup will be automatically deleted
   * (calculated from create_time +
   * [retain_days][google.cloud.gkebackup.v1.Backup.retain_days]).
   */
  retainExpireTime?:
    | Date
    | undefined;
  /**
   * Output only. The customer managed encryption key that was used to encrypt
   * the Backup's artifacts.  Inherited from the parent BackupPlan's
   * [encryption_key][google.cloud.gkebackup.v1.BackupPlan.BackupConfig.encryption_key]
   * value.
   */
  encryptionKey?:
    | EncryptionKey
    | undefined;
  /** Output only. If True, all namespaces were included in the Backup. */
  allNamespaces?:
    | boolean
    | undefined;
  /**
   * Output only. If set, the list of namespaces that were included in the
   * Backup.
   */
  selectedNamespaces?:
    | Namespaces
    | undefined;
  /**
   * Output only. If set, the list of ProtectedApplications whose resources
   * were included in the Backup.
   */
  selectedApplications?:
    | NamespacedNames
    | undefined;
  /**
   * Output only. Whether or not the Backup contains volume data.  Controlled by
   * the parent BackupPlan's
   * [include_volume_data][google.cloud.gkebackup.v1.BackupPlan.BackupConfig.include_volume_data]
   * value.
   */
  containsVolumeData: boolean;
  /**
   * Output only. Whether or not the Backup contains Kubernetes Secrets.
   * Controlled by the parent BackupPlan's
   * [include_secrets][google.cloud.gkebackup.v1.BackupPlan.BackupConfig.include_secrets]
   * value.
   */
  containsSecrets: boolean;
  /**
   * Output only. Information about the GKE cluster from which this Backup was
   * created.
   */
  clusterMetadata?:
    | Backup_ClusterMetadata
    | undefined;
  /** Output only. Current state of the Backup */
  state: Backup_State;
  /**
   * Output only. Human-readable description of why the backup is in the current
   * `state`.
   */
  stateReason: string;
  /** Output only. Completion time of the Backup */
  completeTime?:
    | Date
    | undefined;
  /**
   * Output only. The total number of Kubernetes resources included in the
   * Backup.
   */
  resourceCount: number;
  /** Output only. The total number of volume backups contained in the Backup. */
  volumeCount: number;
  /**
   * Output only. The total size of the Backup in bytes = config backup size +
   * sum(volume backup sizes)
   */
  sizeBytes: Long;
  /**
   * Output only. `etag` is used for optimistic concurrency control as a way to
   * help prevent simultaneous updates of a backup from overwriting each other.
   * It is strongly suggested that systems make use of the `etag` in the
   * read-modify-write cycle to perform backup updates in order to avoid
   * race conditions: An `etag` is returned in the response to `GetBackup`,
   * and systems are expected to put that etag in the request to
   * `UpdateBackup` or `DeleteBackup` to ensure that their change will be
   * applied to the same version of the resource.
   */
  etag: string;
  /** User specified descriptive string for this Backup. */
  description: string;
  /** Output only. The total number of Kubernetes Pods contained in the Backup. */
  podCount: number;
  /** Output only. The size of the config backup in bytes. */
  configBackupSizeBytes: Long;
}

/** State */
export enum Backup_State {
  /** STATE_UNSPECIFIED - The Backup resource is in the process of being created. */
  STATE_UNSPECIFIED = 0,
  /**
   * CREATING - The Backup resource has been created and the associated BackupJob
   * Kubernetes resource has been injected into the source cluster.
   */
  CREATING = 1,
  /**
   * IN_PROGRESS - The gkebackup agent in the cluster has begun executing the backup
   * operation.
   */
  IN_PROGRESS = 2,
  /** SUCCEEDED - The backup operation has completed successfully. */
  SUCCEEDED = 3,
  /** FAILED - The backup operation has failed. */
  FAILED = 4,
  /**
   * DELETING - This Backup resource (and its associated artifacts) is in the process
   * of being deleted.
   */
  DELETING = 5,
  UNRECOGNIZED = -1,
}

export function backup_StateFromJSON(object: any): Backup_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Backup_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Backup_State.CREATING;
    case 2:
    case "IN_PROGRESS":
      return Backup_State.IN_PROGRESS;
    case 3:
    case "SUCCEEDED":
      return Backup_State.SUCCEEDED;
    case 4:
    case "FAILED":
      return Backup_State.FAILED;
    case 5:
    case "DELETING":
      return Backup_State.DELETING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Backup_State.UNRECOGNIZED;
  }
}

export function backup_StateToJSON(object: Backup_State): string {
  switch (object) {
    case Backup_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Backup_State.CREATING:
      return "CREATING";
    case Backup_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Backup_State.SUCCEEDED:
      return "SUCCEEDED";
    case Backup_State.FAILED:
      return "FAILED";
    case Backup_State.DELETING:
      return "DELETING";
    case Backup_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Information about the GKE cluster from which this Backup was created. */
export interface Backup_ClusterMetadata {
  /**
   * The source cluster from which this Backup was created.
   * Valid formats:
   *
   *   - `projects/* /locations/* /clusters/*`
   *   - `projects/* /zones/* /clusters/*`
   *
   * This is inherited from the parent BackupPlan's
   * [cluster][google.cloud.gkebackup.v1.BackupPlan.cluster] field.
   */
  cluster: string;
  /** The Kubernetes server version of the source cluster. */
  k8sVersion: string;
  /** A list of the Backup for GKE CRD versions found in the cluster. */
  backupCrdVersions: { [key: string]: string };
  /** GKE version */
  gkeVersion?:
    | string
    | undefined;
  /** Anthos version */
  anthosVersion?: string | undefined;
}

export interface Backup_ClusterMetadata_BackupCrdVersionsEntry {
  key: string;
  value: string;
}

export interface Backup_LabelsEntry {
  key: string;
  value: string;
}

/** Defines the configuration and scheduling for a "line" of Backups. */
export interface BackupPlan {
  /**
   * Output only. The full name of the BackupPlan resource.
   * Format: `projects/* /locations/* /backupPlans/*`
   */
  name: string;
  /**
   * Output only. Server generated global unique identifier of
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier) format.
   */
  uid: string;
  /** Output only. The timestamp when this BackupPlan resource was created. */
  createTime?:
    | Date
    | undefined;
  /**
   * Output only. The timestamp when this BackupPlan resource was last
   * updated.
   */
  updateTime?:
    | Date
    | undefined;
  /** User specified descriptive string for this BackupPlan. */
  description: string;
  /**
   * Required. Immutable. The source cluster from which Backups will be created
   * via this BackupPlan. Valid formats:
   *
   * - `projects/* /locations/* /clusters/*`
   * - `projects/* /zones/* /clusters/*`
   */
  cluster: string;
  /** RetentionPolicy governs lifecycle of Backups created under this plan. */
  retentionPolicy?:
    | BackupPlan_RetentionPolicy
    | undefined;
  /** A set of custom labels supplied by user. */
  labels: { [key: string]: string };
  /** Defines a schedule for automatic Backup creation via this BackupPlan. */
  backupSchedule?:
    | BackupPlan_Schedule
    | undefined;
  /**
   * Output only. `etag` is used for optimistic concurrency control as a way to
   * help prevent simultaneous updates of a backup plan from overwriting each
   * other. It is strongly suggested that systems make use of the 'etag' in the
   * read-modify-write cycle to perform BackupPlan updates in order to avoid
   * race conditions: An `etag` is returned in the response to `GetBackupPlan`,
   * and systems are expected to put that etag in the request to
   * `UpdateBackupPlan` or `DeleteBackupPlan` to ensure that their change
   * will be applied to the same version of the resource.
   */
  etag: string;
  /**
   * This flag indicates whether this BackupPlan has been deactivated.
   * Setting this field to True locks the BackupPlan such that no further
   * updates will be allowed (except deletes), including the deactivated field
   * itself. It also prevents any new Backups from being created via this
   * BackupPlan (including scheduled Backups).
   *
   * Default: False
   */
  deactivated: boolean;
  /** Defines the configuration of Backups created via this BackupPlan. */
  backupConfig?:
    | BackupPlan_BackupConfig
    | undefined;
  /**
   * Output only. The number of Kubernetes Pods backed up in the
   * last successful Backup created via this BackupPlan.
   */
  protectedPodCount: number;
}

/** RetentionPolicy defines a Backup retention policy for a BackupPlan. */
export interface BackupPlan_RetentionPolicy {
  /**
   * Minimum age for Backups created via this BackupPlan (in days).
   * This field MUST be an integer value between 0-90 (inclusive).
   * A Backup created under this BackupPlan will NOT be deletable until it
   * reaches Backup's (create_time + backup_delete_lock_days).
   * Updating this field of a BackupPlan does NOT affect existing Backups
   * under it. Backups created AFTER a successful update will inherit
   * the new value.
   *
   * Default: 0 (no delete blocking)
   */
  backupDeleteLockDays: number;
  /**
   * The default maximum age of a Backup created via this BackupPlan.
   * This field MUST be an integer value >= 0 and <= 365.
   * If specified, a Backup created under this BackupPlan will be
   * automatically deleted after its age reaches (create_time +
   * backup_retain_days).
   * If not specified, Backups created under this BackupPlan will NOT be
   * subject to automatic deletion.
   * Updating this field does NOT affect existing Backups under it. Backups
   * created AFTER a successful update will automatically pick up the new
   * value.
   * NOTE: backup_retain_days must be >=
   * [backup_delete_lock_days][google.cloud.gkebackup.v1.BackupPlan.RetentionPolicy.backup_delete_lock_days].
   * If
   * [cron_schedule][google.cloud.gkebackup.v1.BackupPlan.Schedule.cron_schedule]
   * is defined, then this must be
   * <= 360 * the creation interval.
   *
   * Default: 0 (no automatic deletion)
   */
  backupRetainDays: number;
  /**
   * This flag denotes whether the retention policy of this BackupPlan is
   * locked.  If set to True, no further update is allowed on this policy,
   * including the `locked` field itself.
   *
   * Default: False
   */
  locked: boolean;
}

/**
 * Schedule defines scheduling parameters for automatically creating Backups
 * via this BackupPlan.
 */
export interface BackupPlan_Schedule {
  /**
   * A standard [cron](https://wikipedia.com/wiki/cron) string that defines a
   * repeating schedule for creating Backups via this BackupPlan. If this is
   * defined, then
   * [backup_retain_days][google.cloud.gkebackup.v1.BackupPlan.RetentionPolicy.backup_retain_days]
   * must also be defined.
   *
   * Default (empty): no automatic backup creation will occur.
   */
  cronSchedule: string;
  /**
   * This flag denotes whether automatic Backup creation is paused for this
   * BackupPlan.
   *
   * Default: False
   */
  paused: boolean;
}

/**
 * BackupConfig defines the configuration of Backups created via this
 * BackupPlan.
 */
export interface BackupPlan_BackupConfig {
  /** If True, include all namespaced resources */
  allNamespaces?:
    | boolean
    | undefined;
  /** If set, include just the resources in the listed namespaces. */
  selectedNamespaces?:
    | Namespaces
    | undefined;
  /**
   * If set, include just the resources referenced by the listed
   * ProtectedApplications.
   */
  selectedApplications?:
    | NamespacedNames
    | undefined;
  /**
   * This flag specifies whether volume data should be backed up when
   * PVCs are included in the scope of a Backup.
   *
   * Default: False
   */
  includeVolumeData: boolean;
  /**
   * This flag specifies whether Kubernetes Secret resources should be
   * included when they fall into the scope of Backups.
   *
   * Default: False
   */
  includeSecrets: boolean;
  /**
   * This defines a customer managed encryption key that will be used to
   * encrypt the "config" portion (the Kubernetes resources) of Backups
   * created via this plan.
   *
   * Default (empty): Config backup artifacts will not be encrypted.
   */
  encryptionKey?: EncryptionKey | undefined;
}

export interface BackupPlan_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Represents both a request to Restore some portion of a Backup into
 * a target GKE cluster and a record of the restore operation itself.
 * Next id: 18
 */
export interface Restore {
  /**
   * Output only. The full name of the Restore resource.
   * Format: `projects/* /locations/* /restorePlans/* /restores/*`
   */
  name: string;
  /**
   * Output only. Server generated global unique identifier of
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier) format.
   */
  uid: string;
  /** Output only. The timestamp when this Restore resource was created. */
  createTime?:
    | Date
    | undefined;
  /**
   * Output only. The timestamp when this Restore resource was last
   * updated.
   */
  updateTime?:
    | Date
    | undefined;
  /** User specified descriptive string for this Restore. */
  description: string;
  /**
   * Required. Immutable. A reference to the
   * [Backup][google.cloud.gkebackup.v1.Backup] used as the source from which
   * this Restore will restore. Note that this Backup must be a sub-resource of
   * the RestorePlan's
   * [backup_plan][google.cloud.gkebackup.v1.RestorePlan.backup_plan]. Format:
   * `projects/* /locations/* /backupPlans/* /backups/*`.
   */
  backup: string;
  /**
   * Output only. The target cluster into which this Restore will restore data.
   * Valid formats:
   *
   *   - `projects/* /locations/* /clusters/*`
   *   - `projects/* /zones/* /clusters/*`
   *
   * Inherited from parent RestorePlan's
   * [cluster][google.cloud.gkebackup.v1.RestorePlan.cluster] value.
   */
  cluster: string;
  /**
   * Output only. Configuration of the Restore.  Inherited from parent
   * RestorePlan's
   * [restore_config][google.cloud.gkebackup.v1.RestorePlan.restore_config].
   */
  restoreConfig?:
    | RestoreConfig
    | undefined;
  /** A set of custom labels supplied by user. */
  labels: { [key: string]: string };
  /** Output only. The current state of the Restore. */
  state: Restore_State;
  /**
   * Output only. Human-readable description of why the Restore is in its
   * current state.
   */
  stateReason: string;
  /** Output only. Timestamp of when the restore operation completed. */
  completeTime?:
    | Date
    | undefined;
  /** Output only. Number of resources restored during the restore execution. */
  resourcesRestoredCount: number;
  /** Output only. Number of resources excluded during the restore execution. */
  resourcesExcludedCount: number;
  /**
   * Output only. Number of resources that failed to be restored during the
   * restore execution.
   */
  resourcesFailedCount: number;
  /** Output only. Number of volumes restored during the restore execution. */
  volumesRestoredCount: number;
  /**
   * Output only. `etag` is used for optimistic concurrency control as a way to
   * help prevent simultaneous updates of a restore from overwriting each other.
   * It is strongly suggested that systems make use of the `etag` in the
   * read-modify-write cycle to perform restore updates in order to avoid
   * race conditions: An `etag` is returned in the response to `GetRestore`,
   * and systems are expected to put that etag in the request to
   * `UpdateRestore` or `DeleteRestore` to ensure that their change will be
   * applied to the same version of the resource.
   */
  etag: string;
}

/** Possible values for state of the Restore. */
export enum Restore_State {
  /** STATE_UNSPECIFIED - The Restore resource is in the process of being created. */
  STATE_UNSPECIFIED = 0,
  /**
   * CREATING - The Restore resource has been created and the associated RestoreJob
   * Kubernetes resource has been injected into target cluster.
   */
  CREATING = 1,
  /**
   * IN_PROGRESS - The gkebackup agent in the cluster has begun executing the restore
   * operation.
   */
  IN_PROGRESS = 2,
  /**
   * SUCCEEDED - The restore operation has completed successfully. Restored workloads may
   * not yet be operational.
   */
  SUCCEEDED = 3,
  /** FAILED - The restore operation has failed. */
  FAILED = 4,
  /** DELETING - This Restore resource is in the process of being deleted. */
  DELETING = 5,
  UNRECOGNIZED = -1,
}

export function restore_StateFromJSON(object: any): Restore_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Restore_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Restore_State.CREATING;
    case 2:
    case "IN_PROGRESS":
      return Restore_State.IN_PROGRESS;
    case 3:
    case "SUCCEEDED":
      return Restore_State.SUCCEEDED;
    case 4:
    case "FAILED":
      return Restore_State.FAILED;
    case 5:
    case "DELETING":
      return Restore_State.DELETING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Restore_State.UNRECOGNIZED;
  }
}

export function restore_StateToJSON(object: Restore_State): string {
  switch (object) {
    case Restore_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Restore_State.CREATING:
      return "CREATING";
    case Restore_State.IN_PROGRESS:
      return "IN_PROGRESS";
    case Restore_State.SUCCEEDED:
      return "SUCCEEDED";
    case Restore_State.FAILED:
      return "FAILED";
    case Restore_State.DELETING:
      return "DELETING";
    case Restore_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Restore_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Configuration of a restore.
 * Next id: 12
 */
export interface RestoreConfig {
  /**
   * Specifies the mechanism to be used to restore volume data.
   * Default: VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED (will be treated as
   * NO_VOLUME_DATA_RESTORATION).
   */
  volumeDataRestorePolicy: RestoreConfig_VolumeDataRestorePolicy;
  /**
   * Defines the behavior for handling the situation where cluster-scoped
   * resources being restored already exist in the target cluster. This MUST be
   * set to a value other than CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED if
   * [cluster_resource_restore_scope][google.cloud.gkebackup.v1.RestoreConfig.cluster_resource_restore_scope]
   * is not empty.
   */
  clusterResourceConflictPolicy: RestoreConfig_ClusterResourceConflictPolicy;
  /**
   * Defines the behavior for handling the situation where sets of namespaced
   * resources being restored already exist in the target cluster. This MUST be
   * set to a value other than NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED.
   */
  namespacedResourceRestoreMode: RestoreConfig_NamespacedResourceRestoreMode;
  /**
   * Identifies the cluster-scoped resources to restore from the Backup.
   * Not specifying it means NO cluster resource will be restored.
   */
  clusterResourceRestoreScope?:
    | RestoreConfig_ClusterResourceRestoreScope
    | undefined;
  /**
   * Restore all namespaced resources in the Backup if set to "True".
   * Specifying this field to "False" is an error.
   */
  allNamespaces?:
    | boolean
    | undefined;
  /**
   * A list of selected Namespaces to restore from the Backup. The listed
   * Namespaces and all resources contained in them will be restored.
   */
  selectedNamespaces?:
    | Namespaces
    | undefined;
  /**
   * A list of selected ProtectedApplications to restore. The listed
   * ProtectedApplications and all the resources to which they refer will be
   * restored.
   */
  selectedApplications?:
    | NamespacedNames
    | undefined;
  /**
   * A list of transformation rules to be applied against Kubernetes resources
   * as they are selected for restoration from a Backup. Rules are executed in
   * order defined - this order matters, as changes made by a rule may impact
   * the filtering logic of subsequent rules. An empty list means no
   * substitution will occur.
   */
  substitutionRules: RestoreConfig_SubstitutionRule[];
}

/** Defines how volume data should be restored */
export enum RestoreConfig_VolumeDataRestorePolicy {
  /** VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED - Unspecified (illegal). */
  VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED = 0,
  /**
   * RESTORE_VOLUME_DATA_FROM_BACKUP - For each PVC to be restored, will create a new underlying volume (and PV)
   * from the corresponding VolumeBackup contained within the Backup.
   */
  RESTORE_VOLUME_DATA_FROM_BACKUP = 1,
  /**
   * REUSE_VOLUME_HANDLE_FROM_BACKUP - For each PVC to be restored, attempt to reuse the original PV contained
   * in the Backup (with its original underlying volume).  Note that option
   * is likely only usable when restoring a workload to its original cluster.
   */
  REUSE_VOLUME_HANDLE_FROM_BACKUP = 2,
  /**
   * NO_VOLUME_DATA_RESTORATION - For each PVC to be restored, PVCs will be created without any particular
   * action to restore data.  In this case, the normal Kubernetes provisioning
   * logic would kick in, and this would likely result in either dynamically
   * provisioning blank PVs or binding to statically provisioned PVs.
   */
  NO_VOLUME_DATA_RESTORATION = 3,
  UNRECOGNIZED = -1,
}

export function restoreConfig_VolumeDataRestorePolicyFromJSON(object: any): RestoreConfig_VolumeDataRestorePolicy {
  switch (object) {
    case 0:
    case "VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED":
      return RestoreConfig_VolumeDataRestorePolicy.VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED;
    case 1:
    case "RESTORE_VOLUME_DATA_FROM_BACKUP":
      return RestoreConfig_VolumeDataRestorePolicy.RESTORE_VOLUME_DATA_FROM_BACKUP;
    case 2:
    case "REUSE_VOLUME_HANDLE_FROM_BACKUP":
      return RestoreConfig_VolumeDataRestorePolicy.REUSE_VOLUME_HANDLE_FROM_BACKUP;
    case 3:
    case "NO_VOLUME_DATA_RESTORATION":
      return RestoreConfig_VolumeDataRestorePolicy.NO_VOLUME_DATA_RESTORATION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestoreConfig_VolumeDataRestorePolicy.UNRECOGNIZED;
  }
}

export function restoreConfig_VolumeDataRestorePolicyToJSON(object: RestoreConfig_VolumeDataRestorePolicy): string {
  switch (object) {
    case RestoreConfig_VolumeDataRestorePolicy.VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED:
      return "VOLUME_DATA_RESTORE_POLICY_UNSPECIFIED";
    case RestoreConfig_VolumeDataRestorePolicy.RESTORE_VOLUME_DATA_FROM_BACKUP:
      return "RESTORE_VOLUME_DATA_FROM_BACKUP";
    case RestoreConfig_VolumeDataRestorePolicy.REUSE_VOLUME_HANDLE_FROM_BACKUP:
      return "REUSE_VOLUME_HANDLE_FROM_BACKUP";
    case RestoreConfig_VolumeDataRestorePolicy.NO_VOLUME_DATA_RESTORATION:
      return "NO_VOLUME_DATA_RESTORATION";
    case RestoreConfig_VolumeDataRestorePolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Defines the behavior for handling the situation where cluster-scoped
 * resources being restored already exist in the target cluster.
 */
export enum RestoreConfig_ClusterResourceConflictPolicy {
  /**
   * CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED - Unspecified. Only allowed if no cluster-scoped resources will be
   * restored.
   */
  CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED = 0,
  /** USE_EXISTING_VERSION - Do not attempt to restore the conflicting resource. */
  USE_EXISTING_VERSION = 1,
  /**
   * USE_BACKUP_VERSION - Delete the existing version before re-creating it from the Backup.
   * Note that this is a dangerous option which could cause unintentional
   * data loss if used inappropriately - for example, deleting a CRD will
   * cause Kubernetes to delete all CRs of that type.
   */
  USE_BACKUP_VERSION = 2,
  UNRECOGNIZED = -1,
}

export function restoreConfig_ClusterResourceConflictPolicyFromJSON(
  object: any,
): RestoreConfig_ClusterResourceConflictPolicy {
  switch (object) {
    case 0:
    case "CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED":
      return RestoreConfig_ClusterResourceConflictPolicy.CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED;
    case 1:
    case "USE_EXISTING_VERSION":
      return RestoreConfig_ClusterResourceConflictPolicy.USE_EXISTING_VERSION;
    case 2:
    case "USE_BACKUP_VERSION":
      return RestoreConfig_ClusterResourceConflictPolicy.USE_BACKUP_VERSION;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestoreConfig_ClusterResourceConflictPolicy.UNRECOGNIZED;
  }
}

export function restoreConfig_ClusterResourceConflictPolicyToJSON(
  object: RestoreConfig_ClusterResourceConflictPolicy,
): string {
  switch (object) {
    case RestoreConfig_ClusterResourceConflictPolicy.CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED:
      return "CLUSTER_RESOURCE_CONFLICT_POLICY_UNSPECIFIED";
    case RestoreConfig_ClusterResourceConflictPolicy.USE_EXISTING_VERSION:
      return "USE_EXISTING_VERSION";
    case RestoreConfig_ClusterResourceConflictPolicy.USE_BACKUP_VERSION:
      return "USE_BACKUP_VERSION";
    case RestoreConfig_ClusterResourceConflictPolicy.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Defines the behavior for handling the situation where sets of namespaced
 * resources being restored already exist in the target cluster.
 */
export enum RestoreConfig_NamespacedResourceRestoreMode {
  /** NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED - Unspecified (invalid). */
  NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED = 0,
  /**
   * DELETE_AND_RESTORE - When conflicting top-level resources (either Namespaces or
   * ProtectedApplications, depending upon the scope) are encountered, this
   * will first trigger a delete of the conflicting resource AND ALL OF ITS
   * REFERENCED RESOURCES (e.g., all resources in the Namespace or all
   * resources referenced by the ProtectedApplication) before restoring the
   * resources from the Backup. This mode should only be used when you are
   * intending to revert some portion of a cluster to an earlier state.
   */
  DELETE_AND_RESTORE = 1,
  /**
   * FAIL_ON_CONFLICT - If conflicting top-level resources (either Namespaces or
   * ProtectedApplications, depending upon the scope) are encountered at the
   * beginning of a restore process, the Restore will fail.  If a conflict
   * occurs during the restore process itself (e.g., because an out of band
   * process creates conflicting resources), a conflict will be reported.
   */
  FAIL_ON_CONFLICT = 2,
  UNRECOGNIZED = -1,
}

export function restoreConfig_NamespacedResourceRestoreModeFromJSON(
  object: any,
): RestoreConfig_NamespacedResourceRestoreMode {
  switch (object) {
    case 0:
    case "NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED":
      return RestoreConfig_NamespacedResourceRestoreMode.NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED;
    case 1:
    case "DELETE_AND_RESTORE":
      return RestoreConfig_NamespacedResourceRestoreMode.DELETE_AND_RESTORE;
    case 2:
    case "FAIL_ON_CONFLICT":
      return RestoreConfig_NamespacedResourceRestoreMode.FAIL_ON_CONFLICT;
    case -1:
    case "UNRECOGNIZED":
    default:
      return RestoreConfig_NamespacedResourceRestoreMode.UNRECOGNIZED;
  }
}

export function restoreConfig_NamespacedResourceRestoreModeToJSON(
  object: RestoreConfig_NamespacedResourceRestoreMode,
): string {
  switch (object) {
    case RestoreConfig_NamespacedResourceRestoreMode.NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED:
      return "NAMESPACED_RESOURCE_RESTORE_MODE_UNSPECIFIED";
    case RestoreConfig_NamespacedResourceRestoreMode.DELETE_AND_RESTORE:
      return "DELETE_AND_RESTORE";
    case RestoreConfig_NamespacedResourceRestoreMode.FAIL_ON_CONFLICT:
      return "FAIL_ON_CONFLICT";
    case RestoreConfig_NamespacedResourceRestoreMode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * This is a direct map to the Kubernetes GroupKind type
 * [GroupKind](https://godoc.org/k8s.io/apimachinery/pkg/runtime/schema#GroupKind)
 * and is used for identifying specific "types" of resources to restore.
 */
export interface RestoreConfig_GroupKind {
  /**
   * API group string of a Kubernetes resource, e.g.
   * "apiextensions.k8s.io", "storage.k8s.io", etc.
   * Note: use empty string for core API group
   */
  resourceGroup: string;
  /**
   * Kind of a Kubernetes resource, e.g.
   * "CustomResourceDefinition", "StorageClass", etc.
   */
  resourceKind: string;
}

/**
 * Defines the scope of cluster-scoped resources to restore.
 *
 * Some group kinds are not reasonable choices for a restore, and will cause
 * an error if selected here. Any scope selection that would restore
 * "all valid" resources automatically excludes these group kinds.
 * - gkebackup.gke.io/BackupJob
 * - gkebackup.gke.io/RestoreJob
 * - metrics.k8s.io/NodeMetrics
 * - migration.k8s.io/StorageState
 * - migration.k8s.io/StorageVersionMigration
 * - Node
 * - snapshot.storage.k8s.io/VolumeSnapshotContent
 * - storage.k8s.io/CSINode
 *
 * Some group kinds are driven by restore configuration elsewhere,
 * and will cause an error if selected here.
 * - Namespace
 * - PersistentVolume
 */
export interface RestoreConfig_ClusterResourceRestoreScope {
  /**
   * A list of cluster-scoped resource group kinds to restore from the
   * backup. If specified, only the selected resources will be restored.
   * Mutually exclusive to any other field in the message.
   */
  selectedGroupKinds: RestoreConfig_GroupKind[];
}

/**
 * A transformation rule to be applied against Kubernetes resources as they
 * are selected for restoration from a Backup. A rule contains both filtering
 * logic (which resources are subject to substitution) and substitution logic.
 */
export interface RestoreConfig_SubstitutionRule {
  /**
   * (Filtering parameter) Any resource subject to substitution must be
   * contained within one of the listed Kubernetes Namespace in the Backup.
   * If this field is not provided, no namespace filtering will be performed
   * (all resources in all Namespaces, including all cluster-scoped resources,
   * will be candidates for substitution).
   * To mix cluster-scoped and namespaced resources in the same rule, use an
   * empty string ("") as one of the target namespaces.
   */
  targetNamespaces: string[];
  /**
   * (Filtering parameter) Any resource subject to substitution must belong to
   * one of the listed "types".
   * If this field is not provided, no type filtering will be performed (all
   * resources of all types matching previous filtering parameters will be
   * candidates for substitution).
   */
  targetGroupKinds: RestoreConfig_GroupKind[];
  /**
   * Required. This is a [JSONPath]
   * (https://kubernetes.io/docs/reference/kubectl/jsonpath/)
   * expression that matches specific fields of candidate
   * resources and it operates as both a filtering parameter (resources that
   * are not matched with this expression will not be candidates for
   * substitution) as well as a field identifier (identifies exactly which
   * fields out of the candidate resources will be modified).
   */
  targetJsonPath: string;
  /**
   * (Filtering parameter) This is a [regular expression]
   * (https://en.wikipedia.org/wiki/Regular_expression)
   * that is compared against the fields matched by the target_json_path
   * expression (and must also have passed the previous filters).
   * Substitution will not be performed against fields whose
   * value does not match this expression. If this field is NOT specified,
   * then ALL fields matched by the target_json_path expression will undergo
   * substitution. Note that an empty (e.g., "", rather than unspecified)
   * value for this field will only match empty fields.
   */
  originalValuePattern: string;
  /**
   * This is the new value to set for any fields that pass the filtering and
   * selection criteria. To remove a value from a Kubernetes resource, either
   * leave this field unspecified, or set it to the empty string ("").
   */
  newValue: string;
}

/**
 * The configuration of a potential series of Restore operations to be performed
 * against Backups belong to a particular BackupPlan.
 * Next id: 13
 */
export interface RestorePlan {
  /**
   * Output only. The full name of the RestorePlan resource.
   * Format: `projects/* /locations/* /restorePlans/*`.
   */
  name: string;
  /**
   * Output only. Server generated global unique identifier of
   * [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier) format.
   */
  uid: string;
  /**
   * Output only. The timestamp when this RestorePlan resource was
   * created.
   */
  createTime?:
    | Date
    | undefined;
  /**
   * Output only. The timestamp when this RestorePlan resource was last
   * updated.
   */
  updateTime?:
    | Date
    | undefined;
  /** User specified descriptive string for this RestorePlan. */
  description: string;
  /**
   * Required. Immutable. A reference to the
   * [BackupPlan][google.cloud.gkebackup.v1.BackupPlan] from which Backups may
   * be used as the source for Restores created via this RestorePlan. Format:
   * `projects/* /locations/* /backupPlans/*`.
   */
  backupPlan: string;
  /**
   * Required. Immutable. The target cluster into which Restores created via
   * this RestorePlan will restore data. NOTE: the cluster's region must be the
   * same as the RestorePlan. Valid formats:
   *
   *   - `projects/* /locations/* /clusters/*`
   *   - `projects/* /zones/* /clusters/*`
   */
  cluster: string;
  /** Required. Configuration of Restores created via this RestorePlan. */
  restoreConfig?:
    | RestoreConfig
    | undefined;
  /** A set of custom labels supplied by user. */
  labels: { [key: string]: string };
  /**
   * Output only. `etag` is used for optimistic concurrency control as a way to
   * help prevent simultaneous updates of a restore from overwriting each other.
   * It is strongly suggested that systems make use of the `etag` in the
   * read-modify-write cycle to perform restore updates in order to avoid
   * race conditions: An `etag` is returned in the response to `GetRestorePlan`,
   * and systems are expected to put that etag in the request to
   * `UpdateRestorePlan` or `DeleteRestorePlan` to ensure that their change
   * will be applied to the same version of the resource.
   */
  etag: string;
}

export interface RestorePlan_LabelsEntry {
  key: string;
  value: string;
}

/** The data within all RestorePlan events. */
export interface RestorePlanEventData {
  /** Optional. The RestorePlan event payload. Unset for deletion events. */
  payload?: RestorePlan | undefined;
}

/** The data within all Backup events. */
export interface BackupEventData {
  /** Optional. The Backup event payload. Unset for deletion events. */
  payload?: Backup | undefined;
}

/** The data within all BackupPlan events. */
export interface BackupPlanEventData {
  /** Optional. The BackupPlan event payload. Unset for deletion events. */
  payload?: BackupPlan | undefined;
}

/** The data within all Restore events. */
export interface RestoreEventData {
  /** Optional. The Restore event payload. Unset for deletion events. */
  payload?: Restore | undefined;
}

function createBaseNamespaces(): Namespaces {
  return { namespaces: [] };
}

export const Namespaces: MessageFns<Namespaces> = {
  encode(message: Namespaces, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.namespaces) {
      writer.uint32(10).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Namespaces {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNamespaces();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespaces.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Namespaces {
    return {
      namespaces: globalThis.Array.isArray(object?.namespaces)
        ? object.namespaces.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Namespaces): unknown {
    const obj: any = {};
    if (message.namespaces?.length) {
      obj.namespaces = message.namespaces;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Namespaces>, I>>(base?: I): Namespaces {
    return Namespaces.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Namespaces>, I>>(object: I): Namespaces {
    const message = createBaseNamespaces();
    message.namespaces = object.namespaces?.map((e) => e) || [];
    return message;
  },
};

function createBaseNamespacedName(): NamespacedName {
  return { namespace: "", name: "" };
}

export const NamespacedName: MessageFns<NamespacedName> = {
  encode(message: NamespacedName, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.namespace !== "") {
      writer.uint32(10).string(message.namespace);
    }
    if (message.name !== "") {
      writer.uint32(18).string(message.name);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NamespacedName {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNamespacedName();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespace = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.name = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NamespacedName {
    return {
      namespace: isSet(object.namespace) ? globalThis.String(object.namespace) : "",
      name: isSet(object.name) ? globalThis.String(object.name) : "",
    };
  },

  toJSON(message: NamespacedName): unknown {
    const obj: any = {};
    if (message.namespace !== "") {
      obj.namespace = message.namespace;
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NamespacedName>, I>>(base?: I): NamespacedName {
    return NamespacedName.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NamespacedName>, I>>(object: I): NamespacedName {
    const message = createBaseNamespacedName();
    message.namespace = object.namespace ?? "";
    message.name = object.name ?? "";
    return message;
  },
};

function createBaseNamespacedNames(): NamespacedNames {
  return { namespacedNames: [] };
}

export const NamespacedNames: MessageFns<NamespacedNames> = {
  encode(message: NamespacedNames, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.namespacedNames) {
      NamespacedName.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NamespacedNames {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNamespacedNames();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.namespacedNames.push(NamespacedName.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NamespacedNames {
    return {
      namespacedNames: globalThis.Array.isArray(object?.namespacedNames)
        ? object.namespacedNames.map((e: any) => NamespacedName.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NamespacedNames): unknown {
    const obj: any = {};
    if (message.namespacedNames?.length) {
      obj.namespacedNames = message.namespacedNames.map((e) => NamespacedName.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NamespacedNames>, I>>(base?: I): NamespacedNames {
    return NamespacedNames.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NamespacedNames>, I>>(object: I): NamespacedNames {
    const message = createBaseNamespacedNames();
    message.namespacedNames = object.namespacedNames?.map((e) => NamespacedName.fromPartial(e)) || [];
    return message;
  },
};

function createBaseEncryptionKey(): EncryptionKey {
  return { gcpKmsEncryptionKey: "" };
}

export const EncryptionKey: MessageFns<EncryptionKey> = {
  encode(message: EncryptionKey, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.gcpKmsEncryptionKey !== "") {
      writer.uint32(10).string(message.gcpKmsEncryptionKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EncryptionKey {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEncryptionKey();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.gcpKmsEncryptionKey = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EncryptionKey {
    return {
      gcpKmsEncryptionKey: isSet(object.gcpKmsEncryptionKey) ? globalThis.String(object.gcpKmsEncryptionKey) : "",
    };
  },

  toJSON(message: EncryptionKey): unknown {
    const obj: any = {};
    if (message.gcpKmsEncryptionKey !== "") {
      obj.gcpKmsEncryptionKey = message.gcpKmsEncryptionKey;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EncryptionKey>, I>>(base?: I): EncryptionKey {
    return EncryptionKey.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EncryptionKey>, I>>(object: I): EncryptionKey {
    const message = createBaseEncryptionKey();
    message.gcpKmsEncryptionKey = object.gcpKmsEncryptionKey ?? "";
    return message;
  },
};

function createBaseBackup(): Backup {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    manual: false,
    labels: {},
    deleteLockDays: 0,
    deleteLockExpireTime: undefined,
    retainDays: 0,
    retainExpireTime: undefined,
    encryptionKey: undefined,
    allNamespaces: undefined,
    selectedNamespaces: undefined,
    selectedApplications: undefined,
    containsVolumeData: false,
    containsSecrets: false,
    clusterMetadata: undefined,
    state: 0,
    stateReason: "",
    completeTime: undefined,
    resourceCount: 0,
    volumeCount: 0,
    sizeBytes: Long.ZERO,
    etag: "",
    description: "",
    podCount: 0,
    configBackupSizeBytes: Long.ZERO,
  };
}

export const Backup: MessageFns<Backup> = {
  encode(message: Backup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.manual !== false) {
      writer.uint32(40).bool(message.manual);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Backup_LabelsEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.deleteLockDays !== 0) {
      writer.uint32(56).int32(message.deleteLockDays);
    }
    if (message.deleteLockExpireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.deleteLockExpireTime), writer.uint32(66).fork()).join();
    }
    if (message.retainDays !== 0) {
      writer.uint32(72).int32(message.retainDays);
    }
    if (message.retainExpireTime !== undefined) {
      Timestamp.encode(toTimestamp(message.retainExpireTime), writer.uint32(82).fork()).join();
    }
    if (message.encryptionKey !== undefined) {
      EncryptionKey.encode(message.encryptionKey, writer.uint32(90).fork()).join();
    }
    if (message.allNamespaces !== undefined) {
      writer.uint32(96).bool(message.allNamespaces);
    }
    if (message.selectedNamespaces !== undefined) {
      Namespaces.encode(message.selectedNamespaces, writer.uint32(106).fork()).join();
    }
    if (message.selectedApplications !== undefined) {
      NamespacedNames.encode(message.selectedApplications, writer.uint32(114).fork()).join();
    }
    if (message.containsVolumeData !== false) {
      writer.uint32(120).bool(message.containsVolumeData);
    }
    if (message.containsSecrets !== false) {
      writer.uint32(128).bool(message.containsSecrets);
    }
    if (message.clusterMetadata !== undefined) {
      Backup_ClusterMetadata.encode(message.clusterMetadata, writer.uint32(138).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(144).int32(message.state);
    }
    if (message.stateReason !== "") {
      writer.uint32(154).string(message.stateReason);
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(162).fork()).join();
    }
    if (message.resourceCount !== 0) {
      writer.uint32(168).int32(message.resourceCount);
    }
    if (message.volumeCount !== 0) {
      writer.uint32(176).int32(message.volumeCount);
    }
    if (!message.sizeBytes.equals(Long.ZERO)) {
      writer.uint32(184).int64(message.sizeBytes.toString());
    }
    if (message.etag !== "") {
      writer.uint32(194).string(message.etag);
    }
    if (message.description !== "") {
      writer.uint32(202).string(message.description);
    }
    if (message.podCount !== 0) {
      writer.uint32(208).int32(message.podCount);
    }
    if (!message.configBackupSizeBytes.equals(Long.ZERO)) {
      writer.uint32(216).int64(message.configBackupSizeBytes.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.manual = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Backup_LabelsEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.labels[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.deleteLockDays = reader.int32();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.deleteLockExpireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.retainDays = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.retainExpireTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.encryptionKey = EncryptionKey.decode(reader, reader.uint32());
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.allNamespaces = reader.bool();
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.selectedNamespaces = Namespaces.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.selectedApplications = NamespacedNames.decode(reader, reader.uint32());
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.containsVolumeData = reader.bool();
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.containsSecrets = reader.bool();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.clusterMetadata = Backup_ClusterMetadata.decode(reader, reader.uint32());
          continue;
        }
        case 18: {
          if (tag !== 144) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.stateReason = reader.string();
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 21: {
          if (tag !== 168) {
            break;
          }

          message.resourceCount = reader.int32();
          continue;
        }
        case 22: {
          if (tag !== 176) {
            break;
          }

          message.volumeCount = reader.int32();
          continue;
        }
        case 23: {
          if (tag !== 184) {
            break;
          }

          message.sizeBytes = Long.fromString(reader.int64().toString());
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 25: {
          if (tag !== 202) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 26: {
          if (tag !== 208) {
            break;
          }

          message.podCount = reader.int32();
          continue;
        }
        case 27: {
          if (tag !== 216) {
            break;
          }

          message.configBackupSizeBytes = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      manual: isSet(object.manual) ? globalThis.Boolean(object.manual) : false,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      deleteLockDays: isSet(object.deleteLockDays) ? globalThis.Number(object.deleteLockDays) : 0,
      deleteLockExpireTime: isSet(object.deleteLockExpireTime)
        ? fromJsonTimestamp(object.deleteLockExpireTime)
        : undefined,
      retainDays: isSet(object.retainDays) ? globalThis.Number(object.retainDays) : 0,
      retainExpireTime: isSet(object.retainExpireTime) ? fromJsonTimestamp(object.retainExpireTime) : undefined,
      encryptionKey: isSet(object.encryptionKey) ? EncryptionKey.fromJSON(object.encryptionKey) : undefined,
      allNamespaces: isSet(object.allNamespaces) ? globalThis.Boolean(object.allNamespaces) : undefined,
      selectedNamespaces: isSet(object.selectedNamespaces) ? Namespaces.fromJSON(object.selectedNamespaces) : undefined,
      selectedApplications: isSet(object.selectedApplications)
        ? NamespacedNames.fromJSON(object.selectedApplications)
        : undefined,
      containsVolumeData: isSet(object.containsVolumeData) ? globalThis.Boolean(object.containsVolumeData) : false,
      containsSecrets: isSet(object.containsSecrets) ? globalThis.Boolean(object.containsSecrets) : false,
      clusterMetadata: isSet(object.clusterMetadata)
        ? Backup_ClusterMetadata.fromJSON(object.clusterMetadata)
        : undefined,
      state: isSet(object.state) ? backup_StateFromJSON(object.state) : 0,
      stateReason: isSet(object.stateReason) ? globalThis.String(object.stateReason) : "",
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
      resourceCount: isSet(object.resourceCount) ? globalThis.Number(object.resourceCount) : 0,
      volumeCount: isSet(object.volumeCount) ? globalThis.Number(object.volumeCount) : 0,
      sizeBytes: isSet(object.sizeBytes) ? Long.fromValue(object.sizeBytes) : Long.ZERO,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      podCount: isSet(object.podCount) ? globalThis.Number(object.podCount) : 0,
      configBackupSizeBytes: isSet(object.configBackupSizeBytes)
        ? Long.fromValue(object.configBackupSizeBytes)
        : Long.ZERO,
    };
  },

  toJSON(message: Backup): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.manual !== false) {
      obj.manual = message.manual;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.deleteLockDays !== 0) {
      obj.deleteLockDays = Math.round(message.deleteLockDays);
    }
    if (message.deleteLockExpireTime !== undefined) {
      obj.deleteLockExpireTime = message.deleteLockExpireTime.toISOString();
    }
    if (message.retainDays !== 0) {
      obj.retainDays = Math.round(message.retainDays);
    }
    if (message.retainExpireTime !== undefined) {
      obj.retainExpireTime = message.retainExpireTime.toISOString();
    }
    if (message.encryptionKey !== undefined) {
      obj.encryptionKey = EncryptionKey.toJSON(message.encryptionKey);
    }
    if (message.allNamespaces !== undefined) {
      obj.allNamespaces = message.allNamespaces;
    }
    if (message.selectedNamespaces !== undefined) {
      obj.selectedNamespaces = Namespaces.toJSON(message.selectedNamespaces);
    }
    if (message.selectedApplications !== undefined) {
      obj.selectedApplications = NamespacedNames.toJSON(message.selectedApplications);
    }
    if (message.containsVolumeData !== false) {
      obj.containsVolumeData = message.containsVolumeData;
    }
    if (message.containsSecrets !== false) {
      obj.containsSecrets = message.containsSecrets;
    }
    if (message.clusterMetadata !== undefined) {
      obj.clusterMetadata = Backup_ClusterMetadata.toJSON(message.clusterMetadata);
    }
    if (message.state !== 0) {
      obj.state = backup_StateToJSON(message.state);
    }
    if (message.stateReason !== "") {
      obj.stateReason = message.stateReason;
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    if (message.resourceCount !== 0) {
      obj.resourceCount = Math.round(message.resourceCount);
    }
    if (message.volumeCount !== 0) {
      obj.volumeCount = Math.round(message.volumeCount);
    }
    if (!message.sizeBytes.equals(Long.ZERO)) {
      obj.sizeBytes = (message.sizeBytes || Long.ZERO).toString();
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.podCount !== 0) {
      obj.podCount = Math.round(message.podCount);
    }
    if (!message.configBackupSizeBytes.equals(Long.ZERO)) {
      obj.configBackupSizeBytes = (message.configBackupSizeBytes || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Backup>, I>>(base?: I): Backup {
    return Backup.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Backup>, I>>(object: I): Backup {
    const message = createBaseBackup();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.manual = object.manual ?? false;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.deleteLockDays = object.deleteLockDays ?? 0;
    message.deleteLockExpireTime = object.deleteLockExpireTime ?? undefined;
    message.retainDays = object.retainDays ?? 0;
    message.retainExpireTime = object.retainExpireTime ?? undefined;
    message.encryptionKey = (object.encryptionKey !== undefined && object.encryptionKey !== null)
      ? EncryptionKey.fromPartial(object.encryptionKey)
      : undefined;
    message.allNamespaces = object.allNamespaces ?? undefined;
    message.selectedNamespaces = (object.selectedNamespaces !== undefined && object.selectedNamespaces !== null)
      ? Namespaces.fromPartial(object.selectedNamespaces)
      : undefined;
    message.selectedApplications = (object.selectedApplications !== undefined && object.selectedApplications !== null)
      ? NamespacedNames.fromPartial(object.selectedApplications)
      : undefined;
    message.containsVolumeData = object.containsVolumeData ?? false;
    message.containsSecrets = object.containsSecrets ?? false;
    message.clusterMetadata = (object.clusterMetadata !== undefined && object.clusterMetadata !== null)
      ? Backup_ClusterMetadata.fromPartial(object.clusterMetadata)
      : undefined;
    message.state = object.state ?? 0;
    message.stateReason = object.stateReason ?? "";
    message.completeTime = object.completeTime ?? undefined;
    message.resourceCount = object.resourceCount ?? 0;
    message.volumeCount = object.volumeCount ?? 0;
    message.sizeBytes = (object.sizeBytes !== undefined && object.sizeBytes !== null)
      ? Long.fromValue(object.sizeBytes)
      : Long.ZERO;
    message.etag = object.etag ?? "";
    message.description = object.description ?? "";
    message.podCount = object.podCount ?? 0;
    message.configBackupSizeBytes =
      (object.configBackupSizeBytes !== undefined && object.configBackupSizeBytes !== null)
        ? Long.fromValue(object.configBackupSizeBytes)
        : Long.ZERO;
    return message;
  },
};

function createBaseBackup_ClusterMetadata(): Backup_ClusterMetadata {
  return { cluster: "", k8sVersion: "", backupCrdVersions: {}, gkeVersion: undefined, anthosVersion: undefined };
}

export const Backup_ClusterMetadata: MessageFns<Backup_ClusterMetadata> = {
  encode(message: Backup_ClusterMetadata, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cluster !== "") {
      writer.uint32(10).string(message.cluster);
    }
    if (message.k8sVersion !== "") {
      writer.uint32(18).string(message.k8sVersion);
    }
    Object.entries(message.backupCrdVersions).forEach(([key, value]) => {
      Backup_ClusterMetadata_BackupCrdVersionsEntry.encode({ key: key as any, value }, writer.uint32(26).fork()).join();
    });
    if (message.gkeVersion !== undefined) {
      writer.uint32(34).string(message.gkeVersion);
    }
    if (message.anthosVersion !== undefined) {
      writer.uint32(42).string(message.anthosVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup_ClusterMetadata {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup_ClusterMetadata();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.k8sVersion = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          const entry3 = Backup_ClusterMetadata_BackupCrdVersionsEntry.decode(reader, reader.uint32());
          if (entry3.value !== undefined) {
            message.backupCrdVersions[entry3.key] = entry3.value;
          }
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.gkeVersion = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.anthosVersion = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup_ClusterMetadata {
    return {
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      k8sVersion: isSet(object.k8sVersion) ? globalThis.String(object.k8sVersion) : "",
      backupCrdVersions: isObject(object.backupCrdVersions)
        ? Object.entries(object.backupCrdVersions).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      gkeVersion: isSet(object.gkeVersion) ? globalThis.String(object.gkeVersion) : undefined,
      anthosVersion: isSet(object.anthosVersion) ? globalThis.String(object.anthosVersion) : undefined,
    };
  },

  toJSON(message: Backup_ClusterMetadata): unknown {
    const obj: any = {};
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.k8sVersion !== "") {
      obj.k8sVersion = message.k8sVersion;
    }
    if (message.backupCrdVersions) {
      const entries = Object.entries(message.backupCrdVersions);
      if (entries.length > 0) {
        obj.backupCrdVersions = {};
        entries.forEach(([k, v]) => {
          obj.backupCrdVersions[k] = v;
        });
      }
    }
    if (message.gkeVersion !== undefined) {
      obj.gkeVersion = message.gkeVersion;
    }
    if (message.anthosVersion !== undefined) {
      obj.anthosVersion = message.anthosVersion;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Backup_ClusterMetadata>, I>>(base?: I): Backup_ClusterMetadata {
    return Backup_ClusterMetadata.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Backup_ClusterMetadata>, I>>(object: I): Backup_ClusterMetadata {
    const message = createBaseBackup_ClusterMetadata();
    message.cluster = object.cluster ?? "";
    message.k8sVersion = object.k8sVersion ?? "";
    message.backupCrdVersions = Object.entries(object.backupCrdVersions ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.gkeVersion = object.gkeVersion ?? undefined;
    message.anthosVersion = object.anthosVersion ?? undefined;
    return message;
  },
};

function createBaseBackup_ClusterMetadata_BackupCrdVersionsEntry(): Backup_ClusterMetadata_BackupCrdVersionsEntry {
  return { key: "", value: "" };
}

export const Backup_ClusterMetadata_BackupCrdVersionsEntry: MessageFns<Backup_ClusterMetadata_BackupCrdVersionsEntry> =
  {
    encode(
      message: Backup_ClusterMetadata_BackupCrdVersionsEntry,
      writer: BinaryWriter = new BinaryWriter(),
    ): BinaryWriter {
      if (message.key !== "") {
        writer.uint32(10).string(message.key);
      }
      if (message.value !== "") {
        writer.uint32(18).string(message.value);
      }
      return writer;
    },

    decode(input: BinaryReader | Uint8Array, length?: number): Backup_ClusterMetadata_BackupCrdVersionsEntry {
      const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
      const end = length === undefined ? reader.len : reader.pos + length;
      const message = createBaseBackup_ClusterMetadata_BackupCrdVersionsEntry();
      while (reader.pos < end) {
        const tag = reader.uint32();
        switch (tag >>> 3) {
          case 1: {
            if (tag !== 10) {
              break;
            }

            message.key = reader.string();
            continue;
          }
          case 2: {
            if (tag !== 18) {
              break;
            }

            message.value = reader.string();
            continue;
          }
        }
        if ((tag & 7) === 4 || tag === 0) {
          break;
        }
        reader.skip(tag & 7);
      }
      return message;
    },

    fromJSON(object: any): Backup_ClusterMetadata_BackupCrdVersionsEntry {
      return {
        key: isSet(object.key) ? globalThis.String(object.key) : "",
        value: isSet(object.value) ? globalThis.String(object.value) : "",
      };
    },

    toJSON(message: Backup_ClusterMetadata_BackupCrdVersionsEntry): unknown {
      const obj: any = {};
      if (message.key !== "") {
        obj.key = message.key;
      }
      if (message.value !== "") {
        obj.value = message.value;
      }
      return obj;
    },

    create<I extends Exact<DeepPartial<Backup_ClusterMetadata_BackupCrdVersionsEntry>, I>>(
      base?: I,
    ): Backup_ClusterMetadata_BackupCrdVersionsEntry {
      return Backup_ClusterMetadata_BackupCrdVersionsEntry.fromPartial(base ?? ({} as any));
    },
    fromPartial<I extends Exact<DeepPartial<Backup_ClusterMetadata_BackupCrdVersionsEntry>, I>>(
      object: I,
    ): Backup_ClusterMetadata_BackupCrdVersionsEntry {
      const message = createBaseBackup_ClusterMetadata_BackupCrdVersionsEntry();
      message.key = object.key ?? "";
      message.value = object.value ?? "";
      return message;
    },
  };

function createBaseBackup_LabelsEntry(): Backup_LabelsEntry {
  return { key: "", value: "" };
}

export const Backup_LabelsEntry: MessageFns<Backup_LabelsEntry> = {
  encode(message: Backup_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Backup_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Backup_LabelsEntry>, I>>(base?: I): Backup_LabelsEntry {
    return Backup_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Backup_LabelsEntry>, I>>(object: I): Backup_LabelsEntry {
    const message = createBaseBackup_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseBackupPlan(): BackupPlan {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    cluster: "",
    retentionPolicy: undefined,
    labels: {},
    backupSchedule: undefined,
    etag: "",
    deactivated: false,
    backupConfig: undefined,
    protectedPodCount: 0,
  };
}

export const BackupPlan: MessageFns<BackupPlan> = {
  encode(message: BackupPlan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.cluster !== "") {
      writer.uint32(50).string(message.cluster);
    }
    if (message.retentionPolicy !== undefined) {
      BackupPlan_RetentionPolicy.encode(message.retentionPolicy, writer.uint32(58).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      BackupPlan_LabelsEntry.encode({ key: key as any, value }, writer.uint32(66).fork()).join();
    });
    if (message.backupSchedule !== undefined) {
      BackupPlan_Schedule.encode(message.backupSchedule, writer.uint32(74).fork()).join();
    }
    if (message.etag !== "") {
      writer.uint32(82).string(message.etag);
    }
    if (message.deactivated !== false) {
      writer.uint32(88).bool(message.deactivated);
    }
    if (message.backupConfig !== undefined) {
      BackupPlan_BackupConfig.encode(message.backupConfig, writer.uint32(98).fork()).join();
    }
    if (message.protectedPodCount !== 0) {
      writer.uint32(104).int32(message.protectedPodCount);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.retentionPolicy = BackupPlan_RetentionPolicy.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = BackupPlan_LabelsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.labels[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.backupSchedule = BackupPlan_Schedule.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.deactivated = reader.bool();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.backupConfig = BackupPlan_BackupConfig.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.protectedPodCount = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlan {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      retentionPolicy: isSet(object.retentionPolicy)
        ? BackupPlan_RetentionPolicy.fromJSON(object.retentionPolicy)
        : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      backupSchedule: isSet(object.backupSchedule) ? BackupPlan_Schedule.fromJSON(object.backupSchedule) : undefined,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
      deactivated: isSet(object.deactivated) ? globalThis.Boolean(object.deactivated) : false,
      backupConfig: isSet(object.backupConfig) ? BackupPlan_BackupConfig.fromJSON(object.backupConfig) : undefined,
      protectedPodCount: isSet(object.protectedPodCount) ? globalThis.Number(object.protectedPodCount) : 0,
    };
  },

  toJSON(message: BackupPlan): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.retentionPolicy !== undefined) {
      obj.retentionPolicy = BackupPlan_RetentionPolicy.toJSON(message.retentionPolicy);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.backupSchedule !== undefined) {
      obj.backupSchedule = BackupPlan_Schedule.toJSON(message.backupSchedule);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    if (message.deactivated !== false) {
      obj.deactivated = message.deactivated;
    }
    if (message.backupConfig !== undefined) {
      obj.backupConfig = BackupPlan_BackupConfig.toJSON(message.backupConfig);
    }
    if (message.protectedPodCount !== 0) {
      obj.protectedPodCount = Math.round(message.protectedPodCount);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlan>, I>>(base?: I): BackupPlan {
    return BackupPlan.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlan>, I>>(object: I): BackupPlan {
    const message = createBaseBackupPlan();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.cluster = object.cluster ?? "";
    message.retentionPolicy = (object.retentionPolicy !== undefined && object.retentionPolicy !== null)
      ? BackupPlan_RetentionPolicy.fromPartial(object.retentionPolicy)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.backupSchedule = (object.backupSchedule !== undefined && object.backupSchedule !== null)
      ? BackupPlan_Schedule.fromPartial(object.backupSchedule)
      : undefined;
    message.etag = object.etag ?? "";
    message.deactivated = object.deactivated ?? false;
    message.backupConfig = (object.backupConfig !== undefined && object.backupConfig !== null)
      ? BackupPlan_BackupConfig.fromPartial(object.backupConfig)
      : undefined;
    message.protectedPodCount = object.protectedPodCount ?? 0;
    return message;
  },
};

function createBaseBackupPlan_RetentionPolicy(): BackupPlan_RetentionPolicy {
  return { backupDeleteLockDays: 0, backupRetainDays: 0, locked: false };
}

export const BackupPlan_RetentionPolicy: MessageFns<BackupPlan_RetentionPolicy> = {
  encode(message: BackupPlan_RetentionPolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.backupDeleteLockDays !== 0) {
      writer.uint32(8).int32(message.backupDeleteLockDays);
    }
    if (message.backupRetainDays !== 0) {
      writer.uint32(16).int32(message.backupRetainDays);
    }
    if (message.locked !== false) {
      writer.uint32(24).bool(message.locked);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlan_RetentionPolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlan_RetentionPolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.backupDeleteLockDays = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.backupRetainDays = reader.int32();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.locked = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlan_RetentionPolicy {
    return {
      backupDeleteLockDays: isSet(object.backupDeleteLockDays) ? globalThis.Number(object.backupDeleteLockDays) : 0,
      backupRetainDays: isSet(object.backupRetainDays) ? globalThis.Number(object.backupRetainDays) : 0,
      locked: isSet(object.locked) ? globalThis.Boolean(object.locked) : false,
    };
  },

  toJSON(message: BackupPlan_RetentionPolicy): unknown {
    const obj: any = {};
    if (message.backupDeleteLockDays !== 0) {
      obj.backupDeleteLockDays = Math.round(message.backupDeleteLockDays);
    }
    if (message.backupRetainDays !== 0) {
      obj.backupRetainDays = Math.round(message.backupRetainDays);
    }
    if (message.locked !== false) {
      obj.locked = message.locked;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlan_RetentionPolicy>, I>>(base?: I): BackupPlan_RetentionPolicy {
    return BackupPlan_RetentionPolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlan_RetentionPolicy>, I>>(object: I): BackupPlan_RetentionPolicy {
    const message = createBaseBackupPlan_RetentionPolicy();
    message.backupDeleteLockDays = object.backupDeleteLockDays ?? 0;
    message.backupRetainDays = object.backupRetainDays ?? 0;
    message.locked = object.locked ?? false;
    return message;
  },
};

function createBaseBackupPlan_Schedule(): BackupPlan_Schedule {
  return { cronSchedule: "", paused: false };
}

export const BackupPlan_Schedule: MessageFns<BackupPlan_Schedule> = {
  encode(message: BackupPlan_Schedule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cronSchedule !== "") {
      writer.uint32(10).string(message.cronSchedule);
    }
    if (message.paused !== false) {
      writer.uint32(16).bool(message.paused);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlan_Schedule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlan_Schedule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.cronSchedule = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.paused = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlan_Schedule {
    return {
      cronSchedule: isSet(object.cronSchedule) ? globalThis.String(object.cronSchedule) : "",
      paused: isSet(object.paused) ? globalThis.Boolean(object.paused) : false,
    };
  },

  toJSON(message: BackupPlan_Schedule): unknown {
    const obj: any = {};
    if (message.cronSchedule !== "") {
      obj.cronSchedule = message.cronSchedule;
    }
    if (message.paused !== false) {
      obj.paused = message.paused;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlan_Schedule>, I>>(base?: I): BackupPlan_Schedule {
    return BackupPlan_Schedule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlan_Schedule>, I>>(object: I): BackupPlan_Schedule {
    const message = createBaseBackupPlan_Schedule();
    message.cronSchedule = object.cronSchedule ?? "";
    message.paused = object.paused ?? false;
    return message;
  },
};

function createBaseBackupPlan_BackupConfig(): BackupPlan_BackupConfig {
  return {
    allNamespaces: undefined,
    selectedNamespaces: undefined,
    selectedApplications: undefined,
    includeVolumeData: false,
    includeSecrets: false,
    encryptionKey: undefined,
  };
}

export const BackupPlan_BackupConfig: MessageFns<BackupPlan_BackupConfig> = {
  encode(message: BackupPlan_BackupConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.allNamespaces !== undefined) {
      writer.uint32(8).bool(message.allNamespaces);
    }
    if (message.selectedNamespaces !== undefined) {
      Namespaces.encode(message.selectedNamespaces, writer.uint32(18).fork()).join();
    }
    if (message.selectedApplications !== undefined) {
      NamespacedNames.encode(message.selectedApplications, writer.uint32(26).fork()).join();
    }
    if (message.includeVolumeData !== false) {
      writer.uint32(32).bool(message.includeVolumeData);
    }
    if (message.includeSecrets !== false) {
      writer.uint32(40).bool(message.includeSecrets);
    }
    if (message.encryptionKey !== undefined) {
      EncryptionKey.encode(message.encryptionKey, writer.uint32(50).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlan_BackupConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlan_BackupConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.allNamespaces = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.selectedNamespaces = Namespaces.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.selectedApplications = NamespacedNames.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.includeVolumeData = reader.bool();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.includeSecrets = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.encryptionKey = EncryptionKey.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlan_BackupConfig {
    return {
      allNamespaces: isSet(object.allNamespaces) ? globalThis.Boolean(object.allNamespaces) : undefined,
      selectedNamespaces: isSet(object.selectedNamespaces) ? Namespaces.fromJSON(object.selectedNamespaces) : undefined,
      selectedApplications: isSet(object.selectedApplications)
        ? NamespacedNames.fromJSON(object.selectedApplications)
        : undefined,
      includeVolumeData: isSet(object.includeVolumeData) ? globalThis.Boolean(object.includeVolumeData) : false,
      includeSecrets: isSet(object.includeSecrets) ? globalThis.Boolean(object.includeSecrets) : false,
      encryptionKey: isSet(object.encryptionKey) ? EncryptionKey.fromJSON(object.encryptionKey) : undefined,
    };
  },

  toJSON(message: BackupPlan_BackupConfig): unknown {
    const obj: any = {};
    if (message.allNamespaces !== undefined) {
      obj.allNamespaces = message.allNamespaces;
    }
    if (message.selectedNamespaces !== undefined) {
      obj.selectedNamespaces = Namespaces.toJSON(message.selectedNamespaces);
    }
    if (message.selectedApplications !== undefined) {
      obj.selectedApplications = NamespacedNames.toJSON(message.selectedApplications);
    }
    if (message.includeVolumeData !== false) {
      obj.includeVolumeData = message.includeVolumeData;
    }
    if (message.includeSecrets !== false) {
      obj.includeSecrets = message.includeSecrets;
    }
    if (message.encryptionKey !== undefined) {
      obj.encryptionKey = EncryptionKey.toJSON(message.encryptionKey);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlan_BackupConfig>, I>>(base?: I): BackupPlan_BackupConfig {
    return BackupPlan_BackupConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlan_BackupConfig>, I>>(object: I): BackupPlan_BackupConfig {
    const message = createBaseBackupPlan_BackupConfig();
    message.allNamespaces = object.allNamespaces ?? undefined;
    message.selectedNamespaces = (object.selectedNamespaces !== undefined && object.selectedNamespaces !== null)
      ? Namespaces.fromPartial(object.selectedNamespaces)
      : undefined;
    message.selectedApplications = (object.selectedApplications !== undefined && object.selectedApplications !== null)
      ? NamespacedNames.fromPartial(object.selectedApplications)
      : undefined;
    message.includeVolumeData = object.includeVolumeData ?? false;
    message.includeSecrets = object.includeSecrets ?? false;
    message.encryptionKey = (object.encryptionKey !== undefined && object.encryptionKey !== null)
      ? EncryptionKey.fromPartial(object.encryptionKey)
      : undefined;
    return message;
  },
};

function createBaseBackupPlan_LabelsEntry(): BackupPlan_LabelsEntry {
  return { key: "", value: "" };
}

export const BackupPlan_LabelsEntry: MessageFns<BackupPlan_LabelsEntry> = {
  encode(message: BackupPlan_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlan_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlan_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlan_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: BackupPlan_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlan_LabelsEntry>, I>>(base?: I): BackupPlan_LabelsEntry {
    return BackupPlan_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlan_LabelsEntry>, I>>(object: I): BackupPlan_LabelsEntry {
    const message = createBaseBackupPlan_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRestore(): Restore {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    backup: "",
    cluster: "",
    restoreConfig: undefined,
    labels: {},
    state: 0,
    stateReason: "",
    completeTime: undefined,
    resourcesRestoredCount: 0,
    resourcesExcludedCount: 0,
    resourcesFailedCount: 0,
    volumesRestoredCount: 0,
    etag: "",
  };
}

export const Restore: MessageFns<Restore> = {
  encode(message: Restore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.backup !== "") {
      writer.uint32(50).string(message.backup);
    }
    if (message.cluster !== "") {
      writer.uint32(58).string(message.cluster);
    }
    if (message.restoreConfig !== undefined) {
      RestoreConfig.encode(message.restoreConfig, writer.uint32(66).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Restore_LabelsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    if (message.state !== 0) {
      writer.uint32(80).int32(message.state);
    }
    if (message.stateReason !== "") {
      writer.uint32(90).string(message.stateReason);
    }
    if (message.completeTime !== undefined) {
      Timestamp.encode(toTimestamp(message.completeTime), writer.uint32(98).fork()).join();
    }
    if (message.resourcesRestoredCount !== 0) {
      writer.uint32(104).int32(message.resourcesRestoredCount);
    }
    if (message.resourcesExcludedCount !== 0) {
      writer.uint32(112).int32(message.resourcesExcludedCount);
    }
    if (message.resourcesFailedCount !== 0) {
      writer.uint32(120).int32(message.resourcesFailedCount);
    }
    if (message.volumesRestoredCount !== 0) {
      writer.uint32(128).int32(message.volumesRestoredCount);
    }
    if (message.etag !== "") {
      writer.uint32(138).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Restore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.backup = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.restoreConfig = RestoreConfig.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          const entry9 = Restore_LabelsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.stateReason = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.completeTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.resourcesRestoredCount = reader.int32();
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.resourcesExcludedCount = reader.int32();
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.resourcesFailedCount = reader.int32();
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.volumesRestoredCount = reader.int32();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Restore {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      restoreConfig: isSet(object.restoreConfig) ? RestoreConfig.fromJSON(object.restoreConfig) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      state: isSet(object.state) ? restore_StateFromJSON(object.state) : 0,
      stateReason: isSet(object.stateReason) ? globalThis.String(object.stateReason) : "",
      completeTime: isSet(object.completeTime) ? fromJsonTimestamp(object.completeTime) : undefined,
      resourcesRestoredCount: isSet(object.resourcesRestoredCount)
        ? globalThis.Number(object.resourcesRestoredCount)
        : 0,
      resourcesExcludedCount: isSet(object.resourcesExcludedCount)
        ? globalThis.Number(object.resourcesExcludedCount)
        : 0,
      resourcesFailedCount: isSet(object.resourcesFailedCount) ? globalThis.Number(object.resourcesFailedCount) : 0,
      volumesRestoredCount: isSet(object.volumesRestoredCount) ? globalThis.Number(object.volumesRestoredCount) : 0,
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: Restore): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.restoreConfig !== undefined) {
      obj.restoreConfig = RestoreConfig.toJSON(message.restoreConfig);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.state !== 0) {
      obj.state = restore_StateToJSON(message.state);
    }
    if (message.stateReason !== "") {
      obj.stateReason = message.stateReason;
    }
    if (message.completeTime !== undefined) {
      obj.completeTime = message.completeTime.toISOString();
    }
    if (message.resourcesRestoredCount !== 0) {
      obj.resourcesRestoredCount = Math.round(message.resourcesRestoredCount);
    }
    if (message.resourcesExcludedCount !== 0) {
      obj.resourcesExcludedCount = Math.round(message.resourcesExcludedCount);
    }
    if (message.resourcesFailedCount !== 0) {
      obj.resourcesFailedCount = Math.round(message.resourcesFailedCount);
    }
    if (message.volumesRestoredCount !== 0) {
      obj.volumesRestoredCount = Math.round(message.volumesRestoredCount);
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Restore>, I>>(base?: I): Restore {
    return Restore.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Restore>, I>>(object: I): Restore {
    const message = createBaseRestore();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.backup = object.backup ?? "";
    message.cluster = object.cluster ?? "";
    message.restoreConfig = (object.restoreConfig !== undefined && object.restoreConfig !== null)
      ? RestoreConfig.fromPartial(object.restoreConfig)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.state = object.state ?? 0;
    message.stateReason = object.stateReason ?? "";
    message.completeTime = object.completeTime ?? undefined;
    message.resourcesRestoredCount = object.resourcesRestoredCount ?? 0;
    message.resourcesExcludedCount = object.resourcesExcludedCount ?? 0;
    message.resourcesFailedCount = object.resourcesFailedCount ?? 0;
    message.volumesRestoredCount = object.volumesRestoredCount ?? 0;
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseRestore_LabelsEntry(): Restore_LabelsEntry {
  return { key: "", value: "" };
}

export const Restore_LabelsEntry: MessageFns<Restore_LabelsEntry> = {
  encode(message: Restore_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Restore_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestore_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Restore_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Restore_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Restore_LabelsEntry>, I>>(base?: I): Restore_LabelsEntry {
    return Restore_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Restore_LabelsEntry>, I>>(object: I): Restore_LabelsEntry {
    const message = createBaseRestore_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRestoreConfig(): RestoreConfig {
  return {
    volumeDataRestorePolicy: 0,
    clusterResourceConflictPolicy: 0,
    namespacedResourceRestoreMode: 0,
    clusterResourceRestoreScope: undefined,
    allNamespaces: undefined,
    selectedNamespaces: undefined,
    selectedApplications: undefined,
    substitutionRules: [],
  };
}

export const RestoreConfig: MessageFns<RestoreConfig> = {
  encode(message: RestoreConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.volumeDataRestorePolicy !== 0) {
      writer.uint32(8).int32(message.volumeDataRestorePolicy);
    }
    if (message.clusterResourceConflictPolicy !== 0) {
      writer.uint32(16).int32(message.clusterResourceConflictPolicy);
    }
    if (message.namespacedResourceRestoreMode !== 0) {
      writer.uint32(24).int32(message.namespacedResourceRestoreMode);
    }
    if (message.clusterResourceRestoreScope !== undefined) {
      RestoreConfig_ClusterResourceRestoreScope.encode(message.clusterResourceRestoreScope, writer.uint32(34).fork())
        .join();
    }
    if (message.allNamespaces !== undefined) {
      writer.uint32(40).bool(message.allNamespaces);
    }
    if (message.selectedNamespaces !== undefined) {
      Namespaces.encode(message.selectedNamespaces, writer.uint32(50).fork()).join();
    }
    if (message.selectedApplications !== undefined) {
      NamespacedNames.encode(message.selectedApplications, writer.uint32(58).fork()).join();
    }
    for (const v of message.substitutionRules) {
      RestoreConfig_SubstitutionRule.encode(v!, writer.uint32(66).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.volumeDataRestorePolicy = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.clusterResourceConflictPolicy = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.namespacedResourceRestoreMode = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.clusterResourceRestoreScope = RestoreConfig_ClusterResourceRestoreScope.decode(
            reader,
            reader.uint32(),
          );
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.allNamespaces = reader.bool();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.selectedNamespaces = Namespaces.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.selectedApplications = NamespacedNames.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.substitutionRules.push(RestoreConfig_SubstitutionRule.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreConfig {
    return {
      volumeDataRestorePolicy: isSet(object.volumeDataRestorePolicy)
        ? restoreConfig_VolumeDataRestorePolicyFromJSON(object.volumeDataRestorePolicy)
        : 0,
      clusterResourceConflictPolicy: isSet(object.clusterResourceConflictPolicy)
        ? restoreConfig_ClusterResourceConflictPolicyFromJSON(object.clusterResourceConflictPolicy)
        : 0,
      namespacedResourceRestoreMode: isSet(object.namespacedResourceRestoreMode)
        ? restoreConfig_NamespacedResourceRestoreModeFromJSON(object.namespacedResourceRestoreMode)
        : 0,
      clusterResourceRestoreScope: isSet(object.clusterResourceRestoreScope)
        ? RestoreConfig_ClusterResourceRestoreScope.fromJSON(object.clusterResourceRestoreScope)
        : undefined,
      allNamespaces: isSet(object.allNamespaces) ? globalThis.Boolean(object.allNamespaces) : undefined,
      selectedNamespaces: isSet(object.selectedNamespaces) ? Namespaces.fromJSON(object.selectedNamespaces) : undefined,
      selectedApplications: isSet(object.selectedApplications)
        ? NamespacedNames.fromJSON(object.selectedApplications)
        : undefined,
      substitutionRules: globalThis.Array.isArray(object?.substitutionRules)
        ? object.substitutionRules.map((e: any) => RestoreConfig_SubstitutionRule.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RestoreConfig): unknown {
    const obj: any = {};
    if (message.volumeDataRestorePolicy !== 0) {
      obj.volumeDataRestorePolicy = restoreConfig_VolumeDataRestorePolicyToJSON(message.volumeDataRestorePolicy);
    }
    if (message.clusterResourceConflictPolicy !== 0) {
      obj.clusterResourceConflictPolicy = restoreConfig_ClusterResourceConflictPolicyToJSON(
        message.clusterResourceConflictPolicy,
      );
    }
    if (message.namespacedResourceRestoreMode !== 0) {
      obj.namespacedResourceRestoreMode = restoreConfig_NamespacedResourceRestoreModeToJSON(
        message.namespacedResourceRestoreMode,
      );
    }
    if (message.clusterResourceRestoreScope !== undefined) {
      obj.clusterResourceRestoreScope = RestoreConfig_ClusterResourceRestoreScope.toJSON(
        message.clusterResourceRestoreScope,
      );
    }
    if (message.allNamespaces !== undefined) {
      obj.allNamespaces = message.allNamespaces;
    }
    if (message.selectedNamespaces !== undefined) {
      obj.selectedNamespaces = Namespaces.toJSON(message.selectedNamespaces);
    }
    if (message.selectedApplications !== undefined) {
      obj.selectedApplications = NamespacedNames.toJSON(message.selectedApplications);
    }
    if (message.substitutionRules?.length) {
      obj.substitutionRules = message.substitutionRules.map((e) => RestoreConfig_SubstitutionRule.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestoreConfig>, I>>(base?: I): RestoreConfig {
    return RestoreConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestoreConfig>, I>>(object: I): RestoreConfig {
    const message = createBaseRestoreConfig();
    message.volumeDataRestorePolicy = object.volumeDataRestorePolicy ?? 0;
    message.clusterResourceConflictPolicy = object.clusterResourceConflictPolicy ?? 0;
    message.namespacedResourceRestoreMode = object.namespacedResourceRestoreMode ?? 0;
    message.clusterResourceRestoreScope =
      (object.clusterResourceRestoreScope !== undefined && object.clusterResourceRestoreScope !== null)
        ? RestoreConfig_ClusterResourceRestoreScope.fromPartial(object.clusterResourceRestoreScope)
        : undefined;
    message.allNamespaces = object.allNamespaces ?? undefined;
    message.selectedNamespaces = (object.selectedNamespaces !== undefined && object.selectedNamespaces !== null)
      ? Namespaces.fromPartial(object.selectedNamespaces)
      : undefined;
    message.selectedApplications = (object.selectedApplications !== undefined && object.selectedApplications !== null)
      ? NamespacedNames.fromPartial(object.selectedApplications)
      : undefined;
    message.substitutionRules = object.substitutionRules?.map((e) => RestoreConfig_SubstitutionRule.fromPartial(e)) ||
      [];
    return message;
  },
};

function createBaseRestoreConfig_GroupKind(): RestoreConfig_GroupKind {
  return { resourceGroup: "", resourceKind: "" };
}

export const RestoreConfig_GroupKind: MessageFns<RestoreConfig_GroupKind> = {
  encode(message: RestoreConfig_GroupKind, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.resourceGroup !== "") {
      writer.uint32(10).string(message.resourceGroup);
    }
    if (message.resourceKind !== "") {
      writer.uint32(18).string(message.resourceKind);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreConfig_GroupKind {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreConfig_GroupKind();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.resourceGroup = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.resourceKind = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreConfig_GroupKind {
    return {
      resourceGroup: isSet(object.resourceGroup) ? globalThis.String(object.resourceGroup) : "",
      resourceKind: isSet(object.resourceKind) ? globalThis.String(object.resourceKind) : "",
    };
  },

  toJSON(message: RestoreConfig_GroupKind): unknown {
    const obj: any = {};
    if (message.resourceGroup !== "") {
      obj.resourceGroup = message.resourceGroup;
    }
    if (message.resourceKind !== "") {
      obj.resourceKind = message.resourceKind;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestoreConfig_GroupKind>, I>>(base?: I): RestoreConfig_GroupKind {
    return RestoreConfig_GroupKind.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestoreConfig_GroupKind>, I>>(object: I): RestoreConfig_GroupKind {
    const message = createBaseRestoreConfig_GroupKind();
    message.resourceGroup = object.resourceGroup ?? "";
    message.resourceKind = object.resourceKind ?? "";
    return message;
  },
};

function createBaseRestoreConfig_ClusterResourceRestoreScope(): RestoreConfig_ClusterResourceRestoreScope {
  return { selectedGroupKinds: [] };
}

export const RestoreConfig_ClusterResourceRestoreScope: MessageFns<RestoreConfig_ClusterResourceRestoreScope> = {
  encode(message: RestoreConfig_ClusterResourceRestoreScope, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.selectedGroupKinds) {
      RestoreConfig_GroupKind.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreConfig_ClusterResourceRestoreScope {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreConfig_ClusterResourceRestoreScope();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.selectedGroupKinds.push(RestoreConfig_GroupKind.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreConfig_ClusterResourceRestoreScope {
    return {
      selectedGroupKinds: globalThis.Array.isArray(object?.selectedGroupKinds)
        ? object.selectedGroupKinds.map((e: any) => RestoreConfig_GroupKind.fromJSON(e))
        : [],
    };
  },

  toJSON(message: RestoreConfig_ClusterResourceRestoreScope): unknown {
    const obj: any = {};
    if (message.selectedGroupKinds?.length) {
      obj.selectedGroupKinds = message.selectedGroupKinds.map((e) => RestoreConfig_GroupKind.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestoreConfig_ClusterResourceRestoreScope>, I>>(
    base?: I,
  ): RestoreConfig_ClusterResourceRestoreScope {
    return RestoreConfig_ClusterResourceRestoreScope.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestoreConfig_ClusterResourceRestoreScope>, I>>(
    object: I,
  ): RestoreConfig_ClusterResourceRestoreScope {
    const message = createBaseRestoreConfig_ClusterResourceRestoreScope();
    message.selectedGroupKinds = object.selectedGroupKinds?.map((e) => RestoreConfig_GroupKind.fromPartial(e)) || [];
    return message;
  },
};

function createBaseRestoreConfig_SubstitutionRule(): RestoreConfig_SubstitutionRule {
  return { targetNamespaces: [], targetGroupKinds: [], targetJsonPath: "", originalValuePattern: "", newValue: "" };
}

export const RestoreConfig_SubstitutionRule: MessageFns<RestoreConfig_SubstitutionRule> = {
  encode(message: RestoreConfig_SubstitutionRule, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.targetNamespaces) {
      writer.uint32(10).string(v!);
    }
    for (const v of message.targetGroupKinds) {
      RestoreConfig_GroupKind.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.targetJsonPath !== "") {
      writer.uint32(26).string(message.targetJsonPath);
    }
    if (message.originalValuePattern !== "") {
      writer.uint32(34).string(message.originalValuePattern);
    }
    if (message.newValue !== "") {
      writer.uint32(42).string(message.newValue);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreConfig_SubstitutionRule {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreConfig_SubstitutionRule();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.targetNamespaces.push(reader.string());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.targetGroupKinds.push(RestoreConfig_GroupKind.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.targetJsonPath = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.originalValuePattern = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.newValue = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreConfig_SubstitutionRule {
    return {
      targetNamespaces: globalThis.Array.isArray(object?.targetNamespaces)
        ? object.targetNamespaces.map((e: any) => globalThis.String(e))
        : [],
      targetGroupKinds: globalThis.Array.isArray(object?.targetGroupKinds)
        ? object.targetGroupKinds.map((e: any) => RestoreConfig_GroupKind.fromJSON(e))
        : [],
      targetJsonPath: isSet(object.targetJsonPath) ? globalThis.String(object.targetJsonPath) : "",
      originalValuePattern: isSet(object.originalValuePattern) ? globalThis.String(object.originalValuePattern) : "",
      newValue: isSet(object.newValue) ? globalThis.String(object.newValue) : "",
    };
  },

  toJSON(message: RestoreConfig_SubstitutionRule): unknown {
    const obj: any = {};
    if (message.targetNamespaces?.length) {
      obj.targetNamespaces = message.targetNamespaces;
    }
    if (message.targetGroupKinds?.length) {
      obj.targetGroupKinds = message.targetGroupKinds.map((e) => RestoreConfig_GroupKind.toJSON(e));
    }
    if (message.targetJsonPath !== "") {
      obj.targetJsonPath = message.targetJsonPath;
    }
    if (message.originalValuePattern !== "") {
      obj.originalValuePattern = message.originalValuePattern;
    }
    if (message.newValue !== "") {
      obj.newValue = message.newValue;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestoreConfig_SubstitutionRule>, I>>(base?: I): RestoreConfig_SubstitutionRule {
    return RestoreConfig_SubstitutionRule.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestoreConfig_SubstitutionRule>, I>>(
    object: I,
  ): RestoreConfig_SubstitutionRule {
    const message = createBaseRestoreConfig_SubstitutionRule();
    message.targetNamespaces = object.targetNamespaces?.map((e) => e) || [];
    message.targetGroupKinds = object.targetGroupKinds?.map((e) => RestoreConfig_GroupKind.fromPartial(e)) || [];
    message.targetJsonPath = object.targetJsonPath ?? "";
    message.originalValuePattern = object.originalValuePattern ?? "";
    message.newValue = object.newValue ?? "";
    return message;
  },
};

function createBaseRestorePlan(): RestorePlan {
  return {
    name: "",
    uid: "",
    createTime: undefined,
    updateTime: undefined,
    description: "",
    backupPlan: "",
    cluster: "",
    restoreConfig: undefined,
    labels: {},
    etag: "",
  };
}

export const RestorePlan: MessageFns<RestorePlan> = {
  encode(message: RestorePlan, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.uid !== "") {
      writer.uint32(18).string(message.uid);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(42).string(message.description);
    }
    if (message.backupPlan !== "") {
      writer.uint32(50).string(message.backupPlan);
    }
    if (message.cluster !== "") {
      writer.uint32(58).string(message.cluster);
    }
    if (message.restoreConfig !== undefined) {
      RestoreConfig.encode(message.restoreConfig, writer.uint32(66).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      RestorePlan_LabelsEntry.encode({ key: key as any, value }, writer.uint32(74).fork()).join();
    });
    if (message.etag !== "") {
      writer.uint32(82).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestorePlan {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestorePlan();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.backupPlan = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.cluster = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.restoreConfig = RestoreConfig.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          const entry9 = RestorePlan_LabelsEntry.decode(reader, reader.uint32());
          if (entry9.value !== undefined) {
            message.labels[entry9.key] = entry9.value;
          }
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestorePlan {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      backupPlan: isSet(object.backupPlan) ? globalThis.String(object.backupPlan) : "",
      cluster: isSet(object.cluster) ? globalThis.String(object.cluster) : "",
      restoreConfig: isSet(object.restoreConfig) ? RestoreConfig.fromJSON(object.restoreConfig) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: RestorePlan): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.backupPlan !== "") {
      obj.backupPlan = message.backupPlan;
    }
    if (message.cluster !== "") {
      obj.cluster = message.cluster;
    }
    if (message.restoreConfig !== undefined) {
      obj.restoreConfig = RestoreConfig.toJSON(message.restoreConfig);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestorePlan>, I>>(base?: I): RestorePlan {
    return RestorePlan.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestorePlan>, I>>(object: I): RestorePlan {
    const message = createBaseRestorePlan();
    message.name = object.name ?? "";
    message.uid = object.uid ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.backupPlan = object.backupPlan ?? "";
    message.cluster = object.cluster ?? "";
    message.restoreConfig = (object.restoreConfig !== undefined && object.restoreConfig !== null)
      ? RestoreConfig.fromPartial(object.restoreConfig)
      : undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseRestorePlan_LabelsEntry(): RestorePlan_LabelsEntry {
  return { key: "", value: "" };
}

export const RestorePlan_LabelsEntry: MessageFns<RestorePlan_LabelsEntry> = {
  encode(message: RestorePlan_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestorePlan_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestorePlan_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestorePlan_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: RestorePlan_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestorePlan_LabelsEntry>, I>>(base?: I): RestorePlan_LabelsEntry {
    return RestorePlan_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestorePlan_LabelsEntry>, I>>(object: I): RestorePlan_LabelsEntry {
    const message = createBaseRestorePlan_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseRestorePlanEventData(): RestorePlanEventData {
  return { payload: undefined };
}

export const RestorePlanEventData: MessageFns<RestorePlanEventData> = {
  encode(message: RestorePlanEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      RestorePlan.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestorePlanEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestorePlanEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = RestorePlan.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestorePlanEventData {
    return { payload: isSet(object.payload) ? RestorePlan.fromJSON(object.payload) : undefined };
  },

  toJSON(message: RestorePlanEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = RestorePlan.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestorePlanEventData>, I>>(base?: I): RestorePlanEventData {
    return RestorePlanEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestorePlanEventData>, I>>(object: I): RestorePlanEventData {
    const message = createBaseRestorePlanEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? RestorePlan.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseBackupEventData(): BackupEventData {
  return { payload: undefined };
}

export const BackupEventData: MessageFns<BackupEventData> = {
  encode(message: BackupEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Backup.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Backup.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupEventData {
    return { payload: isSet(object.payload) ? Backup.fromJSON(object.payload) : undefined };
  },

  toJSON(message: BackupEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Backup.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupEventData>, I>>(base?: I): BackupEventData {
    return BackupEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupEventData>, I>>(object: I): BackupEventData {
    const message = createBaseBackupEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Backup.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseBackupPlanEventData(): BackupPlanEventData {
  return { payload: undefined };
}

export const BackupPlanEventData: MessageFns<BackupPlanEventData> = {
  encode(message: BackupPlanEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      BackupPlan.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupPlanEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupPlanEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = BackupPlan.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupPlanEventData {
    return { payload: isSet(object.payload) ? BackupPlan.fromJSON(object.payload) : undefined };
  },

  toJSON(message: BackupPlanEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = BackupPlan.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupPlanEventData>, I>>(base?: I): BackupPlanEventData {
    return BackupPlanEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupPlanEventData>, I>>(object: I): BackupPlanEventData {
    const message = createBaseBackupPlanEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? BackupPlan.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseRestoreEventData(): RestoreEventData {
  return { payload: undefined };
}

export const RestoreEventData: MessageFns<RestoreEventData> = {
  encode(message: RestoreEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Restore.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): RestoreEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestoreEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Restore.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): RestoreEventData {
    return { payload: isSet(object.payload) ? Restore.fromJSON(object.payload) : undefined };
  },

  toJSON(message: RestoreEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Restore.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<RestoreEventData>, I>>(base?: I): RestoreEventData {
    return RestoreEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<RestoreEventData>, I>>(object: I): RestoreEventData {
    const message = createBaseRestoreEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Restore.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
