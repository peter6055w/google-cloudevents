// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/metastore/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Timestamp } from "../../../../protobuf/timestamp";
import { Int32Value } from "../../../../protobuf/wrappers";
import { DayOfWeek, dayOfWeekFromJSON, dayOfWeekToJSON } from "../../../../type/dayofweek";

export const protobufPackage = "google.events.cloud.metastore.v1";

/** Represents a federation of multiple backend metastores. */
export interface Federation {
  /**
   * Immutable. The relative resource name of the federation, of the
   * form:
   * projects/{project_number}/locations/{location_id}/federations/{federation_id}`.
   */
  name: string;
  /** Output only. The time when the metastore federation was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the metastore federation was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** User-defined labels for the metastore federation. */
  labels: { [key: string]: string };
  /**
   * Immutable. The Apache Hive metastore version of the federation. All backend
   * metastore versions must be compatible with the federation version.
   */
  version: string;
  /**
   * A map from `BackendMetastore` rank to `BackendMetastore`s from which the
   * federation service serves metadata at query time. The map key represents
   * the order in which `BackendMetastore`s should be evaluated to resolve
   * database names at query time and should be greater than or equal to zero. A
   * `BackendMetastore` with a lower number will be evaluated before a
   * `BackendMetastore` with a higher number.
   */
  backendMetastores: { [key: number]: BackendMetastore };
  /** Output only. The federation endpoint. */
  endpointUri: string;
  /** Output only. The current state of the federation. */
  state: Federation_State;
  /**
   * Output only. Additional information about the current state of the
   * metastore federation, if available.
   */
  stateMessage: string;
  /**
   * Output only. The globally unique resource identifier of the metastore
   * federation.
   */
  uid: string;
}

/** The current state of the federation. */
export enum Federation_State {
  /** STATE_UNSPECIFIED - The state of the metastore federation is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The metastore federation is in the process of being created. */
  CREATING = 1,
  /** ACTIVE - The metastore federation is running and ready to serve queries. */
  ACTIVE = 2,
  /**
   * UPDATING - The metastore federation is being updated. It remains usable but cannot
   * accept additional update requests or be deleted at this time.
   */
  UPDATING = 3,
  /** DELETING - The metastore federation is undergoing deletion. It cannot be used. */
  DELETING = 4,
  /**
   * ERROR - The metastore federation has encountered an error and cannot be used. The
   * metastore federation should be deleted.
   */
  ERROR = 5,
  UNRECOGNIZED = -1,
}

export function federation_StateFromJSON(object: any): Federation_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Federation_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Federation_State.CREATING;
    case 2:
    case "ACTIVE":
      return Federation_State.ACTIVE;
    case 3:
    case "UPDATING":
      return Federation_State.UPDATING;
    case 4:
    case "DELETING":
      return Federation_State.DELETING;
    case 5:
    case "ERROR":
      return Federation_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Federation_State.UNRECOGNIZED;
  }
}

export function federation_StateToJSON(object: Federation_State): string {
  switch (object) {
    case Federation_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Federation_State.CREATING:
      return "CREATING";
    case Federation_State.ACTIVE:
      return "ACTIVE";
    case Federation_State.UPDATING:
      return "UPDATING";
    case Federation_State.DELETING:
      return "DELETING";
    case Federation_State.ERROR:
      return "ERROR";
    case Federation_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Federation_LabelsEntry {
  key: string;
  value: string;
}

export interface Federation_BackendMetastoresEntry {
  key: number;
  value?: BackendMetastore | undefined;
}

/** Represents a backend metastore for the federation. */
export interface BackendMetastore {
  /**
   * The relative resource name of the metastore that is being federated.
   * The formats of the relative resource names for the currently supported
   * metastores are listed below:
   *
   * * BigQuery
   *     * `projects/{project_id}`
   * * Dataproc Metastore
   *     * `projects/{project_id}/locations/{location}/services/{service_id}`
   */
  name: string;
  /** The type of the backend metastore. */
  metastoreType: BackendMetastore_MetastoreType;
}

/** The type of the backend metastore. */
export enum BackendMetastore_MetastoreType {
  /** METASTORE_TYPE_UNSPECIFIED - The metastore type is not set. */
  METASTORE_TYPE_UNSPECIFIED = 0,
  /** DATAPROC_METASTORE - The backend metastore is Dataproc Metastore. */
  DATAPROC_METASTORE = 3,
  UNRECOGNIZED = -1,
}

export function backendMetastore_MetastoreTypeFromJSON(object: any): BackendMetastore_MetastoreType {
  switch (object) {
    case 0:
    case "METASTORE_TYPE_UNSPECIFIED":
      return BackendMetastore_MetastoreType.METASTORE_TYPE_UNSPECIFIED;
    case 3:
    case "DATAPROC_METASTORE":
      return BackendMetastore_MetastoreType.DATAPROC_METASTORE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return BackendMetastore_MetastoreType.UNRECOGNIZED;
  }
}

export function backendMetastore_MetastoreTypeToJSON(object: BackendMetastore_MetastoreType): string {
  switch (object) {
    case BackendMetastore_MetastoreType.METASTORE_TYPE_UNSPECIFIED:
      return "METASTORE_TYPE_UNSPECIFIED";
    case BackendMetastore_MetastoreType.DATAPROC_METASTORE:
      return "DATAPROC_METASTORE";
    case BackendMetastore_MetastoreType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A managed metastore service that serves metadata queries. */
export interface Service {
  /**
   * Configuration information specific to running Hive metastore
   * software as the metastore service.
   */
  hiveMetastoreConfig?:
    | HiveMetastoreConfig
    | undefined;
  /**
   * Immutable. The relative resource name of the metastore service, in the
   * following format:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}`.
   */
  name: string;
  /** Output only. The time when the metastore service was created. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the metastore service was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** User-defined labels for the metastore service. */
  labels: { [key: string]: string };
  /**
   * Immutable. The relative resource name of the VPC network on which the
   * instance can be accessed. It is specified in the following form:
   *
   * `projects/{project_number}/global/networks/{network_id}`.
   */
  network: string;
  /** Output only. The URI of the endpoint used to access the metastore service. */
  endpointUri: string;
  /** The TCP port at which the metastore service is reached. Default: 9083. */
  port: number;
  /** Output only. The current state of the metastore service. */
  state: Service_State;
  /**
   * Output only. Additional information about the current state of the
   * metastore service, if available.
   */
  stateMessage: string;
  /**
   * Output only. A Cloud Storage URI (starting with `gs://`) that specifies
   * where artifacts related to the metastore service are stored.
   */
  artifactGcsUri: string;
  /** The tier of the service. */
  tier: Service_Tier;
  /**
   * The one hour maintenance window of the metastore service. This specifies
   * when the service can be restarted for maintenance purposes in UTC time.
   * Maintenance window is not needed for services with the SPANNER
   * database type.
   */
  maintenanceWindow?:
    | MaintenanceWindow
    | undefined;
  /**
   * Output only. The globally unique resource identifier of the metastore
   * service.
   */
  uid: string;
  /** Output only. The metadata management activities of the metastore service. */
  metadataManagementActivity?:
    | MetadataManagementActivity
    | undefined;
  /**
   * Immutable. The release channel of the service.
   * If unspecified, defaults to `STABLE`.
   */
  releaseChannel: Service_ReleaseChannel;
  /**
   * Immutable. Information used to configure the Dataproc Metastore service to
   * encrypt customer data at rest. Cannot be updated.
   */
  encryptionConfig?:
    | EncryptionConfig
    | undefined;
  /**
   * The configuration specifying the network settings for the
   * Dataproc Metastore service.
   */
  networkConfig?:
    | NetworkConfig
    | undefined;
  /** Immutable. The database type that the Metastore service stores its data. */
  databaseType: Service_DatabaseType;
  /**
   * The configuration specifying telemetry settings for the Dataproc Metastore
   * service. If unspecified defaults to `JSON`.
   */
  telemetryConfig?:
    | TelemetryConfig
    | undefined;
  /** Scaling configuration of the metastore service. */
  scalingConfig?: ScalingConfig | undefined;
}

/** The current state of the metastore service. */
export enum Service_State {
  /** STATE_UNSPECIFIED - The state of the metastore service is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The metastore service is in the process of being created. */
  CREATING = 1,
  /** ACTIVE - The metastore service is running and ready to serve queries. */
  ACTIVE = 2,
  /**
   * SUSPENDING - The metastore service is entering suspension. Its query-serving
   * availability may cease unexpectedly.
   */
  SUSPENDING = 3,
  /** SUSPENDED - The metastore service is suspended and unable to serve queries. */
  SUSPENDED = 4,
  /**
   * UPDATING - The metastore service is being updated. It remains usable but cannot
   * accept additional update requests or be deleted at this time.
   */
  UPDATING = 5,
  /** DELETING - The metastore service is undergoing deletion. It cannot be used. */
  DELETING = 6,
  /**
   * ERROR - The metastore service has encountered an error and cannot be used. The
   * metastore service should be deleted.
   */
  ERROR = 7,
  UNRECOGNIZED = -1,
}

export function service_StateFromJSON(object: any): Service_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Service_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Service_State.CREATING;
    case 2:
    case "ACTIVE":
      return Service_State.ACTIVE;
    case 3:
    case "SUSPENDING":
      return Service_State.SUSPENDING;
    case 4:
    case "SUSPENDED":
      return Service_State.SUSPENDED;
    case 5:
    case "UPDATING":
      return Service_State.UPDATING;
    case 6:
    case "DELETING":
      return Service_State.DELETING;
    case 7:
    case "ERROR":
      return Service_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_State.UNRECOGNIZED;
  }
}

export function service_StateToJSON(object: Service_State): string {
  switch (object) {
    case Service_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Service_State.CREATING:
      return "CREATING";
    case Service_State.ACTIVE:
      return "ACTIVE";
    case Service_State.SUSPENDING:
      return "SUSPENDING";
    case Service_State.SUSPENDED:
      return "SUSPENDED";
    case Service_State.UPDATING:
      return "UPDATING";
    case Service_State.DELETING:
      return "DELETING";
    case Service_State.ERROR:
      return "ERROR";
    case Service_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Available service tiers. */
export enum Service_Tier {
  /** TIER_UNSPECIFIED - The tier is not set. */
  TIER_UNSPECIFIED = 0,
  /**
   * DEVELOPER - The developer tier provides limited scalability and no fault tolerance.
   * Good for low-cost proof-of-concept.
   */
  DEVELOPER = 1,
  /**
   * ENTERPRISE - The enterprise tier provides multi-zone high availability, and sufficient
   * scalability for enterprise-level Dataproc Metastore workloads.
   */
  ENTERPRISE = 3,
  UNRECOGNIZED = -1,
}

export function service_TierFromJSON(object: any): Service_Tier {
  switch (object) {
    case 0:
    case "TIER_UNSPECIFIED":
      return Service_Tier.TIER_UNSPECIFIED;
    case 1:
    case "DEVELOPER":
      return Service_Tier.DEVELOPER;
    case 3:
    case "ENTERPRISE":
      return Service_Tier.ENTERPRISE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_Tier.UNRECOGNIZED;
  }
}

export function service_TierToJSON(object: Service_Tier): string {
  switch (object) {
    case Service_Tier.TIER_UNSPECIFIED:
      return "TIER_UNSPECIFIED";
    case Service_Tier.DEVELOPER:
      return "DEVELOPER";
    case Service_Tier.ENTERPRISE:
      return "ENTERPRISE";
    case Service_Tier.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Release channels bundle features of varying levels of stability. Newer
 * features may be introduced initially into less stable release channels and
 * can be automatically promoted into more stable release channels.
 */
export enum Service_ReleaseChannel {
  /** RELEASE_CHANNEL_UNSPECIFIED - Release channel is not specified. */
  RELEASE_CHANNEL_UNSPECIFIED = 0,
  /**
   * CANARY - The `CANARY` release channel contains the newest features, which may be
   * unstable and subject to unresolved issues with no known workarounds.
   * Services using the `CANARY` release channel are not subject to any SLAs.
   */
  CANARY = 1,
  /**
   * STABLE - The `STABLE` release channel contains features that are considered stable
   * and have been validated for production use.
   */
  STABLE = 2,
  UNRECOGNIZED = -1,
}

export function service_ReleaseChannelFromJSON(object: any): Service_ReleaseChannel {
  switch (object) {
    case 0:
    case "RELEASE_CHANNEL_UNSPECIFIED":
      return Service_ReleaseChannel.RELEASE_CHANNEL_UNSPECIFIED;
    case 1:
    case "CANARY":
      return Service_ReleaseChannel.CANARY;
    case 2:
    case "STABLE":
      return Service_ReleaseChannel.STABLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_ReleaseChannel.UNRECOGNIZED;
  }
}

export function service_ReleaseChannelToJSON(object: Service_ReleaseChannel): string {
  switch (object) {
    case Service_ReleaseChannel.RELEASE_CHANNEL_UNSPECIFIED:
      return "RELEASE_CHANNEL_UNSPECIFIED";
    case Service_ReleaseChannel.CANARY:
      return "CANARY";
    case Service_ReleaseChannel.STABLE:
      return "STABLE";
    case Service_ReleaseChannel.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The backend database type for the metastore service. */
export enum Service_DatabaseType {
  /** DATABASE_TYPE_UNSPECIFIED - The DATABASE_TYPE is not set. */
  DATABASE_TYPE_UNSPECIFIED = 0,
  /** MYSQL - MySQL is used to persist the metastore data. */
  MYSQL = 1,
  /** SPANNER - Spanner is used to persist the metastore data. */
  SPANNER = 2,
  UNRECOGNIZED = -1,
}

export function service_DatabaseTypeFromJSON(object: any): Service_DatabaseType {
  switch (object) {
    case 0:
    case "DATABASE_TYPE_UNSPECIFIED":
      return Service_DatabaseType.DATABASE_TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return Service_DatabaseType.MYSQL;
    case 2:
    case "SPANNER":
      return Service_DatabaseType.SPANNER;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Service_DatabaseType.UNRECOGNIZED;
  }
}

export function service_DatabaseTypeToJSON(object: Service_DatabaseType): string {
  switch (object) {
    case Service_DatabaseType.DATABASE_TYPE_UNSPECIFIED:
      return "DATABASE_TYPE_UNSPECIFIED";
    case Service_DatabaseType.MYSQL:
      return "MYSQL";
    case Service_DatabaseType.SPANNER:
      return "SPANNER";
    case Service_DatabaseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface Service_LabelsEntry {
  key: string;
  value: string;
}

/**
 * Maintenance window. This specifies when Dataproc Metastore
 * may perform system maintenance operation to the service.
 */
export interface MaintenanceWindow {
  /** The hour of day (0-23) when the window starts. */
  hourOfDay?:
    | number
    | undefined;
  /** The day of week, when the window starts. */
  dayOfWeek: DayOfWeek;
}

/**
 * Specifies configuration information specific to running Hive metastore
 * software as the metastore service.
 */
export interface HiveMetastoreConfig {
  /** Immutable. The Hive metastore schema version. */
  version: string;
  /**
   * A mapping of Hive metastore configuration key-value pairs to apply to the
   * Hive metastore (configured in `hive-site.xml`). The mappings
   * override system defaults (some keys cannot be overridden). These
   * overrides are also applied to auxiliary versions and can be further
   * customized in the auxiliary version's `AuxiliaryVersionConfig`.
   */
  configOverrides: { [key: string]: string };
  /**
   * Information used to configure the Hive metastore service as a service
   * principal in a Kerberos realm. To disable Kerberos, use the `UpdateService`
   * method and specify this field's path
   * (`hive_metastore_config.kerberos_config`) in the request's `update_mask`
   * while omitting this field from the request's `service`.
   */
  kerberosConfig?:
    | KerberosConfig
    | undefined;
  /**
   * A mapping of Hive metastore version to the auxiliary version
   * configuration. When specified, a secondary Hive metastore service is
   * created along with the primary service. All auxiliary versions must be less
   * than the service's primary version. The key is the auxiliary service name
   * and it must match the regular expression [a-z]([-a-z0-9]*[a-z0-9])?. This
   * means that the first character must be a lowercase letter, and all the
   * following characters must be hyphens, lowercase letters, or digits, except
   * the last character, which cannot be a hyphen.
   */
  auxiliaryVersions: { [key: string]: AuxiliaryVersionConfig };
}

export interface HiveMetastoreConfig_ConfigOverridesEntry {
  key: string;
  value: string;
}

export interface HiveMetastoreConfig_AuxiliaryVersionsEntry {
  key: string;
  value?: AuxiliaryVersionConfig | undefined;
}

/** Configuration information for a Kerberos principal. */
export interface KerberosConfig {
  /**
   * A Kerberos keytab file that can be used to authenticate a service principal
   * with a Kerberos Key Distribution Center (KDC).
   */
  keytab?:
    | Secret
    | undefined;
  /**
   * A Kerberos principal that exists in the both the keytab the KDC
   * to authenticate as. A typical principal is of the form
   * `primary/instance@REALM`, but there is no exact format.
   */
  principal: string;
  /**
   * A Cloud Storage URI that specifies the path to a
   * krb5.conf file. It is of the form `gs://{bucket_name}/path/to/krb5.conf`,
   * although the file does not need to be named krb5.conf explicitly.
   */
  krb5ConfigGcsUri: string;
}

/** A securely stored value. */
export interface Secret {
  /**
   * The relative resource name of a Secret Manager secret version, in the
   * following form:
   *
   * `projects/{project_number}/secrets/{secret_id}/versions/{version_id}`.
   */
  cloudSecret?: string | undefined;
}

/** Encryption settings for the service. */
export interface EncryptionConfig {
  /**
   * The fully qualified customer provided Cloud KMS key name to use for
   * customer data encryption, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/keyRings/{key_ring_id}/cryptoKeys/{crypto_key_id}`.
   */
  kmsKey: string;
}

/** Configuration information for the auxiliary service versions. */
export interface AuxiliaryVersionConfig {
  /**
   * The Hive metastore version of the auxiliary service. It must be less
   * than the primary Hive metastore service's version.
   */
  version: string;
  /**
   * A mapping of Hive metastore configuration key-value pairs to apply to the
   * auxiliary Hive metastore (configured in `hive-site.xml`) in addition to
   * the primary version's overrides. If keys are present in both the auxiliary
   * version's overrides and the primary version's overrides, the value from
   * the auxiliary version's overrides takes precedence.
   */
  configOverrides: { [key: string]: string };
  /**
   * Output only. The network configuration contains the endpoint URI(s) of the
   * auxiliary Hive metastore service.
   */
  networkConfig?: NetworkConfig | undefined;
}

export interface AuxiliaryVersionConfig_ConfigOverridesEntry {
  key: string;
  value: string;
}

/** Network configuration for the Dataproc Metastore service. */
export interface NetworkConfig {
  /**
   * Immutable. The consumer-side network configuration for the Dataproc
   * Metastore instance.
   */
  consumers: NetworkConfig_Consumer[];
}

/** Contains information of the customer's network configurations. */
export interface NetworkConfig_Consumer {
  /**
   * Immutable. The subnetwork of the customer project from which an IP
   * address is reserved and used as the Dataproc Metastore service's
   * endpoint. It is accessible to hosts in the subnet and to all
   * hosts in a subnet in the same region and same network. There must
   * be at least one IP address available in the subnet's primary range. The
   * subnet is specified in the following form:
   *
   * `projects/{project_number}/regions/{region_id}/subnetworks/{subnetwork_id}`
   */
  subnetwork?:
    | string
    | undefined;
  /**
   * Output only. The URI of the endpoint used to access the metastore
   * service.
   */
  endpointUri: string;
}

/** Telemetry Configuration for the Dataproc Metastore service. */
export interface TelemetryConfig {
  /** The output format of the Dataproc Metastore service's logs. */
  logFormat: TelemetryConfig_LogFormat;
}

export enum TelemetryConfig_LogFormat {
  /** LOG_FORMAT_UNSPECIFIED - The LOG_FORMAT is not set. */
  LOG_FORMAT_UNSPECIFIED = 0,
  /** LEGACY - Logging output uses the legacy `textPayload` format. */
  LEGACY = 1,
  /** JSON - Logging output uses the `jsonPayload` format. */
  JSON = 2,
  UNRECOGNIZED = -1,
}

export function telemetryConfig_LogFormatFromJSON(object: any): TelemetryConfig_LogFormat {
  switch (object) {
    case 0:
    case "LOG_FORMAT_UNSPECIFIED":
      return TelemetryConfig_LogFormat.LOG_FORMAT_UNSPECIFIED;
    case 1:
    case "LEGACY":
      return TelemetryConfig_LogFormat.LEGACY;
    case 2:
    case "JSON":
      return TelemetryConfig_LogFormat.JSON;
    case -1:
    case "UNRECOGNIZED":
    default:
      return TelemetryConfig_LogFormat.UNRECOGNIZED;
  }
}

export function telemetryConfig_LogFormatToJSON(object: TelemetryConfig_LogFormat): string {
  switch (object) {
    case TelemetryConfig_LogFormat.LOG_FORMAT_UNSPECIFIED:
      return "LOG_FORMAT_UNSPECIFIED";
    case TelemetryConfig_LogFormat.LEGACY:
      return "LEGACY";
    case TelemetryConfig_LogFormat.JSON:
      return "JSON";
    case TelemetryConfig_LogFormat.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The metadata management activities of the metastore service. */
export interface MetadataManagementActivity {
  /** Output only. The latest metadata exports of the metastore service. */
  metadataExports: MetadataExport[];
  /** Output only. The latest restores of the metastore service. */
  restores: Restore[];
}

/** A metastore resource that imports metadata. */
export interface MetadataImport {
  /** Immutable. A database dump from a pre-existing metastore's database. */
  databaseDump?:
    | MetadataImport_DatabaseDump
    | undefined;
  /**
   * Immutable. The relative resource name of the metadata import, of the form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/metadataImports/{metadata_import_id}`.
   */
  name: string;
  /** The description of the metadata import. */
  description: string;
  /** Output only. The time when the metadata import was started. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the metadata import was last updated. */
  updateTime?:
    | Date
    | undefined;
  /** Output only. The time when the metadata import finished. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The current state of the metadata import. */
  state: MetadataImport_State;
}

/** The current state of the metadata import. */
export enum MetadataImport_State {
  /** STATE_UNSPECIFIED - The state of the metadata import is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata import is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata import completed successfully. */
  SUCCEEDED = 2,
  /** UPDATING - The metadata import is being updated. */
  UPDATING = 3,
  /**
   * FAILED - The metadata import failed, and attempted metadata changes were rolled
   * back.
   */
  FAILED = 4,
  UNRECOGNIZED = -1,
}

export function metadataImport_StateFromJSON(object: any): MetadataImport_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MetadataImport_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return MetadataImport_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return MetadataImport_State.SUCCEEDED;
    case 3:
    case "UPDATING":
      return MetadataImport_State.UPDATING;
    case 4:
    case "FAILED":
      return MetadataImport_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataImport_State.UNRECOGNIZED;
  }
}

export function metadataImport_StateToJSON(object: MetadataImport_State): string {
  switch (object) {
    case MetadataImport_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MetadataImport_State.RUNNING:
      return "RUNNING";
    case MetadataImport_State.SUCCEEDED:
      return "SUCCEEDED";
    case MetadataImport_State.UPDATING:
      return "UPDATING";
    case MetadataImport_State.FAILED:
      return "FAILED";
    case MetadataImport_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * A specification of the location of and metadata about a database dump from
 * a relational database management system.
 */
export interface MetadataImport_DatabaseDump {
  /** The type of the database. */
  databaseType: MetadataImport_DatabaseDump_DatabaseType;
  /**
   * A Cloud Storage object or folder URI that specifies the source from which
   * to import metadata. It must begin with `gs://`.
   */
  gcsUri: string;
  /** The name of the source database. */
  sourceDatabase: string;
  /**
   * Optional. The type of the database dump. If unspecified, defaults to
   * `MYSQL`.
   */
  type: DatabaseDumpSpec_Type;
}

/** The type of the database. */
export enum MetadataImport_DatabaseDump_DatabaseType {
  /** DATABASE_TYPE_UNSPECIFIED - The type of the source database is unknown. */
  DATABASE_TYPE_UNSPECIFIED = 0,
  /** MYSQL - The type of the source database is MySQL. */
  MYSQL = 1,
  UNRECOGNIZED = -1,
}

export function metadataImport_DatabaseDump_DatabaseTypeFromJSON(
  object: any,
): MetadataImport_DatabaseDump_DatabaseType {
  switch (object) {
    case 0:
    case "DATABASE_TYPE_UNSPECIFIED":
      return MetadataImport_DatabaseDump_DatabaseType.DATABASE_TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return MetadataImport_DatabaseDump_DatabaseType.MYSQL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataImport_DatabaseDump_DatabaseType.UNRECOGNIZED;
  }
}

export function metadataImport_DatabaseDump_DatabaseTypeToJSON(
  object: MetadataImport_DatabaseDump_DatabaseType,
): string {
  switch (object) {
    case MetadataImport_DatabaseDump_DatabaseType.DATABASE_TYPE_UNSPECIFIED:
      return "DATABASE_TYPE_UNSPECIFIED";
    case MetadataImport_DatabaseDump_DatabaseType.MYSQL:
      return "MYSQL";
    case MetadataImport_DatabaseDump_DatabaseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a metadata export operation. */
export interface MetadataExport {
  /**
   * Output only. A Cloud Storage URI of a folder that metadata are exported
   * to, in the form of
   * `gs://<bucket_name>/<path_inside_bucket>/<export_folder>`, where
   * `<export_folder>` is automatically generated.
   */
  destinationGcsUri?:
    | string
    | undefined;
  /** Output only. The time when the export started. */
  startTime?:
    | Date
    | undefined;
  /** Output only. The time when the export ended. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The current state of the export. */
  state: MetadataExport_State;
  /** Output only. The type of the database dump. */
  databaseDumpType: DatabaseDumpSpec_Type;
}

/** The current state of the metadata export. */
export enum MetadataExport_State {
  /** STATE_UNSPECIFIED - The state of the metadata export is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata export is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata export completed successfully. */
  SUCCEEDED = 2,
  /** FAILED - The metadata export failed. */
  FAILED = 3,
  /** CANCELLED - The metadata export is cancelled. */
  CANCELLED = 4,
  UNRECOGNIZED = -1,
}

export function metadataExport_StateFromJSON(object: any): MetadataExport_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MetadataExport_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return MetadataExport_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return MetadataExport_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return MetadataExport_State.FAILED;
    case 4:
    case "CANCELLED":
      return MetadataExport_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MetadataExport_State.UNRECOGNIZED;
  }
}

export function metadataExport_StateToJSON(object: MetadataExport_State): string {
  switch (object) {
    case MetadataExport_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MetadataExport_State.RUNNING:
      return "RUNNING";
    case MetadataExport_State.SUCCEEDED:
      return "SUCCEEDED";
    case MetadataExport_State.FAILED:
      return "FAILED";
    case MetadataExport_State.CANCELLED:
      return "CANCELLED";
    case MetadataExport_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a backup resource. */
export interface Backup {
  /**
   * Immutable. The relative resource name of the backup, in the following form:
   *
   * `projects/{project_number}/locations/{location_id}/services/{service_id}/backups/{backup_id}`
   */
  name: string;
  /** Output only. The time when the backup was started. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time when the backup finished creating. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The current state of the backup. */
  state: Backup_State;
  /** Output only. The revision of the service at the time of backup. */
  serviceRevision?:
    | Service
    | undefined;
  /** The description of the backup. */
  description: string;
  /** Output only. Services that are restoring from the backup. */
  restoringServices: string[];
}

/** The current state of the backup. */
export enum Backup_State {
  /** STATE_UNSPECIFIED - The state of the backup is unknown. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The backup is being created. */
  CREATING = 1,
  /** DELETING - The backup is being deleted. */
  DELETING = 2,
  /** ACTIVE - The backup is active and ready to use. */
  ACTIVE = 3,
  /** FAILED - The backup failed. */
  FAILED = 4,
  /** RESTORING - The backup is being restored. */
  RESTORING = 5,
  UNRECOGNIZED = -1,
}

export function backup_StateFromJSON(object: any): Backup_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Backup_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return Backup_State.CREATING;
    case 2:
    case "DELETING":
      return Backup_State.DELETING;
    case 3:
    case "ACTIVE":
      return Backup_State.ACTIVE;
    case 4:
    case "FAILED":
      return Backup_State.FAILED;
    case 5:
    case "RESTORING":
      return Backup_State.RESTORING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Backup_State.UNRECOGNIZED;
  }
}

export function backup_StateToJSON(object: Backup_State): string {
  switch (object) {
    case Backup_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Backup_State.CREATING:
      return "CREATING";
    case Backup_State.DELETING:
      return "DELETING";
    case Backup_State.ACTIVE:
      return "ACTIVE";
    case Backup_State.FAILED:
      return "FAILED";
    case Backup_State.RESTORING:
      return "RESTORING";
    case Backup_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of a metadata restore operation. */
export interface Restore {
  /** Output only. The time when the restore started. */
  startTime?:
    | Date
    | undefined;
  /** Output only. The time when the restore ended. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The current state of the restore. */
  state: Restore_State;
  /**
   * Output only. The relative resource name of the metastore service backup to
   * restore from, in the following form:
   *
   * `projects/{project_id}/locations/{location_id}/services/{service_id}/backups/{backup_id}`.
   */
  backup: string;
  /** Output only. The type of restore. */
  type: Restore_RestoreType;
  /**
   * Output only. The restore details containing the revision of the service to
   * be restored to, in format of JSON.
   */
  details: string;
}

/** The current state of the restore. */
export enum Restore_State {
  /** STATE_UNSPECIFIED - The state of the metadata restore is unknown. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The metadata restore is running. */
  RUNNING = 1,
  /** SUCCEEDED - The metadata restore completed successfully. */
  SUCCEEDED = 2,
  /** FAILED - The metadata restore failed. */
  FAILED = 3,
  /** CANCELLED - The metadata restore is cancelled. */
  CANCELLED = 4,
  UNRECOGNIZED = -1,
}

export function restore_StateFromJSON(object: any): Restore_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return Restore_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return Restore_State.RUNNING;
    case 2:
    case "SUCCEEDED":
      return Restore_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return Restore_State.FAILED;
    case 4:
    case "CANCELLED":
      return Restore_State.CANCELLED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Restore_State.UNRECOGNIZED;
  }
}

export function restore_StateToJSON(object: Restore_State): string {
  switch (object) {
    case Restore_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case Restore_State.RUNNING:
      return "RUNNING";
    case Restore_State.SUCCEEDED:
      return "SUCCEEDED";
    case Restore_State.FAILED:
      return "FAILED";
    case Restore_State.CANCELLED:
      return "CANCELLED";
    case Restore_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The type of restore. If unspecified, defaults to `METADATA_ONLY`. */
export enum Restore_RestoreType {
  /** RESTORE_TYPE_UNSPECIFIED - The restore type is unknown. */
  RESTORE_TYPE_UNSPECIFIED = 0,
  /** FULL - The service's metadata and configuration are restored. */
  FULL = 1,
  /** METADATA_ONLY - Only the service's metadata is restored. */
  METADATA_ONLY = 2,
  UNRECOGNIZED = -1,
}

export function restore_RestoreTypeFromJSON(object: any): Restore_RestoreType {
  switch (object) {
    case 0:
    case "RESTORE_TYPE_UNSPECIFIED":
      return Restore_RestoreType.RESTORE_TYPE_UNSPECIFIED;
    case 1:
    case "FULL":
      return Restore_RestoreType.FULL;
    case 2:
    case "METADATA_ONLY":
      return Restore_RestoreType.METADATA_ONLY;
    case -1:
    case "UNRECOGNIZED":
    default:
      return Restore_RestoreType.UNRECOGNIZED;
  }
}

export function restore_RestoreTypeToJSON(object: Restore_RestoreType): string {
  switch (object) {
    case Restore_RestoreType.RESTORE_TYPE_UNSPECIFIED:
      return "RESTORE_TYPE_UNSPECIFIED";
    case Restore_RestoreType.FULL:
      return "FULL";
    case Restore_RestoreType.METADATA_ONLY:
      return "METADATA_ONLY";
    case Restore_RestoreType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represents the scaling configuration of a metastore service. */
export interface ScalingConfig {
  /**
   * An enum of readable instance sizes, with each instance size mapping to a
   * float value (e.g. InstanceSize.EXTRA_SMALL = scaling_factor(0.1))
   */
  instanceSize?:
    | ScalingConfig_InstanceSize
    | undefined;
  /**
   * Scaling factor, increments of 0.1 for values less than 1.0, and
   * increments of 1.0 for values greater than 1.0.
   */
  scalingFactor?: number | undefined;
}

/** Metastore instance sizes. */
export enum ScalingConfig_InstanceSize {
  /** INSTANCE_SIZE_UNSPECIFIED - Unspecified instance size */
  INSTANCE_SIZE_UNSPECIFIED = 0,
  /** EXTRA_SMALL - Extra small instance size, maps to a scaling factor of 0.1. */
  EXTRA_SMALL = 1,
  /** SMALL - Small instance size, maps to a scaling factor of 0.5. */
  SMALL = 2,
  /** MEDIUM - Medium instance size, maps to a scaling factor of 1.0. */
  MEDIUM = 3,
  /** LARGE - Large instance size, maps to a scaling factor of 3.0. */
  LARGE = 4,
  /** EXTRA_LARGE - Extra large instance size, maps to a scaling factor of 6.0. */
  EXTRA_LARGE = 5,
  UNRECOGNIZED = -1,
}

export function scalingConfig_InstanceSizeFromJSON(object: any): ScalingConfig_InstanceSize {
  switch (object) {
    case 0:
    case "INSTANCE_SIZE_UNSPECIFIED":
      return ScalingConfig_InstanceSize.INSTANCE_SIZE_UNSPECIFIED;
    case 1:
    case "EXTRA_SMALL":
      return ScalingConfig_InstanceSize.EXTRA_SMALL;
    case 2:
    case "SMALL":
      return ScalingConfig_InstanceSize.SMALL;
    case 3:
    case "MEDIUM":
      return ScalingConfig_InstanceSize.MEDIUM;
    case 4:
    case "LARGE":
      return ScalingConfig_InstanceSize.LARGE;
    case 5:
    case "EXTRA_LARGE":
      return ScalingConfig_InstanceSize.EXTRA_LARGE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ScalingConfig_InstanceSize.UNRECOGNIZED;
  }
}

export function scalingConfig_InstanceSizeToJSON(object: ScalingConfig_InstanceSize): string {
  switch (object) {
    case ScalingConfig_InstanceSize.INSTANCE_SIZE_UNSPECIFIED:
      return "INSTANCE_SIZE_UNSPECIFIED";
    case ScalingConfig_InstanceSize.EXTRA_SMALL:
      return "EXTRA_SMALL";
    case ScalingConfig_InstanceSize.SMALL:
      return "SMALL";
    case ScalingConfig_InstanceSize.MEDIUM:
      return "MEDIUM";
    case ScalingConfig_InstanceSize.LARGE:
      return "LARGE";
    case ScalingConfig_InstanceSize.EXTRA_LARGE:
      return "EXTRA_LARGE";
    case ScalingConfig_InstanceSize.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The specification of database dump to import from or export to. */
export interface DatabaseDumpSpec {
}

/** The type of the database dump. */
export enum DatabaseDumpSpec_Type {
  /** TYPE_UNSPECIFIED - The type of the database dump is unknown. */
  TYPE_UNSPECIFIED = 0,
  /** MYSQL - Database dump is a MySQL dump file. */
  MYSQL = 1,
  /** AVRO - Database dump contains Avro files. */
  AVRO = 2,
  UNRECOGNIZED = -1,
}

export function databaseDumpSpec_TypeFromJSON(object: any): DatabaseDumpSpec_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return DatabaseDumpSpec_Type.TYPE_UNSPECIFIED;
    case 1:
    case "MYSQL":
      return DatabaseDumpSpec_Type.MYSQL;
    case 2:
    case "AVRO":
      return DatabaseDumpSpec_Type.AVRO;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatabaseDumpSpec_Type.UNRECOGNIZED;
  }
}

export function databaseDumpSpec_TypeToJSON(object: DatabaseDumpSpec_Type): string {
  switch (object) {
    case DatabaseDumpSpec_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case DatabaseDumpSpec_Type.MYSQL:
      return "MYSQL";
    case DatabaseDumpSpec_Type.AVRO:
      return "AVRO";
    case DatabaseDumpSpec_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The data within all MetadataImport events. */
export interface MetadataImportEventData {
  /** The MetadataImport event payload. */
  payload?: MetadataImport | undefined;
}

/** The data within all Federation events. */
export interface FederationEventData {
  /** Optional. The Federation event payload. Unset for deletion events. */
  payload?: Federation | undefined;
}

/** The data within all Backup events. */
export interface BackupEventData {
  /** Optional. The Backup event payload. Unset for deletion events. */
  payload?: Backup | undefined;
}

/** The data within all Service events. */
export interface ServiceEventData {
  /** Optional. The Service event payload. Unset for deletion events. */
  payload?: Service | undefined;
}

function createBaseFederation(): Federation {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    version: "",
    backendMetastores: {},
    endpointUri: "",
    state: 0,
    stateMessage: "",
    uid: "",
  };
}

export const Federation: MessageFns<Federation> = {
  encode(message: Federation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Federation_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.version !== "") {
      writer.uint32(42).string(message.version);
    }
    Object.entries(message.backendMetastores).forEach(([key, value]) => {
      Federation_BackendMetastoresEntry.encode({ key: key as any, value }, writer.uint32(50).fork()).join();
    });
    if (message.endpointUri !== "") {
      writer.uint32(58).string(message.endpointUri);
    }
    if (message.state !== 0) {
      writer.uint32(64).int32(message.state);
    }
    if (message.stateMessage !== "") {
      writer.uint32(74).string(message.stateMessage);
    }
    if (message.uid !== "") {
      writer.uint32(82).string(message.uid);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Federation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFederation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Federation_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          const entry6 = Federation_BackendMetastoresEntry.decode(reader, reader.uint32());
          if (entry6.value !== undefined) {
            message.backendMetastores[entry6.key] = entry6.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.endpointUri = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.stateMessage = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Federation {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      backendMetastores: isObject(object.backendMetastores)
        ? Object.entries(object.backendMetastores).reduce<{ [key: number]: BackendMetastore }>((acc, [key, value]) => {
          acc[globalThis.Number(key)] = BackendMetastore.fromJSON(value);
          return acc;
        }, {})
        : {},
      endpointUri: isSet(object.endpointUri) ? globalThis.String(object.endpointUri) : "",
      state: isSet(object.state) ? federation_StateFromJSON(object.state) : 0,
      stateMessage: isSet(object.stateMessage) ? globalThis.String(object.stateMessage) : "",
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
    };
  },

  toJSON(message: Federation): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.backendMetastores) {
      const entries = Object.entries(message.backendMetastores);
      if (entries.length > 0) {
        obj.backendMetastores = {};
        entries.forEach(([k, v]) => {
          obj.backendMetastores[k] = BackendMetastore.toJSON(v);
        });
      }
    }
    if (message.endpointUri !== "") {
      obj.endpointUri = message.endpointUri;
    }
    if (message.state !== 0) {
      obj.state = federation_StateToJSON(message.state);
    }
    if (message.stateMessage !== "") {
      obj.stateMessage = message.stateMessage;
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Federation>, I>>(base?: I): Federation {
    return Federation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Federation>, I>>(object: I): Federation {
    const message = createBaseFederation();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.version = object.version ?? "";
    message.backendMetastores = Object.entries(object.backendMetastores ?? {}).reduce<
      { [key: number]: BackendMetastore }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[globalThis.Number(key)] = BackendMetastore.fromPartial(value);
      }
      return acc;
    }, {});
    message.endpointUri = object.endpointUri ?? "";
    message.state = object.state ?? 0;
    message.stateMessage = object.stateMessage ?? "";
    message.uid = object.uid ?? "";
    return message;
  },
};

function createBaseFederation_LabelsEntry(): Federation_LabelsEntry {
  return { key: "", value: "" };
}

export const Federation_LabelsEntry: MessageFns<Federation_LabelsEntry> = {
  encode(message: Federation_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Federation_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFederation_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Federation_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Federation_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Federation_LabelsEntry>, I>>(base?: I): Federation_LabelsEntry {
    return Federation_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Federation_LabelsEntry>, I>>(object: I): Federation_LabelsEntry {
    const message = createBaseFederation_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseFederation_BackendMetastoresEntry(): Federation_BackendMetastoresEntry {
  return { key: 0, value: undefined };
}

export const Federation_BackendMetastoresEntry: MessageFns<Federation_BackendMetastoresEntry> = {
  encode(message: Federation_BackendMetastoresEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== 0) {
      writer.uint32(8).int32(message.key);
    }
    if (message.value !== undefined) {
      BackendMetastore.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Federation_BackendMetastoresEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFederation_BackendMetastoresEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.key = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = BackendMetastore.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Federation_BackendMetastoresEntry {
    return {
      key: isSet(object.key) ? globalThis.Number(object.key) : 0,
      value: isSet(object.value) ? BackendMetastore.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: Federation_BackendMetastoresEntry): unknown {
    const obj: any = {};
    if (message.key !== 0) {
      obj.key = Math.round(message.key);
    }
    if (message.value !== undefined) {
      obj.value = BackendMetastore.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Federation_BackendMetastoresEntry>, I>>(
    base?: I,
  ): Federation_BackendMetastoresEntry {
    return Federation_BackendMetastoresEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Federation_BackendMetastoresEntry>, I>>(
    object: I,
  ): Federation_BackendMetastoresEntry {
    const message = createBaseFederation_BackendMetastoresEntry();
    message.key = object.key ?? 0;
    message.value = (object.value !== undefined && object.value !== null)
      ? BackendMetastore.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseBackendMetastore(): BackendMetastore {
  return { name: "", metastoreType: 0 };
}

export const BackendMetastore: MessageFns<BackendMetastore> = {
  encode(message: BackendMetastore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.metastoreType !== 0) {
      writer.uint32(16).int32(message.metastoreType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackendMetastore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackendMetastore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.metastoreType = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackendMetastore {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      metastoreType: isSet(object.metastoreType) ? backendMetastore_MetastoreTypeFromJSON(object.metastoreType) : 0,
    };
  },

  toJSON(message: BackendMetastore): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.metastoreType !== 0) {
      obj.metastoreType = backendMetastore_MetastoreTypeToJSON(message.metastoreType);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackendMetastore>, I>>(base?: I): BackendMetastore {
    return BackendMetastore.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackendMetastore>, I>>(object: I): BackendMetastore {
    const message = createBaseBackendMetastore();
    message.name = object.name ?? "";
    message.metastoreType = object.metastoreType ?? 0;
    return message;
  },
};

function createBaseService(): Service {
  return {
    hiveMetastoreConfig: undefined,
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    network: "",
    endpointUri: "",
    port: 0,
    state: 0,
    stateMessage: "",
    artifactGcsUri: "",
    tier: 0,
    maintenanceWindow: undefined,
    uid: "",
    metadataManagementActivity: undefined,
    releaseChannel: 0,
    encryptionConfig: undefined,
    networkConfig: undefined,
    databaseType: 0,
    telemetryConfig: undefined,
    scalingConfig: undefined,
  };
}

export const Service: MessageFns<Service> = {
  encode(message: Service, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hiveMetastoreConfig !== undefined) {
      HiveMetastoreConfig.encode(message.hiveMetastoreConfig, writer.uint32(42).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Service_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.network !== "") {
      writer.uint32(58).string(message.network);
    }
    if (message.endpointUri !== "") {
      writer.uint32(66).string(message.endpointUri);
    }
    if (message.port !== 0) {
      writer.uint32(72).int32(message.port);
    }
    if (message.state !== 0) {
      writer.uint32(80).int32(message.state);
    }
    if (message.stateMessage !== "") {
      writer.uint32(90).string(message.stateMessage);
    }
    if (message.artifactGcsUri !== "") {
      writer.uint32(98).string(message.artifactGcsUri);
    }
    if (message.tier !== 0) {
      writer.uint32(104).int32(message.tier);
    }
    if (message.maintenanceWindow !== undefined) {
      MaintenanceWindow.encode(message.maintenanceWindow, writer.uint32(122).fork()).join();
    }
    if (message.uid !== "") {
      writer.uint32(130).string(message.uid);
    }
    if (message.metadataManagementActivity !== undefined) {
      MetadataManagementActivity.encode(message.metadataManagementActivity, writer.uint32(138).fork()).join();
    }
    if (message.releaseChannel !== 0) {
      writer.uint32(152).int32(message.releaseChannel);
    }
    if (message.encryptionConfig !== undefined) {
      EncryptionConfig.encode(message.encryptionConfig, writer.uint32(162).fork()).join();
    }
    if (message.networkConfig !== undefined) {
      NetworkConfig.encode(message.networkConfig, writer.uint32(170).fork()).join();
    }
    if (message.databaseType !== 0) {
      writer.uint32(176).int32(message.databaseType);
    }
    if (message.telemetryConfig !== undefined) {
      TelemetryConfig.encode(message.telemetryConfig, writer.uint32(186).fork()).join();
    }
    if (message.scalingConfig !== undefined) {
      ScalingConfig.encode(message.scalingConfig, writer.uint32(194).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.hiveMetastoreConfig = HiveMetastoreConfig.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Service_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.network = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.endpointUri = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.port = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.stateMessage = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.artifactGcsUri = reader.string();
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.tier = reader.int32() as any;
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.maintenanceWindow = MaintenanceWindow.decode(reader, reader.uint32());
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.metadataManagementActivity = MetadataManagementActivity.decode(reader, reader.uint32());
          continue;
        }
        case 19: {
          if (tag !== 152) {
            break;
          }

          message.releaseChannel = reader.int32() as any;
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.encryptionConfig = EncryptionConfig.decode(reader, reader.uint32());
          continue;
        }
        case 21: {
          if (tag !== 170) {
            break;
          }

          message.networkConfig = NetworkConfig.decode(reader, reader.uint32());
          continue;
        }
        case 22: {
          if (tag !== 176) {
            break;
          }

          message.databaseType = reader.int32() as any;
          continue;
        }
        case 23: {
          if (tag !== 186) {
            break;
          }

          message.telemetryConfig = TelemetryConfig.decode(reader, reader.uint32());
          continue;
        }
        case 24: {
          if (tag !== 194) {
            break;
          }

          message.scalingConfig = ScalingConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service {
    return {
      hiveMetastoreConfig: isSet(object.hiveMetastoreConfig)
        ? HiveMetastoreConfig.fromJSON(object.hiveMetastoreConfig)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      endpointUri: isSet(object.endpointUri) ? globalThis.String(object.endpointUri) : "",
      port: isSet(object.port) ? globalThis.Number(object.port) : 0,
      state: isSet(object.state) ? service_StateFromJSON(object.state) : 0,
      stateMessage: isSet(object.stateMessage) ? globalThis.String(object.stateMessage) : "",
      artifactGcsUri: isSet(object.artifactGcsUri) ? globalThis.String(object.artifactGcsUri) : "",
      tier: isSet(object.tier) ? service_TierFromJSON(object.tier) : 0,
      maintenanceWindow: isSet(object.maintenanceWindow)
        ? MaintenanceWindow.fromJSON(object.maintenanceWindow)
        : undefined,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      metadataManagementActivity: isSet(object.metadataManagementActivity)
        ? MetadataManagementActivity.fromJSON(object.metadataManagementActivity)
        : undefined,
      releaseChannel: isSet(object.releaseChannel) ? service_ReleaseChannelFromJSON(object.releaseChannel) : 0,
      encryptionConfig: isSet(object.encryptionConfig) ? EncryptionConfig.fromJSON(object.encryptionConfig) : undefined,
      networkConfig: isSet(object.networkConfig) ? NetworkConfig.fromJSON(object.networkConfig) : undefined,
      databaseType: isSet(object.databaseType) ? service_DatabaseTypeFromJSON(object.databaseType) : 0,
      telemetryConfig: isSet(object.telemetryConfig) ? TelemetryConfig.fromJSON(object.telemetryConfig) : undefined,
      scalingConfig: isSet(object.scalingConfig) ? ScalingConfig.fromJSON(object.scalingConfig) : undefined,
    };
  },

  toJSON(message: Service): unknown {
    const obj: any = {};
    if (message.hiveMetastoreConfig !== undefined) {
      obj.hiveMetastoreConfig = HiveMetastoreConfig.toJSON(message.hiveMetastoreConfig);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.endpointUri !== "") {
      obj.endpointUri = message.endpointUri;
    }
    if (message.port !== 0) {
      obj.port = Math.round(message.port);
    }
    if (message.state !== 0) {
      obj.state = service_StateToJSON(message.state);
    }
    if (message.stateMessage !== "") {
      obj.stateMessage = message.stateMessage;
    }
    if (message.artifactGcsUri !== "") {
      obj.artifactGcsUri = message.artifactGcsUri;
    }
    if (message.tier !== 0) {
      obj.tier = service_TierToJSON(message.tier);
    }
    if (message.maintenanceWindow !== undefined) {
      obj.maintenanceWindow = MaintenanceWindow.toJSON(message.maintenanceWindow);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.metadataManagementActivity !== undefined) {
      obj.metadataManagementActivity = MetadataManagementActivity.toJSON(message.metadataManagementActivity);
    }
    if (message.releaseChannel !== 0) {
      obj.releaseChannel = service_ReleaseChannelToJSON(message.releaseChannel);
    }
    if (message.encryptionConfig !== undefined) {
      obj.encryptionConfig = EncryptionConfig.toJSON(message.encryptionConfig);
    }
    if (message.networkConfig !== undefined) {
      obj.networkConfig = NetworkConfig.toJSON(message.networkConfig);
    }
    if (message.databaseType !== 0) {
      obj.databaseType = service_DatabaseTypeToJSON(message.databaseType);
    }
    if (message.telemetryConfig !== undefined) {
      obj.telemetryConfig = TelemetryConfig.toJSON(message.telemetryConfig);
    }
    if (message.scalingConfig !== undefined) {
      obj.scalingConfig = ScalingConfig.toJSON(message.scalingConfig);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Service>, I>>(base?: I): Service {
    return Service.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Service>, I>>(object: I): Service {
    const message = createBaseService();
    message.hiveMetastoreConfig = (object.hiveMetastoreConfig !== undefined && object.hiveMetastoreConfig !== null)
      ? HiveMetastoreConfig.fromPartial(object.hiveMetastoreConfig)
      : undefined;
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.network = object.network ?? "";
    message.endpointUri = object.endpointUri ?? "";
    message.port = object.port ?? 0;
    message.state = object.state ?? 0;
    message.stateMessage = object.stateMessage ?? "";
    message.artifactGcsUri = object.artifactGcsUri ?? "";
    message.tier = object.tier ?? 0;
    message.maintenanceWindow = (object.maintenanceWindow !== undefined && object.maintenanceWindow !== null)
      ? MaintenanceWindow.fromPartial(object.maintenanceWindow)
      : undefined;
    message.uid = object.uid ?? "";
    message.metadataManagementActivity =
      (object.metadataManagementActivity !== undefined && object.metadataManagementActivity !== null)
        ? MetadataManagementActivity.fromPartial(object.metadataManagementActivity)
        : undefined;
    message.releaseChannel = object.releaseChannel ?? 0;
    message.encryptionConfig = (object.encryptionConfig !== undefined && object.encryptionConfig !== null)
      ? EncryptionConfig.fromPartial(object.encryptionConfig)
      : undefined;
    message.networkConfig = (object.networkConfig !== undefined && object.networkConfig !== null)
      ? NetworkConfig.fromPartial(object.networkConfig)
      : undefined;
    message.databaseType = object.databaseType ?? 0;
    message.telemetryConfig = (object.telemetryConfig !== undefined && object.telemetryConfig !== null)
      ? TelemetryConfig.fromPartial(object.telemetryConfig)
      : undefined;
    message.scalingConfig = (object.scalingConfig !== undefined && object.scalingConfig !== null)
      ? ScalingConfig.fromPartial(object.scalingConfig)
      : undefined;
    return message;
  },
};

function createBaseService_LabelsEntry(): Service_LabelsEntry {
  return { key: "", value: "" };
}

export const Service_LabelsEntry: MessageFns<Service_LabelsEntry> = {
  encode(message: Service_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Service_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Service_LabelsEntry>, I>>(base?: I): Service_LabelsEntry {
    return Service_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Service_LabelsEntry>, I>>(object: I): Service_LabelsEntry {
    const message = createBaseService_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseMaintenanceWindow(): MaintenanceWindow {
  return { hourOfDay: undefined, dayOfWeek: 0 };
}

export const MaintenanceWindow: MessageFns<MaintenanceWindow> = {
  encode(message: MaintenanceWindow, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.hourOfDay !== undefined) {
      Int32Value.encode({ value: message.hourOfDay! }, writer.uint32(10).fork()).join();
    }
    if (message.dayOfWeek !== 0) {
      writer.uint32(16).int32(message.dayOfWeek);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MaintenanceWindow {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMaintenanceWindow();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.hourOfDay = Int32Value.decode(reader, reader.uint32()).value;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.dayOfWeek = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MaintenanceWindow {
    return {
      hourOfDay: isSet(object.hourOfDay) ? Number(object.hourOfDay) : undefined,
      dayOfWeek: isSet(object.dayOfWeek) ? dayOfWeekFromJSON(object.dayOfWeek) : 0,
    };
  },

  toJSON(message: MaintenanceWindow): unknown {
    const obj: any = {};
    if (message.hourOfDay !== undefined) {
      obj.hourOfDay = message.hourOfDay;
    }
    if (message.dayOfWeek !== 0) {
      obj.dayOfWeek = dayOfWeekToJSON(message.dayOfWeek);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MaintenanceWindow>, I>>(base?: I): MaintenanceWindow {
    return MaintenanceWindow.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MaintenanceWindow>, I>>(object: I): MaintenanceWindow {
    const message = createBaseMaintenanceWindow();
    message.hourOfDay = object.hourOfDay ?? undefined;
    message.dayOfWeek = object.dayOfWeek ?? 0;
    return message;
  },
};

function createBaseHiveMetastoreConfig(): HiveMetastoreConfig {
  return { version: "", configOverrides: {}, kerberosConfig: undefined, auxiliaryVersions: {} };
}

export const HiveMetastoreConfig: MessageFns<HiveMetastoreConfig> = {
  encode(message: HiveMetastoreConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    Object.entries(message.configOverrides).forEach(([key, value]) => {
      HiveMetastoreConfig_ConfigOverridesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.kerberosConfig !== undefined) {
      KerberosConfig.encode(message.kerberosConfig, writer.uint32(26).fork()).join();
    }
    Object.entries(message.auxiliaryVersions).forEach(([key, value]) => {
      HiveMetastoreConfig_AuxiliaryVersionsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          const entry2 = HiveMetastoreConfig_ConfigOverridesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.configOverrides[entry2.key] = entry2.value;
          }
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.kerberosConfig = KerberosConfig.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = HiveMetastoreConfig_AuxiliaryVersionsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.auxiliaryVersions[entry5.key] = entry5.value;
          }
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      configOverrides: isObject(object.configOverrides)
        ? Object.entries(object.configOverrides).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      kerberosConfig: isSet(object.kerberosConfig) ? KerberosConfig.fromJSON(object.kerberosConfig) : undefined,
      auxiliaryVersions: isObject(object.auxiliaryVersions)
        ? Object.entries(object.auxiliaryVersions).reduce<{ [key: string]: AuxiliaryVersionConfig }>(
          (acc, [key, value]) => {
            acc[key] = AuxiliaryVersionConfig.fromJSON(value);
            return acc;
          },
          {},
        )
        : {},
    };
  },

  toJSON(message: HiveMetastoreConfig): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.configOverrides) {
      const entries = Object.entries(message.configOverrides);
      if (entries.length > 0) {
        obj.configOverrides = {};
        entries.forEach(([k, v]) => {
          obj.configOverrides[k] = v;
        });
      }
    }
    if (message.kerberosConfig !== undefined) {
      obj.kerberosConfig = KerberosConfig.toJSON(message.kerberosConfig);
    }
    if (message.auxiliaryVersions) {
      const entries = Object.entries(message.auxiliaryVersions);
      if (entries.length > 0) {
        obj.auxiliaryVersions = {};
        entries.forEach(([k, v]) => {
          obj.auxiliaryVersions[k] = AuxiliaryVersionConfig.toJSON(v);
        });
      }
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<HiveMetastoreConfig>, I>>(base?: I): HiveMetastoreConfig {
    return HiveMetastoreConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<HiveMetastoreConfig>, I>>(object: I): HiveMetastoreConfig {
    const message = createBaseHiveMetastoreConfig();
    message.version = object.version ?? "";
    message.configOverrides = Object.entries(object.configOverrides ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.kerberosConfig = (object.kerberosConfig !== undefined && object.kerberosConfig !== null)
      ? KerberosConfig.fromPartial(object.kerberosConfig)
      : undefined;
    message.auxiliaryVersions = Object.entries(object.auxiliaryVersions ?? {}).reduce<
      { [key: string]: AuxiliaryVersionConfig }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = AuxiliaryVersionConfig.fromPartial(value);
      }
      return acc;
    }, {});
    return message;
  },
};

function createBaseHiveMetastoreConfig_ConfigOverridesEntry(): HiveMetastoreConfig_ConfigOverridesEntry {
  return { key: "", value: "" };
}

export const HiveMetastoreConfig_ConfigOverridesEntry: MessageFns<HiveMetastoreConfig_ConfigOverridesEntry> = {
  encode(message: HiveMetastoreConfig_ConfigOverridesEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig_ConfigOverridesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig_ConfigOverridesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig_ConfigOverridesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: HiveMetastoreConfig_ConfigOverridesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<HiveMetastoreConfig_ConfigOverridesEntry>, I>>(
    base?: I,
  ): HiveMetastoreConfig_ConfigOverridesEntry {
    return HiveMetastoreConfig_ConfigOverridesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<HiveMetastoreConfig_ConfigOverridesEntry>, I>>(
    object: I,
  ): HiveMetastoreConfig_ConfigOverridesEntry {
    const message = createBaseHiveMetastoreConfig_ConfigOverridesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry(): HiveMetastoreConfig_AuxiliaryVersionsEntry {
  return { key: "", value: undefined };
}

export const HiveMetastoreConfig_AuxiliaryVersionsEntry: MessageFns<HiveMetastoreConfig_AuxiliaryVersionsEntry> = {
  encode(message: HiveMetastoreConfig_AuxiliaryVersionsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== undefined) {
      AuxiliaryVersionConfig.encode(message.value, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = AuxiliaryVersionConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? AuxiliaryVersionConfig.fromJSON(object.value) : undefined,
    };
  },

  toJSON(message: HiveMetastoreConfig_AuxiliaryVersionsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== undefined) {
      obj.value = AuxiliaryVersionConfig.toJSON(message.value);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<HiveMetastoreConfig_AuxiliaryVersionsEntry>, I>>(
    base?: I,
  ): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    return HiveMetastoreConfig_AuxiliaryVersionsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<HiveMetastoreConfig_AuxiliaryVersionsEntry>, I>>(
    object: I,
  ): HiveMetastoreConfig_AuxiliaryVersionsEntry {
    const message = createBaseHiveMetastoreConfig_AuxiliaryVersionsEntry();
    message.key = object.key ?? "";
    message.value = (object.value !== undefined && object.value !== null)
      ? AuxiliaryVersionConfig.fromPartial(object.value)
      : undefined;
    return message;
  },
};

function createBaseKerberosConfig(): KerberosConfig {
  return { keytab: undefined, principal: "", krb5ConfigGcsUri: "" };
}

export const KerberosConfig: MessageFns<KerberosConfig> = {
  encode(message: KerberosConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.keytab !== undefined) {
      Secret.encode(message.keytab, writer.uint32(10).fork()).join();
    }
    if (message.principal !== "") {
      writer.uint32(18).string(message.principal);
    }
    if (message.krb5ConfigGcsUri !== "") {
      writer.uint32(26).string(message.krb5ConfigGcsUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): KerberosConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseKerberosConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.keytab = Secret.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.principal = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.krb5ConfigGcsUri = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): KerberosConfig {
    return {
      keytab: isSet(object.keytab) ? Secret.fromJSON(object.keytab) : undefined,
      principal: isSet(object.principal) ? globalThis.String(object.principal) : "",
      krb5ConfigGcsUri: isSet(object.krb5ConfigGcsUri) ? globalThis.String(object.krb5ConfigGcsUri) : "",
    };
  },

  toJSON(message: KerberosConfig): unknown {
    const obj: any = {};
    if (message.keytab !== undefined) {
      obj.keytab = Secret.toJSON(message.keytab);
    }
    if (message.principal !== "") {
      obj.principal = message.principal;
    }
    if (message.krb5ConfigGcsUri !== "") {
      obj.krb5ConfigGcsUri = message.krb5ConfigGcsUri;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<KerberosConfig>, I>>(base?: I): KerberosConfig {
    return KerberosConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<KerberosConfig>, I>>(object: I): KerberosConfig {
    const message = createBaseKerberosConfig();
    message.keytab = (object.keytab !== undefined && object.keytab !== null)
      ? Secret.fromPartial(object.keytab)
      : undefined;
    message.principal = object.principal ?? "";
    message.krb5ConfigGcsUri = object.krb5ConfigGcsUri ?? "";
    return message;
  },
};

function createBaseSecret(): Secret {
  return { cloudSecret: undefined };
}

export const Secret: MessageFns<Secret> = {
  encode(message: Secret, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cloudSecret !== undefined) {
      writer.uint32(18).string(message.cloudSecret);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Secret {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSecret();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cloudSecret = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Secret {
    return { cloudSecret: isSet(object.cloudSecret) ? globalThis.String(object.cloudSecret) : undefined };
  },

  toJSON(message: Secret): unknown {
    const obj: any = {};
    if (message.cloudSecret !== undefined) {
      obj.cloudSecret = message.cloudSecret;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Secret>, I>>(base?: I): Secret {
    return Secret.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Secret>, I>>(object: I): Secret {
    const message = createBaseSecret();
    message.cloudSecret = object.cloudSecret ?? undefined;
    return message;
  },
};

function createBaseEncryptionConfig(): EncryptionConfig {
  return { kmsKey: "" };
}

export const EncryptionConfig: MessageFns<EncryptionConfig> = {
  encode(message: EncryptionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.kmsKey !== "") {
      writer.uint32(10).string(message.kmsKey);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): EncryptionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseEncryptionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.kmsKey = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): EncryptionConfig {
    return { kmsKey: isSet(object.kmsKey) ? globalThis.String(object.kmsKey) : "" };
  },

  toJSON(message: EncryptionConfig): unknown {
    const obj: any = {};
    if (message.kmsKey !== "") {
      obj.kmsKey = message.kmsKey;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<EncryptionConfig>, I>>(base?: I): EncryptionConfig {
    return EncryptionConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<EncryptionConfig>, I>>(object: I): EncryptionConfig {
    const message = createBaseEncryptionConfig();
    message.kmsKey = object.kmsKey ?? "";
    return message;
  },
};

function createBaseAuxiliaryVersionConfig(): AuxiliaryVersionConfig {
  return { version: "", configOverrides: {}, networkConfig: undefined };
}

export const AuxiliaryVersionConfig: MessageFns<AuxiliaryVersionConfig> = {
  encode(message: AuxiliaryVersionConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    Object.entries(message.configOverrides).forEach(([key, value]) => {
      AuxiliaryVersionConfig_ConfigOverridesEntry.encode({ key: key as any, value }, writer.uint32(18).fork()).join();
    });
    if (message.networkConfig !== undefined) {
      NetworkConfig.encode(message.networkConfig, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AuxiliaryVersionConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAuxiliaryVersionConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          const entry2 = AuxiliaryVersionConfig_ConfigOverridesEntry.decode(reader, reader.uint32());
          if (entry2.value !== undefined) {
            message.configOverrides[entry2.key] = entry2.value;
          }
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.networkConfig = NetworkConfig.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AuxiliaryVersionConfig {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      configOverrides: isObject(object.configOverrides)
        ? Object.entries(object.configOverrides).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      networkConfig: isSet(object.networkConfig) ? NetworkConfig.fromJSON(object.networkConfig) : undefined,
    };
  },

  toJSON(message: AuxiliaryVersionConfig): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.configOverrides) {
      const entries = Object.entries(message.configOverrides);
      if (entries.length > 0) {
        obj.configOverrides = {};
        entries.forEach(([k, v]) => {
          obj.configOverrides[k] = v;
        });
      }
    }
    if (message.networkConfig !== undefined) {
      obj.networkConfig = NetworkConfig.toJSON(message.networkConfig);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AuxiliaryVersionConfig>, I>>(base?: I): AuxiliaryVersionConfig {
    return AuxiliaryVersionConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AuxiliaryVersionConfig>, I>>(object: I): AuxiliaryVersionConfig {
    const message = createBaseAuxiliaryVersionConfig();
    message.version = object.version ?? "";
    message.configOverrides = Object.entries(object.configOverrides ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.networkConfig = (object.networkConfig !== undefined && object.networkConfig !== null)
      ? NetworkConfig.fromPartial(object.networkConfig)
      : undefined;
    return message;
  },
};

function createBaseAuxiliaryVersionConfig_ConfigOverridesEntry(): AuxiliaryVersionConfig_ConfigOverridesEntry {
  return { key: "", value: "" };
}

export const AuxiliaryVersionConfig_ConfigOverridesEntry: MessageFns<AuxiliaryVersionConfig_ConfigOverridesEntry> = {
  encode(
    message: AuxiliaryVersionConfig_ConfigOverridesEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AuxiliaryVersionConfig_ConfigOverridesEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAuxiliaryVersionConfig_ConfigOverridesEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AuxiliaryVersionConfig_ConfigOverridesEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AuxiliaryVersionConfig_ConfigOverridesEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AuxiliaryVersionConfig_ConfigOverridesEntry>, I>>(
    base?: I,
  ): AuxiliaryVersionConfig_ConfigOverridesEntry {
    return AuxiliaryVersionConfig_ConfigOverridesEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AuxiliaryVersionConfig_ConfigOverridesEntry>, I>>(
    object: I,
  ): AuxiliaryVersionConfig_ConfigOverridesEntry {
    const message = createBaseAuxiliaryVersionConfig_ConfigOverridesEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseNetworkConfig(): NetworkConfig {
  return { consumers: [] };
}

export const NetworkConfig: MessageFns<NetworkConfig> = {
  encode(message: NetworkConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.consumers) {
      NetworkConfig_Consumer.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NetworkConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetworkConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.consumers.push(NetworkConfig_Consumer.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NetworkConfig {
    return {
      consumers: globalThis.Array.isArray(object?.consumers)
        ? object.consumers.map((e: any) => NetworkConfig_Consumer.fromJSON(e))
        : [],
    };
  },

  toJSON(message: NetworkConfig): unknown {
    const obj: any = {};
    if (message.consumers?.length) {
      obj.consumers = message.consumers.map((e) => NetworkConfig_Consumer.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NetworkConfig>, I>>(base?: I): NetworkConfig {
    return NetworkConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NetworkConfig>, I>>(object: I): NetworkConfig {
    const message = createBaseNetworkConfig();
    message.consumers = object.consumers?.map((e) => NetworkConfig_Consumer.fromPartial(e)) || [];
    return message;
  },
};

function createBaseNetworkConfig_Consumer(): NetworkConfig_Consumer {
  return { subnetwork: undefined, endpointUri: "" };
}

export const NetworkConfig_Consumer: MessageFns<NetworkConfig_Consumer> = {
  encode(message: NetworkConfig_Consumer, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.subnetwork !== undefined) {
      writer.uint32(10).string(message.subnetwork);
    }
    if (message.endpointUri !== "") {
      writer.uint32(26).string(message.endpointUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NetworkConfig_Consumer {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetworkConfig_Consumer();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.subnetwork = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.endpointUri = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NetworkConfig_Consumer {
    return {
      subnetwork: isSet(object.subnetwork) ? globalThis.String(object.subnetwork) : undefined,
      endpointUri: isSet(object.endpointUri) ? globalThis.String(object.endpointUri) : "",
    };
  },

  toJSON(message: NetworkConfig_Consumer): unknown {
    const obj: any = {};
    if (message.subnetwork !== undefined) {
      obj.subnetwork = message.subnetwork;
    }
    if (message.endpointUri !== "") {
      obj.endpointUri = message.endpointUri;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NetworkConfig_Consumer>, I>>(base?: I): NetworkConfig_Consumer {
    return NetworkConfig_Consumer.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NetworkConfig_Consumer>, I>>(object: I): NetworkConfig_Consumer {
    const message = createBaseNetworkConfig_Consumer();
    message.subnetwork = object.subnetwork ?? undefined;
    message.endpointUri = object.endpointUri ?? "";
    return message;
  },
};

function createBaseTelemetryConfig(): TelemetryConfig {
  return { logFormat: 0 };
}

export const TelemetryConfig: MessageFns<TelemetryConfig> = {
  encode(message: TelemetryConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.logFormat !== 0) {
      writer.uint32(8).int32(message.logFormat);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TelemetryConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTelemetryConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.logFormat = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TelemetryConfig {
    return { logFormat: isSet(object.logFormat) ? telemetryConfig_LogFormatFromJSON(object.logFormat) : 0 };
  },

  toJSON(message: TelemetryConfig): unknown {
    const obj: any = {};
    if (message.logFormat !== 0) {
      obj.logFormat = telemetryConfig_LogFormatToJSON(message.logFormat);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TelemetryConfig>, I>>(base?: I): TelemetryConfig {
    return TelemetryConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TelemetryConfig>, I>>(object: I): TelemetryConfig {
    const message = createBaseTelemetryConfig();
    message.logFormat = object.logFormat ?? 0;
    return message;
  },
};

function createBaseMetadataManagementActivity(): MetadataManagementActivity {
  return { metadataExports: [], restores: [] };
}

export const MetadataManagementActivity: MessageFns<MetadataManagementActivity> = {
  encode(message: MetadataManagementActivity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.metadataExports) {
      MetadataExport.encode(v!, writer.uint32(10).fork()).join();
    }
    for (const v of message.restores) {
      Restore.encode(v!, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataManagementActivity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataManagementActivity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.metadataExports.push(MetadataExport.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.restores.push(Restore.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataManagementActivity {
    return {
      metadataExports: globalThis.Array.isArray(object?.metadataExports)
        ? object.metadataExports.map((e: any) => MetadataExport.fromJSON(e))
        : [],
      restores: globalThis.Array.isArray(object?.restores) ? object.restores.map((e: any) => Restore.fromJSON(e)) : [],
    };
  },

  toJSON(message: MetadataManagementActivity): unknown {
    const obj: any = {};
    if (message.metadataExports?.length) {
      obj.metadataExports = message.metadataExports.map((e) => MetadataExport.toJSON(e));
    }
    if (message.restores?.length) {
      obj.restores = message.restores.map((e) => Restore.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MetadataManagementActivity>, I>>(base?: I): MetadataManagementActivity {
    return MetadataManagementActivity.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MetadataManagementActivity>, I>>(object: I): MetadataManagementActivity {
    const message = createBaseMetadataManagementActivity();
    message.metadataExports = object.metadataExports?.map((e) => MetadataExport.fromPartial(e)) || [];
    message.restores = object.restores?.map((e) => Restore.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMetadataImport(): MetadataImport {
  return {
    databaseDump: undefined,
    name: "",
    description: "",
    createTime: undefined,
    updateTime: undefined,
    endTime: undefined,
    state: 0,
  };
}

export const MetadataImport: MessageFns<MetadataImport> = {
  encode(message: MetadataImport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.databaseDump !== undefined) {
      MetadataImport_DatabaseDump.encode(message.databaseDump, writer.uint32(50).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.description !== "") {
      writer.uint32(18).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(26).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(34).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(58).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataImport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataImport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.databaseDump = MetadataImport_DatabaseDump.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataImport {
    return {
      databaseDump: isSet(object.databaseDump) ? MetadataImport_DatabaseDump.fromJSON(object.databaseDump) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? metadataImport_StateFromJSON(object.state) : 0,
    };
  },

  toJSON(message: MetadataImport): unknown {
    const obj: any = {};
    if (message.databaseDump !== undefined) {
      obj.databaseDump = MetadataImport_DatabaseDump.toJSON(message.databaseDump);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = metadataImport_StateToJSON(message.state);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MetadataImport>, I>>(base?: I): MetadataImport {
    return MetadataImport.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MetadataImport>, I>>(object: I): MetadataImport {
    const message = createBaseMetadataImport();
    message.databaseDump = (object.databaseDump !== undefined && object.databaseDump !== null)
      ? MetadataImport_DatabaseDump.fromPartial(object.databaseDump)
      : undefined;
    message.name = object.name ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    return message;
  },
};

function createBaseMetadataImport_DatabaseDump(): MetadataImport_DatabaseDump {
  return { databaseType: 0, gcsUri: "", sourceDatabase: "", type: 0 };
}

export const MetadataImport_DatabaseDump: MessageFns<MetadataImport_DatabaseDump> = {
  encode(message: MetadataImport_DatabaseDump, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.databaseType !== 0) {
      writer.uint32(8).int32(message.databaseType);
    }
    if (message.gcsUri !== "") {
      writer.uint32(18).string(message.gcsUri);
    }
    if (message.sourceDatabase !== "") {
      writer.uint32(26).string(message.sourceDatabase);
    }
    if (message.type !== 0) {
      writer.uint32(32).int32(message.type);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataImport_DatabaseDump {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataImport_DatabaseDump();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.databaseType = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.gcsUri = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.sourceDatabase = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataImport_DatabaseDump {
    return {
      databaseType: isSet(object.databaseType)
        ? metadataImport_DatabaseDump_DatabaseTypeFromJSON(object.databaseType)
        : 0,
      gcsUri: isSet(object.gcsUri) ? globalThis.String(object.gcsUri) : "",
      sourceDatabase: isSet(object.sourceDatabase) ? globalThis.String(object.sourceDatabase) : "",
      type: isSet(object.type) ? databaseDumpSpec_TypeFromJSON(object.type) : 0,
    };
  },

  toJSON(message: MetadataImport_DatabaseDump): unknown {
    const obj: any = {};
    if (message.databaseType !== 0) {
      obj.databaseType = metadataImport_DatabaseDump_DatabaseTypeToJSON(message.databaseType);
    }
    if (message.gcsUri !== "") {
      obj.gcsUri = message.gcsUri;
    }
    if (message.sourceDatabase !== "") {
      obj.sourceDatabase = message.sourceDatabase;
    }
    if (message.type !== 0) {
      obj.type = databaseDumpSpec_TypeToJSON(message.type);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MetadataImport_DatabaseDump>, I>>(base?: I): MetadataImport_DatabaseDump {
    return MetadataImport_DatabaseDump.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MetadataImport_DatabaseDump>, I>>(object: I): MetadataImport_DatabaseDump {
    const message = createBaseMetadataImport_DatabaseDump();
    message.databaseType = object.databaseType ?? 0;
    message.gcsUri = object.gcsUri ?? "";
    message.sourceDatabase = object.sourceDatabase ?? "";
    message.type = object.type ?? 0;
    return message;
  },
};

function createBaseMetadataExport(): MetadataExport {
  return { destinationGcsUri: undefined, startTime: undefined, endTime: undefined, state: 0, databaseDumpType: 0 };
}

export const MetadataExport: MessageFns<MetadataExport> = {
  encode(message: MetadataExport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.destinationGcsUri !== undefined) {
      writer.uint32(34).string(message.destinationGcsUri);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.databaseDumpType !== 0) {
      writer.uint32(40).int32(message.databaseDumpType);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataExport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataExport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.destinationGcsUri = reader.string();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.databaseDumpType = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataExport {
    return {
      destinationGcsUri: isSet(object.destinationGcsUri) ? globalThis.String(object.destinationGcsUri) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? metadataExport_StateFromJSON(object.state) : 0,
      databaseDumpType: isSet(object.databaseDumpType) ? databaseDumpSpec_TypeFromJSON(object.databaseDumpType) : 0,
    };
  },

  toJSON(message: MetadataExport): unknown {
    const obj: any = {};
    if (message.destinationGcsUri !== undefined) {
      obj.destinationGcsUri = message.destinationGcsUri;
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = metadataExport_StateToJSON(message.state);
    }
    if (message.databaseDumpType !== 0) {
      obj.databaseDumpType = databaseDumpSpec_TypeToJSON(message.databaseDumpType);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MetadataExport>, I>>(base?: I): MetadataExport {
    return MetadataExport.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MetadataExport>, I>>(object: I): MetadataExport {
    const message = createBaseMetadataExport();
    message.destinationGcsUri = object.destinationGcsUri ?? undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.databaseDumpType = object.databaseDumpType ?? 0;
    return message;
  },
};

function createBaseBackup(): Backup {
  return {
    name: "",
    createTime: undefined,
    endTime: undefined,
    state: 0,
    serviceRevision: undefined,
    description: "",
    restoringServices: [],
  };
}

export const Backup: MessageFns<Backup> = {
  encode(message: Backup, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(26).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.serviceRevision !== undefined) {
      Service.encode(message.serviceRevision, writer.uint32(42).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(50).string(message.description);
    }
    for (const v of message.restoringServices) {
      writer.uint32(58).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Backup {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.serviceRevision = Service.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.restoringServices.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Backup {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? backup_StateFromJSON(object.state) : 0,
      serviceRevision: isSet(object.serviceRevision) ? Service.fromJSON(object.serviceRevision) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      restoringServices: globalThis.Array.isArray(object?.restoringServices)
        ? object.restoringServices.map((e: any) => globalThis.String(e))
        : [],
    };
  },

  toJSON(message: Backup): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = backup_StateToJSON(message.state);
    }
    if (message.serviceRevision !== undefined) {
      obj.serviceRevision = Service.toJSON(message.serviceRevision);
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.restoringServices?.length) {
      obj.restoringServices = message.restoringServices;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Backup>, I>>(base?: I): Backup {
    return Backup.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Backup>, I>>(object: I): Backup {
    const message = createBaseBackup();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.serviceRevision = (object.serviceRevision !== undefined && object.serviceRevision !== null)
      ? Service.fromPartial(object.serviceRevision)
      : undefined;
    message.description = object.description ?? "";
    message.restoringServices = object.restoringServices?.map((e) => e) || [];
    return message;
  },
};

function createBaseRestore(): Restore {
  return { startTime: undefined, endTime: undefined, state: 0, backup: "", type: 0, details: "" };
}

export const Restore: MessageFns<Restore> = {
  encode(message: Restore, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.backup !== "") {
      writer.uint32(34).string(message.backup);
    }
    if (message.type !== 0) {
      writer.uint32(40).int32(message.type);
    }
    if (message.details !== "") {
      writer.uint32(50).string(message.details);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Restore {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseRestore();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.backup = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.details = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Restore {
    return {
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      state: isSet(object.state) ? restore_StateFromJSON(object.state) : 0,
      backup: isSet(object.backup) ? globalThis.String(object.backup) : "",
      type: isSet(object.type) ? restore_RestoreTypeFromJSON(object.type) : 0,
      details: isSet(object.details) ? globalThis.String(object.details) : "",
    };
  },

  toJSON(message: Restore): unknown {
    const obj: any = {};
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.state !== 0) {
      obj.state = restore_StateToJSON(message.state);
    }
    if (message.backup !== "") {
      obj.backup = message.backup;
    }
    if (message.type !== 0) {
      obj.type = restore_RestoreTypeToJSON(message.type);
    }
    if (message.details !== "") {
      obj.details = message.details;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Restore>, I>>(base?: I): Restore {
    return Restore.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Restore>, I>>(object: I): Restore {
    const message = createBaseRestore();
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.state = object.state ?? 0;
    message.backup = object.backup ?? "";
    message.type = object.type ?? 0;
    message.details = object.details ?? "";
    return message;
  },
};

function createBaseScalingConfig(): ScalingConfig {
  return { instanceSize: undefined, scalingFactor: undefined };
}

export const ScalingConfig: MessageFns<ScalingConfig> = {
  encode(message: ScalingConfig, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instanceSize !== undefined) {
      writer.uint32(8).int32(message.instanceSize);
    }
    if (message.scalingFactor !== undefined) {
      writer.uint32(21).float(message.scalingFactor);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ScalingConfig {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseScalingConfig();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.instanceSize = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 21) {
            break;
          }

          message.scalingFactor = reader.float();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ScalingConfig {
    return {
      instanceSize: isSet(object.instanceSize) ? scalingConfig_InstanceSizeFromJSON(object.instanceSize) : undefined,
      scalingFactor: isSet(object.scalingFactor) ? globalThis.Number(object.scalingFactor) : undefined,
    };
  },

  toJSON(message: ScalingConfig): unknown {
    const obj: any = {};
    if (message.instanceSize !== undefined) {
      obj.instanceSize = scalingConfig_InstanceSizeToJSON(message.instanceSize);
    }
    if (message.scalingFactor !== undefined) {
      obj.scalingFactor = message.scalingFactor;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ScalingConfig>, I>>(base?: I): ScalingConfig {
    return ScalingConfig.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ScalingConfig>, I>>(object: I): ScalingConfig {
    const message = createBaseScalingConfig();
    message.instanceSize = object.instanceSize ?? undefined;
    message.scalingFactor = object.scalingFactor ?? undefined;
    return message;
  },
};

function createBaseDatabaseDumpSpec(): DatabaseDumpSpec {
  return {};
}

export const DatabaseDumpSpec: MessageFns<DatabaseDumpSpec> = {
  encode(_: DatabaseDumpSpec, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatabaseDumpSpec {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatabaseDumpSpec();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): DatabaseDumpSpec {
    return {};
  },

  toJSON(_: DatabaseDumpSpec): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<DatabaseDumpSpec>, I>>(base?: I): DatabaseDumpSpec {
    return DatabaseDumpSpec.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DatabaseDumpSpec>, I>>(_: I): DatabaseDumpSpec {
    const message = createBaseDatabaseDumpSpec();
    return message;
  },
};

function createBaseMetadataImportEventData(): MetadataImportEventData {
  return { payload: undefined };
}

export const MetadataImportEventData: MessageFns<MetadataImportEventData> = {
  encode(message: MetadataImportEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      MetadataImport.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MetadataImportEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMetadataImportEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = MetadataImport.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MetadataImportEventData {
    return { payload: isSet(object.payload) ? MetadataImport.fromJSON(object.payload) : undefined };
  },

  toJSON(message: MetadataImportEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = MetadataImport.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MetadataImportEventData>, I>>(base?: I): MetadataImportEventData {
    return MetadataImportEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MetadataImportEventData>, I>>(object: I): MetadataImportEventData {
    const message = createBaseMetadataImportEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? MetadataImport.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseFederationEventData(): FederationEventData {
  return { payload: undefined };
}

export const FederationEventData: MessageFns<FederationEventData> = {
  encode(message: FederationEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Federation.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): FederationEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFederationEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Federation.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): FederationEventData {
    return { payload: isSet(object.payload) ? Federation.fromJSON(object.payload) : undefined };
  },

  toJSON(message: FederationEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Federation.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<FederationEventData>, I>>(base?: I): FederationEventData {
    return FederationEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<FederationEventData>, I>>(object: I): FederationEventData {
    const message = createBaseFederationEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Federation.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseBackupEventData(): BackupEventData {
  return { payload: undefined };
}

export const BackupEventData: MessageFns<BackupEventData> = {
  encode(message: BackupEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Backup.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): BackupEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseBackupEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Backup.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): BackupEventData {
    return { payload: isSet(object.payload) ? Backup.fromJSON(object.payload) : undefined };
  },

  toJSON(message: BackupEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Backup.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<BackupEventData>, I>>(base?: I): BackupEventData {
    return BackupEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<BackupEventData>, I>>(object: I): BackupEventData {
    const message = createBaseBackupEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Backup.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseServiceEventData(): ServiceEventData {
  return { payload: undefined };
}

export const ServiceEventData: MessageFns<ServiceEventData> = {
  encode(message: ServiceEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Service.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Service.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceEventData {
    return { payload: isSet(object.payload) ? Service.fromJSON(object.payload) : undefined };
  },

  toJSON(message: ServiceEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Service.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ServiceEventData>, I>>(base?: I): ServiceEventData {
    return ServiceEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ServiceEventData>, I>>(object: I): ServiceEventData {
    const message = createBaseServiceEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Service.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
