// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/cloud/vmmigration/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { Duration } from "../../../../protobuf/duration";
import { Timestamp } from "../../../../protobuf/timestamp";
import { Help_Link, LocalizedMessage } from "../../../../rpc/error_details";
import { Status } from "../../../../rpc/status";

export const protobufPackage = "google.events.cloud.vmmigration.v1";

/** Types of disks supported for Compute Engine VM. */
export enum ComputeEngineDiskType {
  /** COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED - An unspecified disk type. Will be used as STANDARD. */
  COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED = 0,
  /** COMPUTE_ENGINE_DISK_TYPE_STANDARD - A Standard disk type. */
  COMPUTE_ENGINE_DISK_TYPE_STANDARD = 1,
  /** COMPUTE_ENGINE_DISK_TYPE_SSD - SSD hard disk type. */
  COMPUTE_ENGINE_DISK_TYPE_SSD = 2,
  /**
   * COMPUTE_ENGINE_DISK_TYPE_BALANCED - An alternative to SSD persistent disks that balance performance and
   * cost.
   */
  COMPUTE_ENGINE_DISK_TYPE_BALANCED = 3,
  UNRECOGNIZED = -1,
}

export function computeEngineDiskTypeFromJSON(object: any): ComputeEngineDiskType {
  switch (object) {
    case 0:
    case "COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED":
      return ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED;
    case 1:
    case "COMPUTE_ENGINE_DISK_TYPE_STANDARD":
      return ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_STANDARD;
    case 2:
    case "COMPUTE_ENGINE_DISK_TYPE_SSD":
      return ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_SSD;
    case 3:
    case "COMPUTE_ENGINE_DISK_TYPE_BALANCED":
      return ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_BALANCED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeEngineDiskType.UNRECOGNIZED;
  }
}

export function computeEngineDiskTypeToJSON(object: ComputeEngineDiskType): string {
  switch (object) {
    case ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED:
      return "COMPUTE_ENGINE_DISK_TYPE_UNSPECIFIED";
    case ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_STANDARD:
      return "COMPUTE_ENGINE_DISK_TYPE_STANDARD";
    case ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_SSD:
      return "COMPUTE_ENGINE_DISK_TYPE_SSD";
    case ComputeEngineDiskType.COMPUTE_ENGINE_DISK_TYPE_BALANCED:
      return "COMPUTE_ENGINE_DISK_TYPE_BALANCED";
    case ComputeEngineDiskType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Types of licenses used in OS adaptation. */
export enum ComputeEngineLicenseType {
  /** COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT - The license type is the default for the OS. */
  COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT = 0,
  /** COMPUTE_ENGINE_LICENSE_TYPE_PAYG - The license type is Pay As You Go license type. */
  COMPUTE_ENGINE_LICENSE_TYPE_PAYG = 1,
  /** COMPUTE_ENGINE_LICENSE_TYPE_BYOL - The license type is Bring Your Own License type. */
  COMPUTE_ENGINE_LICENSE_TYPE_BYOL = 2,
  UNRECOGNIZED = -1,
}

export function computeEngineLicenseTypeFromJSON(object: any): ComputeEngineLicenseType {
  switch (object) {
    case 0:
    case "COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT":
      return ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT;
    case 1:
    case "COMPUTE_ENGINE_LICENSE_TYPE_PAYG":
      return ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_PAYG;
    case 2:
    case "COMPUTE_ENGINE_LICENSE_TYPE_BYOL":
      return ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_BYOL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeEngineLicenseType.UNRECOGNIZED;
  }
}

export function computeEngineLicenseTypeToJSON(object: ComputeEngineLicenseType): string {
  switch (object) {
    case ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT:
      return "COMPUTE_ENGINE_LICENSE_TYPE_DEFAULT";
    case ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_PAYG:
      return "COMPUTE_ENGINE_LICENSE_TYPE_PAYG";
    case ComputeEngineLicenseType.COMPUTE_ENGINE_LICENSE_TYPE_BYOL:
      return "COMPUTE_ENGINE_LICENSE_TYPE_BYOL";
    case ComputeEngineLicenseType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Possible values for vm boot option. */
export enum ComputeEngineBootOption {
  /** COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED - The boot option is unknown. */
  COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED = 0,
  /** COMPUTE_ENGINE_BOOT_OPTION_EFI - The boot option is EFI. */
  COMPUTE_ENGINE_BOOT_OPTION_EFI = 1,
  /** COMPUTE_ENGINE_BOOT_OPTION_BIOS - The boot option is BIOS. */
  COMPUTE_ENGINE_BOOT_OPTION_BIOS = 2,
  UNRECOGNIZED = -1,
}

export function computeEngineBootOptionFromJSON(object: any): ComputeEngineBootOption {
  switch (object) {
    case 0:
    case "COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED":
      return ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED;
    case 1:
    case "COMPUTE_ENGINE_BOOT_OPTION_EFI":
      return ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_EFI;
    case 2:
    case "COMPUTE_ENGINE_BOOT_OPTION_BIOS":
      return ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_BIOS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeEngineBootOption.UNRECOGNIZED;
  }
}

export function computeEngineBootOptionToJSON(object: ComputeEngineBootOption): string {
  switch (object) {
    case ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED:
      return "COMPUTE_ENGINE_BOOT_OPTION_UNSPECIFIED";
    case ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_EFI:
      return "COMPUTE_ENGINE_BOOT_OPTION_EFI";
    case ComputeEngineBootOption.COMPUTE_ENGINE_BOOT_OPTION_BIOS:
      return "COMPUTE_ENGINE_BOOT_OPTION_BIOS";
    case ComputeEngineBootOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * ReplicationCycle contains information about the current replication cycle
 * status.
 */
export interface ReplicationCycle {
  /** The identifier of the ReplicationCycle. */
  name: string;
  /** The cycle's ordinal number. */
  cycleNumber: number;
  /** The time the replication cycle has started. */
  startTime?:
    | Date
    | undefined;
  /** The time the replication cycle has ended. */
  endTime?:
    | Date
    | undefined;
  /** The accumulated duration the replication cycle was paused. */
  totalPauseDuration?:
    | Duration
    | undefined;
  /**
   * The current progress in percentage of this cycle.
   * Was replaced by 'steps' field, which breaks down the cycle progression more
   * accurately.
   */
  progressPercent: number;
  /** The cycle's steps list representing its progress. */
  steps: CycleStep[];
  /** State of the ReplicationCycle. */
  state: ReplicationCycle_State;
  /** Provides details on the state of the cycle in case of an error. */
  error?:
    | Status
    | undefined;
  /** Output only. Warnings that occurred during the cycle. */
  warnings: MigrationWarning[];
}

/** Possible states of a replication cycle. */
export enum ReplicationCycle_State {
  /**
   * STATE_UNSPECIFIED - The state is unknown. This is used for API compatibility only and is not
   * used by the system.
   */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The replication cycle is running. */
  RUNNING = 1,
  /** PAUSED - The replication cycle is paused. */
  PAUSED = 2,
  /** FAILED - The replication cycle finished with errors. */
  FAILED = 3,
  /** SUCCEEDED - The replication cycle finished successfully. */
  SUCCEEDED = 4,
  UNRECOGNIZED = -1,
}

export function replicationCycle_StateFromJSON(object: any): ReplicationCycle_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return ReplicationCycle_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return ReplicationCycle_State.RUNNING;
    case 2:
    case "PAUSED":
      return ReplicationCycle_State.PAUSED;
    case 3:
    case "FAILED":
      return ReplicationCycle_State.FAILED;
    case 4:
    case "SUCCEEDED":
      return ReplicationCycle_State.SUCCEEDED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ReplicationCycle_State.UNRECOGNIZED;
  }
}

export function replicationCycle_StateToJSON(object: ReplicationCycle_State): string {
  switch (object) {
    case ReplicationCycle_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case ReplicationCycle_State.RUNNING:
      return "RUNNING";
    case ReplicationCycle_State.PAUSED:
      return "PAUSED";
    case ReplicationCycle_State.FAILED:
      return "FAILED";
    case ReplicationCycle_State.SUCCEEDED:
      return "SUCCEEDED";
    case ReplicationCycle_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** CycleStep holds information about a step progress. */
export interface CycleStep {
  /** Initializing replication step. */
  initializingReplication?:
    | InitializingReplicationStep
    | undefined;
  /** Replicating step. */
  replicating?:
    | ReplicatingStep
    | undefined;
  /** Post processing step. */
  postProcessing?:
    | PostProcessingStep
    | undefined;
  /** The time the cycle step has started. */
  startTime?:
    | Date
    | undefined;
  /** The time the cycle step has ended. */
  endTime?: Date | undefined;
}

/** InitializingReplicationStep contains specific step details. */
export interface InitializingReplicationStep {
}

/** ReplicatingStep contains specific step details. */
export interface ReplicatingStep {
  /** Total bytes to be handled in the step. */
  totalBytes: Long;
  /** Replicated bytes in the step. */
  replicatedBytes: Long;
  /**
   * The source disks replication rate for the last 2 minutes in bytes per
   * second.
   */
  lastTwoMinutesAverageBytesPerSecond: Long;
  /**
   * The source disks replication rate for the last 30 minutes in bytes per
   * second.
   */
  lastThirtyMinutesAverageBytesPerSecond: Long;
}

/** PostProcessingStep contains specific step details. */
export interface PostProcessingStep {
}

/** ReplicationSync contain information about the last replica sync to the cloud. */
export interface ReplicationSync {
  /**
   * The most updated snapshot created time in the source that finished
   * replication.
   */
  lastSyncTime?: Date | undefined;
}

/**
 * MigratingVm describes the VM that will be migrated from a Source environment
 * and its replication state.
 */
export interface MigratingVm {
  /** Details of the target VM in Compute Engine. */
  computeEngineTargetDefaults?:
    | ComputeEngineTargetDefaults
    | undefined;
  /** Output only. Details of the VM from an AWS source. */
  awsSourceVmDetails?:
    | AwsSourceVmDetails
    | undefined;
  /** Output only. The identifier of the MigratingVm. */
  name: string;
  /**
   * The unique ID of the VM in the source.
   * The VM's name in vSphere can be changed, so this is not the VM's name but
   * rather its moRef id. This id is of the form vm-<num>.
   */
  sourceVmId: string;
  /** The display name attached to the MigratingVm by the user. */
  displayName: string;
  /** The description attached to the migrating VM by the user. */
  description: string;
  /** The replication schedule policy. */
  policy?:
    | SchedulePolicy
    | undefined;
  /**
   * Output only. The time the migrating VM was created (this refers to this
   * resource and not to the time it was installed in the source).
   */
  createTime?:
    | Date
    | undefined;
  /** Output only. The last time the migrating VM resource was updated. */
  updateTime?:
    | Date
    | undefined;
  /**
   * Output only. The most updated snapshot created time in the source that
   * finished replication.
   */
  lastSync?:
    | ReplicationSync
    | undefined;
  /** Output only. State of the MigratingVm. */
  state: MigratingVm_State;
  /** Output only. The last time the migrating VM state was updated. */
  stateTime?:
    | Date
    | undefined;
  /** Output only. Details of the current running replication cycle. */
  currentSyncInfo?:
    | ReplicationCycle
    | undefined;
  /**
   * Output only. Details of the last replication cycle. This will be updated
   * whenever a replication cycle is finished and is not to be confused with
   * last_sync which is only updated on successful replication cycles.
   */
  lastReplicationCycle?:
    | ReplicationCycle
    | undefined;
  /**
   * Output only. The group this migrating vm is included in, if any. The group
   * is represented by the full path of the appropriate
   * [Group][google.cloud.vmmigration.v1.Group] resource.
   */
  group: string;
  /** The labels of the migrating VM. */
  labels: { [key: string]: string };
  /**
   * Output only. The recent [clone jobs][google.cloud.vmmigration.v1.CloneJob]
   * performed on the migrating VM. This field holds the vm's last completed
   * clone job and the vm's running clone job, if one exists.
   * Note: To have this field populated you need to explicitly request it via
   * the "view" parameter of the Get/List request.
   */
  recentCloneJobs: CloneJob[];
  /**
   * Output only. Provides details on the state of the Migrating VM in case of
   * an error in replication.
   */
  error?:
    | Status
    | undefined;
  /**
   * Output only. The recent cutover jobs performed on the migrating VM.
   * This field holds the vm's last completed cutover job and the vm's
   * running cutover job, if one exists.
   * Note: To have this field populated you need to explicitly request it via
   * the "view" parameter of the Get/List request.
   */
  recentCutoverJobs: CutoverJob[];
  /**
   * Output only. Provides details of future CutoverJobs of a MigratingVm.
   * Set to empty when cutover forecast is unavailable.
   */
  cutoverForecast?: CutoverForecast | undefined;
}

/** The possible values of the state/health of source VM. */
export enum MigratingVm_State {
  /** STATE_UNSPECIFIED - The state was not sampled by the health checks yet. */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The VM in the source is being verified. */
  PENDING = 1,
  /** READY - The source VM was verified, and it's ready to start replication. */
  READY = 2,
  /** FIRST_SYNC - Migration is going through the first sync cycle. */
  FIRST_SYNC = 3,
  /** ACTIVE - The replication is active, and it's running or scheduled to run. */
  ACTIVE = 4,
  /**
   * CUTTING_OVER - The source VM is being turned off, and a final replication is currently
   * running.
   */
  CUTTING_OVER = 7,
  /**
   * CUTOVER - The source VM was stopped and replicated. The replication is currently
   * paused.
   */
  CUTOVER = 8,
  /** FINAL_SYNC - A cutover job is active and replication cycle is running the final sync. */
  FINAL_SYNC = 9,
  /**
   * PAUSED - The replication was paused by the user and no cycles are scheduled to
   * run.
   */
  PAUSED = 10,
  /**
   * FINALIZING - The migrating VM is being finalized and migration resources are being
   * removed.
   */
  FINALIZING = 11,
  /**
   * FINALIZED - The replication process is done. The migrating VM is finalized and no
   * longer consumes billable resources.
   */
  FINALIZED = 12,
  /**
   * ERROR - The replication process encountered an unrecoverable error and was
   * aborted.
   */
  ERROR = 13,
  UNRECOGNIZED = -1,
}

export function migratingVm_StateFromJSON(object: any): MigratingVm_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return MigratingVm_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return MigratingVm_State.PENDING;
    case 2:
    case "READY":
      return MigratingVm_State.READY;
    case 3:
    case "FIRST_SYNC":
      return MigratingVm_State.FIRST_SYNC;
    case 4:
    case "ACTIVE":
      return MigratingVm_State.ACTIVE;
    case 7:
    case "CUTTING_OVER":
      return MigratingVm_State.CUTTING_OVER;
    case 8:
    case "CUTOVER":
      return MigratingVm_State.CUTOVER;
    case 9:
    case "FINAL_SYNC":
      return MigratingVm_State.FINAL_SYNC;
    case 10:
    case "PAUSED":
      return MigratingVm_State.PAUSED;
    case 11:
    case "FINALIZING":
      return MigratingVm_State.FINALIZING;
    case 12:
    case "FINALIZED":
      return MigratingVm_State.FINALIZED;
    case 13:
    case "ERROR":
      return MigratingVm_State.ERROR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigratingVm_State.UNRECOGNIZED;
  }
}

export function migratingVm_StateToJSON(object: MigratingVm_State): string {
  switch (object) {
    case MigratingVm_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case MigratingVm_State.PENDING:
      return "PENDING";
    case MigratingVm_State.READY:
      return "READY";
    case MigratingVm_State.FIRST_SYNC:
      return "FIRST_SYNC";
    case MigratingVm_State.ACTIVE:
      return "ACTIVE";
    case MigratingVm_State.CUTTING_OVER:
      return "CUTTING_OVER";
    case MigratingVm_State.CUTOVER:
      return "CUTOVER";
    case MigratingVm_State.FINAL_SYNC:
      return "FINAL_SYNC";
    case MigratingVm_State.PAUSED:
      return "PAUSED";
    case MigratingVm_State.FINALIZING:
      return "FINALIZING";
    case MigratingVm_State.FINALIZED:
      return "FINALIZED";
    case MigratingVm_State.ERROR:
      return "ERROR";
    case MigratingVm_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

export interface MigratingVm_LabelsEntry {
  key: string;
  value: string;
}

/** CutoverForecast holds information about future CutoverJobs of a MigratingVm. */
export interface CutoverForecast {
  /** Output only. Estimation of the CutoverJob duration. */
  estimatedCutoverJobDuration?: Duration | undefined;
}

/**
 * CloneJob describes the process of creating a clone of a
 * [MigratingVM][google.cloud.vmmigration.v1.MigratingVm] to the
 * requested target based on the latest successful uploaded snapshots.
 * While the migration cycles of a MigratingVm take place, it is possible to
 * verify the uploaded VM can be started in the cloud, by creating a clone. The
 * clone can be created without any downtime, and it is created using the latest
 * snapshots which are already in the cloud. The cloneJob is only responsible
 * for its work, not its products, which means once it is finished, it will
 * never touch the instance it created. It will only delete it in case of the
 * CloneJob being cancelled or upon failure to clone.
 */
export interface CloneJob {
  /** Output only. Details of the target VM in Compute Engine. */
  computeEngineTargetDetails?:
    | ComputeEngineTargetDetails
    | undefined;
  /**
   * Output only. The time the clone job was created (as an API call, not when
   * it was actually created in the target).
   */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time the clone job was ended. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The name of the clone. */
  name: string;
  /** Output only. State of the clone job. */
  state: CloneJob_State;
  /** Output only. The time the state was last updated. */
  stateTime?:
    | Date
    | undefined;
  /**
   * Output only. Provides details for the errors that led to the Clone Job's
   * state.
   */
  error?:
    | Status
    | undefined;
  /** Output only. The clone steps list representing its progress. */
  steps: CloneStep[];
}

/** Possible states of the clone job. */
export enum CloneJob_State {
  /**
   * STATE_UNSPECIFIED - The state is unknown. This is used for API compatibility only and is not
   * used by the system.
   */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The clone job has not yet started. */
  PENDING = 1,
  /** ACTIVE - The clone job is active and running. */
  ACTIVE = 2,
  /** FAILED - The clone job finished with errors. */
  FAILED = 3,
  /** SUCCEEDED - The clone job finished successfully. */
  SUCCEEDED = 4,
  /** CANCELLED - The clone job was cancelled. */
  CANCELLED = 5,
  /** CANCELLING - The clone job is being cancelled. */
  CANCELLING = 6,
  /** ADAPTING_OS - OS adaptation is running as part of the clone job to generate license. */
  ADAPTING_OS = 7,
  UNRECOGNIZED = -1,
}

export function cloneJob_StateFromJSON(object: any): CloneJob_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CloneJob_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return CloneJob_State.PENDING;
    case 2:
    case "ACTIVE":
      return CloneJob_State.ACTIVE;
    case 3:
    case "FAILED":
      return CloneJob_State.FAILED;
    case 4:
    case "SUCCEEDED":
      return CloneJob_State.SUCCEEDED;
    case 5:
    case "CANCELLED":
      return CloneJob_State.CANCELLED;
    case 6:
    case "CANCELLING":
      return CloneJob_State.CANCELLING;
    case 7:
    case "ADAPTING_OS":
      return CloneJob_State.ADAPTING_OS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CloneJob_State.UNRECOGNIZED;
  }
}

export function cloneJob_StateToJSON(object: CloneJob_State): string {
  switch (object) {
    case CloneJob_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CloneJob_State.PENDING:
      return "PENDING";
    case CloneJob_State.ACTIVE:
      return "ACTIVE";
    case CloneJob_State.FAILED:
      return "FAILED";
    case CloneJob_State.SUCCEEDED:
      return "SUCCEEDED";
    case CloneJob_State.CANCELLED:
      return "CANCELLED";
    case CloneJob_State.CANCELLING:
      return "CANCELLING";
    case CloneJob_State.ADAPTING_OS:
      return "ADAPTING_OS";
    case CloneJob_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** CloneStep holds information about the clone step progress. */
export interface CloneStep {
  /** Adapting OS step. */
  adaptingOs?:
    | AdaptingOSStep
    | undefined;
  /** Preparing VM disks step. */
  preparingVmDisks?:
    | PreparingVMDisksStep
    | undefined;
  /** Instantiating migrated VM step. */
  instantiatingMigratedVm?:
    | InstantiatingMigratedVMStep
    | undefined;
  /** The time the step has started. */
  startTime?:
    | Date
    | undefined;
  /** The time the step has ended. */
  endTime?: Date | undefined;
}

/** AdaptingOSStep contains specific step details. */
export interface AdaptingOSStep {
}

/** PreparingVMDisksStep contains specific step details. */
export interface PreparingVMDisksStep {
}

/** InstantiatingMigratedVMStep contains specific step details. */
export interface InstantiatingMigratedVMStep {
}

/**
 * CutoverJob message describes a cutover of a migrating VM. The CutoverJob is
 * the operation of shutting down the VM, creating a snapshot and
 * clonning the VM using the replicated snapshot.
 */
export interface CutoverJob {
  /** Output only. Details of the target VM in Compute Engine. */
  computeEngineTargetDetails?:
    | ComputeEngineTargetDetails
    | undefined;
  /**
   * Output only. The time the cutover job was created (as an API call, not when
   * it was actually created in the target).
   */
  createTime?:
    | Date
    | undefined;
  /** Output only. The time the cutover job had finished. */
  endTime?:
    | Date
    | undefined;
  /** Output only. The name of the cutover job. */
  name: string;
  /** Output only. State of the cutover job. */
  state: CutoverJob_State;
  /** Output only. The time the state was last updated. */
  stateTime?:
    | Date
    | undefined;
  /** Output only. The current progress in percentage of the cutover job. */
  progressPercent: number;
  /**
   * Output only. Provides details for the errors that led to the Cutover Job's
   * state.
   */
  error?:
    | Status
    | undefined;
  /**
   * Output only. A message providing possible extra details about the current
   * state.
   */
  stateMessage: string;
  /** Output only. The cutover steps list representing its progress. */
  steps: CutoverStep[];
}

/** Possible states of the cutover job. */
export enum CutoverJob_State {
  /**
   * STATE_UNSPECIFIED - The state is unknown. This is used for API compatibility only and is not
   * used by the system.
   */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The cutover job has not yet started. */
  PENDING = 1,
  /** FAILED - The cutover job finished with errors. */
  FAILED = 2,
  /** SUCCEEDED - The cutover job finished successfully. */
  SUCCEEDED = 3,
  /** CANCELLED - The cutover job was cancelled. */
  CANCELLED = 4,
  /** CANCELLING - The cutover job is being cancelled. */
  CANCELLING = 5,
  /** ACTIVE - The cutover job is active and running. */
  ACTIVE = 6,
  /** ADAPTING_OS - OS adaptation is running as part of the cutover job to generate license. */
  ADAPTING_OS = 7,
  UNRECOGNIZED = -1,
}

export function cutoverJob_StateFromJSON(object: any): CutoverJob_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return CutoverJob_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return CutoverJob_State.PENDING;
    case 2:
    case "FAILED":
      return CutoverJob_State.FAILED;
    case 3:
    case "SUCCEEDED":
      return CutoverJob_State.SUCCEEDED;
    case 4:
    case "CANCELLED":
      return CutoverJob_State.CANCELLED;
    case 5:
    case "CANCELLING":
      return CutoverJob_State.CANCELLING;
    case 6:
    case "ACTIVE":
      return CutoverJob_State.ACTIVE;
    case 7:
    case "ADAPTING_OS":
      return CutoverJob_State.ADAPTING_OS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return CutoverJob_State.UNRECOGNIZED;
  }
}

export function cutoverJob_StateToJSON(object: CutoverJob_State): string {
  switch (object) {
    case CutoverJob_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case CutoverJob_State.PENDING:
      return "PENDING";
    case CutoverJob_State.FAILED:
      return "FAILED";
    case CutoverJob_State.SUCCEEDED:
      return "SUCCEEDED";
    case CutoverJob_State.CANCELLED:
      return "CANCELLED";
    case CutoverJob_State.CANCELLING:
      return "CANCELLING";
    case CutoverJob_State.ACTIVE:
      return "ACTIVE";
    case CutoverJob_State.ADAPTING_OS:
      return "ADAPTING_OS";
    case CutoverJob_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** CutoverStep holds information about the cutover step progress. */
export interface CutoverStep {
  /** A replication cycle prior cutover step. */
  previousReplicationCycle?:
    | ReplicationCycle
    | undefined;
  /** Shutting down VM step. */
  shuttingDownSourceVm?:
    | ShuttingDownSourceVMStep
    | undefined;
  /** Final sync step. */
  finalSync?:
    | ReplicationCycle
    | undefined;
  /** Preparing VM disks step. */
  preparingVmDisks?:
    | PreparingVMDisksStep
    | undefined;
  /** Instantiating migrated VM step. */
  instantiatingMigratedVm?:
    | InstantiatingMigratedVMStep
    | undefined;
  /** The time the step has started. */
  startTime?:
    | Date
    | undefined;
  /** The time the step has ended. */
  endTime?: Date | undefined;
}

/** ShuttingDownSourceVMStep contains specific step details. */
export interface ShuttingDownSourceVMStep {
}

/**
 * Source message describes a specific vm migration Source resource. It contains
 * the source environment information.
 */
export interface Source {
  /** Vmware type source details. */
  vmware?:
    | VmwareSourceDetails
    | undefined;
  /** AWS type source details. */
  aws?:
    | AwsSourceDetails
    | undefined;
  /** Output only. The Source name. */
  name: string;
  /** Output only. The create time timestamp. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The update time timestamp. */
  updateTime?:
    | Date
    | undefined;
  /** The labels of the source. */
  labels: { [key: string]: string };
  /** User-provided description of the source. */
  description: string;
}

export interface Source_LabelsEntry {
  key: string;
  value: string;
}

/**
 * VmwareSourceDetails message describes a specific source details for the
 * vmware source type.
 */
export interface VmwareSourceDetails {
  /** The credentials username. */
  username: string;
  /** The ip address of the vcenter this Source represents. */
  vcenterIp: string;
  /** The thumbprint representing the certificate for the vcenter. */
  thumbprint: string;
  /** The hostname of the vcenter. */
  resolvedVcenterHost: string;
}

/**
 * AwsSourceDetails message describes a specific source details for the
 * AWS source type.
 */
export interface AwsSourceDetails {
  /** AWS Credentials using access key id and secret. */
  accessKeyCreds?:
    | AwsSourceDetails_AccessKeyCredentials
    | undefined;
  /** Immutable. The AWS region that the source VMs will be migrated from. */
  awsRegion: string;
  /** Output only. State of the source as determined by the health check. */
  state: AwsSourceDetails_State;
  /**
   * Output only. Provides details on the state of the Source in case of an
   * error.
   */
  error?:
    | Status
    | undefined;
  /** AWS resource tags to limit the scope of the source inventory. */
  inventoryTagList: AwsSourceDetails_Tag[];
  /**
   * AWS security group names to limit the scope of the source
   * inventory.
   */
  inventorySecurityGroupNames: string[];
  /**
   * User specified tags to add to every M2VM generated resource in AWS.
   * These tags will be set in addition to the default tags that are set as part
   * of the migration process. The tags must not begin with the reserved prefix
   * `m2vm`.
   */
  migrationResourcesUserTags: { [key: string]: string };
  /**
   * Output only. The source's public IP. All communication initiated by this
   * source will originate from this IP.
   */
  publicIp: string;
}

/** The possible values of the state. */
export enum AwsSourceDetails_State {
  /**
   * STATE_UNSPECIFIED - The state is unknown. This is used for API compatibility only and is not
   * used by the system.
   */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The state was not sampled by the health checks yet. */
  PENDING = 1,
  /**
   * FAILED - The source is available but might not be usable yet due to invalid
   * credentials or another reason.
   * The error message will contain further details.
   */
  FAILED = 2,
  /** ACTIVE - The source exists and its credentials were verified. */
  ACTIVE = 3,
  UNRECOGNIZED = -1,
}

export function awsSourceDetails_StateFromJSON(object: any): AwsSourceDetails_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return AwsSourceDetails_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return AwsSourceDetails_State.PENDING;
    case 2:
    case "FAILED":
      return AwsSourceDetails_State.FAILED;
    case 3:
    case "ACTIVE":
      return AwsSourceDetails_State.ACTIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsSourceDetails_State.UNRECOGNIZED;
  }
}

export function awsSourceDetails_StateToJSON(object: AwsSourceDetails_State): string {
  switch (object) {
    case AwsSourceDetails_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case AwsSourceDetails_State.PENDING:
      return "PENDING";
    case AwsSourceDetails_State.FAILED:
      return "FAILED";
    case AwsSourceDetails_State.ACTIVE:
      return "ACTIVE";
    case AwsSourceDetails_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Message describing AWS Credentials using access key id and secret. */
export interface AwsSourceDetails_AccessKeyCredentials {
  /** AWS access key ID. */
  accessKeyId: string;
}

/** Tag is an AWS tag representation. */
export interface AwsSourceDetails_Tag {
  /** Key of tag. */
  key: string;
  /** Value of tag. */
  value: string;
}

export interface AwsSourceDetails_MigrationResourcesUserTagsEntry {
  key: string;
  value: string;
}

/**
 * DatacenterConnector message describes a connector between the Source and
 * Google Cloud, which is installed on a vmware datacenter (an OVA vm installed
 * by the user) to connect the Datacenter to Google Cloud and support vm
 * migration data transfer.
 */
export interface DatacenterConnector {
  /**
   * Output only. The time the connector was created (as an API call, not when
   * it was actually installed).
   */
  createTime?:
    | Date
    | undefined;
  /** Output only. The last time the connector was updated with an API call. */
  updateTime?:
    | Date
    | undefined;
  /** Output only. The connector's name. */
  name: string;
  /**
   * Immutable. A unique key for this connector. This key is internal to the OVA
   * connector and is supplied with its creation during the registration process
   * and can not be modified.
   */
  registrationId: string;
  /**
   * The service account to use in the connector when communicating with the
   * cloud.
   */
  serviceAccount: string;
  /**
   * The version running in the DatacenterConnector. This is supplied by the OVA
   * connector during the registration process and can not be modified.
   */
  version: string;
  /**
   * Output only. The communication channel between the datacenter connector and
   * Google Cloud.
   */
  bucket: string;
  /**
   * Output only. State of the DatacenterConnector, as determined by the health
   * checks.
   */
  state: DatacenterConnector_State;
  /** Output only. The time the state was last set. */
  stateTime?:
    | Date
    | undefined;
  /**
   * Output only. Provides details on the state of the Datacenter Connector in
   * case of an error.
   */
  error?:
    | Status
    | undefined;
  /**
   * Output only. Appliance OVA version.
   * This is the OVA which is manually installed by the user and contains the
   * infrastructure for the automatically updatable components on the appliance.
   */
  applianceInfrastructureVersion: string;
  /**
   * Output only. Appliance last installed update bundle version.
   * This is the version of the automatically updatable components on the
   * appliance.
   */
  applianceSoftwareVersion: string;
  /** Output only. The available versions for updating this appliance. */
  availableVersions?:
    | AvailableUpdates
    | undefined;
  /** Output only. The status of the current / last upgradeAppliance operation. */
  upgradeStatus?: UpgradeStatus | undefined;
}

/** The possible values of the state. */
export enum DatacenterConnector_State {
  /**
   * STATE_UNSPECIFIED - The state is unknown. This is used for API compatibility only and is not
   * used by the system.
   */
  STATE_UNSPECIFIED = 0,
  /** PENDING - The state was not sampled by the health checks yet. */
  PENDING = 1,
  /** OFFLINE - The source was sampled by health checks and is not available. */
  OFFLINE = 2,
  /**
   * FAILED - The source is available but might not be usable yet due to unvalidated
   * credentials or another reason. The credentials referred to are the ones
   * to the Source. The error message will contain further details.
   */
  FAILED = 3,
  /** ACTIVE - The source exists and its credentials were verified. */
  ACTIVE = 4,
  UNRECOGNIZED = -1,
}

export function datacenterConnector_StateFromJSON(object: any): DatacenterConnector_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return DatacenterConnector_State.STATE_UNSPECIFIED;
    case 1:
    case "PENDING":
      return DatacenterConnector_State.PENDING;
    case 2:
    case "OFFLINE":
      return DatacenterConnector_State.OFFLINE;
    case 3:
    case "FAILED":
      return DatacenterConnector_State.FAILED;
    case 4:
    case "ACTIVE":
      return DatacenterConnector_State.ACTIVE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return DatacenterConnector_State.UNRECOGNIZED;
  }
}

export function datacenterConnector_StateToJSON(object: DatacenterConnector_State): string {
  switch (object) {
    case DatacenterConnector_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case DatacenterConnector_State.PENDING:
      return "PENDING";
    case DatacenterConnector_State.OFFLINE:
      return "OFFLINE";
    case DatacenterConnector_State.FAILED:
      return "FAILED";
    case DatacenterConnector_State.ACTIVE:
      return "ACTIVE";
    case DatacenterConnector_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** UpgradeStatus contains information about upgradeAppliance operation. */
export interface UpgradeStatus {
  /** The version to upgrade to. */
  version: string;
  /** The state of the upgradeAppliance operation. */
  state: UpgradeStatus_State;
  /** Provides details on the state of the upgrade operation in case of an error. */
  error?:
    | Status
    | undefined;
  /** The time the operation was started. */
  startTime?:
    | Date
    | undefined;
  /** The version from which we upgraded. */
  previousVersion: string;
}

/** The possible values of the state. */
export enum UpgradeStatus_State {
  /** STATE_UNSPECIFIED - The state was not sampled by the health checks yet. */
  STATE_UNSPECIFIED = 0,
  /** RUNNING - The upgrade has started. */
  RUNNING = 1,
  /** FAILED - The upgrade failed. */
  FAILED = 2,
  /** SUCCEEDED - The upgrade finished successfully. */
  SUCCEEDED = 3,
  UNRECOGNIZED = -1,
}

export function upgradeStatus_StateFromJSON(object: any): UpgradeStatus_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return UpgradeStatus_State.STATE_UNSPECIFIED;
    case 1:
    case "RUNNING":
      return UpgradeStatus_State.RUNNING;
    case 2:
    case "FAILED":
      return UpgradeStatus_State.FAILED;
    case 3:
    case "SUCCEEDED":
      return UpgradeStatus_State.SUCCEEDED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return UpgradeStatus_State.UNRECOGNIZED;
  }
}

export function upgradeStatus_StateToJSON(object: UpgradeStatus_State): string {
  switch (object) {
    case UpgradeStatus_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case UpgradeStatus_State.RUNNING:
      return "RUNNING";
    case UpgradeStatus_State.FAILED:
      return "FAILED";
    case UpgradeStatus_State.SUCCEEDED:
      return "SUCCEEDED";
    case UpgradeStatus_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Holds informatiom about the available versions for upgrade. */
export interface AvailableUpdates {
  /**
   * The newest deployable version of the appliance.
   * The current appliance can't be updated into this version, and the owner
   * must manually deploy this OVA to a new appliance.
   */
  newDeployableAppliance?:
    | ApplianceVersion
    | undefined;
  /**
   * The latest version for in place update.
   * The current appliance can be updated to this version using the API or m4c
   * CLI.
   */
  inPlaceUpdate?: ApplianceVersion | undefined;
}

/** Describes an appliance version. */
export interface ApplianceVersion {
  /** The appliance version. */
  version: string;
  /** A link for downloading the version. */
  uri: string;
  /** Determine whether it's critical to upgrade the appliance to this version. */
  critical: boolean;
  /** Link to a page that contains the version release notes. */
  releaseNotesUri: string;
}

/** VmwareVmDetails describes a VM in vCenter. */
export interface VmwareVmDetails {
  /**
   * The VM's id in the source (note that this is not the MigratingVm's id).
   * This is the moref id of the VM.
   */
  vmId: string;
  /** The id of the vCenter's datacenter this VM is contained in. */
  datacenterId: string;
  /** The descriptive name of the vCenter's datacenter this VM is contained in. */
  datacenterDescription: string;
  /** The unique identifier of the VM in vCenter. */
  uuid: string;
  /** The display name of the VM. Note that this is not necessarily unique. */
  displayName: string;
  /** The power state of the VM at the moment list was taken. */
  powerState: VmwareVmDetails_PowerState;
  /** The number of cpus in the VM. */
  cpuCount: number;
  /** The size of the memory of the VM in MB. */
  memoryMb: number;
  /** The number of disks the VM has. */
  diskCount: number;
  /** The total size of the storage allocated to the VM in MB. */
  committedStorageMb: Long;
  /**
   * The VM's OS. See for example
   * https://vdc-repo.vmware.com/vmwb-repository/dcr-public/da47f910-60ac-438b-8b9b-6122f4d14524/16b7274a-bf8b-4b4c-a05e-746f2aa93c8c/doc/vim.vm.GuestOsDescriptor.GuestOsIdentifier.html
   * for types of strings this might hold.
   */
  guestDescription: string;
  /** Output only. The VM Boot Option. */
  bootOption: VmwareVmDetails_BootOption;
}

/** Possible values for the power state of the VM. */
export enum VmwareVmDetails_PowerState {
  /** POWER_STATE_UNSPECIFIED - Power state is not specified. */
  POWER_STATE_UNSPECIFIED = 0,
  /** ON - The VM is turned ON. */
  ON = 1,
  /** OFF - The VM is turned OFF. */
  OFF = 2,
  /** SUSPENDED - The VM is suspended. This is similar to hibernation or sleep mode. */
  SUSPENDED = 3,
  UNRECOGNIZED = -1,
}

export function vmwareVmDetails_PowerStateFromJSON(object: any): VmwareVmDetails_PowerState {
  switch (object) {
    case 0:
    case "POWER_STATE_UNSPECIFIED":
      return VmwareVmDetails_PowerState.POWER_STATE_UNSPECIFIED;
    case 1:
    case "ON":
      return VmwareVmDetails_PowerState.ON;
    case 2:
    case "OFF":
      return VmwareVmDetails_PowerState.OFF;
    case 3:
    case "SUSPENDED":
      return VmwareVmDetails_PowerState.SUSPENDED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return VmwareVmDetails_PowerState.UNRECOGNIZED;
  }
}

export function vmwareVmDetails_PowerStateToJSON(object: VmwareVmDetails_PowerState): string {
  switch (object) {
    case VmwareVmDetails_PowerState.POWER_STATE_UNSPECIFIED:
      return "POWER_STATE_UNSPECIFIED";
    case VmwareVmDetails_PowerState.ON:
      return "ON";
    case VmwareVmDetails_PowerState.OFF:
      return "OFF";
    case VmwareVmDetails_PowerState.SUSPENDED:
      return "SUSPENDED";
    case VmwareVmDetails_PowerState.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Possible values for vm boot option. */
export enum VmwareVmDetails_BootOption {
  /** BOOT_OPTION_UNSPECIFIED - The boot option is unknown. */
  BOOT_OPTION_UNSPECIFIED = 0,
  /** EFI - The boot option is EFI. */
  EFI = 1,
  /** BIOS - The boot option is BIOS. */
  BIOS = 2,
  UNRECOGNIZED = -1,
}

export function vmwareVmDetails_BootOptionFromJSON(object: any): VmwareVmDetails_BootOption {
  switch (object) {
    case 0:
    case "BOOT_OPTION_UNSPECIFIED":
      return VmwareVmDetails_BootOption.BOOT_OPTION_UNSPECIFIED;
    case 1:
    case "EFI":
      return VmwareVmDetails_BootOption.EFI;
    case 2:
    case "BIOS":
      return VmwareVmDetails_BootOption.BIOS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return VmwareVmDetails_BootOption.UNRECOGNIZED;
  }
}

export function vmwareVmDetails_BootOptionToJSON(object: VmwareVmDetails_BootOption): string {
  switch (object) {
    case VmwareVmDetails_BootOption.BOOT_OPTION_UNSPECIFIED:
      return "BOOT_OPTION_UNSPECIFIED";
    case VmwareVmDetails_BootOption.EFI:
      return "EFI";
    case VmwareVmDetails_BootOption.BIOS:
      return "BIOS";
    case VmwareVmDetails_BootOption.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Utilization report details the utilization (CPU, memory, etc.) of selected
 * source VMs.
 */
export interface UtilizationReport {
  /** Output only. The report unique name. */
  name: string;
  /** The report display name, as assigned by the user. */
  displayName: string;
  /** Output only. Current state of the report. */
  state: UtilizationReport_State;
  /** Output only. The time the state was last set. */
  stateTime?:
    | Date
    | undefined;
  /**
   * Output only. Provides details on the state of the report in case of an
   * error.
   */
  error?:
    | Status
    | undefined;
  /**
   * Output only. The time the report was created (this refers to the time of
   * the request, not the time the report creation completed).
   */
  createTime?:
    | Date
    | undefined;
  /** Time frame of the report. */
  timeFrame: UtilizationReport_TimeFrame;
  /**
   * Output only. The point in time when the time frame ends. Notice that the
   * time frame is counted backwards. For instance if the "frame_end_time" value
   * is 2021/01/20 and the time frame is WEEK then the report covers the week
   * between 2021/01/20 and 2021/01/14.
   */
  frameEndTime?:
    | Date
    | undefined;
  /** Output only. Total number of VMs included in the report. */
  vmCount: number;
  /**
   * List of utilization information per VM.
   * When sent as part of the request, the "vm_id" field is used in order to
   * specify which VMs to include in the report. In that case all other fields
   * are ignored.
   */
  vms: VmUtilizationInfo[];
}

/** Utilization report state. */
export enum UtilizationReport_State {
  /** STATE_UNSPECIFIED - The state is unknown. This value is not in use. */
  STATE_UNSPECIFIED = 0,
  /** CREATING - The report is in the making. */
  CREATING = 1,
  /** SUCCEEDED - Report creation completed successfully. */
  SUCCEEDED = 2,
  /** FAILED - Report creation failed. */
  FAILED = 3,
  UNRECOGNIZED = -1,
}

export function utilizationReport_StateFromJSON(object: any): UtilizationReport_State {
  switch (object) {
    case 0:
    case "STATE_UNSPECIFIED":
      return UtilizationReport_State.STATE_UNSPECIFIED;
    case 1:
    case "CREATING":
      return UtilizationReport_State.CREATING;
    case 2:
    case "SUCCEEDED":
      return UtilizationReport_State.SUCCEEDED;
    case 3:
    case "FAILED":
      return UtilizationReport_State.FAILED;
    case -1:
    case "UNRECOGNIZED":
    default:
      return UtilizationReport_State.UNRECOGNIZED;
  }
}

export function utilizationReport_StateToJSON(object: UtilizationReport_State): string {
  switch (object) {
    case UtilizationReport_State.STATE_UNSPECIFIED:
      return "STATE_UNSPECIFIED";
    case UtilizationReport_State.CREATING:
      return "CREATING";
    case UtilizationReport_State.SUCCEEDED:
      return "SUCCEEDED";
    case UtilizationReport_State.FAILED:
      return "FAILED";
    case UtilizationReport_State.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Report time frame options. */
export enum UtilizationReport_TimeFrame {
  /** TIME_FRAME_UNSPECIFIED - The time frame was not specified and will default to WEEK. */
  TIME_FRAME_UNSPECIFIED = 0,
  /** WEEK - One week. */
  WEEK = 1,
  /** MONTH - One month. */
  MONTH = 2,
  /** YEAR - One year. */
  YEAR = 3,
  UNRECOGNIZED = -1,
}

export function utilizationReport_TimeFrameFromJSON(object: any): UtilizationReport_TimeFrame {
  switch (object) {
    case 0:
    case "TIME_FRAME_UNSPECIFIED":
      return UtilizationReport_TimeFrame.TIME_FRAME_UNSPECIFIED;
    case 1:
    case "WEEK":
      return UtilizationReport_TimeFrame.WEEK;
    case 2:
    case "MONTH":
      return UtilizationReport_TimeFrame.MONTH;
    case 3:
    case "YEAR":
      return UtilizationReport_TimeFrame.YEAR;
    case -1:
    case "UNRECOGNIZED":
    default:
      return UtilizationReport_TimeFrame.UNRECOGNIZED;
  }
}

export function utilizationReport_TimeFrameToJSON(object: UtilizationReport_TimeFrame): string {
  switch (object) {
    case UtilizationReport_TimeFrame.TIME_FRAME_UNSPECIFIED:
      return "TIME_FRAME_UNSPECIFIED";
    case UtilizationReport_TimeFrame.WEEK:
      return "WEEK";
    case UtilizationReport_TimeFrame.MONTH:
      return "MONTH";
    case UtilizationReport_TimeFrame.YEAR:
      return "YEAR";
    case UtilizationReport_TimeFrame.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Utilization information of a single VM. */
export interface VmUtilizationInfo {
  /** The description of the VM in a Source of type Vmware. */
  vmwareVmDetails?:
    | VmwareVmDetails
    | undefined;
  /** The VM's ID in the source. */
  vmId: string;
  /** Utilization metrics for this VM. */
  utilization?: VmUtilizationMetrics | undefined;
}

/** Utilization metrics values for a single VM. */
export interface VmUtilizationMetrics {
  /** Max CPU usage, percent. */
  cpuMaxPercent: number;
  /** Average CPU usage, percent. */
  cpuAveragePercent: number;
  /** Max memory usage, percent. */
  memoryMaxPercent: number;
  /** Average memory usage, percent. */
  memoryAveragePercent: number;
  /** Max disk IO rate, in kilobytes per second. */
  diskIoRateMaxKbps: Long;
  /** Average disk IO rate, in kilobytes per second. */
  diskIoRateAverageKbps: Long;
  /**
   * Max network throughput (combined transmit-rates and receive-rates), in
   * kilobytes per second.
   */
  networkThroughputMaxKbps: Long;
  /**
   * Average network throughput (combined transmit-rates and receive-rates), in
   * kilobytes per second.
   */
  networkThroughputAverageKbps: Long;
}

/**
 * ComputeEngineTargetDefaults is a collection of details for creating a VM in a
 * target Compute Engine project.
 */
export interface ComputeEngineTargetDefaults {
  /** The name of the VM to create. */
  vmName: string;
  /**
   * The full path of the resource of type TargetProject which represents the
   * Compute Engine project in which to create this VM.
   */
  targetProject: string;
  /** The zone in which to create the VM. */
  zone: string;
  /** The machine type series to create the VM with. */
  machineTypeSeries: string;
  /** The machine type to create the VM with. */
  machineType: string;
  /** A map of network tags to associate with the VM. */
  networkTags: string[];
  /** List of NICs connected to this VM. */
  networkInterfaces: NetworkInterface[];
  /** The service account to associate the VM with. */
  serviceAccount: string;
  /** The disk type to use in the VM. */
  diskType: ComputeEngineDiskType;
  /** A map of labels to associate with the VM. */
  labels: { [key: string]: string };
  /** The license type to use in OS adaptation. */
  licenseType: ComputeEngineLicenseType;
  /** Output only. The OS license returned from the adaptation module report. */
  appliedLicense?:
    | AppliedLicense
    | undefined;
  /** Compute instance scheduling information (if empty default is used). */
  computeScheduling?:
    | ComputeScheduling
    | undefined;
  /**
   * Defines whether the instance has Secure Boot enabled.
   * This can be set to true only if the vm boot option is EFI.
   */
  secureBoot: boolean;
  /** Output only. The VM Boot Option, as set in the source vm. */
  bootOption: ComputeEngineBootOption;
  /** The metadata key/value pairs to assign to the VM. */
  metadata: { [key: string]: string };
  /** Additional licenses to assign to the VM. */
  additionalLicenses: string[];
  /** The hostname to assign to the VM. */
  hostname: string;
}

export interface ComputeEngineTargetDefaults_LabelsEntry {
  key: string;
  value: string;
}

export interface ComputeEngineTargetDefaults_MetadataEntry {
  key: string;
  value: string;
}

/**
 * ComputeEngineTargetDetails is a collection of details for creating a VM in a
 * target Compute Engine project.
 */
export interface ComputeEngineTargetDetails {
  /** The name of the VM to create. */
  vmName: string;
  /** The Google Cloud target project ID or project name. */
  project: string;
  /** The zone in which to create the VM. */
  zone: string;
  /** The machine type series to create the VM with. */
  machineTypeSeries: string;
  /** The machine type to create the VM with. */
  machineType: string;
  /** A map of network tags to associate with the VM. */
  networkTags: string[];
  /** List of NICs connected to this VM. */
  networkInterfaces: NetworkInterface[];
  /** The service account to associate the VM with. */
  serviceAccount: string;
  /** The disk type to use in the VM. */
  diskType: ComputeEngineDiskType;
  /** A map of labels to associate with the VM. */
  labels: { [key: string]: string };
  /** The license type to use in OS adaptation. */
  licenseType: ComputeEngineLicenseType;
  /** The OS license returned from the adaptation module report. */
  appliedLicense?:
    | AppliedLicense
    | undefined;
  /** Compute instance scheduling information (if empty default is used). */
  computeScheduling?:
    | ComputeScheduling
    | undefined;
  /**
   * Defines whether the instance has Secure Boot enabled.
   * This can be set to true only if the vm boot option is EFI.
   */
  secureBoot: boolean;
  /** The VM Boot Option, as set in the source vm. */
  bootOption: ComputeEngineBootOption;
  /** The metadata key/value pairs to assign to the VM. */
  metadata: { [key: string]: string };
  /** Additional licenses to assign to the VM. */
  additionalLicenses: string[];
  /** The hostname to assign to the VM. */
  hostname: string;
}

export interface ComputeEngineTargetDetails_LabelsEntry {
  key: string;
  value: string;
}

export interface ComputeEngineTargetDetails_MetadataEntry {
  key: string;
  value: string;
}

/** NetworkInterface represents a NIC of a VM. */
export interface NetworkInterface {
  /** The network to connect the NIC to. */
  network: string;
  /** The subnetwork to connect the NIC to. */
  subnetwork: string;
  /**
   * The internal IP to define in the NIC.
   * The formats accepted are: `ephemeral` \ ipv4 address \ a named address
   * resource full path.
   */
  internalIp: string;
  /** The external IP to define in the NIC. */
  externalIp: string;
}

/** AppliedLicense holds the license data returned by adaptation module report. */
export interface AppliedLicense {
  /** The license type that was used in OS adaptation. */
  type: AppliedLicense_Type;
  /** The OS license returned from the adaptation module's report. */
  osLicense: string;
}

/** License types used in OS adaptation. */
export enum AppliedLicense_Type {
  /** TYPE_UNSPECIFIED - Unspecified license for the OS. */
  TYPE_UNSPECIFIED = 0,
  /** NONE - No license available for the OS. */
  NONE = 1,
  /** PAYG - The license type is Pay As You Go license type. */
  PAYG = 2,
  /** BYOL - The license type is Bring Your Own License type. */
  BYOL = 3,
  UNRECOGNIZED = -1,
}

export function appliedLicense_TypeFromJSON(object: any): AppliedLicense_Type {
  switch (object) {
    case 0:
    case "TYPE_UNSPECIFIED":
      return AppliedLicense_Type.TYPE_UNSPECIFIED;
    case 1:
    case "NONE":
      return AppliedLicense_Type.NONE;
    case 2:
    case "PAYG":
      return AppliedLicense_Type.PAYG;
    case 3:
    case "BYOL":
      return AppliedLicense_Type.BYOL;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AppliedLicense_Type.UNRECOGNIZED;
  }
}

export function appliedLicense_TypeToJSON(object: AppliedLicense_Type): string {
  switch (object) {
    case AppliedLicense_Type.TYPE_UNSPECIFIED:
      return "TYPE_UNSPECIFIED";
    case AppliedLicense_Type.NONE:
      return "NONE";
    case AppliedLicense_Type.PAYG:
      return "PAYG";
    case AppliedLicense_Type.BYOL:
      return "BYOL";
    case AppliedLicense_Type.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Node Affinity: the configuration of desired nodes onto which this Instance
 * could be scheduled. Based on
 * https://cloud.google.com/compute/docs/reference/rest/v1/instances/setScheduling
 */
export interface SchedulingNodeAffinity {
  /** The label key of Node resource to reference. */
  key: string;
  /**
   * The operator to use for the node resources specified in the `values`
   * parameter.
   */
  operator: SchedulingNodeAffinity_Operator;
  /** Corresponds to the label values of Node resource. */
  values: string[];
}

/**
 * Possible types of node selection operators. Valid operators are IN for
 * affinity and NOT_IN for anti-affinity.
 */
export enum SchedulingNodeAffinity_Operator {
  /** OPERATOR_UNSPECIFIED - An unknown, unexpected behavior. */
  OPERATOR_UNSPECIFIED = 0,
  /** IN - The node resource group should be in these resources affinity. */
  IN = 1,
  /** NOT_IN - The node resource group should not be in these resources affinity. */
  NOT_IN = 2,
  UNRECOGNIZED = -1,
}

export function schedulingNodeAffinity_OperatorFromJSON(object: any): SchedulingNodeAffinity_Operator {
  switch (object) {
    case 0:
    case "OPERATOR_UNSPECIFIED":
      return SchedulingNodeAffinity_Operator.OPERATOR_UNSPECIFIED;
    case 1:
    case "IN":
      return SchedulingNodeAffinity_Operator.IN;
    case 2:
    case "NOT_IN":
      return SchedulingNodeAffinity_Operator.NOT_IN;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SchedulingNodeAffinity_Operator.UNRECOGNIZED;
  }
}

export function schedulingNodeAffinity_OperatorToJSON(object: SchedulingNodeAffinity_Operator): string {
  switch (object) {
    case SchedulingNodeAffinity_Operator.OPERATOR_UNSPECIFIED:
      return "OPERATOR_UNSPECIFIED";
    case SchedulingNodeAffinity_Operator.IN:
      return "IN";
    case SchedulingNodeAffinity_Operator.NOT_IN:
      return "NOT_IN";
    case SchedulingNodeAffinity_Operator.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Scheduling information for VM on maintenance/restart behaviour and
 * node allocation in sole tenant nodes.
 */
export interface ComputeScheduling {
  /**
   * How the instance should behave when the host machine undergoes
   * maintenance that may temporarily impact instance performance.
   */
  onHostMaintenance: ComputeScheduling_OnHostMaintenance;
  /**
   * Whether the Instance should be automatically restarted whenever it is
   * terminated by Compute Engine (not terminated by user).
   * This configuration is identical to `automaticRestart` field in Compute
   * Engine create instance under scheduling.
   * It was changed to an enum (instead of a boolean) to match the default
   * value in Compute Engine which is automatic restart.
   */
  restartType: ComputeScheduling_RestartType;
  /**
   * A set of node affinity and anti-affinity configurations for sole tenant
   * nodes.
   */
  nodeAffinities: SchedulingNodeAffinity[];
  /**
   * The minimum number of virtual CPUs this instance will consume when
   * running on a sole-tenant node. Ignored if no node_affinites are
   * configured.
   */
  minNodeCpus: number;
}

export enum ComputeScheduling_OnHostMaintenance {
  /** ON_HOST_MAINTENANCE_UNSPECIFIED - An unknown, unexpected behavior. */
  ON_HOST_MAINTENANCE_UNSPECIFIED = 0,
  /** TERMINATE - Terminate the instance when the host machine undergoes maintenance. */
  TERMINATE = 1,
  /** MIGRATE - Migrate the instance when the host machine undergoes maintenance. */
  MIGRATE = 2,
  UNRECOGNIZED = -1,
}

export function computeScheduling_OnHostMaintenanceFromJSON(object: any): ComputeScheduling_OnHostMaintenance {
  switch (object) {
    case 0:
    case "ON_HOST_MAINTENANCE_UNSPECIFIED":
      return ComputeScheduling_OnHostMaintenance.ON_HOST_MAINTENANCE_UNSPECIFIED;
    case 1:
    case "TERMINATE":
      return ComputeScheduling_OnHostMaintenance.TERMINATE;
    case 2:
    case "MIGRATE":
      return ComputeScheduling_OnHostMaintenance.MIGRATE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeScheduling_OnHostMaintenance.UNRECOGNIZED;
  }
}

export function computeScheduling_OnHostMaintenanceToJSON(object: ComputeScheduling_OnHostMaintenance): string {
  switch (object) {
    case ComputeScheduling_OnHostMaintenance.ON_HOST_MAINTENANCE_UNSPECIFIED:
      return "ON_HOST_MAINTENANCE_UNSPECIFIED";
    case ComputeScheduling_OnHostMaintenance.TERMINATE:
      return "TERMINATE";
    case ComputeScheduling_OnHostMaintenance.MIGRATE:
      return "MIGRATE";
    case ComputeScheduling_OnHostMaintenance.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/**
 * Defines whether the Instance should be automatically restarted whenever
 * it is terminated by Compute Engine (not terminated by user).
 */
export enum ComputeScheduling_RestartType {
  /** RESTART_TYPE_UNSPECIFIED - Unspecified behavior. This will use the default. */
  RESTART_TYPE_UNSPECIFIED = 0,
  /**
   * AUTOMATIC_RESTART - The Instance should be automatically restarted whenever it is
   * terminated by Compute Engine.
   */
  AUTOMATIC_RESTART = 1,
  /**
   * NO_AUTOMATIC_RESTART - The Instance isn't automatically restarted whenever it is
   * terminated by Compute Engine.
   */
  NO_AUTOMATIC_RESTART = 2,
  UNRECOGNIZED = -1,
}

export function computeScheduling_RestartTypeFromJSON(object: any): ComputeScheduling_RestartType {
  switch (object) {
    case 0:
    case "RESTART_TYPE_UNSPECIFIED":
      return ComputeScheduling_RestartType.RESTART_TYPE_UNSPECIFIED;
    case 1:
    case "AUTOMATIC_RESTART":
      return ComputeScheduling_RestartType.AUTOMATIC_RESTART;
    case 2:
    case "NO_AUTOMATIC_RESTART":
      return ComputeScheduling_RestartType.NO_AUTOMATIC_RESTART;
    case -1:
    case "UNRECOGNIZED":
    default:
      return ComputeScheduling_RestartType.UNRECOGNIZED;
  }
}

export function computeScheduling_RestartTypeToJSON(object: ComputeScheduling_RestartType): string {
  switch (object) {
    case ComputeScheduling_RestartType.RESTART_TYPE_UNSPECIFIED:
      return "RESTART_TYPE_UNSPECIFIED";
    case ComputeScheduling_RestartType.AUTOMATIC_RESTART:
      return "AUTOMATIC_RESTART";
    case ComputeScheduling_RestartType.NO_AUTOMATIC_RESTART:
      return "NO_AUTOMATIC_RESTART";
    case ComputeScheduling_RestartType.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A policy for scheduling replications. */
export interface SchedulePolicy {
  /** The idle duration between replication stages. */
  idleDuration?:
    | Duration
    | undefined;
  /**
   * A flag to indicate whether to skip OS adaptation during the replication
   * sync. OS adaptation is a process where the VM's operating system undergoes
   * changes and adaptations to fully function on Compute Engine.
   */
  skipOsAdaptation: boolean;
}

/**
 * TargetProject message represents a target Compute Engine project for a
 * migration or a clone.
 */
export interface TargetProject {
  /** Output only. The name of the target project. */
  name: string;
  /** The target project ID (number) or project name. */
  project: string;
  /** The target project's description. */
  description: string;
  /**
   * Output only. The time this target project resource was created (not related
   * to when the Compute Engine project it points to was created).
   */
  createTime?:
    | Date
    | undefined;
  /** Output only. The last time the target project resource was updated. */
  updateTime?: Date | undefined;
}

/**
 * Describes message for 'Group' resource. The Group is a collections of several
 * MigratingVms.
 */
export interface Group {
  /** Output only. The Group name. */
  name: string;
  /** Output only. The create time timestamp. */
  createTime?:
    | Date
    | undefined;
  /** Output only. The update time timestamp. */
  updateTime?:
    | Date
    | undefined;
  /** User-provided description of the group. */
  description: string;
  /** Display name is a user defined name for this group which can be updated. */
  displayName: string;
}

/**
 * Represents migration resource warning information that can be used with
 * google.rpc.Status message. MigrationWarning is used to present the user with
 * warning information in migration operations.
 */
export interface MigrationWarning {
  /** The warning code. */
  code: MigrationWarning_WarningCode;
  /** The localized warning message. */
  warningMessage?:
    | LocalizedMessage
    | undefined;
  /** Suggested action for solving the warning. */
  actionItem?:
    | LocalizedMessage
    | undefined;
  /** URL(s) pointing to additional information on handling the current warning. */
  helpLinks: Help_Link[];
  /** The time the warning occurred. */
  warningTime?: Date | undefined;
}

/** Represents possible warning codes. */
export enum MigrationWarning_WarningCode {
  /** WARNING_CODE_UNSPECIFIED - Default value. This value is not used. */
  WARNING_CODE_UNSPECIFIED = 0,
  /** ADAPTATION_WARNING - A warning originated from OS Adaptation. */
  ADAPTATION_WARNING = 1,
  UNRECOGNIZED = -1,
}

export function migrationWarning_WarningCodeFromJSON(object: any): MigrationWarning_WarningCode {
  switch (object) {
    case 0:
    case "WARNING_CODE_UNSPECIFIED":
      return MigrationWarning_WarningCode.WARNING_CODE_UNSPECIFIED;
    case 1:
    case "ADAPTATION_WARNING":
      return MigrationWarning_WarningCode.ADAPTATION_WARNING;
    case -1:
    case "UNRECOGNIZED":
    default:
      return MigrationWarning_WarningCode.UNRECOGNIZED;
  }
}

export function migrationWarning_WarningCodeToJSON(object: MigrationWarning_WarningCode): string {
  switch (object) {
    case MigrationWarning_WarningCode.WARNING_CODE_UNSPECIFIED:
      return "WARNING_CODE_UNSPECIFIED";
    case MigrationWarning_WarningCode.ADAPTATION_WARNING:
      return "ADAPTATION_WARNING";
    case MigrationWarning_WarningCode.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Represent the source AWS VM details. */
export interface AwsSourceVmDetails {
  /** The firmware type of the source VM. */
  firmware: AwsSourceVmDetails_Firmware;
  /** The total size of the disks being migrated in bytes. */
  committedStorageBytes: Long;
  /** The disks attached to the source VM. */
  disks: AwsSourceVmDetails_AwsDiskDetails[];
}

/** Possible values for AWS VM firmware. */
export enum AwsSourceVmDetails_Firmware {
  /** FIRMWARE_UNSPECIFIED - The firmware is unknown. */
  FIRMWARE_UNSPECIFIED = 0,
  /** EFI - The firmware is EFI. */
  EFI = 1,
  /** BIOS - The firmware is BIOS. */
  BIOS = 2,
  UNRECOGNIZED = -1,
}

export function awsSourceVmDetails_FirmwareFromJSON(object: any): AwsSourceVmDetails_Firmware {
  switch (object) {
    case 0:
    case "FIRMWARE_UNSPECIFIED":
      return AwsSourceVmDetails_Firmware.FIRMWARE_UNSPECIFIED;
    case 1:
    case "EFI":
      return AwsSourceVmDetails_Firmware.EFI;
    case 2:
    case "BIOS":
      return AwsSourceVmDetails_Firmware.BIOS;
    case -1:
    case "UNRECOGNIZED":
    default:
      return AwsSourceVmDetails_Firmware.UNRECOGNIZED;
  }
}

export function awsSourceVmDetails_FirmwareToJSON(object: AwsSourceVmDetails_Firmware): string {
  switch (object) {
    case AwsSourceVmDetails_Firmware.FIRMWARE_UNSPECIFIED:
      return "FIRMWARE_UNSPECIFIED";
    case AwsSourceVmDetails_Firmware.EFI:
      return "EFI";
    case AwsSourceVmDetails_Firmware.BIOS:
      return "BIOS";
    case AwsSourceVmDetails_Firmware.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** The details of an AWS instance disk. */
export interface AwsSourceVmDetails_AwsDiskDetails {
  /** The ordinal number of the disk. */
  diskNumber: number;
  /** AWS volume ID. */
  volumeId: string;
  /** Size in GB. */
  sizeGb: Long;
}

/** The data within all UtilizationReport events. */
export interface UtilizationReportEventData {
  /** Optional. The UtilizationReport event payload. Unset for deletion events. */
  payload?: UtilizationReport | undefined;
}

/** The data within all Group events. */
export interface GroupEventData {
  /** Optional. The Group event payload. Unset for deletion events. */
  payload?: Group | undefined;
}

/** The data within all CloneJob events. */
export interface CloneJobEventData {
  /** The CloneJob event payload. */
  payload?: CloneJob | undefined;
}

/** The data within all DatacenterConnector events. */
export interface DatacenterConnectorEventData {
  /** Optional. The DatacenterConnector event payload. Unset for deletion events. */
  payload?: DatacenterConnector | undefined;
}

/** The data within all TargetProject events. */
export interface TargetProjectEventData {
  /** Optional. The TargetProject event payload. Unset for deletion events. */
  payload?: TargetProject | undefined;
}

/** The data within all CutoverJob events. */
export interface CutoverJobEventData {
  /** The CutoverJob event payload. */
  payload?: CutoverJob | undefined;
}

/** The data within all Source events. */
export interface SourceEventData {
  /** Optional. The Source event payload. Unset for deletion events. */
  payload?: Source | undefined;
}

/** The data within all MigratingVm events. */
export interface MigratingVmEventData {
  /** Optional. The MigratingVm event payload. Unset for deletion events. */
  payload?: MigratingVm | undefined;
}

function createBaseReplicationCycle(): ReplicationCycle {
  return {
    name: "",
    cycleNumber: 0,
    startTime: undefined,
    endTime: undefined,
    totalPauseDuration: undefined,
    progressPercent: 0,
    steps: [],
    state: 0,
    error: undefined,
    warnings: [],
  };
}

export const ReplicationCycle: MessageFns<ReplicationCycle> = {
  encode(message: ReplicationCycle, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(106).string(message.name);
    }
    if (message.cycleNumber !== 0) {
      writer.uint32(80).int32(message.cycleNumber);
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(50).fork()).join();
    }
    if (message.totalPauseDuration !== undefined) {
      Duration.encode(message.totalPauseDuration, writer.uint32(58).fork()).join();
    }
    if (message.progressPercent !== 0) {
      writer.uint32(40).int32(message.progressPercent);
    }
    for (const v of message.steps) {
      CycleStep.encode(v!, writer.uint32(74).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(88).int32(message.state);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(98).fork()).join();
    }
    for (const v of message.warnings) {
      MigrationWarning.encode(v!, writer.uint32(114).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicationCycle {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicationCycle();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.cycleNumber = reader.int32();
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.totalPauseDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.progressPercent = reader.int32();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.steps.push(CycleStep.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.warnings.push(MigrationWarning.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicationCycle {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      cycleNumber: isSet(object.cycleNumber) ? globalThis.Number(object.cycleNumber) : 0,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      totalPauseDuration: isSet(object.totalPauseDuration) ? Duration.fromJSON(object.totalPauseDuration) : undefined,
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
      steps: globalThis.Array.isArray(object?.steps) ? object.steps.map((e: any) => CycleStep.fromJSON(e)) : [],
      state: isSet(object.state) ? replicationCycle_StateFromJSON(object.state) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      warnings: globalThis.Array.isArray(object?.warnings)
        ? object.warnings.map((e: any) => MigrationWarning.fromJSON(e))
        : [],
    };
  },

  toJSON(message: ReplicationCycle): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.cycleNumber !== 0) {
      obj.cycleNumber = Math.round(message.cycleNumber);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.totalPauseDuration !== undefined) {
      obj.totalPauseDuration = Duration.toJSON(message.totalPauseDuration);
    }
    if (message.progressPercent !== 0) {
      obj.progressPercent = Math.round(message.progressPercent);
    }
    if (message.steps?.length) {
      obj.steps = message.steps.map((e) => CycleStep.toJSON(e));
    }
    if (message.state !== 0) {
      obj.state = replicationCycle_StateToJSON(message.state);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.warnings?.length) {
      obj.warnings = message.warnings.map((e) => MigrationWarning.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ReplicationCycle>, I>>(base?: I): ReplicationCycle {
    return ReplicationCycle.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ReplicationCycle>, I>>(object: I): ReplicationCycle {
    const message = createBaseReplicationCycle();
    message.name = object.name ?? "";
    message.cycleNumber = object.cycleNumber ?? 0;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.totalPauseDuration = (object.totalPauseDuration !== undefined && object.totalPauseDuration !== null)
      ? Duration.fromPartial(object.totalPauseDuration)
      : undefined;
    message.progressPercent = object.progressPercent ?? 0;
    message.steps = object.steps?.map((e) => CycleStep.fromPartial(e)) || [];
    message.state = object.state ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.warnings = object.warnings?.map((e) => MigrationWarning.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCycleStep(): CycleStep {
  return {
    initializingReplication: undefined,
    replicating: undefined,
    postProcessing: undefined,
    startTime: undefined,
    endTime: undefined,
  };
}

export const CycleStep: MessageFns<CycleStep> = {
  encode(message: CycleStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.initializingReplication !== undefined) {
      InitializingReplicationStep.encode(message.initializingReplication, writer.uint32(26).fork()).join();
    }
    if (message.replicating !== undefined) {
      ReplicatingStep.encode(message.replicating, writer.uint32(34).fork()).join();
    }
    if (message.postProcessing !== undefined) {
      PostProcessingStep.encode(message.postProcessing, writer.uint32(42).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CycleStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCycleStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.initializingReplication = InitializingReplicationStep.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.replicating = ReplicatingStep.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.postProcessing = PostProcessingStep.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CycleStep {
    return {
      initializingReplication: isSet(object.initializingReplication)
        ? InitializingReplicationStep.fromJSON(object.initializingReplication)
        : undefined,
      replicating: isSet(object.replicating) ? ReplicatingStep.fromJSON(object.replicating) : undefined,
      postProcessing: isSet(object.postProcessing) ? PostProcessingStep.fromJSON(object.postProcessing) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: CycleStep): unknown {
    const obj: any = {};
    if (message.initializingReplication !== undefined) {
      obj.initializingReplication = InitializingReplicationStep.toJSON(message.initializingReplication);
    }
    if (message.replicating !== undefined) {
      obj.replicating = ReplicatingStep.toJSON(message.replicating);
    }
    if (message.postProcessing !== undefined) {
      obj.postProcessing = PostProcessingStep.toJSON(message.postProcessing);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CycleStep>, I>>(base?: I): CycleStep {
    return CycleStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CycleStep>, I>>(object: I): CycleStep {
    const message = createBaseCycleStep();
    message.initializingReplication =
      (object.initializingReplication !== undefined && object.initializingReplication !== null)
        ? InitializingReplicationStep.fromPartial(object.initializingReplication)
        : undefined;
    message.replicating = (object.replicating !== undefined && object.replicating !== null)
      ? ReplicatingStep.fromPartial(object.replicating)
      : undefined;
    message.postProcessing = (object.postProcessing !== undefined && object.postProcessing !== null)
      ? PostProcessingStep.fromPartial(object.postProcessing)
      : undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseInitializingReplicationStep(): InitializingReplicationStep {
  return {};
}

export const InitializingReplicationStep: MessageFns<InitializingReplicationStep> = {
  encode(_: InitializingReplicationStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InitializingReplicationStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInitializingReplicationStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): InitializingReplicationStep {
    return {};
  },

  toJSON(_: InitializingReplicationStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<InitializingReplicationStep>, I>>(base?: I): InitializingReplicationStep {
    return InitializingReplicationStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<InitializingReplicationStep>, I>>(_: I): InitializingReplicationStep {
    const message = createBaseInitializingReplicationStep();
    return message;
  },
};

function createBaseReplicatingStep(): ReplicatingStep {
  return {
    totalBytes: Long.ZERO,
    replicatedBytes: Long.ZERO,
    lastTwoMinutesAverageBytesPerSecond: Long.ZERO,
    lastThirtyMinutesAverageBytesPerSecond: Long.ZERO,
  };
}

export const ReplicatingStep: MessageFns<ReplicatingStep> = {
  encode(message: ReplicatingStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (!message.totalBytes.equals(Long.ZERO)) {
      writer.uint32(8).int64(message.totalBytes.toString());
    }
    if (!message.replicatedBytes.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.replicatedBytes.toString());
    }
    if (!message.lastTwoMinutesAverageBytesPerSecond.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.lastTwoMinutesAverageBytesPerSecond.toString());
    }
    if (!message.lastThirtyMinutesAverageBytesPerSecond.equals(Long.ZERO)) {
      writer.uint32(32).int64(message.lastThirtyMinutesAverageBytesPerSecond.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicatingStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicatingStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.totalBytes = Long.fromString(reader.int64().toString());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.replicatedBytes = Long.fromString(reader.int64().toString());
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.lastTwoMinutesAverageBytesPerSecond = Long.fromString(reader.int64().toString());
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.lastThirtyMinutesAverageBytesPerSecond = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicatingStep {
    return {
      totalBytes: isSet(object.totalBytes) ? Long.fromValue(object.totalBytes) : Long.ZERO,
      replicatedBytes: isSet(object.replicatedBytes) ? Long.fromValue(object.replicatedBytes) : Long.ZERO,
      lastTwoMinutesAverageBytesPerSecond: isSet(object.lastTwoMinutesAverageBytesPerSecond)
        ? Long.fromValue(object.lastTwoMinutesAverageBytesPerSecond)
        : Long.ZERO,
      lastThirtyMinutesAverageBytesPerSecond: isSet(object.lastThirtyMinutesAverageBytesPerSecond)
        ? Long.fromValue(object.lastThirtyMinutesAverageBytesPerSecond)
        : Long.ZERO,
    };
  },

  toJSON(message: ReplicatingStep): unknown {
    const obj: any = {};
    if (!message.totalBytes.equals(Long.ZERO)) {
      obj.totalBytes = (message.totalBytes || Long.ZERO).toString();
    }
    if (!message.replicatedBytes.equals(Long.ZERO)) {
      obj.replicatedBytes = (message.replicatedBytes || Long.ZERO).toString();
    }
    if (!message.lastTwoMinutesAverageBytesPerSecond.equals(Long.ZERO)) {
      obj.lastTwoMinutesAverageBytesPerSecond = (message.lastTwoMinutesAverageBytesPerSecond || Long.ZERO).toString();
    }
    if (!message.lastThirtyMinutesAverageBytesPerSecond.equals(Long.ZERO)) {
      obj.lastThirtyMinutesAverageBytesPerSecond = (message.lastThirtyMinutesAverageBytesPerSecond || Long.ZERO)
        .toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ReplicatingStep>, I>>(base?: I): ReplicatingStep {
    return ReplicatingStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ReplicatingStep>, I>>(object: I): ReplicatingStep {
    const message = createBaseReplicatingStep();
    message.totalBytes = (object.totalBytes !== undefined && object.totalBytes !== null)
      ? Long.fromValue(object.totalBytes)
      : Long.ZERO;
    message.replicatedBytes = (object.replicatedBytes !== undefined && object.replicatedBytes !== null)
      ? Long.fromValue(object.replicatedBytes)
      : Long.ZERO;
    message.lastTwoMinutesAverageBytesPerSecond =
      (object.lastTwoMinutesAverageBytesPerSecond !== undefined && object.lastTwoMinutesAverageBytesPerSecond !== null)
        ? Long.fromValue(object.lastTwoMinutesAverageBytesPerSecond)
        : Long.ZERO;
    message.lastThirtyMinutesAverageBytesPerSecond =
      (object.lastThirtyMinutesAverageBytesPerSecond !== undefined &&
          object.lastThirtyMinutesAverageBytesPerSecond !== null)
        ? Long.fromValue(object.lastThirtyMinutesAverageBytesPerSecond)
        : Long.ZERO;
    return message;
  },
};

function createBasePostProcessingStep(): PostProcessingStep {
  return {};
}

export const PostProcessingStep: MessageFns<PostProcessingStep> = {
  encode(_: PostProcessingStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostProcessingStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostProcessingStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): PostProcessingStep {
    return {};
  },

  toJSON(_: PostProcessingStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<PostProcessingStep>, I>>(base?: I): PostProcessingStep {
    return PostProcessingStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PostProcessingStep>, I>>(_: I): PostProcessingStep {
    const message = createBasePostProcessingStep();
    return message;
  },
};

function createBaseReplicationSync(): ReplicationSync {
  return { lastSyncTime: undefined };
}

export const ReplicationSync: MessageFns<ReplicationSync> = {
  encode(message: ReplicationSync, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.lastSyncTime !== undefined) {
      Timestamp.encode(toTimestamp(message.lastSyncTime), writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ReplicationSync {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseReplicationSync();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.lastSyncTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ReplicationSync {
    return { lastSyncTime: isSet(object.lastSyncTime) ? fromJsonTimestamp(object.lastSyncTime) : undefined };
  },

  toJSON(message: ReplicationSync): unknown {
    const obj: any = {};
    if (message.lastSyncTime !== undefined) {
      obj.lastSyncTime = message.lastSyncTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ReplicationSync>, I>>(base?: I): ReplicationSync {
    return ReplicationSync.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ReplicationSync>, I>>(object: I): ReplicationSync {
    const message = createBaseReplicationSync();
    message.lastSyncTime = object.lastSyncTime ?? undefined;
    return message;
  },
};

function createBaseMigratingVm(): MigratingVm {
  return {
    computeEngineTargetDefaults: undefined,
    awsSourceVmDetails: undefined,
    name: "",
    sourceVmId: "",
    displayName: "",
    description: "",
    policy: undefined,
    createTime: undefined,
    updateTime: undefined,
    lastSync: undefined,
    state: 0,
    stateTime: undefined,
    currentSyncInfo: undefined,
    lastReplicationCycle: undefined,
    group: "",
    labels: {},
    recentCloneJobs: [],
    error: undefined,
    recentCutoverJobs: [],
    cutoverForecast: undefined,
  };
}

export const MigratingVm: MessageFns<MigratingVm> = {
  encode(message: MigratingVm, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.computeEngineTargetDefaults !== undefined) {
      ComputeEngineTargetDefaults.encode(message.computeEngineTargetDefaults, writer.uint32(210).fork()).join();
    }
    if (message.awsSourceVmDetails !== undefined) {
      AwsSourceVmDetails.encode(message.awsSourceVmDetails, writer.uint32(234).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.sourceVmId !== "") {
      writer.uint32(18).string(message.sourceVmId);
    }
    if (message.displayName !== "") {
      writer.uint32(146).string(message.displayName);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.policy !== undefined) {
      SchedulePolicy.encode(message.policy, writer.uint32(66).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(74).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(82).fork()).join();
    }
    if (message.lastSync !== undefined) {
      ReplicationSync.encode(message.lastSync, writer.uint32(90).fork()).join();
    }
    if (message.state !== 0) {
      writer.uint32(184).int32(message.state);
    }
    if (message.stateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.stateTime), writer.uint32(178).fork()).join();
    }
    if (message.currentSyncInfo !== undefined) {
      ReplicationCycle.encode(message.currentSyncInfo, writer.uint32(106).fork()).join();
    }
    if (message.lastReplicationCycle !== undefined) {
      ReplicationCycle.encode(message.lastReplicationCycle, writer.uint32(258).fork()).join();
    }
    if (message.group !== "") {
      writer.uint32(122).string(message.group);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      MigratingVm_LabelsEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    for (const v of message.recentCloneJobs) {
      CloneJob.encode(v!, writer.uint32(138).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(154).fork()).join();
    }
    for (const v of message.recentCutoverJobs) {
      CutoverJob.encode(v!, writer.uint32(162).fork()).join();
    }
    if (message.cutoverForecast !== undefined) {
      CutoverForecast.encode(message.cutoverForecast, writer.uint32(266).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigratingVm {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigratingVm();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 26: {
          if (tag !== 210) {
            break;
          }

          message.computeEngineTargetDefaults = ComputeEngineTargetDefaults.decode(reader, reader.uint32());
          continue;
        }
        case 29: {
          if (tag !== 234) {
            break;
          }

          message.awsSourceVmDetails = AwsSourceVmDetails.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.sourceVmId = reader.string();
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.policy = SchedulePolicy.decode(reader, reader.uint32());
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.lastSync = ReplicationSync.decode(reader, reader.uint32());
          continue;
        }
        case 23: {
          if (tag !== 184) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          message.stateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.currentSyncInfo = ReplicationCycle.decode(reader, reader.uint32());
          continue;
        }
        case 32: {
          if (tag !== 258) {
            break;
          }

          message.lastReplicationCycle = ReplicationCycle.decode(reader, reader.uint32());
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.group = reader.string();
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          const entry16 = MigratingVm_LabelsEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.labels[entry16.key] = entry16.value;
          }
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.recentCloneJobs.push(CloneJob.decode(reader, reader.uint32()));
          continue;
        }
        case 19: {
          if (tag !== 154) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.recentCutoverJobs.push(CutoverJob.decode(reader, reader.uint32()));
          continue;
        }
        case 33: {
          if (tag !== 266) {
            break;
          }

          message.cutoverForecast = CutoverForecast.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigratingVm {
    return {
      computeEngineTargetDefaults: isSet(object.computeEngineTargetDefaults)
        ? ComputeEngineTargetDefaults.fromJSON(object.computeEngineTargetDefaults)
        : undefined,
      awsSourceVmDetails: isSet(object.awsSourceVmDetails)
        ? AwsSourceVmDetails.fromJSON(object.awsSourceVmDetails)
        : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      sourceVmId: isSet(object.sourceVmId) ? globalThis.String(object.sourceVmId) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      policy: isSet(object.policy) ? SchedulePolicy.fromJSON(object.policy) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      lastSync: isSet(object.lastSync) ? ReplicationSync.fromJSON(object.lastSync) : undefined,
      state: isSet(object.state) ? migratingVm_StateFromJSON(object.state) : 0,
      stateTime: isSet(object.stateTime) ? fromJsonTimestamp(object.stateTime) : undefined,
      currentSyncInfo: isSet(object.currentSyncInfo) ? ReplicationCycle.fromJSON(object.currentSyncInfo) : undefined,
      lastReplicationCycle: isSet(object.lastReplicationCycle)
        ? ReplicationCycle.fromJSON(object.lastReplicationCycle)
        : undefined,
      group: isSet(object.group) ? globalThis.String(object.group) : "",
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      recentCloneJobs: globalThis.Array.isArray(object?.recentCloneJobs)
        ? object.recentCloneJobs.map((e: any) => CloneJob.fromJSON(e))
        : [],
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      recentCutoverJobs: globalThis.Array.isArray(object?.recentCutoverJobs)
        ? object.recentCutoverJobs.map((e: any) => CutoverJob.fromJSON(e))
        : [],
      cutoverForecast: isSet(object.cutoverForecast) ? CutoverForecast.fromJSON(object.cutoverForecast) : undefined,
    };
  },

  toJSON(message: MigratingVm): unknown {
    const obj: any = {};
    if (message.computeEngineTargetDefaults !== undefined) {
      obj.computeEngineTargetDefaults = ComputeEngineTargetDefaults.toJSON(message.computeEngineTargetDefaults);
    }
    if (message.awsSourceVmDetails !== undefined) {
      obj.awsSourceVmDetails = AwsSourceVmDetails.toJSON(message.awsSourceVmDetails);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.sourceVmId !== "") {
      obj.sourceVmId = message.sourceVmId;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.policy !== undefined) {
      obj.policy = SchedulePolicy.toJSON(message.policy);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.lastSync !== undefined) {
      obj.lastSync = ReplicationSync.toJSON(message.lastSync);
    }
    if (message.state !== 0) {
      obj.state = migratingVm_StateToJSON(message.state);
    }
    if (message.stateTime !== undefined) {
      obj.stateTime = message.stateTime.toISOString();
    }
    if (message.currentSyncInfo !== undefined) {
      obj.currentSyncInfo = ReplicationCycle.toJSON(message.currentSyncInfo);
    }
    if (message.lastReplicationCycle !== undefined) {
      obj.lastReplicationCycle = ReplicationCycle.toJSON(message.lastReplicationCycle);
    }
    if (message.group !== "") {
      obj.group = message.group;
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.recentCloneJobs?.length) {
      obj.recentCloneJobs = message.recentCloneJobs.map((e) => CloneJob.toJSON(e));
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.recentCutoverJobs?.length) {
      obj.recentCutoverJobs = message.recentCutoverJobs.map((e) => CutoverJob.toJSON(e));
    }
    if (message.cutoverForecast !== undefined) {
      obj.cutoverForecast = CutoverForecast.toJSON(message.cutoverForecast);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MigratingVm>, I>>(base?: I): MigratingVm {
    return MigratingVm.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MigratingVm>, I>>(object: I): MigratingVm {
    const message = createBaseMigratingVm();
    message.computeEngineTargetDefaults =
      (object.computeEngineTargetDefaults !== undefined && object.computeEngineTargetDefaults !== null)
        ? ComputeEngineTargetDefaults.fromPartial(object.computeEngineTargetDefaults)
        : undefined;
    message.awsSourceVmDetails = (object.awsSourceVmDetails !== undefined && object.awsSourceVmDetails !== null)
      ? AwsSourceVmDetails.fromPartial(object.awsSourceVmDetails)
      : undefined;
    message.name = object.name ?? "";
    message.sourceVmId = object.sourceVmId ?? "";
    message.displayName = object.displayName ?? "";
    message.description = object.description ?? "";
    message.policy = (object.policy !== undefined && object.policy !== null)
      ? SchedulePolicy.fromPartial(object.policy)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.lastSync = (object.lastSync !== undefined && object.lastSync !== null)
      ? ReplicationSync.fromPartial(object.lastSync)
      : undefined;
    message.state = object.state ?? 0;
    message.stateTime = object.stateTime ?? undefined;
    message.currentSyncInfo = (object.currentSyncInfo !== undefined && object.currentSyncInfo !== null)
      ? ReplicationCycle.fromPartial(object.currentSyncInfo)
      : undefined;
    message.lastReplicationCycle = (object.lastReplicationCycle !== undefined && object.lastReplicationCycle !== null)
      ? ReplicationCycle.fromPartial(object.lastReplicationCycle)
      : undefined;
    message.group = object.group ?? "";
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.recentCloneJobs = object.recentCloneJobs?.map((e) => CloneJob.fromPartial(e)) || [];
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.recentCutoverJobs = object.recentCutoverJobs?.map((e) => CutoverJob.fromPartial(e)) || [];
    message.cutoverForecast = (object.cutoverForecast !== undefined && object.cutoverForecast !== null)
      ? CutoverForecast.fromPartial(object.cutoverForecast)
      : undefined;
    return message;
  },
};

function createBaseMigratingVm_LabelsEntry(): MigratingVm_LabelsEntry {
  return { key: "", value: "" };
}

export const MigratingVm_LabelsEntry: MessageFns<MigratingVm_LabelsEntry> = {
  encode(message: MigratingVm_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigratingVm_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigratingVm_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigratingVm_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: MigratingVm_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MigratingVm_LabelsEntry>, I>>(base?: I): MigratingVm_LabelsEntry {
    return MigratingVm_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MigratingVm_LabelsEntry>, I>>(object: I): MigratingVm_LabelsEntry {
    const message = createBaseMigratingVm_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseCutoverForecast(): CutoverForecast {
  return { estimatedCutoverJobDuration: undefined };
}

export const CutoverForecast: MessageFns<CutoverForecast> = {
  encode(message: CutoverForecast, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.estimatedCutoverJobDuration !== undefined) {
      Duration.encode(message.estimatedCutoverJobDuration, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CutoverForecast {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCutoverForecast();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.estimatedCutoverJobDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CutoverForecast {
    return {
      estimatedCutoverJobDuration: isSet(object.estimatedCutoverJobDuration)
        ? Duration.fromJSON(object.estimatedCutoverJobDuration)
        : undefined,
    };
  },

  toJSON(message: CutoverForecast): unknown {
    const obj: any = {};
    if (message.estimatedCutoverJobDuration !== undefined) {
      obj.estimatedCutoverJobDuration = Duration.toJSON(message.estimatedCutoverJobDuration);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CutoverForecast>, I>>(base?: I): CutoverForecast {
    return CutoverForecast.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CutoverForecast>, I>>(object: I): CutoverForecast {
    const message = createBaseCutoverForecast();
    message.estimatedCutoverJobDuration =
      (object.estimatedCutoverJobDuration !== undefined && object.estimatedCutoverJobDuration !== null)
        ? Duration.fromPartial(object.estimatedCutoverJobDuration)
        : undefined;
    return message;
  },
};

function createBaseCloneJob(): CloneJob {
  return {
    computeEngineTargetDetails: undefined,
    createTime: undefined,
    endTime: undefined,
    name: "",
    state: 0,
    stateTime: undefined,
    error: undefined,
    steps: [],
  };
}

export const CloneJob: MessageFns<CloneJob> = {
  encode(message: CloneJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.computeEngineTargetDetails !== undefined) {
      ComputeEngineTargetDetails.encode(message.computeEngineTargetDetails, writer.uint32(162).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(178).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.state !== 0) {
      writer.uint32(96).int32(message.state);
    }
    if (message.stateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.stateTime), writer.uint32(114).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(138).fork()).join();
    }
    for (const v of message.steps) {
      CloneStep.encode(v!, writer.uint32(186).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloneJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloneJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 20: {
          if (tag !== 162) {
            break;
          }

          message.computeEngineTargetDetails = ComputeEngineTargetDetails.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 22: {
          if (tag !== 178) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.stateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 23: {
          if (tag !== 186) {
            break;
          }

          message.steps.push(CloneStep.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloneJob {
    return {
      computeEngineTargetDetails: isSet(object.computeEngineTargetDetails)
        ? ComputeEngineTargetDetails.fromJSON(object.computeEngineTargetDetails)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      state: isSet(object.state) ? cloneJob_StateFromJSON(object.state) : 0,
      stateTime: isSet(object.stateTime) ? fromJsonTimestamp(object.stateTime) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      steps: globalThis.Array.isArray(object?.steps) ? object.steps.map((e: any) => CloneStep.fromJSON(e)) : [],
    };
  },

  toJSON(message: CloneJob): unknown {
    const obj: any = {};
    if (message.computeEngineTargetDetails !== undefined) {
      obj.computeEngineTargetDetails = ComputeEngineTargetDetails.toJSON(message.computeEngineTargetDetails);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.state !== 0) {
      obj.state = cloneJob_StateToJSON(message.state);
    }
    if (message.stateTime !== undefined) {
      obj.stateTime = message.stateTime.toISOString();
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.steps?.length) {
      obj.steps = message.steps.map((e) => CloneStep.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloneJob>, I>>(base?: I): CloneJob {
    return CloneJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloneJob>, I>>(object: I): CloneJob {
    const message = createBaseCloneJob();
    message.computeEngineTargetDetails =
      (object.computeEngineTargetDetails !== undefined && object.computeEngineTargetDetails !== null)
        ? ComputeEngineTargetDetails.fromPartial(object.computeEngineTargetDetails)
        : undefined;
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.name = object.name ?? "";
    message.state = object.state ?? 0;
    message.stateTime = object.stateTime ?? undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.steps = object.steps?.map((e) => CloneStep.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCloneStep(): CloneStep {
  return {
    adaptingOs: undefined,
    preparingVmDisks: undefined,
    instantiatingMigratedVm: undefined,
    startTime: undefined,
    endTime: undefined,
  };
}

export const CloneStep: MessageFns<CloneStep> = {
  encode(message: CloneStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.adaptingOs !== undefined) {
      AdaptingOSStep.encode(message.adaptingOs, writer.uint32(26).fork()).join();
    }
    if (message.preparingVmDisks !== undefined) {
      PreparingVMDisksStep.encode(message.preparingVmDisks, writer.uint32(34).fork()).join();
    }
    if (message.instantiatingMigratedVm !== undefined) {
      InstantiatingMigratedVMStep.encode(message.instantiatingMigratedVm, writer.uint32(42).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloneStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloneStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.adaptingOs = AdaptingOSStep.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.preparingVmDisks = PreparingVMDisksStep.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.instantiatingMigratedVm = InstantiatingMigratedVMStep.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloneStep {
    return {
      adaptingOs: isSet(object.adaptingOs) ? AdaptingOSStep.fromJSON(object.adaptingOs) : undefined,
      preparingVmDisks: isSet(object.preparingVmDisks)
        ? PreparingVMDisksStep.fromJSON(object.preparingVmDisks)
        : undefined,
      instantiatingMigratedVm: isSet(object.instantiatingMigratedVm)
        ? InstantiatingMigratedVMStep.fromJSON(object.instantiatingMigratedVm)
        : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: CloneStep): unknown {
    const obj: any = {};
    if (message.adaptingOs !== undefined) {
      obj.adaptingOs = AdaptingOSStep.toJSON(message.adaptingOs);
    }
    if (message.preparingVmDisks !== undefined) {
      obj.preparingVmDisks = PreparingVMDisksStep.toJSON(message.preparingVmDisks);
    }
    if (message.instantiatingMigratedVm !== undefined) {
      obj.instantiatingMigratedVm = InstantiatingMigratedVMStep.toJSON(message.instantiatingMigratedVm);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloneStep>, I>>(base?: I): CloneStep {
    return CloneStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloneStep>, I>>(object: I): CloneStep {
    const message = createBaseCloneStep();
    message.adaptingOs = (object.adaptingOs !== undefined && object.adaptingOs !== null)
      ? AdaptingOSStep.fromPartial(object.adaptingOs)
      : undefined;
    message.preparingVmDisks = (object.preparingVmDisks !== undefined && object.preparingVmDisks !== null)
      ? PreparingVMDisksStep.fromPartial(object.preparingVmDisks)
      : undefined;
    message.instantiatingMigratedVm =
      (object.instantiatingMigratedVm !== undefined && object.instantiatingMigratedVm !== null)
        ? InstantiatingMigratedVMStep.fromPartial(object.instantiatingMigratedVm)
        : undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseAdaptingOSStep(): AdaptingOSStep {
  return {};
}

export const AdaptingOSStep: MessageFns<AdaptingOSStep> = {
  encode(_: AdaptingOSStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AdaptingOSStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAdaptingOSStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): AdaptingOSStep {
    return {};
  },

  toJSON(_: AdaptingOSStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<AdaptingOSStep>, I>>(base?: I): AdaptingOSStep {
    return AdaptingOSStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AdaptingOSStep>, I>>(_: I): AdaptingOSStep {
    const message = createBaseAdaptingOSStep();
    return message;
  },
};

function createBasePreparingVMDisksStep(): PreparingVMDisksStep {
  return {};
}

export const PreparingVMDisksStep: MessageFns<PreparingVMDisksStep> = {
  encode(_: PreparingVMDisksStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PreparingVMDisksStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePreparingVMDisksStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): PreparingVMDisksStep {
    return {};
  },

  toJSON(_: PreparingVMDisksStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<PreparingVMDisksStep>, I>>(base?: I): PreparingVMDisksStep {
    return PreparingVMDisksStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PreparingVMDisksStep>, I>>(_: I): PreparingVMDisksStep {
    const message = createBasePreparingVMDisksStep();
    return message;
  },
};

function createBaseInstantiatingMigratedVMStep(): InstantiatingMigratedVMStep {
  return {};
}

export const InstantiatingMigratedVMStep: MessageFns<InstantiatingMigratedVMStep> = {
  encode(_: InstantiatingMigratedVMStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): InstantiatingMigratedVMStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseInstantiatingMigratedVMStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): InstantiatingMigratedVMStep {
    return {};
  },

  toJSON(_: InstantiatingMigratedVMStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<InstantiatingMigratedVMStep>, I>>(base?: I): InstantiatingMigratedVMStep {
    return InstantiatingMigratedVMStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<InstantiatingMigratedVMStep>, I>>(_: I): InstantiatingMigratedVMStep {
    const message = createBaseInstantiatingMigratedVMStep();
    return message;
  },
};

function createBaseCutoverJob(): CutoverJob {
  return {
    computeEngineTargetDetails: undefined,
    createTime: undefined,
    endTime: undefined,
    name: "",
    state: 0,
    stateTime: undefined,
    progressPercent: 0,
    error: undefined,
    stateMessage: "",
    steps: [],
  };
}

export const CutoverJob: MessageFns<CutoverJob> = {
  encode(message: CutoverJob, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.computeEngineTargetDetails !== undefined) {
      ComputeEngineTargetDetails.encode(message.computeEngineTargetDetails, writer.uint32(114).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(130).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.state !== 0) {
      writer.uint32(40).int32(message.state);
    }
    if (message.stateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.stateTime), writer.uint32(50).fork()).join();
    }
    if (message.progressPercent !== 0) {
      writer.uint32(104).int32(message.progressPercent);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(74).fork()).join();
    }
    if (message.stateMessage !== "") {
      writer.uint32(82).string(message.stateMessage);
    }
    for (const v of message.steps) {
      CutoverStep.encode(v!, writer.uint32(138).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CutoverJob {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCutoverJob();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.computeEngineTargetDetails = ComputeEngineTargetDetails.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.stateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.progressPercent = reader.int32();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.stateMessage = reader.string();
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.steps.push(CutoverStep.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CutoverJob {
    return {
      computeEngineTargetDetails: isSet(object.computeEngineTargetDetails)
        ? ComputeEngineTargetDetails.fromJSON(object.computeEngineTargetDetails)
        : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      state: isSet(object.state) ? cutoverJob_StateFromJSON(object.state) : 0,
      stateTime: isSet(object.stateTime) ? fromJsonTimestamp(object.stateTime) : undefined,
      progressPercent: isSet(object.progressPercent) ? globalThis.Number(object.progressPercent) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      stateMessage: isSet(object.stateMessage) ? globalThis.String(object.stateMessage) : "",
      steps: globalThis.Array.isArray(object?.steps) ? object.steps.map((e: any) => CutoverStep.fromJSON(e)) : [],
    };
  },

  toJSON(message: CutoverJob): unknown {
    const obj: any = {};
    if (message.computeEngineTargetDetails !== undefined) {
      obj.computeEngineTargetDetails = ComputeEngineTargetDetails.toJSON(message.computeEngineTargetDetails);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.state !== 0) {
      obj.state = cutoverJob_StateToJSON(message.state);
    }
    if (message.stateTime !== undefined) {
      obj.stateTime = message.stateTime.toISOString();
    }
    if (message.progressPercent !== 0) {
      obj.progressPercent = Math.round(message.progressPercent);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.stateMessage !== "") {
      obj.stateMessage = message.stateMessage;
    }
    if (message.steps?.length) {
      obj.steps = message.steps.map((e) => CutoverStep.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CutoverJob>, I>>(base?: I): CutoverJob {
    return CutoverJob.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CutoverJob>, I>>(object: I): CutoverJob {
    const message = createBaseCutoverJob();
    message.computeEngineTargetDetails =
      (object.computeEngineTargetDetails !== undefined && object.computeEngineTargetDetails !== null)
        ? ComputeEngineTargetDetails.fromPartial(object.computeEngineTargetDetails)
        : undefined;
    message.createTime = object.createTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    message.name = object.name ?? "";
    message.state = object.state ?? 0;
    message.stateTime = object.stateTime ?? undefined;
    message.progressPercent = object.progressPercent ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.stateMessage = object.stateMessage ?? "";
    message.steps = object.steps?.map((e) => CutoverStep.fromPartial(e)) || [];
    return message;
  },
};

function createBaseCutoverStep(): CutoverStep {
  return {
    previousReplicationCycle: undefined,
    shuttingDownSourceVm: undefined,
    finalSync: undefined,
    preparingVmDisks: undefined,
    instantiatingMigratedVm: undefined,
    startTime: undefined,
    endTime: undefined,
  };
}

export const CutoverStep: MessageFns<CutoverStep> = {
  encode(message: CutoverStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.previousReplicationCycle !== undefined) {
      ReplicationCycle.encode(message.previousReplicationCycle, writer.uint32(26).fork()).join();
    }
    if (message.shuttingDownSourceVm !== undefined) {
      ShuttingDownSourceVMStep.encode(message.shuttingDownSourceVm, writer.uint32(34).fork()).join();
    }
    if (message.finalSync !== undefined) {
      ReplicationCycle.encode(message.finalSync, writer.uint32(42).fork()).join();
    }
    if (message.preparingVmDisks !== undefined) {
      PreparingVMDisksStep.encode(message.preparingVmDisks, writer.uint32(50).fork()).join();
    }
    if (message.instantiatingMigratedVm !== undefined) {
      InstantiatingMigratedVMStep.encode(message.instantiatingMigratedVm, writer.uint32(58).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(10).fork()).join();
    }
    if (message.endTime !== undefined) {
      Timestamp.encode(toTimestamp(message.endTime), writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CutoverStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCutoverStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.previousReplicationCycle = ReplicationCycle.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.shuttingDownSourceVm = ShuttingDownSourceVMStep.decode(reader, reader.uint32());
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.finalSync = ReplicationCycle.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.preparingVmDisks = PreparingVMDisksStep.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.instantiatingMigratedVm = InstantiatingMigratedVMStep.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.endTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CutoverStep {
    return {
      previousReplicationCycle: isSet(object.previousReplicationCycle)
        ? ReplicationCycle.fromJSON(object.previousReplicationCycle)
        : undefined,
      shuttingDownSourceVm: isSet(object.shuttingDownSourceVm)
        ? ShuttingDownSourceVMStep.fromJSON(object.shuttingDownSourceVm)
        : undefined,
      finalSync: isSet(object.finalSync) ? ReplicationCycle.fromJSON(object.finalSync) : undefined,
      preparingVmDisks: isSet(object.preparingVmDisks)
        ? PreparingVMDisksStep.fromJSON(object.preparingVmDisks)
        : undefined,
      instantiatingMigratedVm: isSet(object.instantiatingMigratedVm)
        ? InstantiatingMigratedVMStep.fromJSON(object.instantiatingMigratedVm)
        : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      endTime: isSet(object.endTime) ? fromJsonTimestamp(object.endTime) : undefined,
    };
  },

  toJSON(message: CutoverStep): unknown {
    const obj: any = {};
    if (message.previousReplicationCycle !== undefined) {
      obj.previousReplicationCycle = ReplicationCycle.toJSON(message.previousReplicationCycle);
    }
    if (message.shuttingDownSourceVm !== undefined) {
      obj.shuttingDownSourceVm = ShuttingDownSourceVMStep.toJSON(message.shuttingDownSourceVm);
    }
    if (message.finalSync !== undefined) {
      obj.finalSync = ReplicationCycle.toJSON(message.finalSync);
    }
    if (message.preparingVmDisks !== undefined) {
      obj.preparingVmDisks = PreparingVMDisksStep.toJSON(message.preparingVmDisks);
    }
    if (message.instantiatingMigratedVm !== undefined) {
      obj.instantiatingMigratedVm = InstantiatingMigratedVMStep.toJSON(message.instantiatingMigratedVm);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.endTime !== undefined) {
      obj.endTime = message.endTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CutoverStep>, I>>(base?: I): CutoverStep {
    return CutoverStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CutoverStep>, I>>(object: I): CutoverStep {
    const message = createBaseCutoverStep();
    message.previousReplicationCycle =
      (object.previousReplicationCycle !== undefined && object.previousReplicationCycle !== null)
        ? ReplicationCycle.fromPartial(object.previousReplicationCycle)
        : undefined;
    message.shuttingDownSourceVm = (object.shuttingDownSourceVm !== undefined && object.shuttingDownSourceVm !== null)
      ? ShuttingDownSourceVMStep.fromPartial(object.shuttingDownSourceVm)
      : undefined;
    message.finalSync = (object.finalSync !== undefined && object.finalSync !== null)
      ? ReplicationCycle.fromPartial(object.finalSync)
      : undefined;
    message.preparingVmDisks = (object.preparingVmDisks !== undefined && object.preparingVmDisks !== null)
      ? PreparingVMDisksStep.fromPartial(object.preparingVmDisks)
      : undefined;
    message.instantiatingMigratedVm =
      (object.instantiatingMigratedVm !== undefined && object.instantiatingMigratedVm !== null)
        ? InstantiatingMigratedVMStep.fromPartial(object.instantiatingMigratedVm)
        : undefined;
    message.startTime = object.startTime ?? undefined;
    message.endTime = object.endTime ?? undefined;
    return message;
  },
};

function createBaseShuttingDownSourceVMStep(): ShuttingDownSourceVMStep {
  return {};
}

export const ShuttingDownSourceVMStep: MessageFns<ShuttingDownSourceVMStep> = {
  encode(_: ShuttingDownSourceVMStep, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ShuttingDownSourceVMStep {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseShuttingDownSourceVMStep();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(_: any): ShuttingDownSourceVMStep {
    return {};
  },

  toJSON(_: ShuttingDownSourceVMStep): unknown {
    const obj: any = {};
    return obj;
  },

  create<I extends Exact<DeepPartial<ShuttingDownSourceVMStep>, I>>(base?: I): ShuttingDownSourceVMStep {
    return ShuttingDownSourceVMStep.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ShuttingDownSourceVMStep>, I>>(_: I): ShuttingDownSourceVMStep {
    const message = createBaseShuttingDownSourceVMStep();
    return message;
  },
};

function createBaseSource(): Source {
  return {
    vmware: undefined,
    aws: undefined,
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    description: "",
  };
}

export const Source: MessageFns<Source> = {
  encode(message: Source, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmware !== undefined) {
      VmwareSourceDetails.encode(message.vmware, writer.uint32(82).fork()).join();
    }
    if (message.aws !== undefined) {
      AwsSourceDetails.encode(message.aws, writer.uint32(98).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Source_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    if (message.description !== "") {
      writer.uint32(50).string(message.description);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.vmware = VmwareSourceDetails.decode(reader, reader.uint32());
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.aws = AwsSourceDetails.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Source_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.description = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source {
    return {
      vmware: isSet(object.vmware) ? VmwareSourceDetails.fromJSON(object.vmware) : undefined,
      aws: isSet(object.aws) ? AwsSourceDetails.fromJSON(object.aws) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      description: isSet(object.description) ? globalThis.String(object.description) : "",
    };
  },

  toJSON(message: Source): unknown {
    const obj: any = {};
    if (message.vmware !== undefined) {
      obj.vmware = VmwareSourceDetails.toJSON(message.vmware);
    }
    if (message.aws !== undefined) {
      obj.aws = AwsSourceDetails.toJSON(message.aws);
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Source>, I>>(base?: I): Source {
    return Source.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Source>, I>>(object: I): Source {
    const message = createBaseSource();
    message.vmware = (object.vmware !== undefined && object.vmware !== null)
      ? VmwareSourceDetails.fromPartial(object.vmware)
      : undefined;
    message.aws = (object.aws !== undefined && object.aws !== null)
      ? AwsSourceDetails.fromPartial(object.aws)
      : undefined;
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.description = object.description ?? "";
    return message;
  },
};

function createBaseSource_LabelsEntry(): Source_LabelsEntry {
  return { key: "", value: "" };
}

export const Source_LabelsEntry: MessageFns<Source_LabelsEntry> = {
  encode(message: Source_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Source_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Source_LabelsEntry>, I>>(base?: I): Source_LabelsEntry {
    return Source_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Source_LabelsEntry>, I>>(object: I): Source_LabelsEntry {
    const message = createBaseSource_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseVmwareSourceDetails(): VmwareSourceDetails {
  return { username: "", vcenterIp: "", thumbprint: "", resolvedVcenterHost: "" };
}

export const VmwareSourceDetails: MessageFns<VmwareSourceDetails> = {
  encode(message: VmwareSourceDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.username !== "") {
      writer.uint32(10).string(message.username);
    }
    if (message.vcenterIp !== "") {
      writer.uint32(26).string(message.vcenterIp);
    }
    if (message.thumbprint !== "") {
      writer.uint32(34).string(message.thumbprint);
    }
    if (message.resolvedVcenterHost !== "") {
      writer.uint32(42).string(message.resolvedVcenterHost);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VmwareSourceDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVmwareSourceDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.username = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.vcenterIp = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.thumbprint = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.resolvedVcenterHost = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VmwareSourceDetails {
    return {
      username: isSet(object.username) ? globalThis.String(object.username) : "",
      vcenterIp: isSet(object.vcenterIp) ? globalThis.String(object.vcenterIp) : "",
      thumbprint: isSet(object.thumbprint) ? globalThis.String(object.thumbprint) : "",
      resolvedVcenterHost: isSet(object.resolvedVcenterHost) ? globalThis.String(object.resolvedVcenterHost) : "",
    };
  },

  toJSON(message: VmwareSourceDetails): unknown {
    const obj: any = {};
    if (message.username !== "") {
      obj.username = message.username;
    }
    if (message.vcenterIp !== "") {
      obj.vcenterIp = message.vcenterIp;
    }
    if (message.thumbprint !== "") {
      obj.thumbprint = message.thumbprint;
    }
    if (message.resolvedVcenterHost !== "") {
      obj.resolvedVcenterHost = message.resolvedVcenterHost;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<VmwareSourceDetails>, I>>(base?: I): VmwareSourceDetails {
    return VmwareSourceDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VmwareSourceDetails>, I>>(object: I): VmwareSourceDetails {
    const message = createBaseVmwareSourceDetails();
    message.username = object.username ?? "";
    message.vcenterIp = object.vcenterIp ?? "";
    message.thumbprint = object.thumbprint ?? "";
    message.resolvedVcenterHost = object.resolvedVcenterHost ?? "";
    return message;
  },
};

function createBaseAwsSourceDetails(): AwsSourceDetails {
  return {
    accessKeyCreds: undefined,
    awsRegion: "",
    state: 0,
    error: undefined,
    inventoryTagList: [],
    inventorySecurityGroupNames: [],
    migrationResourcesUserTags: {},
    publicIp: "",
  };
}

export const AwsSourceDetails: MessageFns<AwsSourceDetails> = {
  encode(message: AwsSourceDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accessKeyCreds !== undefined) {
      AwsSourceDetails_AccessKeyCredentials.encode(message.accessKeyCreds, writer.uint32(90).fork()).join();
    }
    if (message.awsRegion !== "") {
      writer.uint32(26).string(message.awsRegion);
    }
    if (message.state !== 0) {
      writer.uint32(32).int32(message.state);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(42).fork()).join();
    }
    for (const v of message.inventoryTagList) {
      AwsSourceDetails_Tag.encode(v!, writer.uint32(82).fork()).join();
    }
    for (const v of message.inventorySecurityGroupNames) {
      writer.uint32(58).string(v!);
    }
    Object.entries(message.migrationResourcesUserTags).forEach(([key, value]) => {
      AwsSourceDetails_MigrationResourcesUserTagsEntry.encode({ key: key as any, value }, writer.uint32(66).fork())
        .join();
    });
    if (message.publicIp !== "") {
      writer.uint32(74).string(message.publicIp);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.accessKeyCreds = AwsSourceDetails_AccessKeyCredentials.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.awsRegion = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.inventoryTagList.push(AwsSourceDetails_Tag.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.inventorySecurityGroupNames.push(reader.string());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          const entry8 = AwsSourceDetails_MigrationResourcesUserTagsEntry.decode(reader, reader.uint32());
          if (entry8.value !== undefined) {
            message.migrationResourcesUserTags[entry8.key] = entry8.value;
          }
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.publicIp = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceDetails {
    return {
      accessKeyCreds: isSet(object.accessKeyCreds)
        ? AwsSourceDetails_AccessKeyCredentials.fromJSON(object.accessKeyCreds)
        : undefined,
      awsRegion: isSet(object.awsRegion) ? globalThis.String(object.awsRegion) : "",
      state: isSet(object.state) ? awsSourceDetails_StateFromJSON(object.state) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      inventoryTagList: globalThis.Array.isArray(object?.inventoryTagList)
        ? object.inventoryTagList.map((e: any) => AwsSourceDetails_Tag.fromJSON(e))
        : [],
      inventorySecurityGroupNames: globalThis.Array.isArray(object?.inventorySecurityGroupNames)
        ? object.inventorySecurityGroupNames.map((e: any) => globalThis.String(e))
        : [],
      migrationResourcesUserTags: isObject(object.migrationResourcesUserTags)
        ? Object.entries(object.migrationResourcesUserTags).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      publicIp: isSet(object.publicIp) ? globalThis.String(object.publicIp) : "",
    };
  },

  toJSON(message: AwsSourceDetails): unknown {
    const obj: any = {};
    if (message.accessKeyCreds !== undefined) {
      obj.accessKeyCreds = AwsSourceDetails_AccessKeyCredentials.toJSON(message.accessKeyCreds);
    }
    if (message.awsRegion !== "") {
      obj.awsRegion = message.awsRegion;
    }
    if (message.state !== 0) {
      obj.state = awsSourceDetails_StateToJSON(message.state);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.inventoryTagList?.length) {
      obj.inventoryTagList = message.inventoryTagList.map((e) => AwsSourceDetails_Tag.toJSON(e));
    }
    if (message.inventorySecurityGroupNames?.length) {
      obj.inventorySecurityGroupNames = message.inventorySecurityGroupNames;
    }
    if (message.migrationResourcesUserTags) {
      const entries = Object.entries(message.migrationResourcesUserTags);
      if (entries.length > 0) {
        obj.migrationResourcesUserTags = {};
        entries.forEach(([k, v]) => {
          obj.migrationResourcesUserTags[k] = v;
        });
      }
    }
    if (message.publicIp !== "") {
      obj.publicIp = message.publicIp;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceDetails>, I>>(base?: I): AwsSourceDetails {
    return AwsSourceDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceDetails>, I>>(object: I): AwsSourceDetails {
    const message = createBaseAwsSourceDetails();
    message.accessKeyCreds = (object.accessKeyCreds !== undefined && object.accessKeyCreds !== null)
      ? AwsSourceDetails_AccessKeyCredentials.fromPartial(object.accessKeyCreds)
      : undefined;
    message.awsRegion = object.awsRegion ?? "";
    message.state = object.state ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.inventoryTagList = object.inventoryTagList?.map((e) => AwsSourceDetails_Tag.fromPartial(e)) || [];
    message.inventorySecurityGroupNames = object.inventorySecurityGroupNames?.map((e) => e) || [];
    message.migrationResourcesUserTags = Object.entries(object.migrationResourcesUserTags ?? {}).reduce<
      { [key: string]: string }
    >((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.publicIp = object.publicIp ?? "";
    return message;
  },
};

function createBaseAwsSourceDetails_AccessKeyCredentials(): AwsSourceDetails_AccessKeyCredentials {
  return { accessKeyId: "" };
}

export const AwsSourceDetails_AccessKeyCredentials: MessageFns<AwsSourceDetails_AccessKeyCredentials> = {
  encode(message: AwsSourceDetails_AccessKeyCredentials, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.accessKeyId !== "") {
      writer.uint32(10).string(message.accessKeyId);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceDetails_AccessKeyCredentials {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceDetails_AccessKeyCredentials();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.accessKeyId = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceDetails_AccessKeyCredentials {
    return { accessKeyId: isSet(object.accessKeyId) ? globalThis.String(object.accessKeyId) : "" };
  },

  toJSON(message: AwsSourceDetails_AccessKeyCredentials): unknown {
    const obj: any = {};
    if (message.accessKeyId !== "") {
      obj.accessKeyId = message.accessKeyId;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceDetails_AccessKeyCredentials>, I>>(
    base?: I,
  ): AwsSourceDetails_AccessKeyCredentials {
    return AwsSourceDetails_AccessKeyCredentials.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceDetails_AccessKeyCredentials>, I>>(
    object: I,
  ): AwsSourceDetails_AccessKeyCredentials {
    const message = createBaseAwsSourceDetails_AccessKeyCredentials();
    message.accessKeyId = object.accessKeyId ?? "";
    return message;
  },
};

function createBaseAwsSourceDetails_Tag(): AwsSourceDetails_Tag {
  return { key: "", value: "" };
}

export const AwsSourceDetails_Tag: MessageFns<AwsSourceDetails_Tag> = {
  encode(message: AwsSourceDetails_Tag, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceDetails_Tag {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceDetails_Tag();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceDetails_Tag {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsSourceDetails_Tag): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceDetails_Tag>, I>>(base?: I): AwsSourceDetails_Tag {
    return AwsSourceDetails_Tag.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceDetails_Tag>, I>>(object: I): AwsSourceDetails_Tag {
    const message = createBaseAwsSourceDetails_Tag();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseAwsSourceDetails_MigrationResourcesUserTagsEntry(): AwsSourceDetails_MigrationResourcesUserTagsEntry {
  return { key: "", value: "" };
}

export const AwsSourceDetails_MigrationResourcesUserTagsEntry: MessageFns<
  AwsSourceDetails_MigrationResourcesUserTagsEntry
> = {
  encode(
    message: AwsSourceDetails_MigrationResourcesUserTagsEntry,
    writer: BinaryWriter = new BinaryWriter(),
  ): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceDetails_MigrationResourcesUserTagsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceDetails_MigrationResourcesUserTagsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceDetails_MigrationResourcesUserTagsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: AwsSourceDetails_MigrationResourcesUserTagsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceDetails_MigrationResourcesUserTagsEntry>, I>>(
    base?: I,
  ): AwsSourceDetails_MigrationResourcesUserTagsEntry {
    return AwsSourceDetails_MigrationResourcesUserTagsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceDetails_MigrationResourcesUserTagsEntry>, I>>(
    object: I,
  ): AwsSourceDetails_MigrationResourcesUserTagsEntry {
    const message = createBaseAwsSourceDetails_MigrationResourcesUserTagsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDatacenterConnector(): DatacenterConnector {
  return {
    createTime: undefined,
    updateTime: undefined,
    name: "",
    registrationId: "",
    serviceAccount: "",
    version: "",
    bucket: "",
    state: 0,
    stateTime: undefined,
    error: undefined,
    applianceInfrastructureVersion: "",
    applianceSoftwareVersion: "",
    availableVersions: undefined,
    upgradeStatus: undefined,
  };
}

export const DatacenterConnector: MessageFns<DatacenterConnector> = {
  encode(message: DatacenterConnector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(10).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(18).fork()).join();
    }
    if (message.name !== "") {
      writer.uint32(26).string(message.name);
    }
    if (message.registrationId !== "") {
      writer.uint32(98).string(message.registrationId);
    }
    if (message.serviceAccount !== "") {
      writer.uint32(42).string(message.serviceAccount);
    }
    if (message.version !== "") {
      writer.uint32(50).string(message.version);
    }
    if (message.bucket !== "") {
      writer.uint32(82).string(message.bucket);
    }
    if (message.state !== 0) {
      writer.uint32(56).int32(message.state);
    }
    if (message.stateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.stateTime), writer.uint32(66).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(90).fork()).join();
    }
    if (message.applianceInfrastructureVersion !== "") {
      writer.uint32(106).string(message.applianceInfrastructureVersion);
    }
    if (message.applianceSoftwareVersion !== "") {
      writer.uint32(114).string(message.applianceSoftwareVersion);
    }
    if (message.availableVersions !== undefined) {
      AvailableUpdates.encode(message.availableVersions, writer.uint32(122).fork()).join();
    }
    if (message.upgradeStatus !== undefined) {
      UpgradeStatus.encode(message.upgradeStatus, writer.uint32(130).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatacenterConnector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatacenterConnector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.registrationId = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.bucket = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.stateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.applianceInfrastructureVersion = reader.string();
          continue;
        }
        case 14: {
          if (tag !== 114) {
            break;
          }

          message.applianceSoftwareVersion = reader.string();
          continue;
        }
        case 15: {
          if (tag !== 122) {
            break;
          }

          message.availableVersions = AvailableUpdates.decode(reader, reader.uint32());
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          message.upgradeStatus = UpgradeStatus.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatacenterConnector {
    return {
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      registrationId: isSet(object.registrationId) ? globalThis.String(object.registrationId) : "",
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      bucket: isSet(object.bucket) ? globalThis.String(object.bucket) : "",
      state: isSet(object.state) ? datacenterConnector_StateFromJSON(object.state) : 0,
      stateTime: isSet(object.stateTime) ? fromJsonTimestamp(object.stateTime) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      applianceInfrastructureVersion: isSet(object.applianceInfrastructureVersion)
        ? globalThis.String(object.applianceInfrastructureVersion)
        : "",
      applianceSoftwareVersion: isSet(object.applianceSoftwareVersion)
        ? globalThis.String(object.applianceSoftwareVersion)
        : "",
      availableVersions: isSet(object.availableVersions)
        ? AvailableUpdates.fromJSON(object.availableVersions)
        : undefined,
      upgradeStatus: isSet(object.upgradeStatus) ? UpgradeStatus.fromJSON(object.upgradeStatus) : undefined,
    };
  },

  toJSON(message: DatacenterConnector): unknown {
    const obj: any = {};
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.registrationId !== "") {
      obj.registrationId = message.registrationId;
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.bucket !== "") {
      obj.bucket = message.bucket;
    }
    if (message.state !== 0) {
      obj.state = datacenterConnector_StateToJSON(message.state);
    }
    if (message.stateTime !== undefined) {
      obj.stateTime = message.stateTime.toISOString();
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.applianceInfrastructureVersion !== "") {
      obj.applianceInfrastructureVersion = message.applianceInfrastructureVersion;
    }
    if (message.applianceSoftwareVersion !== "") {
      obj.applianceSoftwareVersion = message.applianceSoftwareVersion;
    }
    if (message.availableVersions !== undefined) {
      obj.availableVersions = AvailableUpdates.toJSON(message.availableVersions);
    }
    if (message.upgradeStatus !== undefined) {
      obj.upgradeStatus = UpgradeStatus.toJSON(message.upgradeStatus);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DatacenterConnector>, I>>(base?: I): DatacenterConnector {
    return DatacenterConnector.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DatacenterConnector>, I>>(object: I): DatacenterConnector {
    const message = createBaseDatacenterConnector();
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.name = object.name ?? "";
    message.registrationId = object.registrationId ?? "";
    message.serviceAccount = object.serviceAccount ?? "";
    message.version = object.version ?? "";
    message.bucket = object.bucket ?? "";
    message.state = object.state ?? 0;
    message.stateTime = object.stateTime ?? undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.applianceInfrastructureVersion = object.applianceInfrastructureVersion ?? "";
    message.applianceSoftwareVersion = object.applianceSoftwareVersion ?? "";
    message.availableVersions = (object.availableVersions !== undefined && object.availableVersions !== null)
      ? AvailableUpdates.fromPartial(object.availableVersions)
      : undefined;
    message.upgradeStatus = (object.upgradeStatus !== undefined && object.upgradeStatus !== null)
      ? UpgradeStatus.fromPartial(object.upgradeStatus)
      : undefined;
    return message;
  },
};

function createBaseUpgradeStatus(): UpgradeStatus {
  return { version: "", state: 0, error: undefined, startTime: undefined, previousVersion: "" };
}

export const UpgradeStatus: MessageFns<UpgradeStatus> = {
  encode(message: UpgradeStatus, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.state !== 0) {
      writer.uint32(16).int32(message.state);
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(26).fork()).join();
    }
    if (message.startTime !== undefined) {
      Timestamp.encode(toTimestamp(message.startTime), writer.uint32(34).fork()).join();
    }
    if (message.previousVersion !== "") {
      writer.uint32(42).string(message.previousVersion);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UpgradeStatus {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUpgradeStatus();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.startTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.previousVersion = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UpgradeStatus {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      state: isSet(object.state) ? upgradeStatus_StateFromJSON(object.state) : 0,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      startTime: isSet(object.startTime) ? fromJsonTimestamp(object.startTime) : undefined,
      previousVersion: isSet(object.previousVersion) ? globalThis.String(object.previousVersion) : "",
    };
  },

  toJSON(message: UpgradeStatus): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.state !== 0) {
      obj.state = upgradeStatus_StateToJSON(message.state);
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.startTime !== undefined) {
      obj.startTime = message.startTime.toISOString();
    }
    if (message.previousVersion !== "") {
      obj.previousVersion = message.previousVersion;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<UpgradeStatus>, I>>(base?: I): UpgradeStatus {
    return UpgradeStatus.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<UpgradeStatus>, I>>(object: I): UpgradeStatus {
    const message = createBaseUpgradeStatus();
    message.version = object.version ?? "";
    message.state = object.state ?? 0;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.startTime = object.startTime ?? undefined;
    message.previousVersion = object.previousVersion ?? "";
    return message;
  },
};

function createBaseAvailableUpdates(): AvailableUpdates {
  return { newDeployableAppliance: undefined, inPlaceUpdate: undefined };
}

export const AvailableUpdates: MessageFns<AvailableUpdates> = {
  encode(message: AvailableUpdates, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.newDeployableAppliance !== undefined) {
      ApplianceVersion.encode(message.newDeployableAppliance, writer.uint32(10).fork()).join();
    }
    if (message.inPlaceUpdate !== undefined) {
      ApplianceVersion.encode(message.inPlaceUpdate, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AvailableUpdates {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAvailableUpdates();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.newDeployableAppliance = ApplianceVersion.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.inPlaceUpdate = ApplianceVersion.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AvailableUpdates {
    return {
      newDeployableAppliance: isSet(object.newDeployableAppliance)
        ? ApplianceVersion.fromJSON(object.newDeployableAppliance)
        : undefined,
      inPlaceUpdate: isSet(object.inPlaceUpdate) ? ApplianceVersion.fromJSON(object.inPlaceUpdate) : undefined,
    };
  },

  toJSON(message: AvailableUpdates): unknown {
    const obj: any = {};
    if (message.newDeployableAppliance !== undefined) {
      obj.newDeployableAppliance = ApplianceVersion.toJSON(message.newDeployableAppliance);
    }
    if (message.inPlaceUpdate !== undefined) {
      obj.inPlaceUpdate = ApplianceVersion.toJSON(message.inPlaceUpdate);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AvailableUpdates>, I>>(base?: I): AvailableUpdates {
    return AvailableUpdates.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AvailableUpdates>, I>>(object: I): AvailableUpdates {
    const message = createBaseAvailableUpdates();
    message.newDeployableAppliance =
      (object.newDeployableAppliance !== undefined && object.newDeployableAppliance !== null)
        ? ApplianceVersion.fromPartial(object.newDeployableAppliance)
        : undefined;
    message.inPlaceUpdate = (object.inPlaceUpdate !== undefined && object.inPlaceUpdate !== null)
      ? ApplianceVersion.fromPartial(object.inPlaceUpdate)
      : undefined;
    return message;
  },
};

function createBaseApplianceVersion(): ApplianceVersion {
  return { version: "", uri: "", critical: false, releaseNotesUri: "" };
}

export const ApplianceVersion: MessageFns<ApplianceVersion> = {
  encode(message: ApplianceVersion, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.version !== "") {
      writer.uint32(10).string(message.version);
    }
    if (message.uri !== "") {
      writer.uint32(18).string(message.uri);
    }
    if (message.critical !== false) {
      writer.uint32(24).bool(message.critical);
    }
    if (message.releaseNotesUri !== "") {
      writer.uint32(34).string(message.releaseNotesUri);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ApplianceVersion {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseApplianceVersion();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.version = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.uri = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.critical = reader.bool();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.releaseNotesUri = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ApplianceVersion {
    return {
      version: isSet(object.version) ? globalThis.String(object.version) : "",
      uri: isSet(object.uri) ? globalThis.String(object.uri) : "",
      critical: isSet(object.critical) ? globalThis.Boolean(object.critical) : false,
      releaseNotesUri: isSet(object.releaseNotesUri) ? globalThis.String(object.releaseNotesUri) : "",
    };
  },

  toJSON(message: ApplianceVersion): unknown {
    const obj: any = {};
    if (message.version !== "") {
      obj.version = message.version;
    }
    if (message.uri !== "") {
      obj.uri = message.uri;
    }
    if (message.critical !== false) {
      obj.critical = message.critical;
    }
    if (message.releaseNotesUri !== "") {
      obj.releaseNotesUri = message.releaseNotesUri;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ApplianceVersion>, I>>(base?: I): ApplianceVersion {
    return ApplianceVersion.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ApplianceVersion>, I>>(object: I): ApplianceVersion {
    const message = createBaseApplianceVersion();
    message.version = object.version ?? "";
    message.uri = object.uri ?? "";
    message.critical = object.critical ?? false;
    message.releaseNotesUri = object.releaseNotesUri ?? "";
    return message;
  },
};

function createBaseVmwareVmDetails(): VmwareVmDetails {
  return {
    vmId: "",
    datacenterId: "",
    datacenterDescription: "",
    uuid: "",
    displayName: "",
    powerState: 0,
    cpuCount: 0,
    memoryMb: 0,
    diskCount: 0,
    committedStorageMb: Long.ZERO,
    guestDescription: "",
    bootOption: 0,
  };
}

export const VmwareVmDetails: MessageFns<VmwareVmDetails> = {
  encode(message: VmwareVmDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmId !== "") {
      writer.uint32(10).string(message.vmId);
    }
    if (message.datacenterId !== "") {
      writer.uint32(18).string(message.datacenterId);
    }
    if (message.datacenterDescription !== "") {
      writer.uint32(26).string(message.datacenterDescription);
    }
    if (message.uuid !== "") {
      writer.uint32(34).string(message.uuid);
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    if (message.powerState !== 0) {
      writer.uint32(48).int32(message.powerState);
    }
    if (message.cpuCount !== 0) {
      writer.uint32(56).int32(message.cpuCount);
    }
    if (message.memoryMb !== 0) {
      writer.uint32(64).int32(message.memoryMb);
    }
    if (message.diskCount !== 0) {
      writer.uint32(72).int32(message.diskCount);
    }
    if (!message.committedStorageMb.equals(Long.ZERO)) {
      writer.uint32(96).int64(message.committedStorageMb.toString());
    }
    if (message.guestDescription !== "") {
      writer.uint32(90).string(message.guestDescription);
    }
    if (message.bootOption !== 0) {
      writer.uint32(104).int32(message.bootOption);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VmwareVmDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVmwareVmDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.vmId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.datacenterId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.datacenterDescription = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.uuid = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 48) {
            break;
          }

          message.powerState = reader.int32() as any;
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.cpuCount = reader.int32();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.memoryMb = reader.int32();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.diskCount = reader.int32();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.committedStorageMb = Long.fromString(reader.int64().toString());
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.guestDescription = reader.string();
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.bootOption = reader.int32() as any;
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VmwareVmDetails {
    return {
      vmId: isSet(object.vmId) ? globalThis.String(object.vmId) : "",
      datacenterId: isSet(object.datacenterId) ? globalThis.String(object.datacenterId) : "",
      datacenterDescription: isSet(object.datacenterDescription) ? globalThis.String(object.datacenterDescription) : "",
      uuid: isSet(object.uuid) ? globalThis.String(object.uuid) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      powerState: isSet(object.powerState) ? vmwareVmDetails_PowerStateFromJSON(object.powerState) : 0,
      cpuCount: isSet(object.cpuCount) ? globalThis.Number(object.cpuCount) : 0,
      memoryMb: isSet(object.memoryMb) ? globalThis.Number(object.memoryMb) : 0,
      diskCount: isSet(object.diskCount) ? globalThis.Number(object.diskCount) : 0,
      committedStorageMb: isSet(object.committedStorageMb) ? Long.fromValue(object.committedStorageMb) : Long.ZERO,
      guestDescription: isSet(object.guestDescription) ? globalThis.String(object.guestDescription) : "",
      bootOption: isSet(object.bootOption) ? vmwareVmDetails_BootOptionFromJSON(object.bootOption) : 0,
    };
  },

  toJSON(message: VmwareVmDetails): unknown {
    const obj: any = {};
    if (message.vmId !== "") {
      obj.vmId = message.vmId;
    }
    if (message.datacenterId !== "") {
      obj.datacenterId = message.datacenterId;
    }
    if (message.datacenterDescription !== "") {
      obj.datacenterDescription = message.datacenterDescription;
    }
    if (message.uuid !== "") {
      obj.uuid = message.uuid;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.powerState !== 0) {
      obj.powerState = vmwareVmDetails_PowerStateToJSON(message.powerState);
    }
    if (message.cpuCount !== 0) {
      obj.cpuCount = Math.round(message.cpuCount);
    }
    if (message.memoryMb !== 0) {
      obj.memoryMb = Math.round(message.memoryMb);
    }
    if (message.diskCount !== 0) {
      obj.diskCount = Math.round(message.diskCount);
    }
    if (!message.committedStorageMb.equals(Long.ZERO)) {
      obj.committedStorageMb = (message.committedStorageMb || Long.ZERO).toString();
    }
    if (message.guestDescription !== "") {
      obj.guestDescription = message.guestDescription;
    }
    if (message.bootOption !== 0) {
      obj.bootOption = vmwareVmDetails_BootOptionToJSON(message.bootOption);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<VmwareVmDetails>, I>>(base?: I): VmwareVmDetails {
    return VmwareVmDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VmwareVmDetails>, I>>(object: I): VmwareVmDetails {
    const message = createBaseVmwareVmDetails();
    message.vmId = object.vmId ?? "";
    message.datacenterId = object.datacenterId ?? "";
    message.datacenterDescription = object.datacenterDescription ?? "";
    message.uuid = object.uuid ?? "";
    message.displayName = object.displayName ?? "";
    message.powerState = object.powerState ?? 0;
    message.cpuCount = object.cpuCount ?? 0;
    message.memoryMb = object.memoryMb ?? 0;
    message.diskCount = object.diskCount ?? 0;
    message.committedStorageMb = (object.committedStorageMb !== undefined && object.committedStorageMb !== null)
      ? Long.fromValue(object.committedStorageMb)
      : Long.ZERO;
    message.guestDescription = object.guestDescription ?? "";
    message.bootOption = object.bootOption ?? 0;
    return message;
  },
};

function createBaseUtilizationReport(): UtilizationReport {
  return {
    name: "",
    displayName: "",
    state: 0,
    stateTime: undefined,
    error: undefined,
    createTime: undefined,
    timeFrame: 0,
    frameEndTime: undefined,
    vmCount: 0,
    vms: [],
  };
}

export const UtilizationReport: MessageFns<UtilizationReport> = {
  encode(message: UtilizationReport, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.displayName !== "") {
      writer.uint32(18).string(message.displayName);
    }
    if (message.state !== 0) {
      writer.uint32(24).int32(message.state);
    }
    if (message.stateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.stateTime), writer.uint32(34).fork()).join();
    }
    if (message.error !== undefined) {
      Status.encode(message.error, writer.uint32(42).fork()).join();
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(50).fork()).join();
    }
    if (message.timeFrame !== 0) {
      writer.uint32(56).int32(message.timeFrame);
    }
    if (message.frameEndTime !== undefined) {
      Timestamp.encode(toTimestamp(message.frameEndTime), writer.uint32(66).fork()).join();
    }
    if (message.vmCount !== 0) {
      writer.uint32(72).int32(message.vmCount);
    }
    for (const v of message.vms) {
      VmUtilizationInfo.encode(v!, writer.uint32(82).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UtilizationReport {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUtilizationReport();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.state = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.stateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.error = Status.decode(reader, reader.uint32());
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.timeFrame = reader.int32() as any;
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.frameEndTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.vmCount = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.vms.push(VmUtilizationInfo.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UtilizationReport {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      state: isSet(object.state) ? utilizationReport_StateFromJSON(object.state) : 0,
      stateTime: isSet(object.stateTime) ? fromJsonTimestamp(object.stateTime) : undefined,
      error: isSet(object.error) ? Status.fromJSON(object.error) : undefined,
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      timeFrame: isSet(object.timeFrame) ? utilizationReport_TimeFrameFromJSON(object.timeFrame) : 0,
      frameEndTime: isSet(object.frameEndTime) ? fromJsonTimestamp(object.frameEndTime) : undefined,
      vmCount: isSet(object.vmCount) ? globalThis.Number(object.vmCount) : 0,
      vms: globalThis.Array.isArray(object?.vms) ? object.vms.map((e: any) => VmUtilizationInfo.fromJSON(e)) : [],
    };
  },

  toJSON(message: UtilizationReport): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.state !== 0) {
      obj.state = utilizationReport_StateToJSON(message.state);
    }
    if (message.stateTime !== undefined) {
      obj.stateTime = message.stateTime.toISOString();
    }
    if (message.error !== undefined) {
      obj.error = Status.toJSON(message.error);
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.timeFrame !== 0) {
      obj.timeFrame = utilizationReport_TimeFrameToJSON(message.timeFrame);
    }
    if (message.frameEndTime !== undefined) {
      obj.frameEndTime = message.frameEndTime.toISOString();
    }
    if (message.vmCount !== 0) {
      obj.vmCount = Math.round(message.vmCount);
    }
    if (message.vms?.length) {
      obj.vms = message.vms.map((e) => VmUtilizationInfo.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<UtilizationReport>, I>>(base?: I): UtilizationReport {
    return UtilizationReport.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<UtilizationReport>, I>>(object: I): UtilizationReport {
    const message = createBaseUtilizationReport();
    message.name = object.name ?? "";
    message.displayName = object.displayName ?? "";
    message.state = object.state ?? 0;
    message.stateTime = object.stateTime ?? undefined;
    message.error = (object.error !== undefined && object.error !== null)
      ? Status.fromPartial(object.error)
      : undefined;
    message.createTime = object.createTime ?? undefined;
    message.timeFrame = object.timeFrame ?? 0;
    message.frameEndTime = object.frameEndTime ?? undefined;
    message.vmCount = object.vmCount ?? 0;
    message.vms = object.vms?.map((e) => VmUtilizationInfo.fromPartial(e)) || [];
    return message;
  },
};

function createBaseVmUtilizationInfo(): VmUtilizationInfo {
  return { vmwareVmDetails: undefined, vmId: "", utilization: undefined };
}

export const VmUtilizationInfo: MessageFns<VmUtilizationInfo> = {
  encode(message: VmUtilizationInfo, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmwareVmDetails !== undefined) {
      VmwareVmDetails.encode(message.vmwareVmDetails, writer.uint32(10).fork()).join();
    }
    if (message.vmId !== "") {
      writer.uint32(26).string(message.vmId);
    }
    if (message.utilization !== undefined) {
      VmUtilizationMetrics.encode(message.utilization, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VmUtilizationInfo {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVmUtilizationInfo();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.vmwareVmDetails = VmwareVmDetails.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.vmId = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.utilization = VmUtilizationMetrics.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VmUtilizationInfo {
    return {
      vmwareVmDetails: isSet(object.vmwareVmDetails) ? VmwareVmDetails.fromJSON(object.vmwareVmDetails) : undefined,
      vmId: isSet(object.vmId) ? globalThis.String(object.vmId) : "",
      utilization: isSet(object.utilization) ? VmUtilizationMetrics.fromJSON(object.utilization) : undefined,
    };
  },

  toJSON(message: VmUtilizationInfo): unknown {
    const obj: any = {};
    if (message.vmwareVmDetails !== undefined) {
      obj.vmwareVmDetails = VmwareVmDetails.toJSON(message.vmwareVmDetails);
    }
    if (message.vmId !== "") {
      obj.vmId = message.vmId;
    }
    if (message.utilization !== undefined) {
      obj.utilization = VmUtilizationMetrics.toJSON(message.utilization);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<VmUtilizationInfo>, I>>(base?: I): VmUtilizationInfo {
    return VmUtilizationInfo.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VmUtilizationInfo>, I>>(object: I): VmUtilizationInfo {
    const message = createBaseVmUtilizationInfo();
    message.vmwareVmDetails = (object.vmwareVmDetails !== undefined && object.vmwareVmDetails !== null)
      ? VmwareVmDetails.fromPartial(object.vmwareVmDetails)
      : undefined;
    message.vmId = object.vmId ?? "";
    message.utilization = (object.utilization !== undefined && object.utilization !== null)
      ? VmUtilizationMetrics.fromPartial(object.utilization)
      : undefined;
    return message;
  },
};

function createBaseVmUtilizationMetrics(): VmUtilizationMetrics {
  return {
    cpuMaxPercent: 0,
    cpuAveragePercent: 0,
    memoryMaxPercent: 0,
    memoryAveragePercent: 0,
    diskIoRateMaxKbps: Long.ZERO,
    diskIoRateAverageKbps: Long.ZERO,
    networkThroughputMaxKbps: Long.ZERO,
    networkThroughputAverageKbps: Long.ZERO,
  };
}

export const VmUtilizationMetrics: MessageFns<VmUtilizationMetrics> = {
  encode(message: VmUtilizationMetrics, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.cpuMaxPercent !== 0) {
      writer.uint32(72).int32(message.cpuMaxPercent);
    }
    if (message.cpuAveragePercent !== 0) {
      writer.uint32(80).int32(message.cpuAveragePercent);
    }
    if (message.memoryMaxPercent !== 0) {
      writer.uint32(88).int32(message.memoryMaxPercent);
    }
    if (message.memoryAveragePercent !== 0) {
      writer.uint32(96).int32(message.memoryAveragePercent);
    }
    if (!message.diskIoRateMaxKbps.equals(Long.ZERO)) {
      writer.uint32(104).int64(message.diskIoRateMaxKbps.toString());
    }
    if (!message.diskIoRateAverageKbps.equals(Long.ZERO)) {
      writer.uint32(112).int64(message.diskIoRateAverageKbps.toString());
    }
    if (!message.networkThroughputMaxKbps.equals(Long.ZERO)) {
      writer.uint32(120).int64(message.networkThroughputMaxKbps.toString());
    }
    if (!message.networkThroughputAverageKbps.equals(Long.ZERO)) {
      writer.uint32(128).int64(message.networkThroughputAverageKbps.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): VmUtilizationMetrics {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseVmUtilizationMetrics();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.cpuMaxPercent = reader.int32();
          continue;
        }
        case 10: {
          if (tag !== 80) {
            break;
          }

          message.cpuAveragePercent = reader.int32();
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.memoryMaxPercent = reader.int32();
          continue;
        }
        case 12: {
          if (tag !== 96) {
            break;
          }

          message.memoryAveragePercent = reader.int32();
          continue;
        }
        case 13: {
          if (tag !== 104) {
            break;
          }

          message.diskIoRateMaxKbps = Long.fromString(reader.int64().toString());
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.diskIoRateAverageKbps = Long.fromString(reader.int64().toString());
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.networkThroughputMaxKbps = Long.fromString(reader.int64().toString());
          continue;
        }
        case 16: {
          if (tag !== 128) {
            break;
          }

          message.networkThroughputAverageKbps = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): VmUtilizationMetrics {
    return {
      cpuMaxPercent: isSet(object.cpuMaxPercent) ? globalThis.Number(object.cpuMaxPercent) : 0,
      cpuAveragePercent: isSet(object.cpuAveragePercent) ? globalThis.Number(object.cpuAveragePercent) : 0,
      memoryMaxPercent: isSet(object.memoryMaxPercent) ? globalThis.Number(object.memoryMaxPercent) : 0,
      memoryAveragePercent: isSet(object.memoryAveragePercent) ? globalThis.Number(object.memoryAveragePercent) : 0,
      diskIoRateMaxKbps: isSet(object.diskIoRateMaxKbps) ? Long.fromValue(object.diskIoRateMaxKbps) : Long.ZERO,
      diskIoRateAverageKbps: isSet(object.diskIoRateAverageKbps)
        ? Long.fromValue(object.diskIoRateAverageKbps)
        : Long.ZERO,
      networkThroughputMaxKbps: isSet(object.networkThroughputMaxKbps)
        ? Long.fromValue(object.networkThroughputMaxKbps)
        : Long.ZERO,
      networkThroughputAverageKbps: isSet(object.networkThroughputAverageKbps)
        ? Long.fromValue(object.networkThroughputAverageKbps)
        : Long.ZERO,
    };
  },

  toJSON(message: VmUtilizationMetrics): unknown {
    const obj: any = {};
    if (message.cpuMaxPercent !== 0) {
      obj.cpuMaxPercent = Math.round(message.cpuMaxPercent);
    }
    if (message.cpuAveragePercent !== 0) {
      obj.cpuAveragePercent = Math.round(message.cpuAveragePercent);
    }
    if (message.memoryMaxPercent !== 0) {
      obj.memoryMaxPercent = Math.round(message.memoryMaxPercent);
    }
    if (message.memoryAveragePercent !== 0) {
      obj.memoryAveragePercent = Math.round(message.memoryAveragePercent);
    }
    if (!message.diskIoRateMaxKbps.equals(Long.ZERO)) {
      obj.diskIoRateMaxKbps = (message.diskIoRateMaxKbps || Long.ZERO).toString();
    }
    if (!message.diskIoRateAverageKbps.equals(Long.ZERO)) {
      obj.diskIoRateAverageKbps = (message.diskIoRateAverageKbps || Long.ZERO).toString();
    }
    if (!message.networkThroughputMaxKbps.equals(Long.ZERO)) {
      obj.networkThroughputMaxKbps = (message.networkThroughputMaxKbps || Long.ZERO).toString();
    }
    if (!message.networkThroughputAverageKbps.equals(Long.ZERO)) {
      obj.networkThroughputAverageKbps = (message.networkThroughputAverageKbps || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<VmUtilizationMetrics>, I>>(base?: I): VmUtilizationMetrics {
    return VmUtilizationMetrics.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<VmUtilizationMetrics>, I>>(object: I): VmUtilizationMetrics {
    const message = createBaseVmUtilizationMetrics();
    message.cpuMaxPercent = object.cpuMaxPercent ?? 0;
    message.cpuAveragePercent = object.cpuAveragePercent ?? 0;
    message.memoryMaxPercent = object.memoryMaxPercent ?? 0;
    message.memoryAveragePercent = object.memoryAveragePercent ?? 0;
    message.diskIoRateMaxKbps = (object.diskIoRateMaxKbps !== undefined && object.diskIoRateMaxKbps !== null)
      ? Long.fromValue(object.diskIoRateMaxKbps)
      : Long.ZERO;
    message.diskIoRateAverageKbps =
      (object.diskIoRateAverageKbps !== undefined && object.diskIoRateAverageKbps !== null)
        ? Long.fromValue(object.diskIoRateAverageKbps)
        : Long.ZERO;
    message.networkThroughputMaxKbps =
      (object.networkThroughputMaxKbps !== undefined && object.networkThroughputMaxKbps !== null)
        ? Long.fromValue(object.networkThroughputMaxKbps)
        : Long.ZERO;
    message.networkThroughputAverageKbps =
      (object.networkThroughputAverageKbps !== undefined && object.networkThroughputAverageKbps !== null)
        ? Long.fromValue(object.networkThroughputAverageKbps)
        : Long.ZERO;
    return message;
  },
};

function createBaseComputeEngineTargetDefaults(): ComputeEngineTargetDefaults {
  return {
    vmName: "",
    targetProject: "",
    zone: "",
    machineTypeSeries: "",
    machineType: "",
    networkTags: [],
    networkInterfaces: [],
    serviceAccount: "",
    diskType: 0,
    labels: {},
    licenseType: 0,
    appliedLicense: undefined,
    computeScheduling: undefined,
    secureBoot: false,
    bootOption: 0,
    metadata: {},
    additionalLicenses: [],
    hostname: "",
  };
}

export const ComputeEngineTargetDefaults: MessageFns<ComputeEngineTargetDefaults> = {
  encode(message: ComputeEngineTargetDefaults, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmName !== "") {
      writer.uint32(10).string(message.vmName);
    }
    if (message.targetProject !== "") {
      writer.uint32(18).string(message.targetProject);
    }
    if (message.zone !== "") {
      writer.uint32(26).string(message.zone);
    }
    if (message.machineTypeSeries !== "") {
      writer.uint32(34).string(message.machineTypeSeries);
    }
    if (message.machineType !== "") {
      writer.uint32(42).string(message.machineType);
    }
    for (const v of message.networkTags) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.networkInterfaces) {
      NetworkInterface.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(66).string(message.serviceAccount);
    }
    if (message.diskType !== 0) {
      writer.uint32(72).int32(message.diskType);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ComputeEngineTargetDefaults_LabelsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.licenseType !== 0) {
      writer.uint32(88).int32(message.licenseType);
    }
    if (message.appliedLicense !== undefined) {
      AppliedLicense.encode(message.appliedLicense, writer.uint32(98).fork()).join();
    }
    if (message.computeScheduling !== undefined) {
      ComputeScheduling.encode(message.computeScheduling, writer.uint32(106).fork()).join();
    }
    if (message.secureBoot !== false) {
      writer.uint32(112).bool(message.secureBoot);
    }
    if (message.bootOption !== 0) {
      writer.uint32(120).int32(message.bootOption);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      ComputeEngineTargetDefaults_MetadataEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    for (const v of message.additionalLicenses) {
      writer.uint32(138).string(v!);
    }
    if (message.hostname !== "") {
      writer.uint32(146).string(message.hostname);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDefaults {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDefaults();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.vmName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.targetProject = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.zone = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.machineTypeSeries = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.machineType = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.networkTags.push(reader.string());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.networkInterfaces.push(NetworkInterface.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.diskType = reader.int32() as any;
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          const entry10 = ComputeEngineTargetDefaults_LabelsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.labels[entry10.key] = entry10.value;
          }
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.licenseType = reader.int32() as any;
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.appliedLicense = AppliedLicense.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.computeScheduling = ComputeScheduling.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.secureBoot = reader.bool();
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.bootOption = reader.int32() as any;
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          const entry16 = ComputeEngineTargetDefaults_MetadataEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.metadata[entry16.key] = entry16.value;
          }
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.additionalLicenses.push(reader.string());
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.hostname = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDefaults {
    return {
      vmName: isSet(object.vmName) ? globalThis.String(object.vmName) : "",
      targetProject: isSet(object.targetProject) ? globalThis.String(object.targetProject) : "",
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      machineTypeSeries: isSet(object.machineTypeSeries) ? globalThis.String(object.machineTypeSeries) : "",
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      networkTags: globalThis.Array.isArray(object?.networkTags)
        ? object.networkTags.map((e: any) => globalThis.String(e))
        : [],
      networkInterfaces: globalThis.Array.isArray(object?.networkInterfaces)
        ? object.networkInterfaces.map((e: any) => NetworkInterface.fromJSON(e))
        : [],
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      diskType: isSet(object.diskType) ? computeEngineDiskTypeFromJSON(object.diskType) : 0,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      licenseType: isSet(object.licenseType) ? computeEngineLicenseTypeFromJSON(object.licenseType) : 0,
      appliedLicense: isSet(object.appliedLicense) ? AppliedLicense.fromJSON(object.appliedLicense) : undefined,
      computeScheduling: isSet(object.computeScheduling)
        ? ComputeScheduling.fromJSON(object.computeScheduling)
        : undefined,
      secureBoot: isSet(object.secureBoot) ? globalThis.Boolean(object.secureBoot) : false,
      bootOption: isSet(object.bootOption) ? computeEngineBootOptionFromJSON(object.bootOption) : 0,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      additionalLicenses: globalThis.Array.isArray(object?.additionalLicenses)
        ? object.additionalLicenses.map((e: any) => globalThis.String(e))
        : [],
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDefaults): unknown {
    const obj: any = {};
    if (message.vmName !== "") {
      obj.vmName = message.vmName;
    }
    if (message.targetProject !== "") {
      obj.targetProject = message.targetProject;
    }
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.machineTypeSeries !== "") {
      obj.machineTypeSeries = message.machineTypeSeries;
    }
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (message.networkTags?.length) {
      obj.networkTags = message.networkTags;
    }
    if (message.networkInterfaces?.length) {
      obj.networkInterfaces = message.networkInterfaces.map((e) => NetworkInterface.toJSON(e));
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.diskType !== 0) {
      obj.diskType = computeEngineDiskTypeToJSON(message.diskType);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.licenseType !== 0) {
      obj.licenseType = computeEngineLicenseTypeToJSON(message.licenseType);
    }
    if (message.appliedLicense !== undefined) {
      obj.appliedLicense = AppliedLicense.toJSON(message.appliedLicense);
    }
    if (message.computeScheduling !== undefined) {
      obj.computeScheduling = ComputeScheduling.toJSON(message.computeScheduling);
    }
    if (message.secureBoot !== false) {
      obj.secureBoot = message.secureBoot;
    }
    if (message.bootOption !== 0) {
      obj.bootOption = computeEngineBootOptionToJSON(message.bootOption);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.additionalLicenses?.length) {
      obj.additionalLicenses = message.additionalLicenses;
    }
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDefaults>, I>>(base?: I): ComputeEngineTargetDefaults {
    return ComputeEngineTargetDefaults.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDefaults>, I>>(object: I): ComputeEngineTargetDefaults {
    const message = createBaseComputeEngineTargetDefaults();
    message.vmName = object.vmName ?? "";
    message.targetProject = object.targetProject ?? "";
    message.zone = object.zone ?? "";
    message.machineTypeSeries = object.machineTypeSeries ?? "";
    message.machineType = object.machineType ?? "";
    message.networkTags = object.networkTags?.map((e) => e) || [];
    message.networkInterfaces = object.networkInterfaces?.map((e) => NetworkInterface.fromPartial(e)) || [];
    message.serviceAccount = object.serviceAccount ?? "";
    message.diskType = object.diskType ?? 0;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.licenseType = object.licenseType ?? 0;
    message.appliedLicense = (object.appliedLicense !== undefined && object.appliedLicense !== null)
      ? AppliedLicense.fromPartial(object.appliedLicense)
      : undefined;
    message.computeScheduling = (object.computeScheduling !== undefined && object.computeScheduling !== null)
      ? ComputeScheduling.fromPartial(object.computeScheduling)
      : undefined;
    message.secureBoot = object.secureBoot ?? false;
    message.bootOption = object.bootOption ?? 0;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.additionalLicenses = object.additionalLicenses?.map((e) => e) || [];
    message.hostname = object.hostname ?? "";
    return message;
  },
};

function createBaseComputeEngineTargetDefaults_LabelsEntry(): ComputeEngineTargetDefaults_LabelsEntry {
  return { key: "", value: "" };
}

export const ComputeEngineTargetDefaults_LabelsEntry: MessageFns<ComputeEngineTargetDefaults_LabelsEntry> = {
  encode(message: ComputeEngineTargetDefaults_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDefaults_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDefaults_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDefaults_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDefaults_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDefaults_LabelsEntry>, I>>(
    base?: I,
  ): ComputeEngineTargetDefaults_LabelsEntry {
    return ComputeEngineTargetDefaults_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDefaults_LabelsEntry>, I>>(
    object: I,
  ): ComputeEngineTargetDefaults_LabelsEntry {
    const message = createBaseComputeEngineTargetDefaults_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseComputeEngineTargetDefaults_MetadataEntry(): ComputeEngineTargetDefaults_MetadataEntry {
  return { key: "", value: "" };
}

export const ComputeEngineTargetDefaults_MetadataEntry: MessageFns<ComputeEngineTargetDefaults_MetadataEntry> = {
  encode(message: ComputeEngineTargetDefaults_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDefaults_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDefaults_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDefaults_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDefaults_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDefaults_MetadataEntry>, I>>(
    base?: I,
  ): ComputeEngineTargetDefaults_MetadataEntry {
    return ComputeEngineTargetDefaults_MetadataEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDefaults_MetadataEntry>, I>>(
    object: I,
  ): ComputeEngineTargetDefaults_MetadataEntry {
    const message = createBaseComputeEngineTargetDefaults_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseComputeEngineTargetDetails(): ComputeEngineTargetDetails {
  return {
    vmName: "",
    project: "",
    zone: "",
    machineTypeSeries: "",
    machineType: "",
    networkTags: [],
    networkInterfaces: [],
    serviceAccount: "",
    diskType: 0,
    labels: {},
    licenseType: 0,
    appliedLicense: undefined,
    computeScheduling: undefined,
    secureBoot: false,
    bootOption: 0,
    metadata: {},
    additionalLicenses: [],
    hostname: "",
  };
}

export const ComputeEngineTargetDetails: MessageFns<ComputeEngineTargetDetails> = {
  encode(message: ComputeEngineTargetDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.vmName !== "") {
      writer.uint32(10).string(message.vmName);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.zone !== "") {
      writer.uint32(26).string(message.zone);
    }
    if (message.machineTypeSeries !== "") {
      writer.uint32(34).string(message.machineTypeSeries);
    }
    if (message.machineType !== "") {
      writer.uint32(42).string(message.machineType);
    }
    for (const v of message.networkTags) {
      writer.uint32(50).string(v!);
    }
    for (const v of message.networkInterfaces) {
      NetworkInterface.encode(v!, writer.uint32(58).fork()).join();
    }
    if (message.serviceAccount !== "") {
      writer.uint32(66).string(message.serviceAccount);
    }
    if (message.diskType !== 0) {
      writer.uint32(72).int32(message.diskType);
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      ComputeEngineTargetDetails_LabelsEntry.encode({ key: key as any, value }, writer.uint32(82).fork()).join();
    });
    if (message.licenseType !== 0) {
      writer.uint32(88).int32(message.licenseType);
    }
    if (message.appliedLicense !== undefined) {
      AppliedLicense.encode(message.appliedLicense, writer.uint32(98).fork()).join();
    }
    if (message.computeScheduling !== undefined) {
      ComputeScheduling.encode(message.computeScheduling, writer.uint32(106).fork()).join();
    }
    if (message.secureBoot !== false) {
      writer.uint32(112).bool(message.secureBoot);
    }
    if (message.bootOption !== 0) {
      writer.uint32(120).int32(message.bootOption);
    }
    Object.entries(message.metadata).forEach(([key, value]) => {
      ComputeEngineTargetDetails_MetadataEntry.encode({ key: key as any, value }, writer.uint32(130).fork()).join();
    });
    for (const v of message.additionalLicenses) {
      writer.uint32(138).string(v!);
    }
    if (message.hostname !== "") {
      writer.uint32(146).string(message.hostname);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.vmName = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.zone = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.machineTypeSeries = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.machineType = reader.string();
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.networkTags.push(reader.string());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.networkInterfaces.push(NetworkInterface.decode(reader, reader.uint32()));
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.serviceAccount = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.diskType = reader.int32() as any;
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          const entry10 = ComputeEngineTargetDetails_LabelsEntry.decode(reader, reader.uint32());
          if (entry10.value !== undefined) {
            message.labels[entry10.key] = entry10.value;
          }
          continue;
        }
        case 11: {
          if (tag !== 88) {
            break;
          }

          message.licenseType = reader.int32() as any;
          continue;
        }
        case 12: {
          if (tag !== 98) {
            break;
          }

          message.appliedLicense = AppliedLicense.decode(reader, reader.uint32());
          continue;
        }
        case 13: {
          if (tag !== 106) {
            break;
          }

          message.computeScheduling = ComputeScheduling.decode(reader, reader.uint32());
          continue;
        }
        case 14: {
          if (tag !== 112) {
            break;
          }

          message.secureBoot = reader.bool();
          continue;
        }
        case 15: {
          if (tag !== 120) {
            break;
          }

          message.bootOption = reader.int32() as any;
          continue;
        }
        case 16: {
          if (tag !== 130) {
            break;
          }

          const entry16 = ComputeEngineTargetDetails_MetadataEntry.decode(reader, reader.uint32());
          if (entry16.value !== undefined) {
            message.metadata[entry16.key] = entry16.value;
          }
          continue;
        }
        case 17: {
          if (tag !== 138) {
            break;
          }

          message.additionalLicenses.push(reader.string());
          continue;
        }
        case 18: {
          if (tag !== 146) {
            break;
          }

          message.hostname = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDetails {
    return {
      vmName: isSet(object.vmName) ? globalThis.String(object.vmName) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      zone: isSet(object.zone) ? globalThis.String(object.zone) : "",
      machineTypeSeries: isSet(object.machineTypeSeries) ? globalThis.String(object.machineTypeSeries) : "",
      machineType: isSet(object.machineType) ? globalThis.String(object.machineType) : "",
      networkTags: globalThis.Array.isArray(object?.networkTags)
        ? object.networkTags.map((e: any) => globalThis.String(e))
        : [],
      networkInterfaces: globalThis.Array.isArray(object?.networkInterfaces)
        ? object.networkInterfaces.map((e: any) => NetworkInterface.fromJSON(e))
        : [],
      serviceAccount: isSet(object.serviceAccount) ? globalThis.String(object.serviceAccount) : "",
      diskType: isSet(object.diskType) ? computeEngineDiskTypeFromJSON(object.diskType) : 0,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      licenseType: isSet(object.licenseType) ? computeEngineLicenseTypeFromJSON(object.licenseType) : 0,
      appliedLicense: isSet(object.appliedLicense) ? AppliedLicense.fromJSON(object.appliedLicense) : undefined,
      computeScheduling: isSet(object.computeScheduling)
        ? ComputeScheduling.fromJSON(object.computeScheduling)
        : undefined,
      secureBoot: isSet(object.secureBoot) ? globalThis.Boolean(object.secureBoot) : false,
      bootOption: isSet(object.bootOption) ? computeEngineBootOptionFromJSON(object.bootOption) : 0,
      metadata: isObject(object.metadata)
        ? Object.entries(object.metadata).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      additionalLicenses: globalThis.Array.isArray(object?.additionalLicenses)
        ? object.additionalLicenses.map((e: any) => globalThis.String(e))
        : [],
      hostname: isSet(object.hostname) ? globalThis.String(object.hostname) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDetails): unknown {
    const obj: any = {};
    if (message.vmName !== "") {
      obj.vmName = message.vmName;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.zone !== "") {
      obj.zone = message.zone;
    }
    if (message.machineTypeSeries !== "") {
      obj.machineTypeSeries = message.machineTypeSeries;
    }
    if (message.machineType !== "") {
      obj.machineType = message.machineType;
    }
    if (message.networkTags?.length) {
      obj.networkTags = message.networkTags;
    }
    if (message.networkInterfaces?.length) {
      obj.networkInterfaces = message.networkInterfaces.map((e) => NetworkInterface.toJSON(e));
    }
    if (message.serviceAccount !== "") {
      obj.serviceAccount = message.serviceAccount;
    }
    if (message.diskType !== 0) {
      obj.diskType = computeEngineDiskTypeToJSON(message.diskType);
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.licenseType !== 0) {
      obj.licenseType = computeEngineLicenseTypeToJSON(message.licenseType);
    }
    if (message.appliedLicense !== undefined) {
      obj.appliedLicense = AppliedLicense.toJSON(message.appliedLicense);
    }
    if (message.computeScheduling !== undefined) {
      obj.computeScheduling = ComputeScheduling.toJSON(message.computeScheduling);
    }
    if (message.secureBoot !== false) {
      obj.secureBoot = message.secureBoot;
    }
    if (message.bootOption !== 0) {
      obj.bootOption = computeEngineBootOptionToJSON(message.bootOption);
    }
    if (message.metadata) {
      const entries = Object.entries(message.metadata);
      if (entries.length > 0) {
        obj.metadata = {};
        entries.forEach(([k, v]) => {
          obj.metadata[k] = v;
        });
      }
    }
    if (message.additionalLicenses?.length) {
      obj.additionalLicenses = message.additionalLicenses;
    }
    if (message.hostname !== "") {
      obj.hostname = message.hostname;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDetails>, I>>(base?: I): ComputeEngineTargetDetails {
    return ComputeEngineTargetDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDetails>, I>>(object: I): ComputeEngineTargetDetails {
    const message = createBaseComputeEngineTargetDetails();
    message.vmName = object.vmName ?? "";
    message.project = object.project ?? "";
    message.zone = object.zone ?? "";
    message.machineTypeSeries = object.machineTypeSeries ?? "";
    message.machineType = object.machineType ?? "";
    message.networkTags = object.networkTags?.map((e) => e) || [];
    message.networkInterfaces = object.networkInterfaces?.map((e) => NetworkInterface.fromPartial(e)) || [];
    message.serviceAccount = object.serviceAccount ?? "";
    message.diskType = object.diskType ?? 0;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.licenseType = object.licenseType ?? 0;
    message.appliedLicense = (object.appliedLicense !== undefined && object.appliedLicense !== null)
      ? AppliedLicense.fromPartial(object.appliedLicense)
      : undefined;
    message.computeScheduling = (object.computeScheduling !== undefined && object.computeScheduling !== null)
      ? ComputeScheduling.fromPartial(object.computeScheduling)
      : undefined;
    message.secureBoot = object.secureBoot ?? false;
    message.bootOption = object.bootOption ?? 0;
    message.metadata = Object.entries(object.metadata ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.additionalLicenses = object.additionalLicenses?.map((e) => e) || [];
    message.hostname = object.hostname ?? "";
    return message;
  },
};

function createBaseComputeEngineTargetDetails_LabelsEntry(): ComputeEngineTargetDetails_LabelsEntry {
  return { key: "", value: "" };
}

export const ComputeEngineTargetDetails_LabelsEntry: MessageFns<ComputeEngineTargetDetails_LabelsEntry> = {
  encode(message: ComputeEngineTargetDetails_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDetails_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDetails_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDetails_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDetails_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDetails_LabelsEntry>, I>>(
    base?: I,
  ): ComputeEngineTargetDetails_LabelsEntry {
    return ComputeEngineTargetDetails_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDetails_LabelsEntry>, I>>(
    object: I,
  ): ComputeEngineTargetDetails_LabelsEntry {
    const message = createBaseComputeEngineTargetDetails_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseComputeEngineTargetDetails_MetadataEntry(): ComputeEngineTargetDetails_MetadataEntry {
  return { key: "", value: "" };
}

export const ComputeEngineTargetDetails_MetadataEntry: MessageFns<ComputeEngineTargetDetails_MetadataEntry> = {
  encode(message: ComputeEngineTargetDetails_MetadataEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeEngineTargetDetails_MetadataEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeEngineTargetDetails_MetadataEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeEngineTargetDetails_MetadataEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: ComputeEngineTargetDetails_MetadataEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeEngineTargetDetails_MetadataEntry>, I>>(
    base?: I,
  ): ComputeEngineTargetDetails_MetadataEntry {
    return ComputeEngineTargetDetails_MetadataEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeEngineTargetDetails_MetadataEntry>, I>>(
    object: I,
  ): ComputeEngineTargetDetails_MetadataEntry {
    const message = createBaseComputeEngineTargetDetails_MetadataEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseNetworkInterface(): NetworkInterface {
  return { network: "", subnetwork: "", internalIp: "", externalIp: "" };
}

export const NetworkInterface: MessageFns<NetworkInterface> = {
  encode(message: NetworkInterface, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.network !== "") {
      writer.uint32(10).string(message.network);
    }
    if (message.subnetwork !== "") {
      writer.uint32(18).string(message.subnetwork);
    }
    if (message.internalIp !== "") {
      writer.uint32(26).string(message.internalIp);
    }
    if (message.externalIp !== "") {
      writer.uint32(34).string(message.externalIp);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): NetworkInterface {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseNetworkInterface();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.network = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.subnetwork = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.internalIp = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.externalIp = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): NetworkInterface {
    return {
      network: isSet(object.network) ? globalThis.String(object.network) : "",
      subnetwork: isSet(object.subnetwork) ? globalThis.String(object.subnetwork) : "",
      internalIp: isSet(object.internalIp) ? globalThis.String(object.internalIp) : "",
      externalIp: isSet(object.externalIp) ? globalThis.String(object.externalIp) : "",
    };
  },

  toJSON(message: NetworkInterface): unknown {
    const obj: any = {};
    if (message.network !== "") {
      obj.network = message.network;
    }
    if (message.subnetwork !== "") {
      obj.subnetwork = message.subnetwork;
    }
    if (message.internalIp !== "") {
      obj.internalIp = message.internalIp;
    }
    if (message.externalIp !== "") {
      obj.externalIp = message.externalIp;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<NetworkInterface>, I>>(base?: I): NetworkInterface {
    return NetworkInterface.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<NetworkInterface>, I>>(object: I): NetworkInterface {
    const message = createBaseNetworkInterface();
    message.network = object.network ?? "";
    message.subnetwork = object.subnetwork ?? "";
    message.internalIp = object.internalIp ?? "";
    message.externalIp = object.externalIp ?? "";
    return message;
  },
};

function createBaseAppliedLicense(): AppliedLicense {
  return { type: 0, osLicense: "" };
}

export const AppliedLicense: MessageFns<AppliedLicense> = {
  encode(message: AppliedLicense, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.type !== 0) {
      writer.uint32(8).int32(message.type);
    }
    if (message.osLicense !== "") {
      writer.uint32(18).string(message.osLicense);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AppliedLicense {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAppliedLicense();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.type = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.osLicense = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AppliedLicense {
    return {
      type: isSet(object.type) ? appliedLicense_TypeFromJSON(object.type) : 0,
      osLicense: isSet(object.osLicense) ? globalThis.String(object.osLicense) : "",
    };
  },

  toJSON(message: AppliedLicense): unknown {
    const obj: any = {};
    if (message.type !== 0) {
      obj.type = appliedLicense_TypeToJSON(message.type);
    }
    if (message.osLicense !== "") {
      obj.osLicense = message.osLicense;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AppliedLicense>, I>>(base?: I): AppliedLicense {
    return AppliedLicense.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AppliedLicense>, I>>(object: I): AppliedLicense {
    const message = createBaseAppliedLicense();
    message.type = object.type ?? 0;
    message.osLicense = object.osLicense ?? "";
    return message;
  },
};

function createBaseSchedulingNodeAffinity(): SchedulingNodeAffinity {
  return { key: "", operator: 0, values: [] };
}

export const SchedulingNodeAffinity: MessageFns<SchedulingNodeAffinity> = {
  encode(message: SchedulingNodeAffinity, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.operator !== 0) {
      writer.uint32(16).int32(message.operator);
    }
    for (const v of message.values) {
      writer.uint32(26).string(v!);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SchedulingNodeAffinity {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchedulingNodeAffinity();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.operator = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.values.push(reader.string());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SchedulingNodeAffinity {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      operator: isSet(object.operator) ? schedulingNodeAffinity_OperatorFromJSON(object.operator) : 0,
      values: globalThis.Array.isArray(object?.values) ? object.values.map((e: any) => globalThis.String(e)) : [],
    };
  },

  toJSON(message: SchedulingNodeAffinity): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.operator !== 0) {
      obj.operator = schedulingNodeAffinity_OperatorToJSON(message.operator);
    }
    if (message.values?.length) {
      obj.values = message.values;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SchedulingNodeAffinity>, I>>(base?: I): SchedulingNodeAffinity {
    return SchedulingNodeAffinity.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SchedulingNodeAffinity>, I>>(object: I): SchedulingNodeAffinity {
    const message = createBaseSchedulingNodeAffinity();
    message.key = object.key ?? "";
    message.operator = object.operator ?? 0;
    message.values = object.values?.map((e) => e) || [];
    return message;
  },
};

function createBaseComputeScheduling(): ComputeScheduling {
  return { onHostMaintenance: 0, restartType: 0, nodeAffinities: [], minNodeCpus: 0 };
}

export const ComputeScheduling: MessageFns<ComputeScheduling> = {
  encode(message: ComputeScheduling, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.onHostMaintenance !== 0) {
      writer.uint32(8).int32(message.onHostMaintenance);
    }
    if (message.restartType !== 0) {
      writer.uint32(40).int32(message.restartType);
    }
    for (const v of message.nodeAffinities) {
      SchedulingNodeAffinity.encode(v!, writer.uint32(26).fork()).join();
    }
    if (message.minNodeCpus !== 0) {
      writer.uint32(32).int32(message.minNodeCpus);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ComputeScheduling {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseComputeScheduling();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.onHostMaintenance = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.restartType = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.nodeAffinities.push(SchedulingNodeAffinity.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.minNodeCpus = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ComputeScheduling {
    return {
      onHostMaintenance: isSet(object.onHostMaintenance)
        ? computeScheduling_OnHostMaintenanceFromJSON(object.onHostMaintenance)
        : 0,
      restartType: isSet(object.restartType) ? computeScheduling_RestartTypeFromJSON(object.restartType) : 0,
      nodeAffinities: globalThis.Array.isArray(object?.nodeAffinities)
        ? object.nodeAffinities.map((e: any) => SchedulingNodeAffinity.fromJSON(e))
        : [],
      minNodeCpus: isSet(object.minNodeCpus) ? globalThis.Number(object.minNodeCpus) : 0,
    };
  },

  toJSON(message: ComputeScheduling): unknown {
    const obj: any = {};
    if (message.onHostMaintenance !== 0) {
      obj.onHostMaintenance = computeScheduling_OnHostMaintenanceToJSON(message.onHostMaintenance);
    }
    if (message.restartType !== 0) {
      obj.restartType = computeScheduling_RestartTypeToJSON(message.restartType);
    }
    if (message.nodeAffinities?.length) {
      obj.nodeAffinities = message.nodeAffinities.map((e) => SchedulingNodeAffinity.toJSON(e));
    }
    if (message.minNodeCpus !== 0) {
      obj.minNodeCpus = Math.round(message.minNodeCpus);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ComputeScheduling>, I>>(base?: I): ComputeScheduling {
    return ComputeScheduling.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ComputeScheduling>, I>>(object: I): ComputeScheduling {
    const message = createBaseComputeScheduling();
    message.onHostMaintenance = object.onHostMaintenance ?? 0;
    message.restartType = object.restartType ?? 0;
    message.nodeAffinities = object.nodeAffinities?.map((e) => SchedulingNodeAffinity.fromPartial(e)) || [];
    message.minNodeCpus = object.minNodeCpus ?? 0;
    return message;
  },
};

function createBaseSchedulePolicy(): SchedulePolicy {
  return { idleDuration: undefined, skipOsAdaptation: false };
}

export const SchedulePolicy: MessageFns<SchedulePolicy> = {
  encode(message: SchedulePolicy, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.idleDuration !== undefined) {
      Duration.encode(message.idleDuration, writer.uint32(10).fork()).join();
    }
    if (message.skipOsAdaptation !== false) {
      writer.uint32(16).bool(message.skipOsAdaptation);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SchedulePolicy {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchedulePolicy();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.idleDuration = Duration.decode(reader, reader.uint32());
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.skipOsAdaptation = reader.bool();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SchedulePolicy {
    return {
      idleDuration: isSet(object.idleDuration) ? Duration.fromJSON(object.idleDuration) : undefined,
      skipOsAdaptation: isSet(object.skipOsAdaptation) ? globalThis.Boolean(object.skipOsAdaptation) : false,
    };
  },

  toJSON(message: SchedulePolicy): unknown {
    const obj: any = {};
    if (message.idleDuration !== undefined) {
      obj.idleDuration = Duration.toJSON(message.idleDuration);
    }
    if (message.skipOsAdaptation !== false) {
      obj.skipOsAdaptation = message.skipOsAdaptation;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SchedulePolicy>, I>>(base?: I): SchedulePolicy {
    return SchedulePolicy.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SchedulePolicy>, I>>(object: I): SchedulePolicy {
    const message = createBaseSchedulePolicy();
    message.idleDuration = (object.idleDuration !== undefined && object.idleDuration !== null)
      ? Duration.fromPartial(object.idleDuration)
      : undefined;
    message.skipOsAdaptation = object.skipOsAdaptation ?? false;
    return message;
  },
};

function createBaseTargetProject(): TargetProject {
  return { name: "", project: "", description: "", createTime: undefined, updateTime: undefined };
}

export const TargetProject: MessageFns<TargetProject> = {
  encode(message: TargetProject, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.project !== "") {
      writer.uint32(18).string(message.project);
    }
    if (message.description !== "") {
      writer.uint32(26).string(message.description);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(34).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetProject {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetProject();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.project = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetProject {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      project: isSet(object.project) ? globalThis.String(object.project) : "",
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
    };
  },

  toJSON(message: TargetProject): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.project !== "") {
      obj.project = message.project;
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetProject>, I>>(base?: I): TargetProject {
    return TargetProject.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetProject>, I>>(object: I): TargetProject {
    const message = createBaseTargetProject();
    message.name = object.name ?? "";
    message.project = object.project ?? "";
    message.description = object.description ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    return message;
  },
};

function createBaseGroup(): Group {
  return { name: "", createTime: undefined, updateTime: undefined, description: "", displayName: "" };
}

export const Group: MessageFns<Group> = {
  encode(message: Group, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    if (message.description !== "") {
      writer.uint32(34).string(message.description);
    }
    if (message.displayName !== "") {
      writer.uint32(42).string(message.displayName);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Group {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGroup();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.description = reader.string();
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Group {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      description: isSet(object.description) ? globalThis.String(object.description) : "",
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
    };
  },

  toJSON(message: Group): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.description !== "") {
      obj.description = message.description;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Group>, I>>(base?: I): Group {
    return Group.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Group>, I>>(object: I): Group {
    const message = createBaseGroup();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.description = object.description ?? "";
    message.displayName = object.displayName ?? "";
    return message;
  },
};

function createBaseMigrationWarning(): MigrationWarning {
  return { code: 0, warningMessage: undefined, actionItem: undefined, helpLinks: [], warningTime: undefined };
}

export const MigrationWarning: MessageFns<MigrationWarning> = {
  encode(message: MigrationWarning, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.code !== 0) {
      writer.uint32(8).int32(message.code);
    }
    if (message.warningMessage !== undefined) {
      LocalizedMessage.encode(message.warningMessage, writer.uint32(18).fork()).join();
    }
    if (message.actionItem !== undefined) {
      LocalizedMessage.encode(message.actionItem, writer.uint32(26).fork()).join();
    }
    for (const v of message.helpLinks) {
      Help_Link.encode(v!, writer.uint32(34).fork()).join();
    }
    if (message.warningTime !== undefined) {
      Timestamp.encode(toTimestamp(message.warningTime), writer.uint32(42).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigrationWarning {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigrationWarning();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.code = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.warningMessage = LocalizedMessage.decode(reader, reader.uint32());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.actionItem = LocalizedMessage.decode(reader, reader.uint32());
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.helpLinks.push(Help_Link.decode(reader, reader.uint32()));
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          message.warningTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigrationWarning {
    return {
      code: isSet(object.code) ? migrationWarning_WarningCodeFromJSON(object.code) : 0,
      warningMessage: isSet(object.warningMessage) ? LocalizedMessage.fromJSON(object.warningMessage) : undefined,
      actionItem: isSet(object.actionItem) ? LocalizedMessage.fromJSON(object.actionItem) : undefined,
      helpLinks: globalThis.Array.isArray(object?.helpLinks)
        ? object.helpLinks.map((e: any) => Help_Link.fromJSON(e))
        : [],
      warningTime: isSet(object.warningTime) ? fromJsonTimestamp(object.warningTime) : undefined,
    };
  },

  toJSON(message: MigrationWarning): unknown {
    const obj: any = {};
    if (message.code !== 0) {
      obj.code = migrationWarning_WarningCodeToJSON(message.code);
    }
    if (message.warningMessage !== undefined) {
      obj.warningMessage = LocalizedMessage.toJSON(message.warningMessage);
    }
    if (message.actionItem !== undefined) {
      obj.actionItem = LocalizedMessage.toJSON(message.actionItem);
    }
    if (message.helpLinks?.length) {
      obj.helpLinks = message.helpLinks.map((e) => Help_Link.toJSON(e));
    }
    if (message.warningTime !== undefined) {
      obj.warningTime = message.warningTime.toISOString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MigrationWarning>, I>>(base?: I): MigrationWarning {
    return MigrationWarning.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MigrationWarning>, I>>(object: I): MigrationWarning {
    const message = createBaseMigrationWarning();
    message.code = object.code ?? 0;
    message.warningMessage = (object.warningMessage !== undefined && object.warningMessage !== null)
      ? LocalizedMessage.fromPartial(object.warningMessage)
      : undefined;
    message.actionItem = (object.actionItem !== undefined && object.actionItem !== null)
      ? LocalizedMessage.fromPartial(object.actionItem)
      : undefined;
    message.helpLinks = object.helpLinks?.map((e) => Help_Link.fromPartial(e)) || [];
    message.warningTime = object.warningTime ?? undefined;
    return message;
  },
};

function createBaseAwsSourceVmDetails(): AwsSourceVmDetails {
  return { firmware: 0, committedStorageBytes: Long.ZERO, disks: [] };
}

export const AwsSourceVmDetails: MessageFns<AwsSourceVmDetails> = {
  encode(message: AwsSourceVmDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.firmware !== 0) {
      writer.uint32(8).int32(message.firmware);
    }
    if (!message.committedStorageBytes.equals(Long.ZERO)) {
      writer.uint32(16).int64(message.committedStorageBytes.toString());
    }
    for (const v of message.disks) {
      AwsSourceVmDetails_AwsDiskDetails.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceVmDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceVmDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.firmware = reader.int32() as any;
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.committedStorageBytes = Long.fromString(reader.int64().toString());
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.disks.push(AwsSourceVmDetails_AwsDiskDetails.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceVmDetails {
    return {
      firmware: isSet(object.firmware) ? awsSourceVmDetails_FirmwareFromJSON(object.firmware) : 0,
      committedStorageBytes: isSet(object.committedStorageBytes)
        ? Long.fromValue(object.committedStorageBytes)
        : Long.ZERO,
      disks: globalThis.Array.isArray(object?.disks)
        ? object.disks.map((e: any) => AwsSourceVmDetails_AwsDiskDetails.fromJSON(e))
        : [],
    };
  },

  toJSON(message: AwsSourceVmDetails): unknown {
    const obj: any = {};
    if (message.firmware !== 0) {
      obj.firmware = awsSourceVmDetails_FirmwareToJSON(message.firmware);
    }
    if (!message.committedStorageBytes.equals(Long.ZERO)) {
      obj.committedStorageBytes = (message.committedStorageBytes || Long.ZERO).toString();
    }
    if (message.disks?.length) {
      obj.disks = message.disks.map((e) => AwsSourceVmDetails_AwsDiskDetails.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceVmDetails>, I>>(base?: I): AwsSourceVmDetails {
    return AwsSourceVmDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceVmDetails>, I>>(object: I): AwsSourceVmDetails {
    const message = createBaseAwsSourceVmDetails();
    message.firmware = object.firmware ?? 0;
    message.committedStorageBytes =
      (object.committedStorageBytes !== undefined && object.committedStorageBytes !== null)
        ? Long.fromValue(object.committedStorageBytes)
        : Long.ZERO;
    message.disks = object.disks?.map((e) => AwsSourceVmDetails_AwsDiskDetails.fromPartial(e)) || [];
    return message;
  },
};

function createBaseAwsSourceVmDetails_AwsDiskDetails(): AwsSourceVmDetails_AwsDiskDetails {
  return { diskNumber: 0, volumeId: "", sizeGb: Long.ZERO };
}

export const AwsSourceVmDetails_AwsDiskDetails: MessageFns<AwsSourceVmDetails_AwsDiskDetails> = {
  encode(message: AwsSourceVmDetails_AwsDiskDetails, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.diskNumber !== 0) {
      writer.uint32(8).int32(message.diskNumber);
    }
    if (message.volumeId !== "") {
      writer.uint32(18).string(message.volumeId);
    }
    if (!message.sizeGb.equals(Long.ZERO)) {
      writer.uint32(24).int64(message.sizeGb.toString());
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): AwsSourceVmDetails_AwsDiskDetails {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseAwsSourceVmDetails_AwsDiskDetails();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.diskNumber = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.volumeId = reader.string();
          continue;
        }
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.sizeGb = Long.fromString(reader.int64().toString());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): AwsSourceVmDetails_AwsDiskDetails {
    return {
      diskNumber: isSet(object.diskNumber) ? globalThis.Number(object.diskNumber) : 0,
      volumeId: isSet(object.volumeId) ? globalThis.String(object.volumeId) : "",
      sizeGb: isSet(object.sizeGb) ? Long.fromValue(object.sizeGb) : Long.ZERO,
    };
  },

  toJSON(message: AwsSourceVmDetails_AwsDiskDetails): unknown {
    const obj: any = {};
    if (message.diskNumber !== 0) {
      obj.diskNumber = Math.round(message.diskNumber);
    }
    if (message.volumeId !== "") {
      obj.volumeId = message.volumeId;
    }
    if (!message.sizeGb.equals(Long.ZERO)) {
      obj.sizeGb = (message.sizeGb || Long.ZERO).toString();
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<AwsSourceVmDetails_AwsDiskDetails>, I>>(
    base?: I,
  ): AwsSourceVmDetails_AwsDiskDetails {
    return AwsSourceVmDetails_AwsDiskDetails.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<AwsSourceVmDetails_AwsDiskDetails>, I>>(
    object: I,
  ): AwsSourceVmDetails_AwsDiskDetails {
    const message = createBaseAwsSourceVmDetails_AwsDiskDetails();
    message.diskNumber = object.diskNumber ?? 0;
    message.volumeId = object.volumeId ?? "";
    message.sizeGb = (object.sizeGb !== undefined && object.sizeGb !== null)
      ? Long.fromValue(object.sizeGb)
      : Long.ZERO;
    return message;
  },
};

function createBaseUtilizationReportEventData(): UtilizationReportEventData {
  return { payload: undefined };
}

export const UtilizationReportEventData: MessageFns<UtilizationReportEventData> = {
  encode(message: UtilizationReportEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      UtilizationReport.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): UtilizationReportEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseUtilizationReportEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = UtilizationReport.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): UtilizationReportEventData {
    return { payload: isSet(object.payload) ? UtilizationReport.fromJSON(object.payload) : undefined };
  },

  toJSON(message: UtilizationReportEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = UtilizationReport.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<UtilizationReportEventData>, I>>(base?: I): UtilizationReportEventData {
    return UtilizationReportEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<UtilizationReportEventData>, I>>(object: I): UtilizationReportEventData {
    const message = createBaseUtilizationReportEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? UtilizationReport.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseGroupEventData(): GroupEventData {
  return { payload: undefined };
}

export const GroupEventData: MessageFns<GroupEventData> = {
  encode(message: GroupEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Group.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GroupEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGroupEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Group.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GroupEventData {
    return { payload: isSet(object.payload) ? Group.fromJSON(object.payload) : undefined };
  },

  toJSON(message: GroupEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Group.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GroupEventData>, I>>(base?: I): GroupEventData {
    return GroupEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GroupEventData>, I>>(object: I): GroupEventData {
    const message = createBaseGroupEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Group.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseCloneJobEventData(): CloneJobEventData {
  return { payload: undefined };
}

export const CloneJobEventData: MessageFns<CloneJobEventData> = {
  encode(message: CloneJobEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      CloneJob.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloneJobEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloneJobEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = CloneJob.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloneJobEventData {
    return { payload: isSet(object.payload) ? CloneJob.fromJSON(object.payload) : undefined };
  },

  toJSON(message: CloneJobEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = CloneJob.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloneJobEventData>, I>>(base?: I): CloneJobEventData {
    return CloneJobEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloneJobEventData>, I>>(object: I): CloneJobEventData {
    const message = createBaseCloneJobEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? CloneJob.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseDatacenterConnectorEventData(): DatacenterConnectorEventData {
  return { payload: undefined };
}

export const DatacenterConnectorEventData: MessageFns<DatacenterConnectorEventData> = {
  encode(message: DatacenterConnectorEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      DatacenterConnector.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): DatacenterConnectorEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatacenterConnectorEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = DatacenterConnector.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): DatacenterConnectorEventData {
    return { payload: isSet(object.payload) ? DatacenterConnector.fromJSON(object.payload) : undefined };
  },

  toJSON(message: DatacenterConnectorEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = DatacenterConnector.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<DatacenterConnectorEventData>, I>>(base?: I): DatacenterConnectorEventData {
    return DatacenterConnectorEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<DatacenterConnectorEventData>, I>>(object: I): DatacenterConnectorEventData {
    const message = createBaseDatacenterConnectorEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? DatacenterConnector.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseTargetProjectEventData(): TargetProjectEventData {
  return { payload: undefined };
}

export const TargetProjectEventData: MessageFns<TargetProjectEventData> = {
  encode(message: TargetProjectEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      TargetProject.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): TargetProjectEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseTargetProjectEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = TargetProject.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): TargetProjectEventData {
    return { payload: isSet(object.payload) ? TargetProject.fromJSON(object.payload) : undefined };
  },

  toJSON(message: TargetProjectEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = TargetProject.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<TargetProjectEventData>, I>>(base?: I): TargetProjectEventData {
    return TargetProjectEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<TargetProjectEventData>, I>>(object: I): TargetProjectEventData {
    const message = createBaseTargetProjectEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? TargetProject.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseCutoverJobEventData(): CutoverJobEventData {
  return { payload: undefined };
}

export const CutoverJobEventData: MessageFns<CutoverJobEventData> = {
  encode(message: CutoverJobEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      CutoverJob.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CutoverJobEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCutoverJobEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = CutoverJob.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CutoverJobEventData {
    return { payload: isSet(object.payload) ? CutoverJob.fromJSON(object.payload) : undefined };
  },

  toJSON(message: CutoverJobEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = CutoverJob.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CutoverJobEventData>, I>>(base?: I): CutoverJobEventData {
    return CutoverJobEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CutoverJobEventData>, I>>(object: I): CutoverJobEventData {
    const message = createBaseCutoverJobEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? CutoverJob.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseSourceEventData(): SourceEventData {
  return { payload: undefined };
}

export const SourceEventData: MessageFns<SourceEventData> = {
  encode(message: SourceEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Source.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Source.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceEventData {
    return { payload: isSet(object.payload) ? Source.fromJSON(object.payload) : undefined };
  },

  toJSON(message: SourceEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Source.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SourceEventData>, I>>(base?: I): SourceEventData {
    return SourceEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SourceEventData>, I>>(object: I): SourceEventData {
    const message = createBaseSourceEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Source.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseMigratingVmEventData(): MigratingVmEventData {
  return { payload: undefined };
}

export const MigratingVmEventData: MessageFns<MigratingVmEventData> = {
  encode(message: MigratingVmEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      MigratingVm.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MigratingVmEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMigratingVmEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = MigratingVm.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MigratingVmEventData {
    return { payload: isSet(object.payload) ? MigratingVm.fromJSON(object.payload) : undefined };
  },

  toJSON(message: MigratingVmEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = MigratingVm.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MigratingVmEventData>, I>>(base?: I): MigratingVmEventData {
    return MigratingVmEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MigratingVmEventData>, I>>(object: I): MigratingVmEventData {
    const message = createBaseMigratingVmEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? MigratingVm.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
