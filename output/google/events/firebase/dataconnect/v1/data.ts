// Code generated by protoc-gen-ts_proto. DO NOT EDIT.
// versions:
//   protoc-gen-ts_proto  v2.7.7
//   protoc               v6.32.0
// source: google/events/firebase/dataconnect/v1/data.proto

/* eslint-disable */
import { BinaryReader, BinaryWriter } from "@bufbuild/protobuf/wire";
import Long from "long";
import { ListValue, Struct } from "../../../../protobuf/struct";
import { Timestamp } from "../../../../protobuf/timestamp";
import { Code, codeFromJSON, codeToJSON } from "../../../../rpc/code";

export const protobufPackage = "google.events.firebase.dataconnect.v1";

/** Configure how much SQL Schema to perform for the given schema. */
export enum SqlSchemaValidation {
  /**
   * SQL_SCHEMA_VALIDATION_UNSPECIFIED - Unspecified SQL schema validation.
   * Default to STRICT.
   */
  SQL_SCHEMA_VALIDATION_UNSPECIFIED = 0,
  /**
   * NONE - Skip no SQL schema validation. Use it with extreme caution.
   * CreateSchema or UpdateSchema will succeed even if SQL database is
   * unavailable or SQL schema is incompatible.
   * Generated SQL may fail at execution time.
   */
  NONE = 1,
  /**
   * STRICT - Connect to the SQL database and validate that the SQL DDL matches the
   * schema exactly. Surface any discrepancies as `FAILED_PRECONDITION` with an
   * `IncompatibleSqlSchemaError` error detail.
   */
  STRICT = 2,
  /**
   * COMPATIBLE - Connect to the SQL database and validate that the SQL DDL has all the SQL
   * resources used in the given Firebase Data Connect Schema. Surface any
   * missing resources as `FAILED_PRECONDITION` with an
   * `IncompatibleSqlSchemaError` error detail. Succeed even if there are
   * unknown tables and columns.
   */
  COMPATIBLE = 3,
  UNRECOGNIZED = -1,
}

export function sqlSchemaValidationFromJSON(object: any): SqlSchemaValidation {
  switch (object) {
    case 0:
    case "SQL_SCHEMA_VALIDATION_UNSPECIFIED":
      return SqlSchemaValidation.SQL_SCHEMA_VALIDATION_UNSPECIFIED;
    case 1:
    case "NONE":
      return SqlSchemaValidation.NONE;
    case 2:
    case "STRICT":
      return SqlSchemaValidation.STRICT;
    case 3:
    case "COMPATIBLE":
      return SqlSchemaValidation.COMPATIBLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSchemaValidation.UNRECOGNIZED;
  }
}

export function sqlSchemaValidationToJSON(object: SqlSchemaValidation): string {
  switch (object) {
    case SqlSchemaValidation.SQL_SCHEMA_VALIDATION_UNSPECIFIED:
      return "SQL_SCHEMA_VALIDATION_UNSPECIFIED";
    case SqlSchemaValidation.NONE:
      return "NONE";
    case SqlSchemaValidation.STRICT:
      return "STRICT";
    case SqlSchemaValidation.COMPATIBLE:
      return "COMPATIBLE";
    case SqlSchemaValidation.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** Configure how to perform SQL Schema migration before deploying the Schema. */
export enum SqlSchemaMigration {
  /** SQL_SCHEMA_MIGRATION_UNSPECIFIED - Unspecified SQL schema migration. */
  SQL_SCHEMA_MIGRATION_UNSPECIFIED = 0,
  /**
   * MIGRATE_COMPATIBLE - Connect to the SQL database and identify any missing SQL resources used
   * in the given Firebase Data Connect Schema.
   * Automatically create necessary SQL resources (SQL table, column, etc)
   * before deploying the schema.
   * During migration steps, the SQL Schema must comply with the previous
   * before_deploy setting in case the migration is interrupted.
   * Therefore, the previous before_deploy setting must not be
   * `schema_validation=STRICT`.
   */
  MIGRATE_COMPATIBLE = 1,
  UNRECOGNIZED = -1,
}

export function sqlSchemaMigrationFromJSON(object: any): SqlSchemaMigration {
  switch (object) {
    case 0:
    case "SQL_SCHEMA_MIGRATION_UNSPECIFIED":
      return SqlSchemaMigration.SQL_SCHEMA_MIGRATION_UNSPECIFIED;
    case 1:
    case "MIGRATE_COMPATIBLE":
      return SqlSchemaMigration.MIGRATE_COMPATIBLE;
    case -1:
    case "UNRECOGNIZED":
    default:
      return SqlSchemaMigration.UNRECOGNIZED;
  }
}

export function sqlSchemaMigrationToJSON(object: SqlSchemaMigration): string {
  switch (object) {
    case SqlSchemaMigration.SQL_SCHEMA_MIGRATION_UNSPECIFIED:
      return "SQL_SCHEMA_MIGRATION_UNSPECIFIED";
    case SqlSchemaMigration.MIGRATE_COMPATIBLE:
      return "MIGRATE_COMPATIBLE";
    case SqlSchemaMigration.UNRECOGNIZED:
    default:
      return "UNRECOGNIZED";
  }
}

/** A Firebase Data Connect service. */
export interface Service {
  /**
   * Identifier. The relative resource name of the Firebase Data Connect
   * service, in the format:
   * ```
   * projects/{project}/locations/{location}/services/{service}
   * ```
   * Note that the service ID is specific to Firebase Data Connect and does not
   * correspond to any of the instance IDs of the underlying data source
   * connections.
   */
  name: string;
  /** Output only. [Output only] Create time stamp. */
  createTime?:
    | Date
    | undefined;
  /** Output only. [Output only] Update time stamp. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Labels as key value pairs. */
  labels: { [key: string]: string };
  /** Optional. Stores small amounts of arbitrary data. */
  annotations: { [key: string]: string };
  /** Output only. System-assigned, unique identifier. */
  uid: string;
  /**
   * Output only. A field that if true, indicates that the system is working
   * update the service.
   */
  reconciling: boolean;
  /** Optional. Mutable human-readable name. 63 character limit. */
  displayName: string;
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   * [AIP-154](https://google.aip.dev/154)
   */
  etag: string;
}

export interface Service_LabelsEntry {
  key: string;
  value: string;
}

export interface Service_AnnotationsEntry {
  key: string;
  value: string;
}

/** A data source that backs Firebase Data Connect services. */
export interface Datasource {
  /** PostgreSQL configurations. */
  postgresql?: PostgreSql | undefined;
}

/** Settings for PostgreSQL data source. */
export interface PostgreSql {
  /** Optional. Configure how much Postgresql schema validation to perform. */
  schemaValidation?:
    | SqlSchemaValidation
    | undefined;
  /** Optional. Configure how to perform Postgresql schema migration. */
  schemaMigration?:
    | SqlSchemaMigration
    | undefined;
  /**
   * No Postgres data source is linked.
   * If set, don't allow `database` and `schema_validation` to be configured.
   */
  unlinked?:
    | boolean
    | undefined;
  /** Cloud SQL configurations. */
  cloudSql?:
    | CloudSqlInstance
    | undefined;
  /** Required. Name of the PostgreSQL database. */
  database: string;
}

/** Settings for CloudSQL instance configuration. */
export interface CloudSqlInstance {
  /**
   * Required. Name of the CloudSQL instance, in the format:
   * ```
   * projects/{project}/locations/{location}/instances/{instance}
   * ```
   */
  instance: string;
}

/** The application schema of a Firebase Data Connect service. */
export interface Schema {
  /**
   * Identifier. The relative resource name of the schema, in the format:
   * ```
   * projects/{project}/locations/{location}/services/{service}/schemas/{schema}
   * ```
   * Right now, the only supported schema is "main".
   */
  name: string;
  /** Output only. [Output only] Create time stamp. */
  createTime?:
    | Date
    | undefined;
  /** Output only. [Output only] Update time stamp. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Labels as key value pairs. */
  labels: { [key: string]: string };
  /** Optional. Stores small amounts of arbitrary data. */
  annotations: { [key: string]: string };
  /** Required. The data sources linked in the schema. */
  datasources: Datasource[];
  /** Required. The source files that comprise the application schema. */
  source?:
    | Source
    | undefined;
  /** Output only. System-assigned, unique identifier. */
  uid: string;
  /**
   * Output only. A field that if true, indicates that the system is working to
   * compile and deploy the schema.
   */
  reconciling: boolean;
  /** Optional. Mutable human-readable name. 63 character limit. */
  displayName: string;
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   * [AIP-154](https://google.aip.dev/154)
   */
  etag: string;
}

export interface Schema_LabelsEntry {
  key: string;
  value: string;
}

export interface Schema_AnnotationsEntry {
  key: string;
  value: string;
}

/** Connector consists of a set of operations, i.e. queries and mutations. */
export interface Connector {
  /**
   * Identifier. The relative resource name of the connector, in the format:
   * ```
   * projects/{project}/locations/{location}/services/{service}/connectors/{connector}
   * ```
   */
  name: string;
  /** Output only. [Output only] Create time stamp. */
  createTime?:
    | Date
    | undefined;
  /** Output only. [Output only] Update time stamp. */
  updateTime?:
    | Date
    | undefined;
  /** Optional. Labels as key value pairs. */
  labels: { [key: string]: string };
  /** Optional. Stores small amounts of arbitrary data. */
  annotations: { [key: string]: string };
  /** Required. The source files that comprise the connector. */
  source?:
    | Source
    | undefined;
  /** Output only. System-assigned, unique identifier. */
  uid: string;
  /**
   * Output only. A field that if true, indicates that the system is working to
   * compile and deploy the connector.
   */
  reconciling: boolean;
  /** Optional. Mutable human-readable name. 63 character limit. */
  displayName: string;
  /**
   * Output only. This checksum is computed by the server based on the value of
   * other fields, and may be sent on update and delete requests to ensure the
   * client has an up-to-date value before proceeding.
   * [AIP-154](https://google.aip.dev/154)
   */
  etag: string;
}

export interface Connector_LabelsEntry {
  key: string;
  value: string;
}

export interface Connector_AnnotationsEntry {
  key: string;
  value: string;
}

/** Used to represent a set of source files. */
export interface Source {
  /** Required. The files that comprise the source set. */
  files: File[];
}

/** Individual files. */
export interface File {
  /**
   * Required. The file name including folder path, if applicable. The path
   * should be relative to a local workspace (e.g.
   * dataconnect/(schema|connector)/*.gql) and not an absolute path (e.g.
   * /absolute/path/(schema|connector)/*.gql).
   */
  path: string;
  /** Required. The file's textual content. */
  content: string;
}

/** The data within all Service events. */
export interface ServiceEventData {
  /** Optional. The Service event payload. Unset for deletion events. */
  payload?: Service | undefined;
}

/** The data within all Schema events. */
export interface SchemaEventData {
  /** Optional. The Schema event payload. Unset for deletion events. */
  payload?: Schema | undefined;
}

/** The data within all Connector events. */
export interface ConnectorEventData {
  /** Optional. The Connector event payload. Unset for deletion events. */
  payload?: Connector | undefined;
}

/** GraphqlError contains the error information of a GraphQL query or mutation. */
export interface GraphqlError {
  /**
   * The detailed error message.
   * The message should help developer understand the underlying problem without
   * leaking internal data.
   */
  message: string;
  /**
   * The source locations where the error occurred.
   * Locations should help developers and toolings identify the source of error
   * quickly.
   *
   * Included in admin endpoints (`ExecuteGraphql`, `ExecuteGraphqlRead`,
   * `UpdateSchema` and `UpdateConnector`) to reference the provided GraphQL
   * GQL document.
   *
   * Omitted in `ExecuteMutation` and `ExecuteQuery` since the caller shouldn't
   * have access access the underlying GQL source.
   */
  locations: SourceLocation[];
  /**
   * The result field which could not be populated due to error.
   *
   * Clients can use path to identify whether a null result is intentional or
   * caused by a runtime error.
   * It should be a list of string or index from the root of GraphQL query
   * document.
   */
  path?:
    | Array<any>
    | undefined;
  /** Additional error information. */
  extensions?: GraphqlErrorExtensions | undefined;
}

/** GraphqlErrorExtensions contains additional information of `GraphqlError`. */
export interface GraphqlErrorExtensions {
  /**
   * The source file name where the error occurred.
   * Included only for `UpdateSchema` and `UpdateConnector`, it corresponds
   * to `File.path` of the provided `Source`.
   */
  file: string;
  /**
   * Maps to canonical gRPC codes.
   * If not specified, it represents `Code.INTERNAL`.
   */
  code: Code;
  /**
   * More detailed error message to assist debugging.
   * It contains application business logic that are inappropriate to leak
   * publicly.
   *
   * In the emulator, Data Connect API always includes it to assist local
   * development and debugging.
   * In the backend, ConnectorService always hides it.
   * GraphqlService without impersonation always include it.
   * GraphqlService with impersonation includes it only if explicitly opted-in
   * with `include_debug_details` in `GraphqlRequestExtensions`.
   */
  debugDetails: string;
}

/** SourceLocation references a location in a GraphQL source. */
export interface SourceLocation {
  /** Line number starting at 1. */
  line: number;
  /** Column number starting at 1. */
  column: number;
}

export interface Mutation {
  /**
   * The result of the execution of the requested operation.
   * If an error was raised before execution begins, the data entry should not
   * be present in the result. (a request error:
   * https://spec.graphql.org/draft/#sec-Errors.Request-Errors) If an error was
   * raised during the execution that prevented a valid response, the data entry
   * in the response should be null. (a field error:
   * https://spec.graphql.org/draft/#sec-Errors.Error-Result-Format)
   */
  data?:
    | { [key: string]: any }
    | undefined;
  /** Values for GraphQL variables provided in this request. */
  variables?:
    | { [key: string]: any }
    | undefined;
  /**
   * Errors of this response.
   * If the data entry in the response is not present, the errors entry must be
   * present.
   * It conforms to https://spec.graphql.org/draft/#sec-Errors.
   */
  errors: GraphqlError[];
}

/** The data within all Mutation events. */
export interface MutationEventData {
  payload?: Mutation | undefined;
}

function createBaseService(): Service {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    annotations: {},
    uid: "",
    reconciling: false,
    displayName: "",
    etag: "",
  };
}

export const Service: MessageFns<Service> = {
  encode(message: Service, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Service_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.annotations).forEach(([key, value]) => {
      Service_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.uid !== "") {
      writer.uint32(50).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(56).bool(message.reconciling);
    }
    if (message.displayName !== "") {
      writer.uint32(66).string(message.displayName);
    }
    if (message.etag !== "") {
      writer.uint32(794).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Service_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Service_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.annotations[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 7: {
          if (tag !== 56) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 99: {
          if (tag !== 794) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: Service): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Service>, I>>(base?: I): Service {
    return Service.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Service>, I>>(object: I): Service {
    const message = createBaseService();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.displayName = object.displayName ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseService_LabelsEntry(): Service_LabelsEntry {
  return { key: "", value: "" };
}

export const Service_LabelsEntry: MessageFns<Service_LabelsEntry> = {
  encode(message: Service_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Service_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Service_LabelsEntry>, I>>(base?: I): Service_LabelsEntry {
    return Service_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Service_LabelsEntry>, I>>(object: I): Service_LabelsEntry {
    const message = createBaseService_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseService_AnnotationsEntry(): Service_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Service_AnnotationsEntry: MessageFns<Service_AnnotationsEntry> = {
  encode(message: Service_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Service_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseService_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Service_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Service_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Service_AnnotationsEntry>, I>>(base?: I): Service_AnnotationsEntry {
    return Service_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Service_AnnotationsEntry>, I>>(object: I): Service_AnnotationsEntry {
    const message = createBaseService_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseDatasource(): Datasource {
  return { postgresql: undefined };
}

export const Datasource: MessageFns<Datasource> = {
  encode(message: Datasource, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.postgresql !== undefined) {
      PostgreSql.encode(message.postgresql, writer.uint32(18).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Datasource {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseDatasource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.postgresql = PostgreSql.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Datasource {
    return { postgresql: isSet(object.postgresql) ? PostgreSql.fromJSON(object.postgresql) : undefined };
  },

  toJSON(message: Datasource): unknown {
    const obj: any = {};
    if (message.postgresql !== undefined) {
      obj.postgresql = PostgreSql.toJSON(message.postgresql);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Datasource>, I>>(base?: I): Datasource {
    return Datasource.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Datasource>, I>>(object: I): Datasource {
    const message = createBaseDatasource();
    message.postgresql = (object.postgresql !== undefined && object.postgresql !== null)
      ? PostgreSql.fromPartial(object.postgresql)
      : undefined;
    return message;
  },
};

function createBasePostgreSql(): PostgreSql {
  return {
    schemaValidation: undefined,
    schemaMigration: undefined,
    unlinked: undefined,
    cloudSql: undefined,
    database: "",
  };
}

export const PostgreSql: MessageFns<PostgreSql> = {
  encode(message: PostgreSql, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.schemaValidation !== undefined) {
      writer.uint32(24).int32(message.schemaValidation);
    }
    if (message.schemaMigration !== undefined) {
      writer.uint32(40).int32(message.schemaMigration);
    }
    if (message.unlinked !== undefined) {
      writer.uint32(32).bool(message.unlinked);
    }
    if (message.cloudSql !== undefined) {
      CloudSqlInstance.encode(message.cloudSql, writer.uint32(18).fork()).join();
    }
    if (message.database !== "") {
      writer.uint32(10).string(message.database);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): PostgreSql {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBasePostgreSql();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 3: {
          if (tag !== 24) {
            break;
          }

          message.schemaValidation = reader.int32() as any;
          continue;
        }
        case 5: {
          if (tag !== 40) {
            break;
          }

          message.schemaMigration = reader.int32() as any;
          continue;
        }
        case 4: {
          if (tag !== 32) {
            break;
          }

          message.unlinked = reader.bool();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.cloudSql = CloudSqlInstance.decode(reader, reader.uint32());
          continue;
        }
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.database = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): PostgreSql {
    return {
      schemaValidation: isSet(object.schemaValidation)
        ? sqlSchemaValidationFromJSON(object.schemaValidation)
        : undefined,
      schemaMigration: isSet(object.schemaMigration) ? sqlSchemaMigrationFromJSON(object.schemaMigration) : undefined,
      unlinked: isSet(object.unlinked) ? globalThis.Boolean(object.unlinked) : undefined,
      cloudSql: isSet(object.cloudSql) ? CloudSqlInstance.fromJSON(object.cloudSql) : undefined,
      database: isSet(object.database) ? globalThis.String(object.database) : "",
    };
  },

  toJSON(message: PostgreSql): unknown {
    const obj: any = {};
    if (message.schemaValidation !== undefined) {
      obj.schemaValidation = sqlSchemaValidationToJSON(message.schemaValidation);
    }
    if (message.schemaMigration !== undefined) {
      obj.schemaMigration = sqlSchemaMigrationToJSON(message.schemaMigration);
    }
    if (message.unlinked !== undefined) {
      obj.unlinked = message.unlinked;
    }
    if (message.cloudSql !== undefined) {
      obj.cloudSql = CloudSqlInstance.toJSON(message.cloudSql);
    }
    if (message.database !== "") {
      obj.database = message.database;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<PostgreSql>, I>>(base?: I): PostgreSql {
    return PostgreSql.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<PostgreSql>, I>>(object: I): PostgreSql {
    const message = createBasePostgreSql();
    message.schemaValidation = object.schemaValidation ?? undefined;
    message.schemaMigration = object.schemaMigration ?? undefined;
    message.unlinked = object.unlinked ?? undefined;
    message.cloudSql = (object.cloudSql !== undefined && object.cloudSql !== null)
      ? CloudSqlInstance.fromPartial(object.cloudSql)
      : undefined;
    message.database = object.database ?? "";
    return message;
  },
};

function createBaseCloudSqlInstance(): CloudSqlInstance {
  return { instance: "" };
}

export const CloudSqlInstance: MessageFns<CloudSqlInstance> = {
  encode(message: CloudSqlInstance, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.instance !== "") {
      writer.uint32(10).string(message.instance);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): CloudSqlInstance {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseCloudSqlInstance();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.instance = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): CloudSqlInstance {
    return { instance: isSet(object.instance) ? globalThis.String(object.instance) : "" };
  },

  toJSON(message: CloudSqlInstance): unknown {
    const obj: any = {};
    if (message.instance !== "") {
      obj.instance = message.instance;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<CloudSqlInstance>, I>>(base?: I): CloudSqlInstance {
    return CloudSqlInstance.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<CloudSqlInstance>, I>>(object: I): CloudSqlInstance {
    const message = createBaseCloudSqlInstance();
    message.instance = object.instance ?? "";
    return message;
  },
};

function createBaseSchema(): Schema {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    annotations: {},
    datasources: [],
    source: undefined,
    uid: "",
    reconciling: false,
    displayName: "",
    etag: "",
  };
}

export const Schema: MessageFns<Schema> = {
  encode(message: Schema, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Schema_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.annotations).forEach(([key, value]) => {
      Schema_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    for (const v of message.datasources) {
      Datasource.encode(v!, writer.uint32(90).fork()).join();
    }
    if (message.source !== undefined) {
      Source.encode(message.source, writer.uint32(58).fork()).join();
    }
    if (message.uid !== "") {
      writer.uint32(66).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(72).bool(message.reconciling);
    }
    if (message.displayName !== "") {
      writer.uint32(82).string(message.displayName);
    }
    if (message.etag !== "") {
      writer.uint32(794).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Schema_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Schema_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.annotations[entry5.key] = entry5.value;
          }
          continue;
        }
        case 11: {
          if (tag !== 90) {
            break;
          }

          message.datasources.push(Datasource.decode(reader, reader.uint32()));
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.source = Source.decode(reader, reader.uint32());
          continue;
        }
        case 8: {
          if (tag !== 66) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 9: {
          if (tag !== 72) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        }
        case 10: {
          if (tag !== 82) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 99: {
          if (tag !== 794) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      datasources: globalThis.Array.isArray(object?.datasources)
        ? object.datasources.map((e: any) => Datasource.fromJSON(e))
        : [],
      source: isSet(object.source) ? Source.fromJSON(object.source) : undefined,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: Schema): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.datasources?.length) {
      obj.datasources = message.datasources.map((e) => Datasource.toJSON(e));
    }
    if (message.source !== undefined) {
      obj.source = Source.toJSON(message.source);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Schema>, I>>(base?: I): Schema {
    return Schema.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Schema>, I>>(object: I): Schema {
    const message = createBaseSchema();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.datasources = object.datasources?.map((e) => Datasource.fromPartial(e)) || [];
    message.source = (object.source !== undefined && object.source !== null)
      ? Source.fromPartial(object.source)
      : undefined;
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.displayName = object.displayName ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseSchema_LabelsEntry(): Schema_LabelsEntry {
  return { key: "", value: "" };
}

export const Schema_LabelsEntry: MessageFns<Schema_LabelsEntry> = {
  encode(message: Schema_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Schema_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Schema_LabelsEntry>, I>>(base?: I): Schema_LabelsEntry {
    return Schema_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Schema_LabelsEntry>, I>>(object: I): Schema_LabelsEntry {
    const message = createBaseSchema_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSchema_AnnotationsEntry(): Schema_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Schema_AnnotationsEntry: MessageFns<Schema_AnnotationsEntry> = {
  encode(message: Schema_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Schema_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchema_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Schema_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Schema_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Schema_AnnotationsEntry>, I>>(base?: I): Schema_AnnotationsEntry {
    return Schema_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Schema_AnnotationsEntry>, I>>(object: I): Schema_AnnotationsEntry {
    const message = createBaseSchema_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseConnector(): Connector {
  return {
    name: "",
    createTime: undefined,
    updateTime: undefined,
    labels: {},
    annotations: {},
    source: undefined,
    uid: "",
    reconciling: false,
    displayName: "",
    etag: "",
  };
}

export const Connector: MessageFns<Connector> = {
  encode(message: Connector, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.name !== "") {
      writer.uint32(10).string(message.name);
    }
    if (message.createTime !== undefined) {
      Timestamp.encode(toTimestamp(message.createTime), writer.uint32(18).fork()).join();
    }
    if (message.updateTime !== undefined) {
      Timestamp.encode(toTimestamp(message.updateTime), writer.uint32(26).fork()).join();
    }
    Object.entries(message.labels).forEach(([key, value]) => {
      Connector_LabelsEntry.encode({ key: key as any, value }, writer.uint32(34).fork()).join();
    });
    Object.entries(message.annotations).forEach(([key, value]) => {
      Connector_AnnotationsEntry.encode({ key: key as any, value }, writer.uint32(42).fork()).join();
    });
    if (message.source !== undefined) {
      Source.encode(message.source, writer.uint32(50).fork()).join();
    }
    if (message.uid !== "") {
      writer.uint32(58).string(message.uid);
    }
    if (message.reconciling !== false) {
      writer.uint32(64).bool(message.reconciling);
    }
    if (message.displayName !== "") {
      writer.uint32(74).string(message.displayName);
    }
    if (message.etag !== "") {
      writer.uint32(794).string(message.etag);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Connector {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnector();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.name = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.createTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.updateTime = fromTimestamp(Timestamp.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          const entry4 = Connector_LabelsEntry.decode(reader, reader.uint32());
          if (entry4.value !== undefined) {
            message.labels[entry4.key] = entry4.value;
          }
          continue;
        }
        case 5: {
          if (tag !== 42) {
            break;
          }

          const entry5 = Connector_AnnotationsEntry.decode(reader, reader.uint32());
          if (entry5.value !== undefined) {
            message.annotations[entry5.key] = entry5.value;
          }
          continue;
        }
        case 6: {
          if (tag !== 50) {
            break;
          }

          message.source = Source.decode(reader, reader.uint32());
          continue;
        }
        case 7: {
          if (tag !== 58) {
            break;
          }

          message.uid = reader.string();
          continue;
        }
        case 8: {
          if (tag !== 64) {
            break;
          }

          message.reconciling = reader.bool();
          continue;
        }
        case 9: {
          if (tag !== 74) {
            break;
          }

          message.displayName = reader.string();
          continue;
        }
        case 99: {
          if (tag !== 794) {
            break;
          }

          message.etag = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Connector {
    return {
      name: isSet(object.name) ? globalThis.String(object.name) : "",
      createTime: isSet(object.createTime) ? fromJsonTimestamp(object.createTime) : undefined,
      updateTime: isSet(object.updateTime) ? fromJsonTimestamp(object.updateTime) : undefined,
      labels: isObject(object.labels)
        ? Object.entries(object.labels).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      annotations: isObject(object.annotations)
        ? Object.entries(object.annotations).reduce<{ [key: string]: string }>((acc, [key, value]) => {
          acc[key] = String(value);
          return acc;
        }, {})
        : {},
      source: isSet(object.source) ? Source.fromJSON(object.source) : undefined,
      uid: isSet(object.uid) ? globalThis.String(object.uid) : "",
      reconciling: isSet(object.reconciling) ? globalThis.Boolean(object.reconciling) : false,
      displayName: isSet(object.displayName) ? globalThis.String(object.displayName) : "",
      etag: isSet(object.etag) ? globalThis.String(object.etag) : "",
    };
  },

  toJSON(message: Connector): unknown {
    const obj: any = {};
    if (message.name !== "") {
      obj.name = message.name;
    }
    if (message.createTime !== undefined) {
      obj.createTime = message.createTime.toISOString();
    }
    if (message.updateTime !== undefined) {
      obj.updateTime = message.updateTime.toISOString();
    }
    if (message.labels) {
      const entries = Object.entries(message.labels);
      if (entries.length > 0) {
        obj.labels = {};
        entries.forEach(([k, v]) => {
          obj.labels[k] = v;
        });
      }
    }
    if (message.annotations) {
      const entries = Object.entries(message.annotations);
      if (entries.length > 0) {
        obj.annotations = {};
        entries.forEach(([k, v]) => {
          obj.annotations[k] = v;
        });
      }
    }
    if (message.source !== undefined) {
      obj.source = Source.toJSON(message.source);
    }
    if (message.uid !== "") {
      obj.uid = message.uid;
    }
    if (message.reconciling !== false) {
      obj.reconciling = message.reconciling;
    }
    if (message.displayName !== "") {
      obj.displayName = message.displayName;
    }
    if (message.etag !== "") {
      obj.etag = message.etag;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Connector>, I>>(base?: I): Connector {
    return Connector.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Connector>, I>>(object: I): Connector {
    const message = createBaseConnector();
    message.name = object.name ?? "";
    message.createTime = object.createTime ?? undefined;
    message.updateTime = object.updateTime ?? undefined;
    message.labels = Object.entries(object.labels ?? {}).reduce<{ [key: string]: string }>((acc, [key, value]) => {
      if (value !== undefined) {
        acc[key] = globalThis.String(value);
      }
      return acc;
    }, {});
    message.annotations = Object.entries(object.annotations ?? {}).reduce<{ [key: string]: string }>(
      (acc, [key, value]) => {
        if (value !== undefined) {
          acc[key] = globalThis.String(value);
        }
        return acc;
      },
      {},
    );
    message.source = (object.source !== undefined && object.source !== null)
      ? Source.fromPartial(object.source)
      : undefined;
    message.uid = object.uid ?? "";
    message.reconciling = object.reconciling ?? false;
    message.displayName = object.displayName ?? "";
    message.etag = object.etag ?? "";
    return message;
  },
};

function createBaseConnector_LabelsEntry(): Connector_LabelsEntry {
  return { key: "", value: "" };
}

export const Connector_LabelsEntry: MessageFns<Connector_LabelsEntry> = {
  encode(message: Connector_LabelsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Connector_LabelsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnector_LabelsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Connector_LabelsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Connector_LabelsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Connector_LabelsEntry>, I>>(base?: I): Connector_LabelsEntry {
    return Connector_LabelsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Connector_LabelsEntry>, I>>(object: I): Connector_LabelsEntry {
    const message = createBaseConnector_LabelsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseConnector_AnnotationsEntry(): Connector_AnnotationsEntry {
  return { key: "", value: "" };
}

export const Connector_AnnotationsEntry: MessageFns<Connector_AnnotationsEntry> = {
  encode(message: Connector_AnnotationsEntry, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.key !== "") {
      writer.uint32(10).string(message.key);
    }
    if (message.value !== "") {
      writer.uint32(18).string(message.value);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Connector_AnnotationsEntry {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnector_AnnotationsEntry();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.key = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.value = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Connector_AnnotationsEntry {
    return {
      key: isSet(object.key) ? globalThis.String(object.key) : "",
      value: isSet(object.value) ? globalThis.String(object.value) : "",
    };
  },

  toJSON(message: Connector_AnnotationsEntry): unknown {
    const obj: any = {};
    if (message.key !== "") {
      obj.key = message.key;
    }
    if (message.value !== "") {
      obj.value = message.value;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Connector_AnnotationsEntry>, I>>(base?: I): Connector_AnnotationsEntry {
    return Connector_AnnotationsEntry.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Connector_AnnotationsEntry>, I>>(object: I): Connector_AnnotationsEntry {
    const message = createBaseConnector_AnnotationsEntry();
    message.key = object.key ?? "";
    message.value = object.value ?? "";
    return message;
  },
};

function createBaseSource(): Source {
  return { files: [] };
}

export const Source: MessageFns<Source> = {
  encode(message: Source, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    for (const v of message.files) {
      File.encode(v!, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Source {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSource();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.files.push(File.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Source {
    return { files: globalThis.Array.isArray(object?.files) ? object.files.map((e: any) => File.fromJSON(e)) : [] };
  },

  toJSON(message: Source): unknown {
    const obj: any = {};
    if (message.files?.length) {
      obj.files = message.files.map((e) => File.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Source>, I>>(base?: I): Source {
    return Source.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Source>, I>>(object: I): Source {
    const message = createBaseSource();
    message.files = object.files?.map((e) => File.fromPartial(e)) || [];
    return message;
  },
};

function createBaseFile(): File {
  return { path: "", content: "" };
}

export const File: MessageFns<File> = {
  encode(message: File, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.path !== "") {
      writer.uint32(10).string(message.path);
    }
    if (message.content !== "") {
      writer.uint32(18).string(message.content);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): File {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseFile();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.path = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.content = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): File {
    return {
      path: isSet(object.path) ? globalThis.String(object.path) : "",
      content: isSet(object.content) ? globalThis.String(object.content) : "",
    };
  },

  toJSON(message: File): unknown {
    const obj: any = {};
    if (message.path !== "") {
      obj.path = message.path;
    }
    if (message.content !== "") {
      obj.content = message.content;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<File>, I>>(base?: I): File {
    return File.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<File>, I>>(object: I): File {
    const message = createBaseFile();
    message.path = object.path ?? "";
    message.content = object.content ?? "";
    return message;
  },
};

function createBaseServiceEventData(): ServiceEventData {
  return { payload: undefined };
}

export const ServiceEventData: MessageFns<ServiceEventData> = {
  encode(message: ServiceEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Service.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ServiceEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseServiceEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Service.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ServiceEventData {
    return { payload: isSet(object.payload) ? Service.fromJSON(object.payload) : undefined };
  },

  toJSON(message: ServiceEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Service.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ServiceEventData>, I>>(base?: I): ServiceEventData {
    return ServiceEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ServiceEventData>, I>>(object: I): ServiceEventData {
    const message = createBaseServiceEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Service.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseSchemaEventData(): SchemaEventData {
  return { payload: undefined };
}

export const SchemaEventData: MessageFns<SchemaEventData> = {
  encode(message: SchemaEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Schema.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SchemaEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSchemaEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Schema.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SchemaEventData {
    return { payload: isSet(object.payload) ? Schema.fromJSON(object.payload) : undefined };
  },

  toJSON(message: SchemaEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Schema.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SchemaEventData>, I>>(base?: I): SchemaEventData {
    return SchemaEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SchemaEventData>, I>>(object: I): SchemaEventData {
    const message = createBaseSchemaEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Schema.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseConnectorEventData(): ConnectorEventData {
  return { payload: undefined };
}

export const ConnectorEventData: MessageFns<ConnectorEventData> = {
  encode(message: ConnectorEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Connector.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): ConnectorEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseConnectorEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Connector.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): ConnectorEventData {
    return { payload: isSet(object.payload) ? Connector.fromJSON(object.payload) : undefined };
  },

  toJSON(message: ConnectorEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Connector.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<ConnectorEventData>, I>>(base?: I): ConnectorEventData {
    return ConnectorEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<ConnectorEventData>, I>>(object: I): ConnectorEventData {
    const message = createBaseConnectorEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Connector.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

function createBaseGraphqlError(): GraphqlError {
  return { message: "", locations: [], path: undefined, extensions: undefined };
}

export const GraphqlError: MessageFns<GraphqlError> = {
  encode(message: GraphqlError, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.message !== "") {
      writer.uint32(10).string(message.message);
    }
    for (const v of message.locations) {
      SourceLocation.encode(v!, writer.uint32(18).fork()).join();
    }
    if (message.path !== undefined) {
      ListValue.encode(ListValue.wrap(message.path), writer.uint32(26).fork()).join();
    }
    if (message.extensions !== undefined) {
      GraphqlErrorExtensions.encode(message.extensions, writer.uint32(34).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GraphqlError {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGraphqlError();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.message = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.locations.push(SourceLocation.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.path = ListValue.unwrap(ListValue.decode(reader, reader.uint32()));
          continue;
        }
        case 4: {
          if (tag !== 34) {
            break;
          }

          message.extensions = GraphqlErrorExtensions.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GraphqlError {
    return {
      message: isSet(object.message) ? globalThis.String(object.message) : "",
      locations: globalThis.Array.isArray(object?.locations)
        ? object.locations.map((e: any) => SourceLocation.fromJSON(e))
        : [],
      path: globalThis.Array.isArray(object.path) ? [...object.path] : undefined,
      extensions: isSet(object.extensions) ? GraphqlErrorExtensions.fromJSON(object.extensions) : undefined,
    };
  },

  toJSON(message: GraphqlError): unknown {
    const obj: any = {};
    if (message.message !== "") {
      obj.message = message.message;
    }
    if (message.locations?.length) {
      obj.locations = message.locations.map((e) => SourceLocation.toJSON(e));
    }
    if (message.path !== undefined) {
      obj.path = message.path;
    }
    if (message.extensions !== undefined) {
      obj.extensions = GraphqlErrorExtensions.toJSON(message.extensions);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GraphqlError>, I>>(base?: I): GraphqlError {
    return GraphqlError.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GraphqlError>, I>>(object: I): GraphqlError {
    const message = createBaseGraphqlError();
    message.message = object.message ?? "";
    message.locations = object.locations?.map((e) => SourceLocation.fromPartial(e)) || [];
    message.path = object.path ?? undefined;
    message.extensions = (object.extensions !== undefined && object.extensions !== null)
      ? GraphqlErrorExtensions.fromPartial(object.extensions)
      : undefined;
    return message;
  },
};

function createBaseGraphqlErrorExtensions(): GraphqlErrorExtensions {
  return { file: "", code: 0, debugDetails: "" };
}

export const GraphqlErrorExtensions: MessageFns<GraphqlErrorExtensions> = {
  encode(message: GraphqlErrorExtensions, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.file !== "") {
      writer.uint32(10).string(message.file);
    }
    if (message.code !== 0) {
      writer.uint32(16).int32(message.code);
    }
    if (message.debugDetails !== "") {
      writer.uint32(26).string(message.debugDetails);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): GraphqlErrorExtensions {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseGraphqlErrorExtensions();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.file = reader.string();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.code = reader.int32() as any;
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.debugDetails = reader.string();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): GraphqlErrorExtensions {
    return {
      file: isSet(object.file) ? globalThis.String(object.file) : "",
      code: isSet(object.code) ? codeFromJSON(object.code) : 0,
      debugDetails: isSet(object.debugDetails) ? globalThis.String(object.debugDetails) : "",
    };
  },

  toJSON(message: GraphqlErrorExtensions): unknown {
    const obj: any = {};
    if (message.file !== "") {
      obj.file = message.file;
    }
    if (message.code !== 0) {
      obj.code = codeToJSON(message.code);
    }
    if (message.debugDetails !== "") {
      obj.debugDetails = message.debugDetails;
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<GraphqlErrorExtensions>, I>>(base?: I): GraphqlErrorExtensions {
    return GraphqlErrorExtensions.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<GraphqlErrorExtensions>, I>>(object: I): GraphqlErrorExtensions {
    const message = createBaseGraphqlErrorExtensions();
    message.file = object.file ?? "";
    message.code = object.code ?? 0;
    message.debugDetails = object.debugDetails ?? "";
    return message;
  },
};

function createBaseSourceLocation(): SourceLocation {
  return { line: 0, column: 0 };
}

export const SourceLocation: MessageFns<SourceLocation> = {
  encode(message: SourceLocation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.line !== 0) {
      writer.uint32(8).int32(message.line);
    }
    if (message.column !== 0) {
      writer.uint32(16).int32(message.column);
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): SourceLocation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseSourceLocation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 8) {
            break;
          }

          message.line = reader.int32();
          continue;
        }
        case 2: {
          if (tag !== 16) {
            break;
          }

          message.column = reader.int32();
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): SourceLocation {
    return {
      line: isSet(object.line) ? globalThis.Number(object.line) : 0,
      column: isSet(object.column) ? globalThis.Number(object.column) : 0,
    };
  },

  toJSON(message: SourceLocation): unknown {
    const obj: any = {};
    if (message.line !== 0) {
      obj.line = Math.round(message.line);
    }
    if (message.column !== 0) {
      obj.column = Math.round(message.column);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<SourceLocation>, I>>(base?: I): SourceLocation {
    return SourceLocation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<SourceLocation>, I>>(object: I): SourceLocation {
    const message = createBaseSourceLocation();
    message.line = object.line ?? 0;
    message.column = object.column ?? 0;
    return message;
  },
};

function createBaseMutation(): Mutation {
  return { data: undefined, variables: undefined, errors: [] };
}

export const Mutation: MessageFns<Mutation> = {
  encode(message: Mutation, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.data !== undefined) {
      Struct.encode(Struct.wrap(message.data), writer.uint32(10).fork()).join();
    }
    if (message.variables !== undefined) {
      Struct.encode(Struct.wrap(message.variables), writer.uint32(18).fork()).join();
    }
    for (const v of message.errors) {
      GraphqlError.encode(v!, writer.uint32(26).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): Mutation {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutation();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.data = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
        case 2: {
          if (tag !== 18) {
            break;
          }

          message.variables = Struct.unwrap(Struct.decode(reader, reader.uint32()));
          continue;
        }
        case 3: {
          if (tag !== 26) {
            break;
          }

          message.errors.push(GraphqlError.decode(reader, reader.uint32()));
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): Mutation {
    return {
      data: isObject(object.data) ? object.data : undefined,
      variables: isObject(object.variables) ? object.variables : undefined,
      errors: globalThis.Array.isArray(object?.errors) ? object.errors.map((e: any) => GraphqlError.fromJSON(e)) : [],
    };
  },

  toJSON(message: Mutation): unknown {
    const obj: any = {};
    if (message.data !== undefined) {
      obj.data = message.data;
    }
    if (message.variables !== undefined) {
      obj.variables = message.variables;
    }
    if (message.errors?.length) {
      obj.errors = message.errors.map((e) => GraphqlError.toJSON(e));
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<Mutation>, I>>(base?: I): Mutation {
    return Mutation.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<Mutation>, I>>(object: I): Mutation {
    const message = createBaseMutation();
    message.data = object.data ?? undefined;
    message.variables = object.variables ?? undefined;
    message.errors = object.errors?.map((e) => GraphqlError.fromPartial(e)) || [];
    return message;
  },
};

function createBaseMutationEventData(): MutationEventData {
  return { payload: undefined };
}

export const MutationEventData: MessageFns<MutationEventData> = {
  encode(message: MutationEventData, writer: BinaryWriter = new BinaryWriter()): BinaryWriter {
    if (message.payload !== undefined) {
      Mutation.encode(message.payload, writer.uint32(10).fork()).join();
    }
    return writer;
  },

  decode(input: BinaryReader | Uint8Array, length?: number): MutationEventData {
    const reader = input instanceof BinaryReader ? input : new BinaryReader(input);
    const end = length === undefined ? reader.len : reader.pos + length;
    const message = createBaseMutationEventData();
    while (reader.pos < end) {
      const tag = reader.uint32();
      switch (tag >>> 3) {
        case 1: {
          if (tag !== 10) {
            break;
          }

          message.payload = Mutation.decode(reader, reader.uint32());
          continue;
        }
      }
      if ((tag & 7) === 4 || tag === 0) {
        break;
      }
      reader.skip(tag & 7);
    }
    return message;
  },

  fromJSON(object: any): MutationEventData {
    return { payload: isSet(object.payload) ? Mutation.fromJSON(object.payload) : undefined };
  },

  toJSON(message: MutationEventData): unknown {
    const obj: any = {};
    if (message.payload !== undefined) {
      obj.payload = Mutation.toJSON(message.payload);
    }
    return obj;
  },

  create<I extends Exact<DeepPartial<MutationEventData>, I>>(base?: I): MutationEventData {
    return MutationEventData.fromPartial(base ?? ({} as any));
  },
  fromPartial<I extends Exact<DeepPartial<MutationEventData>, I>>(object: I): MutationEventData {
    const message = createBaseMutationEventData();
    message.payload = (object.payload !== undefined && object.payload !== null)
      ? Mutation.fromPartial(object.payload)
      : undefined;
    return message;
  },
};

type Builtin = Date | Function | Uint8Array | string | number | boolean | undefined;

export type DeepPartial<T> = T extends Builtin ? T
  : T extends Long ? string | number | Long : T extends globalThis.Array<infer U> ? globalThis.Array<DeepPartial<U>>
  : T extends ReadonlyArray<infer U> ? ReadonlyArray<DeepPartial<U>>
  : T extends {} ? { [K in keyof T]?: DeepPartial<T[K]> }
  : Partial<T>;

type KeysOfUnion<T> = T extends T ? keyof T : never;
export type Exact<P, I extends P> = P extends Builtin ? P
  : P & { [K in keyof P]: Exact<P[K], I[K]> } & { [K in Exclude<keyof I, KeysOfUnion<P>>]: never };

function toTimestamp(date: Date): Timestamp {
  const seconds = numberToLong(Math.trunc(date.getTime() / 1_000));
  const nanos = (date.getTime() % 1_000) * 1_000_000;
  return { seconds, nanos };
}

function fromTimestamp(t: Timestamp): Date {
  let millis = (t.seconds.toNumber() || 0) * 1_000;
  millis += (t.nanos || 0) / 1_000_000;
  return new globalThis.Date(millis);
}

function fromJsonTimestamp(o: any): Date {
  if (o instanceof globalThis.Date) {
    return o;
  } else if (typeof o === "string") {
    return new globalThis.Date(o);
  } else {
    return fromTimestamp(Timestamp.fromJSON(o));
  }
}

function numberToLong(number: number) {
  return Long.fromNumber(number);
}

function isObject(value: any): boolean {
  return typeof value === "object" && value !== null;
}

function isSet(value: any): boolean {
  return value !== null && value !== undefined;
}

export interface MessageFns<T> {
  encode(message: T, writer?: BinaryWriter): BinaryWriter;
  decode(input: BinaryReader | Uint8Array, length?: number): T;
  fromJSON(object: any): T;
  toJSON(message: T): unknown;
  create<I extends Exact<DeepPartial<T>, I>>(base?: I): T;
  fromPartial<I extends Exact<DeepPartial<T>, I>>(object: I): T;
}
